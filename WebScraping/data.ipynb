{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ad266da",
   "metadata": {},
   "source": [
    "## data gathering/ google scholar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3141ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scholarly import scholarly\n",
    "import pandas as pd\n",
    "\n",
    "file_path = 'name.csv'\n",
    "df_authors = pd.read_csv(file_path)\n",
    "\n",
    "# Reformat the names from the CSV file to \"FirstName LastName\"\n",
    "def reformat_name(name):\n",
    "    split_name = name.split(',')\n",
    "    if len(split_name) == 2:\n",
    "        last_name, first_name = split_name[0].strip(), split_name[1].strip()\n",
    "        return f\"{first_name} {last_name}\"\n",
    "    return name\n",
    "\n",
    "# Reformat names\n",
    "df_authors['Formatted Names'] = df_authors.iloc[:, 0].apply(reformat_name)\n",
    "\n",
    "# List of authors\n",
    "authors_all = df_authors['Formatted Names'].tolist()\n",
    "\n",
    "# Function to divide list into chunks of 30\n",
    "def divide_chunks(lst, n):\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]\n",
    "chunk_start = 31\n",
    "# Split the authors list into chunks of 30\n",
    "author_chunks = list(divide_chunks(authors_all[(chunk_start-1)*30:], 30))\n",
    "\n",
    "# Loop through each chunk and process\n",
    "for idx, authors in enumerate(author_chunks, start=chunk_start):\n",
    "    # Initialize an empty list to store paper data\n",
    "    paper_data = []\n",
    "    n = 0\n",
    "    # Search Google Scholar for each author and retrieve their papers\n",
    "    for author in authors:\n",
    "        search_query = scholarly.search_author(author)\n",
    "        author_obj = next(search_query, None)  # Fetch the first result for the author\n",
    "        print(n)\n",
    "        n+=1\n",
    "        if author_obj:\n",
    "            author_filled = scholarly.fill(author_obj)  # Retrieve full author details\n",
    "            author_papers = author_filled['publications']\n",
    "            for paper in author_papers:\n",
    "                # Retrieve paper details: title\n",
    "                title = paper.get('bib', {}).get('title', 'No title available')\n",
    "\n",
    "                # Fetch publication year and convert it to integer if it exists\n",
    "                year = paper.get('bib', {}).get('pub_year', None)\n",
    "                if year is not None:\n",
    "                    try:\n",
    "                        year = int(year)  # Convert year to integer\n",
    "                    except ValueError:\n",
    "                        continue  # Skip this paper if the year is not a valid integer\n",
    "\n",
    "                # Only include papers from 2022 to 2024\n",
    "                if year and 2022 <= year <= 2024:\n",
    "                    # Fetch abstract: Scholarly may not always provide an abstract\n",
    "                    abstract = paper.get('bib', {}).get('abstract', 'No abstract available')\n",
    "\n",
    "                    # Try to fill the paper's details, which might contain the abstract in some cases\n",
    "                    paper_filled = scholarly.fill(paper)\n",
    "                    if 'abstract' in paper_filled.get('bib', {}):\n",
    "                        abstract = paper_filled['bib']['abstract']  # Update abstract if found\n",
    "\n",
    "                    # Append the paper details\n",
    "                    paper_data.append({\n",
    "                        'Author': author,\n",
    "                        'Title': title,\n",
    "                        'Abstract': abstract,\n",
    "                        'Year': year\n",
    "                    })\n",
    "\n",
    "    # Convert to a DataFrame\n",
    "    df_papers = pd.DataFrame(paper_data)\n",
    "\n",
    "    # Save the data to a CSV file for the current chunk\n",
    "    output_csv_path = f'author_papers_2022_2024_part_{idx}.csv'\n",
    "    df_papers.to_csv(output_csv_path, index=False)\n",
    "\n",
    "    # Output the location of the saved CSV file for the current chunk\n",
    "    print(f\"Papers data for part {idx} saved to: {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dec83f4-d286-4f36-a518-236c380ddb75",
   "metadata": {},
   "source": [
    "## combine all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139818aa-93dc-40a0-a24c-2967886f6d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# List of expected chunk files\n",
    "chunk_files = [f'author_papers_2022_2024_part_{i}.csv' for i in range(1, 63)]\n",
    "\n",
    "# Initialize a list to store dataframes\n",
    "dataframes = []\n",
    "\n",
    "# Iterate through the chunk files and add existing ones\n",
    "for file in chunk_files:\n",
    "    if os.path.exists(file):\n",
    "        try:\n",
    "            df = pd.read_csv(file)\n",
    "            dataframes.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file}: {e}\")\n",
    "    else:\n",
    "        print(f\"File not found: {file}. Skipping...\")\n",
    "\n",
    "# Combine all valid dataframes\n",
    "if dataframes:\n",
    "    df_combined = pd.concat(dataframes, ignore_index=True)\n",
    "    df_combined.to_csv('all_author_papers_2022_2024.csv', index=False)\n",
    "    print(\"All chunks combined and saved to all_author_papers_2022_2024.csv\")\n",
    "else:\n",
    "    print(\"No files were found to combine.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1f88b4-57cd-49d2-9971-e8cad0d0bc85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
