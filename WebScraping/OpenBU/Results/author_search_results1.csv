Author,Title,Abstract
ADRIAN WHITTY,Disulfide-mediated stabilization of the IκB kinase binding domain of NF-κB essential modulator (NEMO),"Human NEMO (NF-κB essential modulator) is a 419 residue scaffolding protein that, together with catalytic subunits IKKα and IKKβ, forms the IκB kinase (IKK) complex, a key regulator of NF-κB pathway signaling. NEMO is an elongated homodimer comprising mostly α-helix. It has been shown that a NEMO fragment spanning residues 44-111, which contains the IKKα/β binding site, is structurally disordered in the absence of bound IKKβ. Herein we show that enforcing dimerization of NEMO1-120 or NEMO44-111 constructs through introduction of one or two interchain disulfide bonds, through oxidation of the native Cys54 residue and/or at position 107 through a Leu107Cys mutation, induces a stable α-helical coiled-coil structure that is preorganized to bind IKKβ with high affinity. Chemical and thermal denaturation studies showed that, in the context of a covalent dimer, the ordered structure was stabilized relative to the denatured state by up to 3 kcal/mol. A full-length NEMO-L107C protein formed covalent dimers upon treatment of mammalian cells with H2O2. Furthermore, NEMO-L107C bound endogenous IKKβ in A293T cells, reconstituted TNF-induced NF-κB signaling in NEMO-deficient cells, and interacted with TRAF6. Our results indicate that the IKKβ binding domain of NEMO possesses an ordered structure in the unbound state, provided that it is constrained within a dimer as is the case in the constitutively dimeric full-length NEMO protein. The stability of the NEMO coiled coil is maintained by strong interhelix interactions in the region centered on residue 54. The disulfide-linked constructs we describe herein may be useful for crystallization of NEMO's IKKβ binding domain in the absence of bound IKKβ, thereby facilitating the structural characterization of small-molecule inhibitors."
ADRIAN WHITTY,Inhibition of oncogenic transcription factor REL by the natural product derivative calafianin monomer 101 induces proliferation arrest and apoptosis in human B-lymphoma cell lines,"Increased activity of transcription factor NF-κB has been implicated in many B-cell lymphomas. We investigated effects of synthetic compound calafianin monomer (CM101) on biochemical and biological properties of NF-κB. In human 293 cells, CM101 selectively inhibited DNA binding by overexpressed NF-κB subunits REL (human c-Rel) and p65 as compared to NF-κB p50, and inhibition of REL and p65 DNA binding by CM101 required a conserved cysteine residue. CM101 also inhibited DNA binding by REL in human B-lymphoma cell lines, and the sensitivity of several B-lymphoma cell lines to CM101-induced proliferation arrest and apoptosis correlated with levels of cellular and nuclear REL. CM101 treatment induced both phosphorylation and decreased expression of anti-apoptotic protein Bcl-XL, a REL target gene product, in sensitive B-lymphoma cell lines. Ectopic expression of Bcl-XL protected SUDHL-2 B-lymphoma cells against CM101-induced apoptosis, and overexpression of a transforming mutant of REL decreased the sensitivity of BJAB B-lymphoma cells to CM101-induced apoptosis. Lipopolysaccharide-induced activation of NF-κB signaling upstream components occurred in RAW264.7 macrophages at CM101 concentrations that blocked NF-κB DNA binding. Direct inhibitors of REL may be useful for treating B-cell lymphomas in which REL is active, and may inhibit B-lymphoma cell growth at doses that do not affect some immune-related responses in normal cells."
ADRIAN WHITTY,Fragments and hot spots in drug discovery,
ADRIAN WHITTY,How proteins bind macrocycles,"The potential utility of synthetic macrocycles (MCs) as drugs, particularly against low-druggability targets such as protein-protein interactions, has been widely discussed. There is little information, however, to guide the design of MCs for good target protein-binding activity or bioavailability. To address this knowledge gap, we analyze the binding modes of a representative set of MC-protein complexes. The results, combined with consideration of the physicochemical properties of approved macrocyclic drugs, allow us to propose specific guidelines for the design of synthetic MC libraries with structural and physicochemical features likely to favor strong binding to protein targets as well as good bioavailability. We additionally provide evidence that large, natural product-derived MCs can bind targets that are not druggable by conventional, drug-like compounds, supporting the notion that natural product-inspired synthetic MCs can expand the number of proteins that are druggable by synthetic small molecules."
KAREN JACOBSON,"Development and assessment of a new framework for disease surveillance, prediction, and risk adjustment: the diagnostic items classification system","IMPORTANCE: Current disease risk-adjustment formulas in the US rely on diagnostic classification frameworks that predate the International Classification of Diseases, Tenth Revision, Clinical Modification (ICD-10-CM). OBJECTIVE: To develop an ICD-10-CM-based classification framework for predicting diverse health care payment, quality, and performance outcomes. DESIGN SETTING AND PARTICIPANTS: Physician teams mapped all ICD-10-CM diagnoses into 3 types of diagnostic items (DXIs): main effect DXIs that specify diseases; modifiers, such as laterality, timing, and acuity; and scaled variables, such as body mass index, gestational age, and birth weight. Every diagnosis was mapped to at least 1 DXI. Stepwise and weighted least-squares estimation predicted cost and utilization outcomes, and their performance was compared with models built on (1) the Agency for Healthcare Research and Quality Clinical Classifications Software Refined (CCSR) categories, and (2) the Health and Human Services Hierarchical Condition Categories (HHS-HCC) used in the Affordable Care Act Marketplace. Each model's performance was validated using R 2, mean absolute error, the Cumming prediction measure, and comparisons of actual to predicted outcomes by spending percentiles and by diagnostic frequency. The IBM MarketScan Commercial Claims and Encounters Database, 2016 to 2018, was used, which included privately insured, full- or partial-year eligible enrollees aged 0 to 64 years in plans with medical, drug, and mental health/substance use coverage. MAIN OUTCOMES AND MEASURES: Fourteen concurrent outcomes were predicted: overall and plan-paid health care spending (top-coded and not top-coded); enrollee out-of-pocket spending; hospital days and admissions; emergency department visits; and spending for 6 types of services. The primary outcome was annual health care spending top-coded at $250 000. RESULTS: A total of 65 901 460 person-years were split into 90% estimation/10% validation samples (n = 6 604 259). In all, 3223 DXIs were created: 2435 main effects, 772 modifiers, and 16 scaled items. Stepwise regressions predicting annual health care spending (mean [SD], $5821 [$17 653]) selected 76% of the main effect DXIs with no evidence of overfitting. Validated R 2 was 0.589 in the DXI model, 0.539 for CCSR, and 0.428 for HHS-HCC. Use of DXIs reduced underpayment for enrollees with rare (1-in-a-million) diagnoses by 83% relative to HHS-HCCs. CONCLUSIONS: In this diagnostic modeling study, the new DXI classification system showed improved predictions over existing diagnostic classification systems for all spending and utilization outcomes considered."
SUSAN WALKER,Reproductive inequality in humans and other mammals,"To address claims of human exceptionalism, we determine where humans fit within the greater mammalian distribution of reproductive inequality. We show that humans exhibit lower reproductive skew (i.e., inequality in the number of surviving offspring) among males and smaller sex differences in reproductive skew than most other mammals, while nevertheless falling within the mammalian range. Additionally, female reproductive skew is higher in polygynous human populations than in polygynous nonhumans mammals on average. This patterning of skew can be attributed in part to the prevalence of monogamy in humans compared to the predominance of polygyny in nonhuman mammals, to the limited degree of polygyny in the human societies that practice it, and to the importance of unequally held rival resources to women's fitness. The muted reproductive inequality observed in humans appears to be linked to several unusual characteristics of our species-including high levels of cooperation among males, high dependence on unequally held rival resources, complementarities between maternal and paternal investment, as well as social and legal institutions that enforce monogamous norms."
KIMBERLY HOWARD,Social-emotional learning and career development in elementary settings,
KIMBERLY HOWARD,"The intersection of race, sexual orientation, socioeconomic status, trans identity, and mental health outcomes","The present study examined patterns in trans individuals’ multiple identities and mental health outcomes. Cluster 1 (socioeconomic and racial privilege; n = 239) was characterized by individuals who identified as trans women or cross-dressers, lesbian, bisexual, or questioning; had associates degrees; reported household incomes of $60,000 or more a year; and were non-Latino White. Cluster 2 (educational privilege; n = 191) was characterized by individuals who identified as trans men or genderqueer, gay, or queer; had a bachelor’s degree; reported household incomes of $10,000 or less a year; and were people of color. There was a pattern of individuals in Cluster 1 who identified with two privileged identities (identifying as White and having higher household incomes), whereas individuals in Cluster 2 identified only formal education as a privilege. Individuals in Cluster 2 reported statistically significant levels of anxiety. Implications of these results for future research and clinical practice are examined."
KIMBERLY HOWARD,Stress and depression among veterinary medical students,"While existing literature suggests that professional students (e.g., medical, dental, law, nursing, etc.) experience high levels of stress and depression, the experiences of veterinary medical students have been less well examined. The purpose of this study was to explore the levels of stress and depression among veterinary medical students and to examine the relationship between these variables. Study participants were 1,245 veterinary medical students from North America. The findings provide support for the assertion that veterinary medical students experience high levels of stress and depression. Results also indicated that there is a correlation between stress and depression for veterinary medical students and that female students experience higher levels of stress and depression than their male counterparts."
KIMBERLY HOWARD,Kindergarten teacher perceptions of kindergarten readiness: The importance of social–emotional skills,"Using the National Center for Early Development and Learning’s Transition Practices Survey (1996), Rimm-Kaufman, Pianta, and Cox (2000) addressed teachers’ judgments of children’s problems at Kindergarten entry. Since then, many changes have occurred in both early childhood education and Kindergarten. For example, pre-Kindergarten has been expanded by private, local, state, and federal agencies to serve the needs of all children and Kindergarten teachers are expected to deliver a more rigorous academic curriculum. Therefore, the purpose of this study was to identify current Kindergarten teachers’ judgments about children’s Kindergarten readiness and learning-related behaviors at school entry. Findings from Kindergarten teachers (N=531) indicated that teachers placed a high value on social–emotional skills and viewed many children as not having the requisite skills for successful Kindergarten entry. Further, they believed a large number of children were experiencing significant struggles that could hinder their classroom work. Implications for these findings are discussed as is the need for future research on strategies to enhance young children’s behavioral self-regulation and social-emotional skills prior to and during the transition to Kindergarten."
KIMBERLY HOWARD,"The role of refereed journals in integrating theory, research, and practice",
KIMBERLY HOWARD,Predictors of teacher burnout during the COVID-19 pandemic with machine learning,
KIMBERLY HOWARD,Empowering women in finance through developing girls' financial literacy skills in the United States,"This study examines the effectiveness of a financial literacy program, Invest in Girls (IIG), in promoting financial capability among high school girls. Using a quasi-experimental separate-samples pretest-posttest design and a longitudinal qualitative study, the study aims to assess the program efficacy and investigate the perspectives of the female students on its impact on their knowledge, behavior, and future goals and aspirations. The results indicated that the participants had significantly higher confidence for engaging in financial literacy after the program. The findings from the longitudinal study also suggested that that the program was influencing the students in positive ways, increasing their financial capability and leading them to consider wide occupational pathways available in finance. Given the lack of female leaders in the world of finance, the IIG program aims to address gender disparity in financial knowledge and highlight the importance of building financial literacy skills among girls."
KIMBERLY HOWARD,Embedding life design in future readiness efforts to promote collective impact and economically sustainable communities: conceptual frameworks and case example,"This is the first of two sequential papers describing the design and first-year implementation of a collaborative participatory action research effort between Sociedad Latina, a youth serving organization in Boston, Massachusetts, and Boston University. The collaboration aimed to develop and deliver a combined STEM and career development set of lessons for middle school Latinx youth. In the first paper, life design and the U.N. Sustainable Development Goals are described in relation to the rationale and the design of the career development intervention strategy that aims to help middle school youth discover the ways that learning advanced-STEM skills expand future decent work opportunities both within STEM and outside STEM, ultimately leading to an outcome of well-being and sustainable communities. In addition to providing evidence of career development intervention strategies, a qualitative analysis of the collaboration is described. The second paper will discuss two additional frameworks that guided the design and implementation of our work. As an example of translational research, the paper will provide larger national and regional contexts by describing system level career development interventions underway using Bronfenbrenner’s bioecological and person–process–context–time frameworks."
KIMBERLY HOWARD,Activation instead of Blocking Mesolimbic Dopaminergic Reward Circuitry Is a Preferred Modality in the Long Term Treatment of Reward Deficiency Syndrome (RDS): A Commentary,"BACKGROUND AND HYPOTHESIS. Based on neurochemical and genetic evidence, we suggest that both prevention and treatment of multiple addictions, such as dependence to alcohol, nicotine and glucose, should involve a biphasic approach. Thus, acute treatment should consist of preferential blocking of postsynaptic Nucleus Accumbens (NAc) dopamine receptors (D1-D5), whereas long term activation of the mesolimbic dopaminergic system should involve activation and/or release of Dopamine (DA) at the NAc site. Failure to do so will result in abnormal mood, behavior and potential suicide ideation. Individuals possessing a paucity of serotonergic and/or dopaminergic receptors, and an increased rate of synaptic DA catabolism due to high catabolic genotype of the COMT gene, are predisposed to self-medicating any substance or behavior that will activate DA release, including alcohol, opiates, psychostimulants, nicotine, gambling, sex, and even excessive internet gaming. Acute utilization of these substances and/or stimulatory behaviors induces a feeling of well being. Unfortunately, sustained and prolonged abuse leads to a toxic"" pseudo feeling"" of well being resulting in tolerance and disease or discomfort. Thus, a reduced number of DA receptors, due to carrying the DRD2 A1 allelic genotype, results in excessive craving behavior; whereas a normal or sufficient amount of DA receptors results in low craving behavior. In terms of preventing substance abuse, one goal would be to induce a proliferation of DA D2 receptors in genetically prone individuals. While in vivo experiments using a typical D2 receptor agonist induce down regulation, experiments in vitro have shown that constant stimulation of the DA receptor system via a known D2 agonist results in significant proliferation of D2 receptors in spite of genetic antecedents. In essence, D2 receptor stimulation signals negative feedback mechanisms in the mesolimbic system to induce mRNA expression causing proliferation of D2 receptors. PROPOSAL AND CONCLUSION. The authors propose that D2 receptor stimulation can be accomplished via the use of Synapatmine™, a natural but therapeutic nutraceutical formulation that potentially induces DA release, causing the same induction of D2-directed mRNA and thus proliferation of D2 receptors in the human. This proliferation of D2 receptors in turn will induce the attenuation of craving behavior. In fact as mentioned earlier, this model has been proven in research showing DNA-directed compensatory overexpression (a form of gene therapy) of the DRD2 receptors, resulting in a significant reduction in alcohol craving behavior in alcohol preferring rodents. Utilizing natural dopaminergic repletion therapy to promote long term dopaminergic activation will ultimately lead to a common, safe and effective modality to treat Reward Deficiency Syndrome (RDS) behaviors including Substance Use Disorders (SUD), Attention Deficit Hyperactivity Disorder (ADHD), Obesity and other reward deficient aberrant behaviors. This concept is further supported by the more comprehensive understanding of the role of dopamine in the NAc as a ""wanting"" messenger in the meso-limbic DA system."
KIMBERLY HOWARD,Support and perceptions of teachers working with students with special needs during the COVID-19 pandemic,"Teachers serving students with special needs, students from low-income backgrounds, students with disabilities, and students from underrepresented racial/ethnic backgrounds experienced a myriad of challenges due to the COVID-19 pandemic. This study aims to assess whether and to what extent teachers received resources during the pandemic, and to evaluate the impact of this on their perceptions of student academic engagement. Using the American Teacher Panel (ATP) data collected in October 2020, this research found that 41% of teachers working with diverse and marginalized students did not receive any resources tailored specifically for students with special needs. Teacher experiences with resources were clustered into four groups: Most Supported (35%), Least Supported (41%), Moderately Supported A (16%; received support primarily with students with disabilities), and Moderately Supported B (8%; received support primarily with students with racial/ethnic backgrounds). Across the four groups of teachers, teacher groups classified as less supported were more likely to be teaching in more urbanized settings with larger size schools than the other teacher groups. Additionally, they perceived their students as attending less often and being less ready for grade-level coursework than their counterparts. Discussions for school leaders and counselors are outlined to emphasize the importance of teacher support for effective education during the COVID-19 pandemic."
KIMBERLY HOWARD,Perceived influences on the career choices of children and youth: an exploratory study,"Children’s understanding of factors influencing their career choices was examined. Seventy-two children, in grades kindergarten, 4, and 8, responded to questions about their perceptions of career influences. Responses were coded to capture the nature of the influences identified, including the global versus specific and linear versus interacting nature of these influences. Further, influences were coded as existing proximal versus distal to the child. Results indicate that older children identified more career influences that were either specific or categorical and interacted in dynamic ways. No evidence was found for older children offering influences that existed at a systems level of organization."
NEIL MYLER,Two places for causees in productive isiXhosa morphological causatives,"Productive morphological causatives in isiXhosa exhibit a case alternation regarding the causee, which can be unmarked or instrumental. Much recent literature on similar alternations in causative constructions in other languages analyzes them as involving differences in the size or the category of the constituent selected by the causative morpheme. We show that such an analysis cannot be extended to isiXhosa, and that both alternants are verb-selecting causatives in the sense of Pylkkänen 2008. We propose instead that the alternation actually concerns the place in the structure in which the causee is introduced: in the specifier of the causative head itself in the unmarked causee construction, but in a PP adjoined to the embedded verb phrase in the instrumental causee construction. This paper thus adds to a growing body of evidence that the same thematic roles are not always assigned in the same syntactic positions."
NEIL MYLER,Cliticization feeds agreement: a view from Quechua,"Recent years have seen a surge in work on Person Hierarchy Effects (Béjar and Rezac 2009; Georgi 2011; Lochbihler 2009; Nevins 2007, 2011; Oxford 2014; Walkow 2009; Wiltschko 2008). In this paper, I analyze a curious case of such an effect which has been widely discussed in theoretical and descriptive work on the Quechua family (van de Kerke 1996; Lakämper and Wunderlich 1998; Milliken 1984; Muysken 1981; Weber 1976, 1989). In many Quechua languages, objects bearing the feature [Addressee] interact with subject agreement, but 1st person exclusive objects do not, even in the presence of a 3rd person subject. I dub this effect the [Addressee]-driven Subject Marking Anomaly (A-SMA), adapting the terminology of Weber (1976). After showing that object markers in Quechua languages are in fact object clitics, I argue that the A-SMA emerges from the interaction of cliticization with subject agreement: [Addressee] clitics raise above the subject in the clausal hierarchy, thus feeding agreement, but non-[Addressee] clitics do not. The analysis is extended to a related agreement effect involving plural objects in certain Bolivian and Argentine varieties of Quechua."
NEIL MYLER,Stem storage? Not proven: a reply to Bermúdez-Otero 2013,
NEIL MYLER,Commentary: syntactic approaches to morphology,
NEIL MYLER,Causative~applicative interactions and the nature of appl: the case of isiXhosa (based on joint work with Zoliswa Mali),
NEIL MYLER,Some predictions of a suppletive allomorphy approach to complex copula systems,
NEIL MYLER,Variation in the syntax and semantics of predicative possession in Quechua,This paper employs comparative evidence from two closely-related Quechua languages to argue that predicative possession constructions do not always share a single underlying source crosslinguistically (contra Freeze 1992; and in support of Boneh & Sichel 2010; Levinson 2011). This Quechua case study is especially striking in that the constructions involved are superficially almost identical–the crucial differences between them emerge only when theoretically-informed fieldwork is carried out.
NEIL MYLER,Complex copula systems as suppletive alomorphy,"Languages are known to vary in the number of verbs they exhibit corresponding to English ""be"", in the distribution of such copular verbs, and in the presence or absence of a distinct verb for possession sentences corresponding to English ""have"". This paper offers novel arguments for the position that such differences should be modeled in terms of suppletive allomorphy of the same syntactic element (here dubbed v BE), employing a Late Insertion- based framework. It is shown that such a suppletive allomorphy approach to complex copula systems makes three predictions that distinguish it from non-suppletion-based alternatives (concerning decomposition, possible and impossible syncretisms, and Impoverishment), and that these predictions seem to be correct (although a full test of the possible and impossible syncretisms prediction is not possible in the current state of knowledge)."
NEIL MYLER,"Nuevos hallazgos en morfosintáxis quechua: aplicativos, reflexivos, y las marcas del objeto","Title translation: ""New Findings in Quechua Morphosyntax: Applicatives, Reflexives, and Object Markers"""
NEIL MYLER,Two places for causees in productive isiXhosa morphological causatives,Gave a guest lecture on my joint work with Zoliswa Mali on isiXhosa causatives.
MATTHEW STEWART,Planetary mass spectrometry for agnostic life detection in the Solar system,"For the past fifty years of space exploration, mass spectrometry has provided unique chemical and physical insights on the characteristics of other planetary bodies in the Solar System. A variety of mass spectrometer types, including magnetic sector, quadrupole, time-of-flight, and ion trap, have and will continue to deepen our understanding of the formation and evolution of exploration targets like the surfaces and atmospheres of planets and their moons. An important impetus for the continuing exploration of Mars, Europa, Enceladus, Titan, and Venus involves assessing the habitability of solar system bodies and, ultimately, the search for life—a monumental effort that can be advanced by mass spectrometry. Modern flight-capable mass spectrometers, in combination with various sample processing, separation, and ionization techniques enable sensitive detection of chemical biosignatures. While our canonical knowledge of biosignatures is rooted in Terran-based examples, agnostic approaches in astrobiology can cast a wider net, to search for signs of life that may not be based on Terran-like biochemistry. Here, we delve into the search for extraterrestrial chemical and morphological biosignatures and examine several possible approaches to agnostic life detection using mass spectrometry. We discuss how future missions can help ensure that our search strategies are inclusive of unfamiliar life forms."
MATTHEW STEWART,"Corals of the genus Porites are a locally abundant component of the epibiont community on mangrove prop roots at Calabash Caye, Turneffe Atoll, Belize","Mangroves are generally regarded as inhospitable for corals, but recent reports suggest they provide ecological refuge for some species. We surveyed diverse mangrove habitats on Turneffe Atoll, Belize, documenting 127 colonies of Porites divaricata (Thin Finger Coral) along 1858 m of mangrove prop roots at Calabash Caye and a much more diverse coral assemblage at Crooked Creek. At Calabash, corals were highly clumped, and varied widely in size and morphology, including large well-arborized colonies, encrusting forms with few branches, and new recruits with no branches, suggesting an age-structuredpopulation exhibiting extensive morphological plasticity. The data described here contributeto an emerging picture of mangroves as potentially critical habitat for many Caribbeancoral species."
MATTHEW STEWART,Scintillation light detection in the 6-m drift-length ProtoDUNE Dual Phase liquid argon TPC,"DUNE is a dual-site experiment for long-baseline neutrino oscillation studies, neutrino astrophysics and nucleon decay searches. ProtoDUNE Dual Phase (DP) is a 6  ×  6  ×  6 m 3 liquid argon time-projection-chamber (LArTPC) that recorded cosmic-muon data at the CERN Neutrino Platform in 2019-2020 as a prototype of the DUNE Far Detector. Charged particles propagating through the LArTPC produce ionization and scintillation light. The scintillation light signal in these detectors can provide the trigger for non-beam events. In addition, it adds precise timing capabilities and improves the calorimetry measurements. In ProtoDUNE-DP, scintillation and electroluminescence light produced by cosmic muons in the LArTPC is collected by photomultiplier tubes placed up to 7 m away from the ionizing track. In this paper, the ProtoDUNE-DP photon detection system performance is evaluated with a particular focus on the different wavelength shifters, such as PEN and TPB, and the use of Xe-doped LAr, considering its future use in giant LArTPCs. The scintillation light production and propagation processes are analyzed and a comparison of simulation to data is performed, improving understanding of the liquid argon properties."
MATTHEW STEWART,Prospects for beyond the standard model physics searches at the deep underground neutrino experiment: DUNE collaboration,"The Deep Underground Neutrino Experiment (DUNE) will be a powerful tool for a variety of physics topics. The high-intensity proton beams provide a large neutrino flux, sampled by a near detector system consisting of a combination of capable precision detectors, and by the massive far detector system located deep underground. This configuration sets up DUNE as a machine for discovery, as it enables opportunities not only to perform precision neutrino measurements that may uncover deviations from the present three-flavor mixing paradigm, but also to discover new particles and unveil new interactions and symmetries beyond those predicted in the Standard Model (SM). Of the many potential beyond the Standard Model (BSM) topics DUNE will probe, this paper presents a selection of studies quantifying DUNE's sensitivities to sterile neutrino mixing, heavy neutral leptons, non-standard interactions, CPT symmetry violation, Lorentz invariance violation, neutrino trident production, dark matter from both beam induced and cosmogenic sources, baryon number violation, and other new physics topics that complement those at high-energy colliders and significantly extend the present reach."
MATTHEW STEWART,Identification and reconstruction of low-energy electrons in the ProtoDUNE-SP detector,
MATTHEW STEWART,The long-baseline neutrino experiment: exploring fundamental symmetries of the universe,"The preponderance of matter over antimatter in the early Universe, the dynamics of the supernova bursts that produced the heavy elements necessary for life and whether protons eventually decay --- these mysteries at the forefront of particle physics and astrophysics are key to understanding the early evolution of our Universe, its current state and its eventual fate. The Long-Baseline Neutrino Experiment (LBNE) represents an extensively developed plan for a world-class experiment dedicated to addressing these questions. LBNE is conceived around three central components: (1) a new, high-intensity neutrino source generated from a megawatt-class proton accelerator at Fermi National Accelerator Laboratory, (2) a near neutrino detector just downstream of the source, and (3) a massive liquid argon time-projection chamber deployed as a far detector deep underground at the Sanford Underground Research Facility. This facility, located at the site of the former Homestake Mine in Lead, South Dakota, is approximately 1,300 km from the neutrino source at Fermilab -- a distance (baseline) that delivers optimal sensitivity to neutrino charge-parity symmetry violation and mass ordering effects. This ambitious yet cost-effective design incorporates scalability and flexibility and can accommodate a variety of upgrades and contributions. With its exceptional combination of experimental configuration, technical capabilities, and potential for transformative discoveries, LBNE promises to be a vital facility for the field of particle physics worldwide, providing physicists from around the globe with opportunities to collaborate in a twenty to thirty year program of exciting science. In this document we provide a comprehensive overview of LBNE's scientific objectives, its place in the landscape of neutrino physics worldwide, the technologies it will incorporate and the capabilities it will possess."
SAM LING,Arousal‐based pupil modulation is dictated by luminance,"Pupillometry has become a standard measure for assessing arousal state. However, environmental factors such as luminance, a primary dictator of pupillary responses, often vary across studies. To what degree does luminance interact with arousal-driven pupillary changes? Here, we parametrically assessed luminance-driven pupillary responses across a wide-range of luminances, while concurrently manipulating cognitive arousal using auditory math problems of varying difficulty. At the group-level, our results revealed that the modulatory effect of cognitive arousal on pupil size interacts multiplicatively with luminance, with the largest effects occurring at low and mid-luminances. However, at the level of individuals, there were qualitatively distinct individual differences in the modulatory effect of cognitive arousal on luminance-driven pupillary responses. Our findings suggest that pupillometry as a measure for assessing arousal requires more careful consideration: there are ranges of luminance levels that are more ideal in observing pupillary differences between arousal conditions than others."
SAM LING,Scintillation light detection in the 6-m drift-length ProtoDUNE Dual Phase liquid argon TPC,"DUNE is a dual-site experiment for long-baseline neutrino oscillation studies, neutrino astrophysics and nucleon decay searches. ProtoDUNE Dual Phase (DP) is a 6  ×  6  ×  6 m 3 liquid argon time-projection-chamber (LArTPC) that recorded cosmic-muon data at the CERN Neutrino Platform in 2019-2020 as a prototype of the DUNE Far Detector. Charged particles propagating through the LArTPC produce ionization and scintillation light. The scintillation light signal in these detectors can provide the trigger for non-beam events. In addition, it adds precise timing capabilities and improves the calorimetry measurements. In ProtoDUNE-DP, scintillation and electroluminescence light produced by cosmic muons in the LArTPC is collected by photomultiplier tubes placed up to 7 m away from the ionizing track. In this paper, the ProtoDUNE-DP photon detection system performance is evaluated with a particular focus on the different wavelength shifters, such as PEN and TPB, and the use of Xe-doped LAr, considering its future use in giant LArTPCs. The scintillation light production and propagation processes are analyzed and a comparison of simulation to data is performed, improving understanding of the liquid argon properties."
SAM LING,Identification and reconstruction of low-energy electrons in the ProtoDUNE-SP detector,
SAM LING,The long-baseline neutrino experiment: exploring fundamental symmetries of the universe,"The preponderance of matter over antimatter in the early Universe, the dynamics of the supernova bursts that produced the heavy elements necessary for life and whether protons eventually decay --- these mysteries at the forefront of particle physics and astrophysics are key to understanding the early evolution of our Universe, its current state and its eventual fate. The Long-Baseline Neutrino Experiment (LBNE) represents an extensively developed plan for a world-class experiment dedicated to addressing these questions. LBNE is conceived around three central components: (1) a new, high-intensity neutrino source generated from a megawatt-class proton accelerator at Fermi National Accelerator Laboratory, (2) a near neutrino detector just downstream of the source, and (3) a massive liquid argon time-projection chamber deployed as a far detector deep underground at the Sanford Underground Research Facility. This facility, located at the site of the former Homestake Mine in Lead, South Dakota, is approximately 1,300 km from the neutrino source at Fermilab -- a distance (baseline) that delivers optimal sensitivity to neutrino charge-parity symmetry violation and mass ordering effects. This ambitious yet cost-effective design incorporates scalability and flexibility and can accommodate a variety of upgrades and contributions. With its exceptional combination of experimental configuration, technical capabilities, and potential for transformative discoveries, LBNE promises to be a vital facility for the field of particle physics worldwide, providing physicists from around the globe with opportunities to collaborate in a twenty to thirty year program of exciting science. In this document we provide a comprehensive overview of LBNE's scientific objectives, its place in the landscape of neutrino physics worldwide, the technologies it will incorporate and the capabilities it will possess."
ADAM GUREN,House price momentum and strategic complementarity,"House prices exhibit substantially more momentum, positive autocorrelation in price changes, than existing theories can explain. I introduce an amplification mechanism to reconcile this discrepancy. Sellers do not set a unilaterally high or low list price because they face a concave demand curve: increasing the price of an above-average-priced house rapidly reduces its sale probability, but cutting the price of a below-average-priced house only slightly improves its sale probability. The resulting strategic complementarity amplifies frictions because sellers gradually adjust their price to stay near average. I provide empirical evidence for concave demand using a quantitative search model that amplifies momentum two- to threefold."
ADAM GUREN,What can we learn from cross-sectional empirical estimates in macroeconomics?,"Recent empirical work uses variation across cities or regions to identify the effects of economic shocks of interest to macroeconomists. The interpretation of such estimates is complicated by the fact that they reflect both partial equilibrium and local general equilibrium effects of the shocks. We propose an approach for recovering estimates of partial equilibrium effects from these cross-regional empirical estimates. The basic idea is to divide the cross-regional estimate by an estimate of the local fiscal multiplier, which measures the strength of local general equilibrium amplification. We apply this approach to recent estimates of housing wealth effects based on city-level variation, and derive conditions under which the adjustment is exact. We then evaluate its accuracy in a richer general equilibrium model of consumption and housing. The paper also reconciles the positive cross-sectional correlation between house price growth and construction with the notion that cities with larger price volatility have lower housing supply elasticities using a model in which housing supply elasticities are more dispersed in the long run than in the short run."
ADAM GUREN,Housing wealth effects: the long view,"We provide new time-varying estimates of the housing wealth effect back to the 1980s. We use three identification strategies: OLS with a rich set of controls, the Saiz housing supply elasticity instrument, and a new instrument that exploits systematic differences in city-level exposure to regional house price cycles. All three identification strategies indicate that housing wealth elasticities were if anything slightly smaller in the 2000s than in earlier time periods. This implies that the important role housing played in the boom and bust of the 2000s was due to larger price movements rather than an increase in the sensitivity of consumption to house prices. Full-sample estimates based on our new instrument are smaller than recent estimates, though they remain economically important. We find no significant evidence of a boom-bust asymmetry in the housing wealth elasticity. We show that these empirical results are consistent with the behavior of the housing wealth elasticity in a standard life-cycle model with borrowing constraints, uninsurable income risk, illiquid housing, and long-term mortgages. In our model, the housing wealth elasticity is relatively insensitive to changes in the distribution of LTV for two reasons: First, low-leverage homeowners account for a substantial and stable part of the aggregate housing wealth elasticity; Second, a rightward shift in the LTV distribution increases not only the number of highly sensitive constrained agents but also the number of underwater agents whose consumption is insensitive to house prices."
ADAM GUREN,How do foreclosures exacerbate housing downturns?,"This article uses a structural model to show that foreclosures played a crucial role in exacerbating the recent housing bust and to analyse foreclosure mitigation policy. We consider a dynamic search model in which foreclosures freeze the market for non-foreclosures and reduce price and sales volume by eroding lender equity, destroying the credit of potential buyers, and making buyers more selective. These effects cause price-default spirals that amplify an initial shock and help the model fit both national and cross-sectional moments better than a model without foreclosure. When calibrated to the recent bust, the model reveals that the amplification generated by foreclosures is significant: ruined credit and choosey buyers account for 25.4% of the total decline in non-distressed prices and lender losses account for an additional 22.6%. For policy, we find that principal reduction is less cost-effective than lender equity injections or introducing a single seller that holds foreclosures off the market until demand rebounds. We also show that policies that slow down the pace of foreclosures can be counterproductive."
ADAM GUREN,Mortgage design in an equilibrium model of the housing market,"How can mortgages be redesigned to reduce macrovolatility and default? We address this question using a quantitative equilibrium life‐cycle model. Designs with countercyclical payments outperform fixed payments. Among those, designs that front‐load payment reductions in recessions outperform those that spread relief over the full term. Front‐loading alleviates liquidity constraints when they bind most, reducing default and stimulating housing demand. To illustrate, a fixed‐rate mortgage (FRM) with an option to convert to adjustable‐rate mortgage, which front‐loads payment reductions relative to an FRM with an option to refinance underwater, reduces price and consumption declines six times as much and default three times as much."
ADAM GUREN,Making the house a home: the stimulative effect of home purchases on consumption and investment,"We introduce and quantify a new channel through which the housing market affects household spending: the home purchase channel. Households spend on average $8,000 more on home-related durables and home improvements in the two years following a home purchase. Expenditures on nondurables and durables unrelated to the home remain unchanged or decrease modestly. The home purchase channel played a substantial role in the Great Recession, accounting for one-third of the decline in spending on home-related durables and home improvements from 2005 to 2010."
ADAM GUREN,The 2000s housing cycle with 2020 hindsight: a neo-Kindlebergerian view,
STEFANIA GARETTO,What are the consequences of global banking for the international transmission of shocks? A quantitative analysis,"The global financial crisis of 2008 was followed by a wave of regulatory reforms that affected large banks, especially those with a global presence. These reforms were reactive to the crisis. In this paper we propose a structural model of global banking that can be used proactively to perform counterfactual analysis on the effects of alternative regulatory policies. The structure of the model mimics the US regulatory framework and highlights the organizational choices that banks face when entering a foreign market: branching versus subsidiarization. When calibrated to match moments from a sample of European banks, the model is able to replicate the response of the US banking sector to the European sovereign debt crisis. Our counterfactual analysis suggests that pervasive subsidiarization, higher capital requirements, or ad hoc monetary policy interventions would have mitigated the effects of the crisis on US lending."
JAMES BIRD,Dataset: effects of salinity beyond coalescence on submicron aerosol distributions,This dataset was created from laboratory experiments investigating the effect of salinity on submicron aerosol production. Bubbles generated in solutions of sodium acetate and artificial seawater were tested with corresponding measurements of the submicron aerosol size distribution. The bubbling below and above the surface of the liquid are imaged.
JAMES BIRD,"Aceso: v. 4, no. 1",
JAMES BIRD,The eighteenth data release of the Sloan Digital Sky Surveys: targeting and first spectra from SDSS-V,"The eighteenth data release (DR18) of the Sloan Digital Sky Survey (SDSS) is the first one for SDSS-V, the fifth generation of the survey. SDSS-V comprises three primary scientific programs or “Mappers”: the Milky Way Mapper (MWM), the Black Hole Mapper (BHM), and the Local Volume Mapper. This data release contains extensive targeting information for the two multiobject spectroscopy programs (MWM and BHM), including input catalogs and selection functions for their numerous scientific objectives. We describe the production of the targeting databases and their calibration and scientifically focused components. DR18 also includes ∼25,000 new SDSS spectra and supplemental information for X-ray sources identified by eROSITA in its eFEDS field. We present updates to some of the SDSS software pipelines and preview changes anticipated for DR19. We also describe three value-added catalogs (VACs) based on SDSS-IV data that have been published since DR17, and one VAC based on the SDSS-V data in the eFEDS field."
JAMES BIRD,A new wrinkle on liquid sheets: Turning the mechanism of viscous bubble collapse upside down,"Viscous bubbles are prevalent in both natural and industrial settings. Their rupture and collapse may be accompanied by features typically associated with elastic sheets, including the development of radial wrinkles. Previous investigators concluded that the film weight is responsible for both the film collapse and wrinkling instability. Conversely, we show here experimentally that gravity plays a negligible role: The same collapse and wrinkling arise independently of the bubble's orientation. We found that surface tension drives the collapse and initiates a dynamic buckling instability. Because the film weight is irrelevant, our results suggest that wrinkling may likewise accompany the breakup of relatively small-scale, curved viscous and viscoelastic films, including those in the respiratory tract responsible for aerosol production from exhalation events."
JAMES BIRD,Threshold for discretely self-similar satellite drop formation from a retracting liquid cone,"Predicting the size of droplets that pinch off from a liquid jet is important to applications ranging from bubble-initiated atmospheric aerosols to inkjet printing. These predictions are complicated by smaller satellite drops that form when a thin liquid thread develops and breaks up faster than its ends fully retract. Typically this process is modeled by perturbing a cylindrical liquid thread with an amplitude that is small relative to the cylinder diameter. Yet early on in the pinch-off process, the ends of the liquid thread are conical and lack a characteristic length scale from which to normalize a finite perturbation. Here we numerically simulate the retraction of nearly-inviscid conical filaments and introduce self-similar perturbations to drive the system into a discretely self-similar retraction that can enable breakup without biasing a particular length scale. We find that for most cone angles, the perturbation amplitude must exceed a threshold for satellite drops to form. We show that this critical perturbation amplitude depends on the cone angle and can be accurately predicted by an argument based on the static stability of the initial perturbed cone."
JAMES BIRD,Universal non-monotonic drainage in large bare viscous bubbles,"Bubbles will rest at the surface of a liquid bath until their spherical cap drains sufficiently to spontaneously rupture. For large film caps, the memory of initial conditions is believed to be erased due to a visco-gravitational flow, whose velocity increases from the top of the bubble to its base. Consequently, the film thickness has been calculated to be relatively uniform as it thins, regardless of whether the drainage is regulated by shear or elongation. Here, we demonstrate that for large bare bubbles, the film thickness is highly nonuniform throughout drainage, spanning orders of magnitude from top to base. We link the film thickness profile to a universal non-monotonic drainage flow that depends on the bubble thinning rate. These results highlight an unexpected coupling between drainage velocity and bubble thickness profiles and provide critical insight needed to understand the retraction and breakup dynamics of these bubbles upon rupture."
JAMES BIRD,Minimum size for the top jet drop from a bursting bubble,"Jet drops ejected from bursting bubbles are ubiquitous, transporting aromatics from sparkling beverages, pathogens from contaminated water sources, and sea salts and organic species from the ocean surface to the atmosphere. In all of these processes, the smallest drops are noteworthy because their slow settling velocities allow them to persist longer and travel further than large drops, provided they escape the viscous sublayer. Yet it is unclear what sets the limit to how small these jet drops can become. Here we directly observe microscale jet drop formation and demonstrate that the smallest jet drops are not produced by the smallest jet drop-producing bubbles, as first predicted numerically by Duchemin et al. [Phys. Fluids, 14(9):3000 (2002)]. Through a combination of high-speed imaging and numerical simulation, we show that the minimum jet drop size is set by an interplay of viscous and inertial-capillary forces both prior and subsequent to the jet formation. Based on the observation of self-similar jet growth, the jet drop size is decomposed into a shape factor and a jet growth time to rationalize the non-monotonic relationship of drop size to bubble size. These findings provide constraints on submicron aerosol production from jet drops in the ocean."
JAMES BIRD,Dataset: Modeling the concentration enhancement and selectivity of plastic particle transport in sea spray aerosols,"This dataset was created from a combination of theoretical models investigating the concentration enhancement and selectivity of plastic particle transport in sea spray aerosols. Following the approach and assumptions outlined in a paper with the same title, the data reports the theoretical enrichment expected in film drops and jet drops on a per bubble size per particle size basis. The bounds of the enrichment depend on the attachment efficiency, which can vary from zero to one, and representative values for the model are calculated for both extremes. Furthermore, this enrichment combines with the bubble-size distribution modeled from a breaking wave along with the plastic particle size distribution modeled from observations to produce an estimate for the number flux of ejected particles per wave on a per bubble size per particle size basis. Calculation results are also provided for the particle surface area and volume flux on a per bubble size per particle size basis from bursting bubbles with and without scavenging (attachment efficiency one or zero). Finally, the ratios of the enrichment, number, area, and volume are computed when integrated across particle size and bubble size."
MAYANK VARIA,Brief announcement: asynchronous verifiable information dispersal with near-optimal communication,
MAYANK VARIA,A cryptographic airbag for metadata: protecting business records against unlimited search and seizure,"Governments around the world require that electronic service providers, including telecoms, ISP’s, and even online services like Twitter and Facebook, must provide law enforcement agencies (LEA’s) with broad access to so-called “business records” including communications metadata. Metadata is data about data; it does not include the contents of the users’ communications, but it does typically show who each user communicated with, and at what times, and for how long. Metadata is actually surprisingly powerful, especially in a time when more and more messages are being encrypted from “endto- end.” In this paper, we present a new approach for protecting communications metadata and other business records against unwarranted, bulk seizure. Our approach is designed from the start to be robust against this new class of political and legal attack. To achieve this, we borrow the recent notion of cryptographic crumple zones [31], i.e. encryption that can be broken, but only at a substantial monetary cost. We propose that a service provider who wishes to protect their users’ privacy should encrypt each business record with its own unique, crumpled, symmetric key. Then, a law enforcement agency who compels disclosure of the records learns only ciphertext until they expend the necessary resources to recover keys for the records of interest. We show how this approach can be easily applied to protect metadata in the form of network flow records. We describe how a service provider might select the work factor of the crumpling algorithm to allow legitimate investigations while preventing the use of metadata for mass surveillance."
MAYANK VARIA,Can the government compel decryption? Don't trust -- verify,"If a court knows that a respondent knows the password to a device, can the court compel the respondent to enter that password into the device? In this work, we propose a new approach to the foregone conclusion doctrine from Fisher v US that governs the answer to this question. The Holy Grail of this line of work would be a framework for reasoning about whether the testimony implicit in any action is already known to the government. In this paper we attempt something narrower. We introduce a framework for specifying actions for which all implicit testimony is, constructively, a foregone conclusion. Our approach is centered around placing the burden of proof on the government to demonstrate that it is not ""rely[ing] on the truthtelling"" of the respondent. Building on original legal analysis and using precise computer science formalisms, we propose demonstrability as a new central concept for describing compelled acts. We additionally provide a language for whether a compelled action meaningfully entails the respondent to perform in a manner that is 'as good as' the government's desired goal. Then, we apply our definitions to analyze the compellability of several cryptographic primitives including decryption, multifactor authentication, commitment schemes, and hash functions. In particular, our framework reaches a novel conclusion about compelled decryption in the setting that the encryption scheme is deniable: the government can compel but the respondent is free to use any password of her choice."
MAYANK VARIA,Accessible privacy-preserving web-based data analysis for assessing and addressing economic inequalities,"An essential component of initiatives that aim to address pervasive inequalities of any kind is the ability to collect empirical evidence of both the status quo baseline and of any improvement that can be attributed to prescribed and deployed interventions. Unfortunately, two substantial barriers can arise preventing the collection and analysis of such empirical evidence: (1) the sensitive nature of the data itself and (2) a lack of technical sophistication and infrastructure available to both an initiative's beneficiaries and to those spearheading it. In the last few years, it has been shown that a cryptographic primitive called secure multi-party computation (MPC) can provide a natural technological resolution to this conundrum. MPC allows an otherwise disinterested third party to contribute its technical expertise and resources, to avoid incurring any additional liabilities itself, and (counterintuitively) to reduce the level of data exposure that existing parties must accept to achieve their data analysis goals. However, achieving these benefits requires the deliberate design of MPC tools and frameworks whose level of accessibility to non-technical users with limited infrastructure and expertise is state-of-the-art. We describe our own experiences designing, implementing, and deploying such usable web applications for secure data analysis within the context of two real-world initiatives that focus on promoting economic equality."
MAYANK VARIA,DEMO: integrating MPC in big data workflows,"Secure multi-party computation (MPC) allows multiple parties to perform a joint computation without disclosing their private inputs. Many real-world joint computation use cases, however, involve data analyses on very large data sets, and are implemented by software engineers who lack MPC knowledge. Moreover, the collaborating parties -- e.g., several companies -- often deploy different data analytics stacks internally. These restrictions hamper the real-world usability of MPC. To address these challenges, we combine existing MPC frameworks with data-parallel analytics frameworks by extending the Musketeer big data workflow manager [4]. Musketeer automatically generates code for both the sensitive parts of a workflow, which are executed in MPC, and the remainder of the computation, which runs on scalable, widely-deployed analytics systems. In a prototype use case, we compute the Herfindahl-Hirschman Index (HHI), an index of market concentration used in antitrust regulation, on an aggregate 156GB of taxi trip data over five transportation companies. Our implementation computes the HHI in about 20 minutes using a combination of Hadoop and VIFF [1], while even ""mixed mode"" MPC with VIFF alone would have taken many hours. Finally, we discuss future research questions that we seek to address using our approach."
MAYANK VARIA,User-centric distributed solutions for privacy-preserving analytics,
MAYANK VARIA,Secure MPC for analytics as a web application,"Companies, government agencies, and other organizations have been analyzing data pertaining to their internal operations with great effect, such as in evaluating performance or improving efficiency. While each organization's own data is valuable internally, aggregate data from multiple organizations can have value to the organizations themselves, policymakers, and society. Unfortunately, an organization's data is often proprietary and confidential, and its release may be potentially deleterious to the organization's interests. Secure multi-party computation (MPC) resolves this tension: aggregate data may be computed while protecting each contributor's confidentiality. Theoretical constructs have been known for decades [1]-[3] and recent efforts aim to deliver them to end-users [4]-[6]."
MAYANK VARIA,The security of NTP's datagram protocol,"For decades, the Network Time Protocol (NTP) has been used to synchronize computer clocks over untrusted network paths. This work takes a new look at the security of NTP’s datagram protocol. We argue that NTP’s datagram protocol in RFC5905 is both underspecified and flawed. The NTP specifications do not sufficiently respect (1) the conflicting security requirements of different NTP modes, and (2) the mechanism NTP uses to prevent off-path attacks. A further problem is that (3) NTP’s control-query interface reveals sensitive information that can be exploited in off-path attacks. We exploit these problems in several attacks that remote attackers can use to maliciously alter a target’s time. We use network scans to find millions of IPs that are vulnerable to our attacks. Finally, we move beyond identifying attacks by developing a cryptographic model and using it to prove the security of a new backwards-compatible client/server protocol for NTP."
MAYANK VARIA,Batched differentially private information retrieval,"Private Information Retrieval (PIR) allows several clients to query a database held by one or more servers, such that the contents of their queries remain private. Prior PIR schemes have achieved sublinear communication and computation by leveraging computational assumptions, federating trust among many servers, relaxing security to permit differentially private leakage, refactoring effort into an offline stage to reduce online costs, or amortizing costs over a large batch of queries. In this work, we present an efficient PIR protocol that combines all of the above techniques to achieve constant amortized communication and computation complexity in the size of the database and constant client work. We leverage differentially private leakage in order to provide better trade-offs between privacy and efficiency. Our protocol achieves speed-ups up to and exceeding 10x in practical settings compared to state of the art PIR protocols, and can scale to batches with hundreds of millions of queries on cheap commodity AWS machines. Our protocol builds upon a new secret sharing scheme that is both incremental and non-malleable, which may be of interest to a wider audience. Our protocol provides security up to abort against malicious adversaries that can corrupt all but one party."
MAYANK VARIA,Hecate: abuse reporting in secure messengers with sealed sender,"End-to-end encryption provides strong privacy protections to billions of people, but it also complicates efforts to moderate content that can seriously harm people. To address this concern, Tyagi et al. [CRYPTO 2019] introduced the concept of asymmetric message franking (AMF), which allows people to report abusive content to a moderator, while otherwise retaining end-to-end privacy by default and even compatibility with anonymous communication systems like Signal’s sealed sender. In this work, we provide a new construction for asymmetric message franking called Hecate that is faster, more secure, and introduces additional functionality compared to Tyagi et al. First, our construction uses fewer invocations of standardized crypto primitives and operates in the plain model. Second, on top of AMF’s accountability and deniability requirements, we also add forward and backward secrecy. Third, we combine AMF with source tracing, another approach to content moderation that has previously been considered only in the setting of non-anonymous networks. Source tracing allows for messages to be forwarded, and a report only identifies the original source who created a message. To provide anonymity for senders and forwarders, we introduce a model of ""AMF with preprocessing"" whereby every client authenticates with the moderator out-of-band to receive a token that they later consume when sending a message anonymously."
MAYANK VARIA,Formalizing human ingenuity: a quantitative framework for copyright law's substantial similarity,"A central notion in U.S. copyright law is judging the substantial similarity between an original and an (allegedly) derived work. Capturing this notion has proven elusive, and the many approaches offered by case law and legal scholarship are often ill-defined, contradictory, or internally-inconsistent. This work suggests that key parts of the substantial-similarity puzzle are amendable to modeling inspired by theoretical computer science. Our proposed framework quantitatively evaluates how much ""novelty"" is needed to produce the derived work with access to the original work, versus reproducing it without access to the copyrighted elements of the original work. ""Novelty"" is captured by a computational notion of description length, in the spirit of Kolmogorov-Levin complexity, which is robust to mechanical transformations and availability of contextual information. This results in an actionable framework that could be used by courts as an aid for deciding substantial similarity. We evaluate it on several pivotal cases in copyright law and observe that the results are consistent with the rulings, and are philosophically aligned with the abstraction-filtration-comparison test of Altai."
MAYANK VARIA,Universally composable end-to-end secure messaging,
MAYANK VARIA,Callisto: a cryptographic approach to detecting serial perpetrators of sexual misconduct,"Sexual misconduct is prevalent in workplace and education settings but stigma and risk of further damage deter many victims from seeking justice. Callisto, a non-profit that has created an online sexual assault reporting platform for college campuses, is expanding its work to combat sexual assault and harassment in other industries. In this new product, users will be invited to an online ""matching escrow"" that will detect repeat perpetrators and create pathways to support for victims. Users submit encrypted data about their perpetrator, and this data can only be decrypted by the Callisto Options Counselor (a lawyer), when another user enters the identity of the same perpetrator. If the perpetrator identities match, both users will be put in touch independently with the Options Counselor, who will connect them to each other (if appropriate) and help them determine their best path towards justice. The client relationships with the Options Counselors are structured so that any client-counselor communications would be privileged. A combination of client-side encryption, encrypted communication channels, oblivious pseudo-random functions, key federation, and Shamir Secret Sharing keep data confidential in transit, at rest, and during the matching process with the guarantee that only the lawyer ever has access to user submitted data, and even then only when a match is identified."
MAYANK VARIA,Moving in next door: Network flooding as a side channel in cloud environments,"Co-locating multiple tenants' virtual machines (VMs) on the same host underpins public clouds' affordability, but sharing physical hardware also exposes consumer VMs to side channel attacks from adversarial co-residents. We demonstrate passive bandwidth measurement to perform traffic analysis attacks on co-located VMs. Our attacks do not assume a privileged position in the network or require any communication between adversarial and victim VMs. Using a single feature in the observed bandwidth data, our algorithm can identify which of 3 potential YouTube videos a co-resident VM streamed with 66% accuracy. We discuss defense from both a cloud provider's and a consumer's perspective, showing that effective defense is difficult to achieve without costly under-utilization on the part of the cloud provider or over-utilization on the part of the consumer."
MAYANK VARIA,Two-server distributed ORAM with sublinear computation and constant rounds,
MAYANK VARIA,Secret sharing MPC on FPGAs in the datacenter,"Multi-Party Computation (MPC) is a technique enabling data from several sources to be used in a secure computation revealing only the result while protecting the orig- inal data, facilitating shared utilization of data sets gathered by different entities. The presence of Field Programmable Gate Array (FPGA) hardware in datacenters can provide accelerated computing as well as low latency, high bandwidth communication that bolsters the performance of MPC and lowers the barrier to using MPC for many applications. In this work, we propose a Secret Sharing FPGA design based on the protocol described by Araki et al. [1]. We compare our hardware design to the original authors’ software implementations of Secret Sharing and to work accelerating MPC protocols based on Garbled Circuits with FPGAs. Our conclusion is that Secret Sharing in the datacenter is competitive and when implemented on FPGA hardware was able to use at least 10× fewer computer resources than the original work using CPUs."
MAYANK VARIA,"Mechanizing the proof of adaptive, information-theoretic security of cryptographic protocols in the random Oracle model","We report on our research on proving the security of multi-party cryptographic protocols using the EASYCRYPT proof assistant. We work in the computational model using the sequence of games approach, and define honest-butcurious (semi-honest) security using a variation of the real/ideal paradigm in which, for each protocol party, an adversary chooses protocol inputs in an attempt to distinguish the party's real and ideal games. Our proofs are information-theoretic, instead of being based on complexity theory and computational assumptions. We employ oracles (e.g., random oracles for hashing) whose encapsulated states depend on dynamically-made, nonprogrammable random choices. By limiting an adversary's oracle use, one may obtain concrete upper bounds on the distances between a party's real and ideal games that are expressed in terms of game parameters. Furthermore, our proofs work for adaptive adversaries, ones that, when choosing the value of a protocol input, may condition this choice on their current protocol view and oracle knowledge. We provide an analysis in EASYCRYPT of a three party private count retrieval protocol. We emphasize the lessons learned from completing this proof."
MAYANK VARIA,Arithmetic and Boolean secret sharing MPC on FPGAs in the data center,"Multi-Party Computation (MPC) is an important technique used to enable computation over confidential data from several sources. The public cloud provides a unique opportunity to enable MPC in a low latency environment. Field Programmable Gate Array (FPGA) hardware adoption allows for both MPC acceleration and utilization of low latency, high bandwidth communication networks that substantially improve the performance of MPC applications. In this work, we show how designing arithmetic and Boolean Multi-Party Computation gates for FPGAs in a cloud provide improvements to current MPC offerings and ease their use in applications such as machine learning. We focus on the usage of Secret Sharing MPC first designed by Araki et al [1] to design our FPGA MPC while also providing a comparison with those utilizing Garbled Circuits for MPC. We show that Secret Sharing MPC provides a better usage of cloud resources, specifically FPGA acceleration, than Garbled Circuits and is able to use at least a 10 × less computer resources as compared to the original design using CPUs."
MAYANK VARIA,Anonymous collocation discovery: taming the coronavirus while preserving privacy,"Successful containment of the Coronavirus pandemic rests on the ability to quickly and reliably identify those who have been in close proximity to a contagious individual. Existing tools for doing so rely on the collection of exact location information of individuals over lengthy time periods, and combining this information with other personal information. This unprecedented encroachment on individual privacy at national scales has created an outcry and risks rejection of these tools. We propose an alternative: an extremely simple scheme for providing fine-grained and timely alerts to users who have been in the close vicinity of an infected individual. Crucially, this is done while preserving the anonymity of all individuals, and without collecting or storing any personal information or location history. Our approach is based on using short-range communication mechanisms, like Bluetooth, that are available in all modern cell phones. It can be deployed with very little infrastructure, and incurs a relatively low false-positive rate compared to other collocation methods. We also describe a number of extensions and tradeoffs. We believe that the privacy guarantees provided by the scheme will encourage quick and broad voluntary adoption. When combined with sufficient testing capacity and existing best practices from healthcare professionals, we hope that this may significantly reduce the infection rate."
MAYANK VARIA,Balanced byzantine reliable broadcast with near-optimal communication and improved computation,
MAYANK VARIA,Secure multi-party computation for analytics deployed as a lightweight web application,"We describe the definition, design, implementation, and deployment of a secure multi-party computation protocol and web application. The protocol and application allow groups of cooperating parties with minimal expertise and no specialized resources to compute basic statistical analytics on their collective data sets without revealing the contributions of individual participants. The application was developed specifically to support a Boston Women’s Workforce Council (BWWC) study of wage disparities within employer organizations in the Greater Boston Area. The application has been deployed successfully to support two data collection sessions (in 2015 and in 2016) to obtain data pertaining to compensation levels across genders and demographics. Our experience provides insights into the particular security and usability requirements (and tradeoffs) a successful “MPC-as-a-service” platform design and implementation must negotiate."
MAYANK VARIA,Crypto crumple zones: enabling limited access without mass surveillance,"Governments around the world are demanding more access to encrypted data, but it has been difficult to build a system that allows the authorities some access without providing unlimited access in practice. In this paper, we present new techniques for maximizing user privacy in jurisdictions that require support for so-called “exceptional access” to encrypted data. In contrast to previous work on this topic (e.g., key escrow), our approach places most of the responsibility for achieving exceptional access on the government, rather than on the users or developers of cryptographic tools. As a result, our constructions are very simple and lightweight, and they can be easily retrofitted onto existing applications and protocols. Critically, we introduce no new third parties, and we add no new messages beyond a single new Diffie-Hellman key exchange in protocols that already use Diffie-Hellman. We present two constructions for crumpling cryptographic keys to make it possible-although arbitrarily expensive-for a government to recover the plaintext for targeted messages. Our symmetric crumpling technique uses a hash-based proof of work to impose a linear cost on the adversary for each message she wishes to recover. Additionally, our public-key crumpling method uses a novel application of Diffie-Hellman over modular arithmetic groups to create an extremely expensive puzzle that the adversary must solve before she can recover even a single message. Our initial analysis shows that we can impose an upfront cost in the range of 100Mtoseveralbilliondollarsandalinearcostbetween1K-$1M per message. We show how our constructions can easily be adapted to common tools including PGP, Signal, SRTP, full-disk encryption, and file-based encryption."
MAYANK VARIA,On the universally composable security of OpenStack,"We initiate an effort to demonstrate how we can provide a rigorous, perceptible and holistic security analysis of a very large scale system. We choose OpenStack to exemplify our approach. OpenStack is the prevalent open-source, non-proprietary package for managing cloud services and data centers. It is highly complex and consists of multiple inter-related components which are developed by separate, loosely coordinated groups. All of these properties make the security analysis of OpenStack both a crucial mission and a challenging one. We base our modeling and security analysis in the universally composable (UC) security framework, which has been so far used mainly for analyzing security of cryptographic protocols. Indeed, demonstrating how the UC framework can be used to argue about security-sensitive systems which are mostly non-cryptographic, in nature, is one of the main contributions of this work. Our analysis has the following key features: 1. It is user-centric: It stresses the security guarantees given to users of the system, in terms of privacy, correctness, and timeliness of the services. 2. It provides defense in depth: It considers the security of OpenStack even when some of the components are compromised. This departs from the traditional design approach of OpenStack, which assumes that all services are fully trusted. 3. It is modular: It formulates security properties for individual components and uses them to assert security properties of the overall system. 4. It is extendable: Due to the scale of OpenStack, we limit the analysis to some core services of OpenStack at a high level. The analysis is extendable to more detail of the services, and other services can be added to the model using the same methodology, without much conceptual difficulty. Because of the modularity of the analysis, new services can be added one by one, almost independently of each other. Although our analysis covers only a number of core components of OpenStack, it formulates some basic and important security trade offs in the design. It also naturally paves the way to a more comprehensive analysis of OpenStack. In addition, as a by-product result of our modeling, we introduce a novel tokening mechanism, RAFT, which is backward compatible with Fernet Token currently used in OpenStack. By applying the UC framework, we prove that RAFT's one-time use tokens can realize a more secure OpenStack cloud than bearer tokens do."
MAYANK VARIA,Multi-regulation computing: examining the legal and policy questions that arise from secure multiparty computation,"This work examines privacy laws and regulations that limit disclosure of personal data, and explores whether and how these restrictions apply when participants use cryptographically secure multi-party computation (MPC). By protecting data during use, MPC can help to foster the positive effects of data usage while mitigating potential negative impacts of data sharing in scenarios where participants want to analyze data that is subject to one or more privacy laws, especially when these laws are in apparent conflict so data cannot be shared in the clear. But paradoxically, most adoptions of MPC to date involve data that is not subject to any formal privacy regulation. We posit that a major impediment to the adoption of MPC is the difficulty of mapping this new technology onto the design principles of data privacy laws. To address this issue and with the goal of spurring adoption of MPC, this work introduces the first systematic framework to reason about the extent to which secure multiparty computation implicates data privacy laws. Our framework revolves around three questions: a definitional question on whether the encodings still constitute ‘personal data,’ a process question about whether the act of executing MPC constitutes a data disclosure event, and a liability question about what happens if something goes wrong. We conclude by providing advice to regulators and suggestions to early adoptors to spur uptake of MPC."
MAYANK VARIA,Automated exposure notification for COVID-19,"In the current COVID-19 pandemic, various Automated Exposure Notification (AEN) systems have been proposed to help quickly identify potential contacts of infected individuals. All these systems try to leverage the current understanding of the following factors: transmission risk, technology to address risk modeling, system policies and privacy considerations. While AEN holds promise for mitigating the spread of COVID-19, using short-range communication channels (Bluetooth) in smartphones to detect close individual contacts may be inaccurate for modeling and informing transmission risk. This work finds that the current close contact definitions may be inadequate to reduce viral spread using AEN technology. Consequently, relying on distance measurements from Bluetooth Low-Energy may not be optimal for determining risks of exposure and protecting privacy. This paper's literature analysis suggests that AEN may perform better by using broadly accessible technologies to sense the respiratory activity, mask status, or environment of participants. Moreover, the paper remains cognizant that smartphone sensors can leak private information and thus recommends additional objectives for maintaining user privacy without compromising utility for population health. This literature review and analysis will simultaneously interest (i) health professionals who desire a fundamental understanding of the design and utility of AEN systems and (ii) technologists interested in understanding their epidemiological basis in the light of recent research. Ultimately, the two disparate communities need to understand each other to assess the value of AEN systems in mitigating viral spread, whether for the COVID-19 pandemic or for future ones."
MAYANK VARIA,Conclave: secure multi-party computation on big data,"Secure Multi-Party Computation (MPC) allows mutually distrusting parties to run joint computations without revealing private data. Current MPC algorithms scale poorly with data size, which makes MPC on ""big data"" prohibitively slow and inhibits its practical use. Many relational analytics queries can maintain MPC's end-to-end security guarantee without using cryptographic MPC techniques for all operations. Conclave is a query compiler that accelerates such queries by transforming them into a combination of data-parallel, local cleartext processing and small MPC steps. When parties trust others with specific subsets of the data, Conclave applies new hybrid MPC-cleartext protocols to run additional steps outside of MPC and improve scalability further. Our Conclave prototype generates code for cleartext processing in Python and Spark, and for secure MPC using the Sharemind and Obliv-C frameworks. Conclave scales to data sets between three and six orders of magnitude larger than state-of-the-art MPC frameworks support on their own. Thanks to its hybrid protocols and additional optimizations, Conclave also substantially outperforms SMCQL, the most similar existing system."
MAYANK VARIA,DEMO: integrating MPC in big data workflows,"Secure multi-party computation (MPC) allows multiple parties to perform a joint computation without disclosing their private inputs. Many real-world joint computation use cases, however, involve data analyses on very large data sets, and are implemented by software engineers who lack MPC knowledge. Moreover, the collaborating parties – e.g., several companies – often deploy different data analytics stacks internally. These restrictions hamper the realworld usability of MPC. To address these challenges, we combine existing MPC frameworks with data-parallel analytics frameworks by extending the Musketeer big data workflow manager [4]. Musketeer automatically generates code for both the sensitive parts of a workflow, which are executed in MPC, and the remaining portions of the computation, which run on scalable, widely-deployed analytics systems. In a prototype use case, we compute the HerfindahlHirschman Index (HHI), an index of market concentration used in antitrust regulation, on an aggregate 156 GB of taxi trip data over five transportation companies. Our implementation computes the HHI in about 20 minutes using a combination of Hadoop and VIFF [1], while even “mixed mode” MPC with VIFF alone would have taken many hours. Finally, we discuss future research questions that we seek to address using our approach."
MAYANK VARIA,An analysis of acceptance policies for blockchain transactions,"The standard acceptance policy for a cryptocurrency transaction at most exchanges is to wait until the transaction is placed in the blockchain and followed by a certain number of blocks. However, as noted by Sompolinsky and Zohar [16], the amount of time for blocks to arrive should also be taken into account as it affects the probability of double spending. Specifically, they propose a dynamic policy for transaction acceptance that depends on both the number of confirmations and the amount of time since transaction broadcast. In this work we study the implications of using such a policy compared with the standard option that ignores block timing information. Using an exact expression for the probability of double spend, via numerical results, we analyze time to transaction acceptance (performance) as well as the time and cost to perform a double spend attack (security). We show that while expected time required for transaction acceptance is improved using a dynamic policy, the time and cost to perform a double spend attack for a particular transaction is reduced."
MAYANK VARIA,Privacy-preserving automated exposure notification,"Contact tracing is an essential component of public health efforts to slow the spread of COVID-19 and other infectious diseases. Automating parts of the contact tracing process has the potential to significantly increase its scalability and efficacy, but also raises an array of privacy concerns, including the risk of unwanted identification of infected individuals and clandestine collection of privacy-invasive data about the population at large. In this paper, we focus on automating the exposure notification part of contact tracing, which notifies people who have been in close proximity to infected people of their potential exposure to the virus. This work is among the first to focus on the privacy aspects of automated exposure notification. We introduce two privacy-preserving exposure notification schemes based on proximity detection. Both systems are decentralized - no central entity has access to sensitive data. The first scheme is simple and highly efficient, and provides strong privacy for non-diagnosed individuals and some privacy for diagnosed individuals. The second scheme provides enhanced privacy guarantees for diagnosed individuals, at some cost to efficiency. We provide formal definitions for automated exposure notification and its security, and we prove the security of our constructions with respect to these definitions."
MAYANK VARIA,Protecting cryptography against compelled self-incrimination,"The information security community has devoted substantial effort to the design, development, and universal deployment of strong encryption schemes that withstand search and seizure by computationally- powerful nation-state adversaries. In response, governments are increasingly turning to a different tactic: issuing subpoenas that compel people to decrypt devices themselves, under the penalty of contempt of court if they do not comply. Compelled decryption subpoenas sidestep questions around government search powers that have dominated the Crypto Wars and instead touch upon a different (and still unsettled) area of the law: how encryption relates to a person's right to silence and against self-incrimination. In this work, we provide a rigorous, composable definition of a critical piece of the law that determines whether cryptosystems are vulnerable to government compelled disclosure in the United States. We justify our definition by showing that it is consistent with prior court cases. We prove that decryption is often not compellable by the government under our definition. Conversely, we show that many techniques that bolster security overall can leave one more vulnerable to compelled disclosure. As a result, we initiate the study of protecting cryptographic protocols against the threat of future compelled disclosure. We find that secure multi-party computation is particularly vulnerable to this threat, and we design and implement new schemes that are provably resilient in the face of government compelled disclosure. We believe this work should in influence the design of future cryptographic primitives and contribute toward the legal debates over the constitutionality of compelled decryption."
MAYANK VARIA,SoK: cryptographically protected database search,"Protected database search systems cryptographically isolate the roles of reading from, writing to, and administering the database. This separation limits unnecessary administrator access and protects data in the case of system breaches. Since protected search was introduced in 2000, the area has grown rapidly, systems are offered by academia, start-ups, and established companies. However, there is no best protected search system or set of techniques. Design of such systems is a balancing act between security, functionality, performance, and usability. This challenge is made more difficult by ongoing database specialization, as some users will want the functionality of SQL, NoSQL, or NewSQL databases. This database evolution will continue, and the protected search community should be able to quickly provide functionality consistent with newly invented databases. At the same time, the community must accurately and clearly characterize the tradeoffs between different approaches. To address these challenges, we provide the following contributions:(1) An identification of the important primitive operations across database paradigms. We find there are a small number of base operations that can be used and combined to support a large number of database paradigms.(2) An evaluation of the current state of protected search systems in implementing these base operations. This evaluation describes the main approaches and tradeoffs for each base operation. Furthermore, it puts protected search in the context of unprotected search, identifying key gaps in functionality.(3) An analysis of attacks against protected search for different base queries.(4) A roadmap and tools for transforming a protected search system into a protected database, including an open-source performance evaluation platform and initial user opinions of protected search."
MAYANK VARIA,"Role-based ecosystem for the design, development, and deployment of secure multi-party data analytics applications","Software applications that employ secure multi-party computation (MPC) can empower individuals and organizations to benefit from privacy-preserving data analyses when data sharing is encumbered by confidentiality concerns, legal constraints, or corporate policies. MPC is already being incorporated into software solutions in some domains; however, individual use cases do not fully convey the variety, extent, and complexity of the opportunities of MPC. This position paper articulates a rolebased perspective that can provide some insight into how future research directions, infrastructure development and evaluation approaches, and deployment practices for MPC may evolve. Drawing on our own lessons from existing real-world deployments and the fundamental characteristics of MPC that make it a compelling technology, we propose a role-based conceptual framework for describing MPC deployment scenarios. Our framework acknowledges and leverages a novel assortment of roles that emerge from the fundamental ways in which MPC protocols support federation of functionalities and responsibilities. Defining these roles using the new opportunities for federation that MPC enables in turn can help identify and organize the capabilities, concerns, incentives, and trade-offs that affect the entities (software engineers, government regulators, corporate executives, end-users, and others) that participate in an MPC deployment scenario. This framework can not only guide the development of an ecosystem of modular and composable MPC tools, but can make explicit some of the opportunities that researchers and software engineers (and any organizations they form) have to differentiate and specialize the artifacts and services they choose to design, develop, and deploy. We demonstrate how this framework can be used to describe existing MPC deployment scenarios, how new opportunities in a scenario can be observed by disentangling roles inhabited by the involved parties, and how this can motivate the development of MPC libraries and software tools that specialize not by application domain but by role."
MAYANK VARIA,Case study: disclosure of indirect device fingerprinting in privacy policies,"Recent developments in online tracking make it harder for individuals to detect and block trackers. This is especially true for de- vice fingerprinting techniques that websites use to identify and track individual devices. Direct trackers { those that directly ask the device for identifying information { can often be blocked with browser configu- rations or other simple techniques. However, some sites have shifted to indirect tracking methods, which attempt to uniquely identify a device by asking the browser to perform a seemingly-unrelated task. One type of indirect tracking known as Canvas fingerprinting causes the browser to render a graphic recording rendering statistics as a unique identifier. Even experts find it challenging to discern some indirect fingerprinting methods. In this work, we aim to observe how indirect device fingerprint- ing methods are disclosed in privacy policies, and consider whether the disclosures are sufficient to enable website visitors to block the track- ing methods. We compare these disclosures to the disclosure of direct fingerprinting methods on the same websites. Our case study analyzes one indirect ngerprinting technique, Canvas fingerprinting. We use an existing automated detector of this fingerprint- ing technique to conservatively detect its use on Alexa Top 500 websites that cater to United States consumers, and we examine the privacy poli- cies of the resulting 28 websites. Disclosures of indirect fingerprinting vary in specificity. None described the specific methods with enough granularity to know the website used Canvas fingerprinting. Conversely, many sites did provide enough detail about usage of direct fingerprint- ing methods to allow a website visitor to reliably detect and block those techniques. We conclude that indirect fingerprinting methods are often technically difficult to detect, and are not identified with specificity in legal privacy notices. This makes indirect fingerprinting more difficult to block, and therefore risks disturbing the tentative armistice between individuals and websites currently in place for direct fingerprinting. This paper illustrates differences in fingerprinting approaches, and explains why technologists, technology lawyers, and policymakers need to appreciate the challenges of indirect fingerprinting."
MAYANK VARIA,On the universally composable security of OpenStack,"We initiate an effort to demonstrate how we can provide a rigorous, perceptible and holistic security analysis of a very large scale system. We choose OpenStack to exemplify our approach. OpenStack is the prevalent open-source, non-proprietary package for managing cloud services and data centers. It is highly complex and consists of multiple inter-related components which are developed by separate, loosely coordinated groups. All of these properties make the security analysis of OpenStack both a crucial mission and a challenging one. We base our modeling and security analysis in the universally composable (UC) security framework, which has been so far used mainly for analyzing security of cryptographic protocols. Indeed, demonstrating how the UC framework can be used to argue about security-sensitive systems which are mostly non-cryptographic, in nature, is one of the main contributions of this work. Our analysis has the following key features: 1. It is user-centric: It stresses the security guarantees given to users of the system, in terms of privacy, correctness, and timeliness of the services. 2. It provides defense in depth: It considers the security of OpenStack even when some of the components are compromised. This departs from the traditional design approach of OpenStack, which assumes that all services are fully trusted. 3. It is modular: It formulates security properties for individual components and uses them to assert security properties of the overall system. 4. It is extendable: Due to the scale of OpenStack, we limit the analysis to some core services of OpenStack at a high level. The analysis is extendable to more detail of the services, and other services can be added to the model using the same methodology, without much conceptual di culty. Because of the modularity of the analysis, new services can be added one by one, almost independently of each other. Although our analysis covers only a number of core components of OpenStack, it formulates some basic and important security trade o s in the design. It also naturally paves the way to a more comprehensive analysis of OpenStack. In addition, as a by-product result of our modeling, we introduce a novel tokening mechanism, RAFT, which is backward compatible with Fernet Token currently used in OpenStack. By applying the UC framework, we prove that RAFT's one-time use tokens can realize a more secure OpenStack cloud than bearer tokens do."
MAYANK VARIA,From usability to secure computing and back again,"Secure multi-party computation (MPC) allows multiple parties to jointly compute the output of a function while preserving the privacy of any individual party’s inputs to that function. As MPC protocols transition from research prototypes to realworld applications, the usability of MPC-enabled applications is increasingly critical to their successful deployment and widespread adoption. Our Web-MPC platform, designed with a focus on usability, has been deployed for privacy-preserving data aggregation initiatives with the City of Boston and the Greater Boston Chamber of Commerce. After building and deploying an initial version of the platform, we conducted a heuristic evaluation to identify usability improvements and implemented corresponding application enhancements. However, it is difficult to gauge the effectiveness of these changes within the context of real-world deployments using traditional web analytics tools without compromising the security guarantees of the platform. This work consists of two contributions that address this challenge: (1) the Web-MPC platform has been extended with the capability to collect web analytics using existing MPC protocols, and (2) as a test of this feature and a way to inform future work, this capability has been leveraged to conduct a usability study comparing the two versions ofWeb-MPC. While many efforts have focused on ways to enhance the usability of privacy-preserving technologies, this study serves as a model for using a privacy-preserving data-driven approach to evaluate and enhance the usability of privacy-preserving websites and applications deployed in realworld scenarios. Data collected in this study yields insights into the relationship between usability and security; these can help inform future implementations of MPC solutions."
MAYANK VARIA,EasyUC: using EasyCrypt to mechanize proofs of universally composable security,"We present a methodology for using the EasyCrypt proof assistant (originally designed for mechanizing the generation of proofs of game-based security of cryptographic schemes and protocols) to mechanize proofs of security of cryptographic protocols within the universally composable (UC) security framework. This allows, for the first time, the mechanization and formal verification of the entire sequence of steps needed for proving simulation-based security in a modular way: Specifying a protocol and the desired ideal functionality; Constructing a simulator and demonstrating its validity, via reduction to hard computational problems; Invoking the universal composition operation and demonstrating that it indeed preserves security. We demonstrate our methodology on a simple example: stating and proving the security of secure message communication via a one-time pad, where the key comes from a Diffie-Hellman key-exchange, assuming ideally authenticated communication. We first put together EasyCrypt-verified proofs that: (a) the Diffie-Hellman protocol UC-realizes an ideal key-exchange functionality, assuming hardness of the Decisional Diffie-Hellman problem, and (b) one-time-pad encryption, with a key obtained using ideal key-exchange, UC-realizes an ideal secure-communication functionality. We then mechanically combine the two proofs into an EasyCrypt-verified proof that the composed protocol realizes the same ideal secure-communication functionality. Although formulating a methodology that is both sound and workable has proven to be a complex task, we are hopeful that it will prove to be the basis for mechanized UC security analyses for significantly more complex protocols and tasks."
MAYANK VARIA,Principal inertia components and applications,"We explore properties and applications of the principal inertia components (PICs) between two discrete random variables X and Y. The PICs lie in the intersection of information and estimation theory, and provide a fine-grained decomposition of the dependence between X and Y. Moreover, the PICs describe which functions of X can or cannot be reliably inferred (in terms of MMSE), given an observation of Y. We demonstrate that the PICs play an important role in information theory, and they can be used to characterize information-theoretic limits of certain estimation problems. In privacy settings, we prove that the PICs are related to the fundamental limits of perfect privacy."
MAYANK VARIA,Privacy with estimation guarantees,"We study the central problem in data privacy: how to share data with an analyst while providing both privacy and utility guarantees to the user that owns the data. In this setting, we present an estimation-theoretic analysis of the privacy-utility trade-o (PUT). Here, an analyst is allowed to reconstruct (in a mean-squared error sense) certain functions of the data (utility), while other private functions should not be reconstructed with distortion below a certain thresh- old (privacy). We demonstrate how chi-square information captures the fundamental PUT in this case and provide bounds for the best PUT. We propose a convex program to compute privacy-assuring mappings when the functions to be disclosed and hidden are known a priori and the data distribution is known. We derive lower bounds on the minimum mean-squared error of estimating a target function from the disclosed data and evaluate the robustness of our approach when an empirical distribution is used to compute the privacy-assuring mappings in- stead of the true data distribution. We illustrate the proposed approach through two numerical experiments."
MAYANK VARIA,Batched differentially private information retrieval,
MAYANK VARIA,Secrecy: Secure collaborative analytics on secret-shared data,"We study the problem of composing and optimizing relational query plans under secure multi-party computation (MPC). MPC enables mutually distrusting parties to jointly compute arbitrary functions over private data, while preserving data privacy from each other and from external entities. In this paper, we propose a relational MPC framework based on replicated secret sharing. We define a set of oblivious operators, explain the secure primitives they rely on, and provide an analysis of their costs in terms of operations and inter-party communication. We show how these operators can be composed to form end-to-end oblivious queries, and we introduce logical and physical optimizations that dramatically reduce the space and communication requirements during query execution, in some cases from quadratic to linear with respect to the cardinality of the input. We provide an efficient implementation of our framework, called Secrecy, and evaluate it using real queries from several MPC application areas. Our results demonstrate that the optimizations we propose can result in up to 1000× lower execution times compared to baseline approaches, enabling Secrecy to outperform state-of-the-art frameworks and compute MPC queries on millions of input rows with a single thread per party."
MAYANK VARIA,QueryShield: cryptographically secure analytics in the cloud,"We present a demonstration of QueryShield, a service for streamlined, cryptographically secure data analytics in the cloud. With QueryShield, data analysts can advertise analysis descriptions to data owners, who may agree to participate in a computation for profit or for the greater good, provided that their data remain private. QueryShield supports relational and time series analytics with provable data privacy guarantees using secure multi-party computation (MPC). At the same time, it makes MPC accessible to non-expert users by offering a familiar web interface and fully-automated orchestration of cryptographic computations. We devise three demonstration scenarios for conference attendees: (i) an interactive survey of private employment information to estimate the industry-academia wage gap in the data management community, (ii) a relational analysis that identifies credit score anomalies in sensitive customer data from multiple credit agencies, and (iii) a medical use case that assesses the effectiveness of insulin dose frequency in a patient cohort."
ANUSHYA CHANDRAN,Shortcuts to dynamic polarization,"Dynamic polarization protocols aim to hyperpolarize a spin bath by transferring spin polarization from a well-controlled qubit such as a quantum dot or a color defect. Building on techniques from shortcuts to adiabaticity, we design fast and efficient dynamic polarization protocols in central spin models that apply to dipolarly interacting systems. The protocols maximize the transfer of polarization via bright states at a nearby integrable point, exploit the integrability-breaking terms to reduce the statistical weight on dark states that do not transfer polarization, and realize experimentally accessible local counterdiabatic driving through Floquet engineering. A master equation treatment suggests that the protocol duration scales linearly with the number of bath spins with a prefactor that can be orders of magnitude smaller than that of unassisted protocols. This work opens pathways to cool spin baths and extend qubit coherence times for applications in quantum information processing and metrology."
ANUSHYA CHANDRAN,Swift heat transfer by fast-forward driving in open quantum systems,"Typically, time-dependent thermodynamic protocols need to run asymptotically slowly in order to avoid dissipative losses. By adapting ideas from counterdiabatic driving and Floquet engineering to open systems, we develop fast-forward protocols for swiftly thermalizing a system oscillator locally coupled to an optical phonon bath. These protocols control the system frequency and the system-bath coupling to induce a resonant state exchange between the system and the bath. We apply the fast-forward protocols to realize a fast approximate Otto engine operating at high power near the Carnot efficiency. Our results suggest design principles for swift cooling protocols in coupled many-body systems."
ANUSHYA CHANDRAN,Persistent dark states in anisotropic central spin models,"Long-lived dark states, in which an experimentally accessible qubit is not in thermal equilibrium with a surrounding spin bath, are pervasive in solid-state systems. We explain the ubiquity of dark states in a large class of inhomogeneous central spin models using the proximity to integrable lines with exact dark eigenstates. At numerically accessible sizes, dark states persist as eigenstates at large deviations from integrability, and the qubit retains memory of its initial polarization at long times. Although the eigenstates of the system are chaotic, exhibiting exponential sensitivity to small perturbations, they do not satisfy the eigenstate thermalization hypothesis. Rather, we predict long relaxation times that increase exponentially with system size. We propose that this intermediate chaotic but non-ergodic regime characterizes mesoscopic quantum dot and diamond defect systems, as we see no numerical tendency towards conventional thermalization with a finite relaxation time."
ANUSHYA CHANDRAN,Integrability and quench dynamics in the spin-1 central spin XX model,"Central spin models provide an idealized description of interactions between a central degree of freedom and a mesoscopic environment of surrounding spins. We show that the family of models with a spin-1 at the center and XX interactions of arbitrary strength with surrounding spins is integrable. Specifically, we derive an extensive set of conserved quantities and obtain the exact eigenstates using the Bethe ansatz. As in the homogenous limit, the states divide into two exponentially large classes: bright states, in which the spin-1 is entangled with its surroundings, and dark states, in which it is not. On resonance, the bright states further break up into two classes depending on their weight on states with central spin polarization zero. These classes are probed in quench dynamics wherein they prevent the central spin from reaching thermal equilibrium. In the single spin-flip sector we explicitly construct the bright states and show that the central spin exhibits oscillatory dynamics as a consequence of the semilocalization of these eigenstates. We relate the integrability to the closely related class of integrable Richardson-Gaudin models, and conjecture that the spin-s central spin XX model is integrable for any s."
JOHN L CELENZA,Auxin and tryptophan homeostasis are facilitated by the ISS1/VAS1 aromatic aminotransferase in arabidopsis,"Indole-3-acetic acid (IAA) plays a critical role in regulating numerous aspects of plant growth and development. While there is much genetic support for tryptophan-dependent (Trp-D) IAA synthesis pathways, there is little genetic evidence for tryptophan-independent (Trp-I) IAA synthesis pathways. Using Arabidopsis, we identified two mutant alleles of ISS1 ( I: ndole S: evere S: ensitive) that display indole-dependent IAA overproduction phenotypes including leaf epinasty and adventitious rooting. Stable isotope labeling showed that iss1, but not WT, uses primarily Trp-I IAA synthesis when grown on indole-supplemented medium. In contrast, both iss1 and WT use primarily Trp-D IAA synthesis when grown on unsupplemented medium. iss1 seedlings produce 8-fold higher levels of IAA when grown on indole and surprisingly have a 174-fold increase in Trp. These findings indicate that the iss1 mutant's increase in Trp-I IAA synthesis is due to a loss of Trp catabolism. ISS1 was identified as At1g80360, a predicted aromatic aminotransferase, and in vitro and in vivo analysis confirmed this activity. At1g80360 was previously shown to primarily carry out the conversion of indole-3-pyruvic acid to Trp as an IAA homeostatic mechanism in young seedlings. Our results suggest that in addition to this activity, in more mature plants ISS1 has a role in Trp catabolism and possibly in the metabolism of other aromatic amino acids. We postulate that this loss of Trp catabolism impacts the use of Trp-D and/or Trp-I IAA synthesis pathways."
CHRISTOPHER WELLS,"Trump, Twitter, and news media responsiveness: a media systems approach","How populists engage with media of various types, and are treated by those media, are questions of international interest. In the United States, Donald Trump stands out for both his populism-inflected campaign style and his success at attracting media attention. This article examines how interactions between candidate communications, social media, partisan media, and news media combined to shape attention to Trump, Clinton, Cruz, and Sanders during the 2015–2016 American presidential primary elections. We identify six major components of the American media system and measure candidates’ efforts to gain attention from them. Our results demonstrate that social media activity, in the form of retweets of candidate posts, provided a significant boost to news media coverage of Trump, but no comparable boost for other candidates. Furthermore, Trump tweeted more at times when he had recently garnered less of a relative advantage in news attention, suggesting he strategically used Twitter to trigger coverage."
CHRISTOPHER WELLS,The temporal turn in communication research: time series analyses sing computational approaches,"Some of the most pioneering work in our field is occurring where emerging computational approaches are meeting time series analytic techniques. Combining these methods is helping scholars improve our understanding of phenomena as varied as news and issue attention cycles, physiological responses to communication exposure, changes in mass opinion, and the dynamics between social media and legacy news media. In this article, we summarize the current state of computational communication science techniques to generate sequential data for use in time series analysis and suggest directions for further development. In particular, we consider the long-standing place of temporal dynamics for our field’s main theories; overview recent work combining computational science with time series analysis; present narrative accounts of two major research programs in this area; and review techniques of time series analysis, including major concerns for communication researchers working in the area."
CHRISTOPHER WELLS,The long-baseline neutrino experiment: exploring fundamental symmetries of the universe,"The preponderance of matter over antimatter in the early Universe, the dynamics of the supernova bursts that produced the heavy elements necessary for life and whether protons eventually decay --- these mysteries at the forefront of particle physics and astrophysics are key to understanding the early evolution of our Universe, its current state and its eventual fate. The Long-Baseline Neutrino Experiment (LBNE) represents an extensively developed plan for a world-class experiment dedicated to addressing these questions. LBNE is conceived around three central components: (1) a new, high-intensity neutrino source generated from a megawatt-class proton accelerator at Fermi National Accelerator Laboratory, (2) a near neutrino detector just downstream of the source, and (3) a massive liquid argon time-projection chamber deployed as a far detector deep underground at the Sanford Underground Research Facility. This facility, located at the site of the former Homestake Mine in Lead, South Dakota, is approximately 1,300 km from the neutrino source at Fermilab -- a distance (baseline) that delivers optimal sensitivity to neutrino charge-parity symmetry violation and mass ordering effects. This ambitious yet cost-effective design incorporates scalability and flexibility and can accommodate a variety of upgrades and contributions. With its exceptional combination of experimental configuration, technical capabilities, and potential for transformative discoveries, LBNE promises to be a vital facility for the field of particle physics worldwide, providing physicists from around the globe with opportunities to collaborate in a twenty to thirty year program of exciting science. In this document we provide a comprehensive overview of LBNE's scientific objectives, its place in the landscape of neutrino physics worldwide, the technologies it will incorporate and the capabilities it will possess."
YUAN SUN,Development and validation of a prognostic risk score system for COVID-19 inpatients: a multi-center retrospective study in China,"Coronavirus disease 2019 (COVID-19) has become a worldwide pandemic. Hospitalized patients of COVID-19 suffer from a high mortality rate, motivating the development of convenient and practical methods that allow clinicians to promptly identify high-risk patients. Here, we have developed a risk score using clinical data from 1479 inpatients admitted to Tongji Hospital, Wuhan, China (development cohort) and externally validated with data from two other centers: 141 inpatients from Jinyintan Hospital, Wuhan, China (validation cohort 1) and 432 inpatients from The Third People's Hospital of Shenzhen, Shenzhen, China (validation cohort 2). The risk score is based on three biomarkers that are readily available in routine blood samples and can easily be translated into a probability of death. The risk score can predict the mortality of individual patients more than 12 d in advance with more than 90% accuracy across all cohorts. Moreover, the Kaplan-Meier score shows that patients can be clearly differentiated upon admission as low, intermediate, or high risk, with an area under the curve (AUC) score of 0.9551. In summary, a simple risk score has been validated to predict death in patients infected with severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2); it has also been validated in independent cohorts."
YUAN SUN,First Sagittarius A* Event Horizon Telescope results. V. Testing astrophysical models of the galactic center black hole,"In this paper we provide a first physical interpretation for the Event Horizon Telescope's (EHT) 2017 observations of Sgr A*. Our main approach is to compare resolved EHT data at 230 GHz and unresolved non-EHT observations from radio to X-ray wavelengths to predictions from a library of models based on time-dependent general relativistic magnetohydrodynamics simulations, including aligned, tilted, and stellar-wind-fed simulations; radiative transfer is performed assuming both thermal and nonthermal electron distribution functions. We test the models against 11 constraints drawn from EHT 230 GHz data and observations at 86 GHz, 2.2 μm, and in the X-ray. All models fail at least one constraint. Light-curve variability provides a particularly severe constraint, failing nearly all strongly magnetized (magnetically arrested disk (MAD)) models and a large fraction of weakly magnetized models. A number of models fail only the variability constraints. We identify a promising cluster of these models, which are MAD and have inclination i ≤ 30°. They have accretion rate (5.2–9.5) × 10−9 M ⊙ yr−1, bolometric luminosity (6.8–9.2) × 1035 erg s−1, and outflow power (1.3–4.8) × 1038 erg s−1. We also find that all models with i ≥ 70° fail at least two constraints, as do all models with equal ion and electron temperature; exploratory, nonthermal model sets tend to have higher 2.2 μm flux density; and the population of cold electrons is limited by X-ray constraints due to the risk of bremsstrahlung overproduction. Finally, we discuss physical and numerical limitations of the models, highlighting the possible importance of kinetic effects and duration of the simulations."
YUAN SUN,First M87 Event Horizon Telescope results. VII. Polarization of the ring,"In 2017 April, the Event Horizon Telescope (EHT) observed the near-horizon region around the supermassive black hole at the core of the M87 galaxy. These 1.3 mm wavelength observations revealed a compact asymmetric ring-like source morphology. This structure originates from synchrotron emission produced by relativistic plasma located in the immediate vicinity of the black hole. Here we present the corresponding linear-polarimetric EHT images of the center of M87. We find that only a part of the ring is significantly polarized. The resolved fractional linear polarization has a maximum located in the southwest part of the ring, where it rises to the level of ∼15%. The polarization position angles are arranged in a nearly azimuthal pattern. We perform quantitative measurements of relevant polarimetric properties of the compact emission and find evidence for the temporal evolution of the polarized source structure over one week of EHT observations. The details of the polarimetric data reduction and calibration methodology are provided. We carry out the data analysis using multiple independent imaging and modeling techniques, each of which is validated against a suite of synthetic data sets. The gross polarimetric structure and its apparent evolution with time are insensitive to the method used to reconstruct the image. These polarimetric images carry information about the structure of the magnetic fields responsible for the synchrotron emission. Their physical interpretation is discussed in an accompanying publication."
YUAN SUN,First M87 Event Horizon Telescope results. VIII. Magnetic field structure near The Event Horizon,"Event Horizon Telescope (EHT) observations at 230 GHz have now imaged polarized emission around the supermassive black hole in M87 on event-horizon scales. This polarized synchrotron radiation probes the structure of magnetic fields and the plasma properties near the black hole. Here we compare the resolved polarization structure observed by the EHT, along with simultaneous unresolved observations with the Atacama Large Millimeter/submillimeter Array, to expectations from theoretical models. The low fractional linear polarization in the resolved image suggests that the polarization is scrambled on scales smaller than the EHT beam, which we attribute to Faraday rotation internal to the emission region. We estimate the average density n_e ∼ 10^4–7 cm^−3, magnetic field strength B ∼ 1–30 G, and electron temperature T_e ∼ (1–12) × 10^10 K of the radiating plasma in a simple one-zone emission model. We show that the net azimuthal linear polarization pattern may result from organized, poloidal magnetic fields in the emission region. In a quantitative comparison with a large library of simulated polarimetric images from general relativistic magnetohydrodynamic (GRMHD) simulations, we identify a subset of physical models that can explain critical features of the polarimetric EHT observations while producing a relativistic jet of sufficient power. The consistent GRMHD models are all of magnetically arrested accretion disks, where near-horizon magnetic fields are dynamically important. We use the models to infer a mass accretion rate onto the black hole in M87 of (3–20) × 10^−4 M ⊙ yr^−1."
YUAN SUN,Resolving the inner parsec of the blazar J1924–2914 with the event horizon telescope,"The blazar J1924–2914 is a primary Event Horizon Telescope (EHT) calibrator for the Galactic center’s black hole Sagittarius A*. Here we present the first total and linearly polarized intensity images of this source obtained with the unprecedented 20 μas resolution of the EHT. J1924–2914 is a very compact flat-spectrum radio source with strong optical variability and polarization. In April 2017 the source was observed quasi-simultaneously with the EHT (April 5–11), the Global Millimeter VLBI Array (April 3), and the Very Long Baseline Array (April 28), giving a novel view of the source at four observing frequencies, 230, 86, 8.7, and 2.3 GHz. These observations probe jet properties from the subparsec to 100 pc scales. We combine the multifrequency images of J1924–2914 to study the source morphology. We find that the jet exhibits a characteristic bending, with a gradual clockwise rotation of the jet projected position angle of about 90° between 2.3 and 230 GHz. Linearly polarized intensity images of J1924–2914 with the extremely fine resolution of the EHT provide evidence for ordered toroidal magnetic fields in the blazar compact core."
YUAN SUN,A universal power-law prescription for variability from synthetic images of black hole accretion flows,"We present a framework for characterizing the spatiotemporal power spectrum of the variability expected from the horizon-scale emission structure around supermassive black holes, and we apply this framework to a library of general relativistic magnetohydrodynamic (GRMHD) simulations and associated general relativistic ray-traced images relevant for Event Horizon Telescope (EHT) observations of Sgr A*. We find that the variability power spectrum is generically a red-noise process in both the temporal and spatial dimensions, with the peak in power occurring on the longest timescales and largest spatial scales. When both the time-averaged source structure and the spatially integrated light-curve variability are removed, the residual power spectrum exhibits a universal broken power-law behavior. On small spatial frequencies, the residual power spectrum rises as the square of the spatial frequency and is proportional to the variance in the centroid of emission. Beyond some peak in variability power, the residual power spectrum falls as that of the time-averaged source structure, which is similar across simulations; this behavior can be naturally explained if the variability arises from a multiplicative random field that has a steeper high-frequency power-law index than that of the time-averaged source structure. We briefly explore the ability of power spectral variability studies to constrain physical parameters relevant for the GRMHD simulations, which can be scaled to provide predictions for black holes in a range of systems in the optically thin regime. We present specific expectations for the behavior of the M87* and Sgr A* accretion flows as observed by the EHT."
YUAN SUN,Millimeter light curves of Sagittarius A* observed during the 2017 Event Horizon Telescope campaign,"The Event Horizon Telescope (EHT) observed the compact radio source, Sagittarius A* (Sgr A*), in the Galactic Center on 2017 April 5–11 in the 1.3 mm wavelength band. At the same time, interferometric array data from the Atacama Large Millimeter/submillimeter Array and the Submillimeter Array were collected, providing Sgr A* light curves simultaneous with the EHT observations. These data sets, complementing the EHT very long baseline interferometry, are characterized by a cadence and signal-to-noise ratio previously unattainable for Sgr A* at millimeter wavelengths, and they allow for the investigation of source variability on timescales as short as a minute. While most of the light curves correspond to a low variability state of Sgr A*, the April 11 observations follow an X-ray flare and exhibit strongly enhanced variability. All of the light curves are consistent with a red-noise process, with a power spectral density (PSD) slope measured to be between −2 and −3 on timescales between 1 minute and several hours. Our results indicate a steepening of the PSD slope for timescales shorter than 0.3 hr. The spectral energy distribution is flat at 220 GHz, and there are no time lags between the 213 and 229 GHz frequency bands, suggesting low optical depth for the event horizon scale source. We characterize Sgr A*’s variability, highlighting the different behavior observed just after the X-ray flare, and use Gaussian process modeling to extract a decorrelation timescale and a PSD slope. We also investigate the systematic calibration uncertainties by analyzing data from independent data reduction pipelines."
YUAN SUN,Selective dynamical imaging of interferometric data,"Recent developments in very long baseline interferometry (VLBI) have made it possible for the Event Horizon Telescope (EHT) to resolve the innermost accretion flows of the largest supermassive black holes on the sky. The sparse nature of the EHT’s (u, v)-coverage presents a challenge when attempting to resolve highly time-variable sources. We demonstrate that the changing (u, v)-coverage of the EHT can contain regions of time over the course of a single observation that facilitate dynamical imaging. These optimal time regions typically have projected baseline distributions that are approximately angularly isotropic and radially homogeneous. We derive a metric of coverage quality based on baseline isotropy and density that is capable of ranking array configurations by their ability to produce accurate dynamical reconstructions. We compare this metric to existing metrics in the literature and investigate their utility by performing dynamical reconstructions on synthetic data from simulated EHT observations of sources with simple orbital variability. We then use these results to make recommendations for imaging the 2017 EHT Sgr A* data set."
YUAN SUN,First Sagittarius A* Event Horizon Telescope results. VI. Testing the black hole metric,"Astrophysical black holes are expected to be described by the Kerr metric. This is the only stationary, vacuum, axisymmetric metric, without electromagnetic charge, that satisfies Einstein’s equations and does not have pathologies outside of the event horizon. We present new constraints on potential deviations from the Kerr prediction based on 2017 EHT observations of Sagittarius A* (Sgr A*). We calibrate the relationship between the geometrically defined black hole shadow and the observed size of the ring-like images using a library that includes both Kerr and non-Kerr simulations. We use the exquisite prior constraints on the mass-to-distance ratio for Sgr A* to show that the observed image size is within ∼10% of the Kerr predictions. We use these bounds to constrain metrics that are parametrically different from Kerr, as well as the charges of several known spacetimes. To consider alternatives to the presence of an event horizon, we explore the possibility that Sgr A* is a compact object with a surface that either absorbs and thermally reemits incident radiation or partially reflects it. Using the observed image size and the broadband spectrum of Sgr A*, we conclude that a thermal surface can be ruled out and a fully reflective one is unlikely. We compare our results to the broader landscape of gravitational tests. Together with the bounds found for stellar-mass black holes and the M87 black hole, our observations provide further support that the external spacetimes of all black holes are described by the Kerr metric, independent of their mass."
YUAN SUN,Polarimetric properties of Event Horizon Telescope targets from ALMA,"We present the results from a full polarization study carried out with the Atacama Large Millimeter/submillimeter Array (ALMA) during the first Very Long Baseline Interferometry (VLBI) campaign, which was conducted in 2017 April in the λ3 mm and λ1.3 mm bands, in concert with the Global mm-VLBI Array (GMVA) and the Event Horizon Telescope (EHT), respectively. We determine the polarization and Faraday properties of all VLBI targets, including Sgr A*, M87, and a dozen radio-loud active galactic nuclei (AGNs), in the two bands at several epochs in a time window of 10 days. We detect high linear polarization fractions (2%–15%) and large rotation measures (RM &gt; 103.3–105.5 rad m−2), confirming the trends of previous AGN studies at millimeter wavelengths. We find that blazars are more strongly polarized than other AGNs in the sample, while exhibiting (on average) order-of-magnitude lower RM values, consistent with the AGN viewing angle unification scheme. For Sgr A* we report a mean RM of (−4.2 ± 0.3) × 105 rad m−2 at 1.3 mm, consistent with measurements over the past decade and, for the first time, an RM of (–2.1 ± 0.1) × 105 rad m−2 at 3 mm, suggesting that about half of the Faraday rotation at 1.3 mm may occur between the 3 mm photosphere and the 1.3 mm source. We also report the first unambiguous measurement of RM toward the M87 nucleus at millimeter wavelengths, which undergoes significant changes in magnitude and sign reversals on a one year timescale, spanning the range from −1.2 to 0.3 × 105 rad m−2 at 3 mm and −4.1 to 1.5 × 105 rad m−2 at 1.3 mm. Given this time variability, we argue that, unlike the case of Sgr A*, the RM in M87 does not provide an accurate estimate of the mass accretion rate onto the black hole. We put forward a two-component model, comprised of a variable compact region and a static extended region, that can simultaneously explain the polarimetric properties observed by both the EHT (on horizon scales) and ALMA (which observes the combined emission from both components). These measurements provide critical constraints for the calibration, analysis, and interpretation of simultaneously obtained VLBI data with the EHT and GMVA."
YUAN SUN,"First Sagittarius A* Event Horizon Telescope results. IV. Variability, morphology, and black hole mass","In this paper we quantify the temporal variability and image morphology of the horizon-scale emission from Sgr A*, as observed by the EHT in 2017 April at a wavelength of 1.3 mm. We find that the Sgr A* data exhibit variability that exceeds what can be explained by the uncertainties in the data or by the effects of interstellar scattering. The magnitude of this variability can be a substantial fraction of the correlated flux density, reaching ∼100% on some baselines. Through an exploration of simple geometric source models, we demonstrate that ring-like morphologies provide better fits to the Sgr A* data than do other morphologies with comparable complexity. We develop two strategies for fitting static geometric ring models to the time-variable Sgr A* data; one strategy fits models to short segments of data over which the source is static and averages these independent fits, while the other fits models to the full data set using a parametric model for the structural variability power spectrum around the average source structure. Both geometric modeling and image-domain feature extraction techniques determine the ring diameter to be 51.8 ± 2.3 μas (68% credible intervals), with the ring thickness constrained to have an FWHM between ∼30% and 50% of the ring diameter. To bring the diameter measurements to a common physical scale, we calibrate them using synthetic data generated from GRMHD simulations. This calibration constrains the angular size of the gravitational radius to be 4.8_-0.7^+1.4 μas, which we combine with an independent distance measurement from maser parallaxes to determine the mass of Sgr A* to be 4.0_-0.6^+10^6 M⊙."
YUAN SUN,"First Sagittarius A* Event Horizon Telescope results. II. EHT and multiwavelength observations, data processing, and calibration","We present Event Horizon Telescope (EHT) 1.3 mm measurements of the radio source located at the position of the supermassive black hole Sagittarius A* (Sgr A*), collected during the 2017 April 5–11 campaign. The observations were carried out with eight facilities at six locations across the globe. Novel calibration methods are employed to account for Sgr A*'s flux variability. The majority of the 1.3 mm emission arises from horizon scales, where intrinsic structural source variability is detected on timescales of minutes to hours. The effects of interstellar scattering on the image and its variability are found to be subdominant to intrinsic source structure. The calibrated visibility amplitudes, particularly the locations of the visibility minima, are broadly consistent with a blurred ring with a diameter of ∼50 μas, as determined in later works in this series. Contemporaneous multiwavelength monitoring of Sgr A* was performed at 22, 43, and 86 GHz and at near-infrared and X-ray wavelengths. Several X-ray flares from Sgr A* are detected by Chandra, one at low significance jointly with Swift on 2017 April 7 and the other at higher significance jointly with NuSTAR on 2017 April 11. The brighter April 11 flare is not observed simultaneously by the EHT but is followed by a significant increase in millimeter flux variability immediately after the X-ray outburst, indicating a likely connection in the emission physics near the event horizon. We compare Sgr A*’s broadband flux during the EHT campaign to its historical spectral energy distribution and find that both the quiescent emission and flare emission are consistent with its long-term behavior."
YUAN SUN,Broadband multi-wavelength properties of M87 during the 2017 Event Horizon Telescope campaign,"In 2017, the Event Horizon Telescope (EHT) Collaboration succeeded in capturing the first direct image of the center of the M87 galaxy. The asymmetric ring morphology and size are consistent with theoretical expectations for a weakly accreting supermassive black hole of mass ∼6.5 × 109 M ⊙. The EHTC also partnered with several international facilities in space and on the ground, to arrange an extensive, quasi-simultaneous multi-wavelength campaign. This Letter presents the results and analysis of this campaign, as well as the multi-wavelength data as a legacy data repository. We captured M87 in a historically low state, and the core flux dominates over HST-1 at high energies, making it possible to combine core flux constraints with the more spatially precise very long baseline interferometry data. We present the most complete simultaneous multi-wavelength spectrum of the active nucleus to date, and discuss the complexity and caveats of combining data from different spatial scales into one broadband spectrum. We apply two heuristic, isotropic leptonic single-zone models to provide insight into the basic source properties, but conclude that a structured jet is necessary to explain M87’s spectrum. We can exclude that the simultaneous γ-ray emission is produced via inverse Compton emission in the same region producing the EHT mm-band emission, and further conclude that the γ-rays can only be produced in the inner jets (inward of HST-1) if there are strongly particle-dominated regions. Direct synchrotron emission from accelerated protons and secondaries cannot yet be excluded."
YUAN SUN,First Sagittarius A* Event Horizon Telescope results. III. Imaging of the Galactic center supermassive black hole,"We present the first event-horizon-scale images and spatiotemporal analysis of Sgr A* taken with the Event Horizon Telescope in 2017 April at a wavelength of 1.3 mm. Imaging of Sgr A* has been conducted through surveys over a wide range of imaging assumptions using the classical CLEAN algorithm, regularized maximum likelihood methods, and a Bayesian posterior sampling method. Different prescriptions have been used to account for scattering effects by the interstellar medium toward the Galactic center. Mitigation of the rapid intraday variability that characterizes Sgr A* has been carried out through the addition of a “variability noise budget” in the observed visibilities, facilitating the reconstruction of static full-track images. Our static reconstructions of Sgr A* can be clustered into four representative morphologies that correspond to ring images with three different azimuthal brightness distributions and a small cluster that contains diverse nonring morphologies. Based on our extensive analysis of the effects of sparse (u, v)-coverage, source variability, and interstellar scattering, as well as studies of simulated visibility data, we conclude that the Event Horizon Telescope Sgr A* data show compelling evidence for an image that is dominated by a bright ring of emission with a ring diameter of ∼50 μas, consistent with the expected “shadow” of a 4 × 106 M⊙ black hole in the Galactic center located at a distance of 8 kpc."
YUAN SUN,Characterizing and mitigating intraday variability: reconstructing source structure in accreting black holes with mm-VLBI,"The extraordinary physical resolution afforded by the Event Horizon Telescope has opened a window onto the astrophysical phenomena unfolding on horizon scales in two known black holes, M87* and Sgr A*. However, with this leap in resolution has come a new set of practical complications. Sgr A* exhibits intraday variability that violates the assumptions underlying Earth aperture synthesis, limiting traditional image reconstruction methods to short timescales and data sets with very sparse (u, v) coverage. We present a new set of tools to detect and mitigate this variability. We develop a data-driven, model-agnostic procedure to detect and characterize the spatial structure of intraday variability. This method is calibrated against a large set of mock data sets, producing an empirical estimator of the spatial power spectrum of the brightness fluctuations. We present a novel Bayesian noise modeling algorithm that simultaneously reconstructs an average image and statistical measure of the fluctuations about it using a parameterized form for the excess variance in the complex visibilities not otherwise explained by the statistical errors. These methods are validated using a variety of simulated data, including general relativistic magnetohydrodynamic simulations appropriate for Sgr A* and M87*. We find that the reconstructed source structure and variability are robust to changes in the underlying image model. We apply these methods to the 2017 EHT observations of M87*, finding evidence for variability across the EHT observing campaign. The variability mitigation strategies presented are widely applicable to very long baseline interferometry observations of variable sources generally, for which they provide a data-informed averaging procedure and natural characterization of inter-epoch image consistency."
YUAN SUN,The polarized image of a synchrotron-emitting ring of gas orbiting a black hole,"Synchrotron radiation from hot gas near a black hole results in a polarized image. The image polarization is determined by effects including the orientation of the magnetic field in the emitting region, relativistic motion of the gas, strong gravitational lensing by the black hole, and parallel transport in the curved spacetime. We explore these effects using a simple model of an axisymmetric, equatorial accretion disk around a Schwarzschild black hole. By using an approximate expression for the null geodesics derived by Beloborodov and conservation of the Walker–Penrose constant, we provide analytic estimates for the image polarization. We test this model using currently favored general relativistic magnetohydrodynamic simulations of M87*, using ring parameters given by the simulations. For a subset of these with modest Faraday effects, we show that the ring model broadly reproduces the polarimetric image morphology. Our model also predicts the polarization evolution for compact flaring regions, such as those observed from Sgr A* with GRAVITY. With suitably chosen parameters, our simple model can reproduce the EVPA pattern and relative polarized intensity in Event Horizon Telescope images of M87*. Under the physically motivated assumption that the magnetic field trails the fluid velocity, this comparison is consistent with the clockwise rotation inferred from total intensity images."
YUAN SUN,First Sagittarius A* Event Horizon Telescope results. I. The shadow of the supermassive black hole in the center of the Milky Way,"We present the first Event Horizon Telescope (EHT) observations of Sagittarius A* (Sgr A*), the Galactic center source associated with a supermassive black hole. These observations were conducted in 2017 using a global interferometric array of eight telescopes operating at a wavelength of λ = 1.3 mm. The EHT data resolve a compact emission region with intrahour variability. A variety of imaging and modeling analyses all support an image that is dominated by a bright, thick ring with a diameter of 51.8 ± 2.3 μas (68% credible interval). The ring has modest azimuthal brightness asymmetry and a comparatively dim interior. Using a large suite of numerical simulations, we demonstrate that the EHT images of Sgr A* are consistent with the expected appearance of a Kerr black hole with mass ∼4 × 106 M ⊙, which is inferred to exist at this location based on previous infrared observations of individual stellar orbits, as well as maser proper-motion studies. Our model comparisons disfavor scenarios where the black hole is viewed at high inclination (i &gt; 50°), as well as nonspinning black holes and those with retrograde accretion disks. Our results provide direct evidence for the presence of a supermassive black hole at the center of the Milky Way, and for the first time we connect the predictions from dynamical measurements of stellar orbits on scales of 103–105 gravitational radii to event-horizon-scale images and variability. Furthermore, a comparison with the EHT results for the supermassive black hole M87* shows consistency with the predictions of general relativity spanning over three orders of magnitude in central mass."
YUAN SUN,The variability of the black hole image in M87 at the dynamical timescale,"The black hole images obtained with the Event Horizon Telescope (EHT) are expected to be variable at the dynamical timescale near their horizons. For the black hole at the center of the M87 galaxy, this timescale (5–61 days) is comparable to the 6 day extent of the 2017 EHT observations. Closure phases along baseline triangles are robust interferometric observables that are sensitive to the expected structural changes of the images but are free of station-based atmospheric and instrumental errors. We explored the day-to-day variability in closure-phase measurements on all six linearly independent nontrivial baseline triangles that can be formed from the 2017 observations. We showed that three triangles exhibit very low day-to-day variability, with a dispersion of ∼3°–5°. The only triangles that exhibit substantially higher variability (∼90°–180°) are the ones with baselines that cross the visibility amplitude minima on the u–v plane, as expected from theoretical modeling. We used two sets of general relativistic magnetohydrodynamic simulations to explore the dependence of the predicted variability on various black hole and accretion-flow parameters. We found that changing the magnetic field configuration, electron temperature model, or black hole spin has a marginal effect on the model consistency with the observed level of variability. On the other hand, the most discriminating image characteristic of models is the fractional width of the bright ring of emission. Models that best reproduce the observed small level of variability are characterized by thin ring-like images with structures dominated by gravitational lensing effects and thus least affected by turbulence in the accreting plasmas."
YUAN SUN,Constraints on black-hole charges with the 2017 EHT observations of M87*,
YUAN SUN,The long-baseline neutrino experiment: exploring fundamental symmetries of the universe,"The preponderance of matter over antimatter in the early Universe, the dynamics of the supernova bursts that produced the heavy elements necessary for life and whether protons eventually decay --- these mysteries at the forefront of particle physics and astrophysics are key to understanding the early evolution of our Universe, its current state and its eventual fate. The Long-Baseline Neutrino Experiment (LBNE) represents an extensively developed plan for a world-class experiment dedicated to addressing these questions. LBNE is conceived around three central components: (1) a new, high-intensity neutrino source generated from a megawatt-class proton accelerator at Fermi National Accelerator Laboratory, (2) a near neutrino detector just downstream of the source, and (3) a massive liquid argon time-projection chamber deployed as a far detector deep underground at the Sanford Underground Research Facility. This facility, located at the site of the former Homestake Mine in Lead, South Dakota, is approximately 1,300 km from the neutrino source at Fermilab -- a distance (baseline) that delivers optimal sensitivity to neutrino charge-parity symmetry violation and mass ordering effects. This ambitious yet cost-effective design incorporates scalability and flexibility and can accommodate a variety of upgrades and contributions. With its exceptional combination of experimental configuration, technical capabilities, and potential for transformative discoveries, LBNE promises to be a vital facility for the field of particle physics worldwide, providing physicists from around the globe with opportunities to collaborate in a twenty to thirty year program of exciting science. In this document we provide a comprehensive overview of LBNE's scientific objectives, its place in the landscape of neutrino physics worldwide, the technologies it will incorporate and the capabilities it will possess."
JOHN NGO,Friends of hot Jupiters. II. No correspondence between hot-Jupiter spin-orbit misalignment and the incidence of directly imaged stellar companions,"Multi-star systems are common, yet little is known about a stellar companion's influence on the formation and evolution of planetary systems. For instance, stellar companions may have facilitated the inward migration of hot Jupiters toward to their present day positions. Many observed short-period gas giant planets also have orbits that are misaligned with respect to their star's spin axis, which has also been attributed to the presence of a massive outer companion on a non-coplanar orbit. We present the results of a multi-band direct imaging survey using Keck NIRC2 to measure the fraction of short-period gas giant planets found in multi-star systems. Over three years, we completed a survey of 50 targets (""Friends of Hot Jupiters"") with 27 targets showing some signature of multi-body interaction (misaligned or eccentric orbits) and 23 targets in a control sample (well-aligned and circular orbits). We report the masses, projected separations, and confirmed common proper motion for the 19 stellar companions found around 17 stars. Correcting for survey incompleteness, we report companion fractions of 48% ± 9%, 47% ± 12%, and 51% ± 13% in our total, misaligned/eccentric, and control samples, respectively. This total stellar companion fraction is 2.8σ larger than the fraction of field stars with companions approximately 50-2000 AU. We observe no correlation between misaligned/eccentric hot Jupiter systems and the incidence of stellar companions. Combining this result with our previous radial velocity survey, we determine that 72% ± 16% of hot Jupiters are part of multi-planet and/or multi-star systems."
JOHN NGO,Split-miniSOG for detecting and localizing intracellular protein-protein interactions: application to correlated light and electron microscopy,"A protein-fragment complementation assay (PCA) for detecting and localizing intracellular protein-protein interactions (PPIs) was built by bisection of miniSOG, a fluorescent flavoprotein derived from the light, oxygen, voltage (LOV)-2 domain of Arabidopsis phototropin. When brought together by interacting proteins, the fragments reconstitute a functional reporter that permits tagged protein complexes to be visualized by fluorescence light microscopy (LM), and then by standard as well as “multicolor” electron microscopy (EM) via the photooxidation of 3-3’-diaminobenzidine (DAB) and its derivatives."
JOHN NGO,Engineering clinically-approved drug gated CAR circuits,"[Chimeric antigen receptor (CAR) T cell immunotherapy has the potential to revolutionize cancer medicine. However, excessive CAR activation, lack of tumor-specific surface markers, and antigen escape have limited the safety and efficacy of CAR T cell therapy. A multi-antigen targeting CAR system that is regulated by safe, clinically-approved pharmaceutical agents is urgently needed, yet only a few simple systems have been developed, and even fewer have been evaluated for efficacy in vivo. Here, we present NASCAR (NS3 ASsociated CAR), a collection of induc-ible ON and OFF switch CAR circuits engineered with a NS3 protease domain deriving from the Hepatitis C Virus (HCV). We establish their ability to regulate CAR activity using multiple FDA-approved antiviral protease inhibitors, including grazoprevir (GZV), both in vitro and in a xenograft tumor model. In addition, we have engineered several dual-gated NASCAR circuits, consisting of an AND logic gate CAR, universal ON-OFF CAR, and a switchboard CAR. These engineered receptors enhance control over T cell activity and tumor-targeting specificity. Together, our com-prehensive set of multiplex drug-gated CAR circuits represent a dynamic, tunable, and clinically-ready set of modules for enhancing the safety of CAR T cell therapy.]"
JOHN NGO,"Friends of hot Jupiters. IV. Stellar companions beyond 50 au might facilitate giant planet formation, but most are unlikely to cause Kozai-Lidov migration","Stellar companions can influence the formation and evolution of planetary systems, but there are currently few observational constraints on the properties of planet-hosting binary star systems. We search for stellar companions around 77 transiting hot Jupiter systems to explore the statistical properties of this population of companions as compared to field stars of similar spectral type. After correcting for survey incompleteness, we find that $47 \% \pm 7 \% $ of hot Jupiter systems have stellar companions with semimajor axes between 50 and 2000 au. This is 2.9 times larger than the field star companion fraction in this separation range, with a significance of $4.4\sigma $. In the 1–50 au range, only ${3.9}_{-2.0}^{+4.5} \% $ of hot Jupiters host stellar companions, compared to the field star value of $16.4 \% \pm 0.7 \% $, which is a $2.7\sigma $ difference. We find that the distribution of mass ratios for stellar companions to hot Jupiter systems peaks at small values and therefore differs from that of field star binaries which tend to be uniformly distributed across all mass ratios. We conclude that either wide separation stellar binaries are more favorable sites for gas giant planet formation at all separations, or that the presence of stellar companions preferentially causes the inward migration of gas giant planets that formed farther out in the disk via dynamical processes such as Kozai–Lidov oscillations. We determine that less than 20% of hot Jupiters have stellar companions capable of inducing Kozai–Lidov oscillations assuming initial semimajor axes between 1 and 5 au, implying that the enhanced companion occurrence is likely correlated with environments where gas giants can form efficiently."
JEN-WEI LIN,Supporting data in ENDNOTE for: focused ultrasound transiently increases membrane conductance in isolated crayfish axon,
JEN-WEI LIN,Infrared inhibition impacts on locally initiated and propagating action potentials and the downstream synaptic transmission,"SIGNIFICANCE: Systematic studies of the physiological outputs induced by infrared (IR)-mediated inhibition of motor nerves can provide guidance for therapeutic applications and offer critical insights into IR light modulation of complex neural networks. AIM: We explore the IR-mediated inhibition of action potentials (APs) that either propagate along single axons or are initiated locally and their downstream synaptic transmission responses. APPROACH: APs were evoked locally by two-electrode current clamp or at a distance for propagating APs. The neuromuscular transmission was recorded with intracellular electrodes in muscle cells or macro-patch pipettes on terminal bouton clusters. RESULTS: IR light pulses completely and reversibly terminate the locally initiated APs firing at low frequencies, which leads to blocking of the synaptic transmission. However, IR light pulses only suppress but do not block the amplitude and duration of propagating APs nor locally initiated APs firing at high frequencies. Such suppressed APs do not influence the postsynaptic responses at a distance. While the suppression of AP amplitude and duration is similar for propagating and locally evoked APs, only the former exhibits a 7% to 21% increase in the maximum time derivative of the AP rising phase. CONCLUSIONS: The suppressed APs of motor axons can resume their waveforms after passing the localized IR light illumination site, leaving the muscular and synaptic responses unchanged. IR-mediated modulation on propagating and locally evoked APs should be considered as two separate models for axonal and somatic modulations."
JOSHUA DAVID CAMPBELL,Feedforward control algorithms for MEMS galvos and scanners,
JOSHUA DAVID CAMPBELL,Genome-wide characterization of microRNA and gene expression patterns in smoking-related lung disease,"Smoking-related lung diseases such as chronic obstructive pulmonary disease (COPD) and lung cancer are significant public health concerns world-wide. High throughput genomic technologies have opened up a new realm of understanding into the complexities of human disease by providing a means by which we can gain considerable amounts of information about a sample. In my research, I examine genome-wide gene expression via microarrays and microRNA expression via small RNA-sequencing (small RNA-Seq) to gain insights into lung disease pathogenesis, assess novel strategies for identifying therapeutics, and develop biomarkers for earlier diagnosis of disease. First, I revealed mechanisms of emphysema progression within individuals by leveraging a unique dataset that contains multiple lung-tissue samples per patient collected from regions with different levels of emphysematous destruction. Pathways involved in immune response and tissue remodeling were enriched among gene expression profiles associated with increasing regional emphysema severity. Using the Connectivity Map, a compound was discovered capable of reversing the gene-expression signature of increasing emphysema severity which can serve as a lead in therapeutic development for COPD. [TRUNCATED]"
JOSHUA DAVID CAMPBELL,Zeptometer metrology using the Casimir effect,"In this paper, we discuss using the Casimir force in conjunction with a MEMS parametric amplifier to construct a quantum displacement amplifier. Such a mechanical amplifier converts DC displacements into much larger AC oscillations via the quantum gain of the system which, in some cases, can be a factor of a million or more. This would allow one to build chip scale metrology systems with zeptometer positional resolution. This approach leverages quantum fluctuations to build a device with a sensitivity that can’t be obtained with classical systems."
JOSHUA DAVID CAMPBELL,Bulk brain tissue cell-type deconvolution with bias correction for single-nuclei RNA sequencing data using DeTREM,"BACKGROUND: Quantifying cell-type abundance in bulk tissue RNA-sequencing enables researchers to better understand complex systems. Newer deconvolution methodologies, such as MuSiC, use cell-type signatures derived from single-cell RNA-sequencing (scRNA-seq) data to make these calculations. Single-nuclei RNA-sequencing (snRNA-seq) reference data can be used instead of scRNA-seq data for tissues such as human brain where single-cell data are difficult to obtain, but accuracy suffers due to sequencing differences between the technologies. RESULTS: We propose a modification to MuSiC entitled 'DeTREM' which compensates for sequencing differences between the cell-type signature and bulk RNA-seq datasets in order to better predict cell-type fractions. We show DeTREM to be more accurate than MuSiC in simulated and real human brain bulk RNA-sequencing datasets with various cell-type abundance estimates. We also compare DeTREM to SCDC and CIBERSORTx, two recent deconvolution methods that use scRNA-seq cell-type signatures. We find that they perform well in simulated data but produce less accurate results than DeTREM when used to deconvolute human brain data. CONCLUSION: DeTREM improves the deconvolution accuracy of MuSiC and outperforms other deconvolution methods when applied to snRNA-seq data. DeTREM enables accurate cell-type deconvolution in situations where scRNA-seq data are not available. This modification improves characterization cell-type specific effects in brain tissue and identification of cell-type abundance differences under various conditions."
JOSHUA DAVID CAMPBELL,"The Mutational signature comprehensive analysis toolkit (musicatk) for the discovery, prediction, and exploration of mutational signatures","Mutational signatures are patterns of somatic alterations in the genome caused by carcinogenic exposures or aberrant cellular processes. To provide a comprehensive workflow for preprocessing, analysis, and visualization of mutational signatures, we created the Mutational Signature Comprehensive Analysis Toolkit (musicatk) package. musicatk enables users to select different schemas for counting mutation types and to easily combine count tables from different schemas. Multiple distinct methods are available to deconvolute signatures and exposures or to predict exposures in individual samples given a pre-existing set of signatures. Additional exploratory features include the ability to compare signatures to the Catalogue Of Somatic Mutations In Cancer (COSMIC) database, embed tumors in two dimensions with uniform manifold approximation and projection, cluster tumors into subgroups based on exposure frequencies, identify differentially active exposures between tumor subgroups, and plot exposure distributions across user-defined annotations such as tumor type. Overall, musicatk will enable users to gain novel insights into the patterns of mutational signatures observed in cancer cohorts. SIGNIFICANCE: The musicatk package empowers researchers to characterize mutational signatures and tumor heterogeneity with a comprehensive set of preprocessing utilities, discovery and prediction tools, and multiple functions for downstream analysis and visualization."
JOSHUA DAVID CAMPBELL,Celda: a Bayesian model to perform co-clustering of genes into modules and cells into subpopulations using single-cell RNA-seq data,"Single-cell RNA-seq (scRNA-seq) has emerged as a powerful technique to quantify gene expression in individual cells and to elucidate the molecular and cellular building blocks of complex tissues. We developed a novel Bayesian hierarchical model called Cellular Latent Dirichlet Allocation (Celda) to perform co-clustering of genes into transcriptional modules and cells into subpopulations. Celda can quantify the probabilistic contribution of each gene to each module, each module to each cell population and each cell population to each sample. In a peripheral blood mononuclear cell dataset, Celda identified a subpopulation of proliferating T cells and a plasma cell which were missed by two other common single-cell workflows. Celda also identified transcriptional modules that could be used to characterize unique and shared biological programs across cell types. Finally, Celda outperformed other approaches for clustering genes into modules on simulated data. Celda presents a novel method for characterizing transcriptional programs and cellular heterogeneity in scRNA-seq data."
JOSHUA DAVID CAMPBELL,Characterization and decontamination of background noise in droplet-based single-cell protein expression data with DecontPro,"Assays such as CITE-seq can measure the abundance of cell surface proteins on individual cells using antibody derived tags (ADTs). However, many ADTs have high levels of background noise that can obfuscate down-stream analyses. In an exploratory analysis of PBMC datasets, we find that some droplets that were originally called 'empty' due to low levels of RNA contained high levels of ADTs and likely corresponded to neutrophils. We identified a novel type of artifact in the empty droplets called a 'spongelet' which has medium levels of ADT expression and is distinct from ambient noise. ADT expression levels in the spongelets correlate to ADT expression levels in the background peak of true cells in several datasets suggesting that they can contribute to background noise along with ambient ADTs. We then developed DecontPro, a novel Bayesian hierarchical model that can decontaminate ADT data by estimating and removing contamination from these sources. DecontPro outperforms other decontamination tools in removing aberrantly expressed ADTs while retaining native ADTs and in improving clustering specificity. Overall, these results suggest that identification of empty drops should be performed separately for RNA and ADT data and that DecontPro can be incorporated into CITE-seq workflows to improve the quality of downstream analyses."
JOSHUA DAVID CAMPBELL,"Comprehensive generation, visualization, and reporting of quality control metrics for single-cell RNA sequencing data","Single-cell RNA sequencing (scRNA-seq) can be used to gain insights into cellular heterogeneity within complex tissues. However, various technical artifacts can be present in scRNA-seq data and should be assessed before performing downstream analyses. While several tools have been developed to perform individual quality control (QC) tasks, they are scattered in different packages across several programming environments. Here, to streamline the process of generating and visualizing QC metrics for scRNA-seq data, we built the SCTK-QC pipeline within the singleCellTK R package. The SCTK-QC workflow can import data from several single-cell platforms and preprocessing tools and includes steps for empty droplet detection, generation of standard QC metrics, prediction of doublets, and estimation of ambient RNA. It can run on the command line, within the R console, on the cloud platform or with an interactive graphical user interface. Overall, the SCTK-QC pipeline streamlines and standardizes the process of performing QC for scRNA-seq data."
JOSHUA DAVID CAMPBELL,Decontamination of ambient RNA in single-cell RNA-seq with DecontX,"Droplet-based microfluidic devices have become widely used to perform single-cell RNA sequencing (scRNA-seq). However, ambient RNA present in the cell suspension can be aberrantly counted along with a cell's native mRNA and result in cross-contamination of transcripts between different cell populations. DecontX is a novel Bayesian method to estimate and remove contamination in individual cells. DecontX accurately predicts contamination levels in a mouse-human mixture dataset and removes aberrant expression of marker genes in PBMC datasets. We also compare the contamination levels between four different scRNA-seq protocols. Overall, DecontX can be incorporated into scRNA-seq workflows to improve downstream analyses."
JOSHUA DAVID CAMPBELL,Interactive single cell RNA-Seq analysis with Single Cell Toolkit (SCTK),"I will present the Single Cell Toolkit (SCTK), an R package and interactive single cell RNA-sequencing (scRNA-Seq) analysis package that provides the first complete workflow for scRNA-Seq data analysis and visualization using a set of R functions and an interactive web interface. Users can perform analysis with modules for filtering raw results, clustering, batch correction, differential expression, pathway enrichment, and scRNA-Seq study design. The toolkit supports command line or pipeline data processing, and results can be loaded into the GUI for additional exploration and downstream analysis. We demonstrate the effectiveness of the SCTK on multiple scRNA-seq examples, including data from mucosal-associated invariant T cells, induced pluripotent stem cells, and breast cancer tumor cells. While other scRNA-Seq analysis tools exist, the SCTK is the first fully interactive analysis toolkit for scRNA-Seq data available within the R language."
KARSTEN LUNZE,Health and human rights: advocacy tools for structural HIV prevention among Russian drug users,"Injection drug use fuels the HIV/AIDS epidemic in the Russian Federation (Russia). Evidence suggests that repressive drug law enforcement is part of the HIV risk environment and associated with risk behaviors that promote HIV transmission among people who inject drugs (PWID). However, no quantitative studies on police involvement and associated risk behaviors or health outcomes exist from Russia. We conducted a mixed-methods study in St. Petersburg, Moscow, and Vladikavkaz to characterize the impact of current policing practices on HIV-risk behaviors and overdose among PWID; and to explore attitudes of stakeholders about Russian drug policy and opportunities to change. Descriptive and multivariate regression analyses of quantitative cross-sectional data from 582 HIV prevention trial participants showed that reported policing practices such as arbitrary arrests, planting of false evidence, and extrajudicial syringe confiscations, are common in Russia and are associated with adverse risk behaviors and health outcomes such as receptive needle sharing and drug overdose, respectively. These policing practices often constitute human rights violations. We failed to demonstrate any deterrent effect of abusive policing practices on drug use. A qualitative exploration among 23 key stakeholders revealed that police violence in various forms is ubiquitous in the lives of Russian PWID. Police abuse is rooted in stigma and a power imbalance between police and PWID, and reinforced by police corruption and the dehumanization of PWID. This study suggests that police practices are part of the HIV risk environment of Russian PWID. The translation of empiric evidence into policy change in the Russian country context might be facilitated by police trainings emphasizing public health and harm reduction principles as well as the development of joint public safety/public health task forces. Using research evidence from other countries to influence policy in Russia has had limited effects. Therefore, more evidence from Russian studies is needed to advance the alignment of public health and public safety efforts to effectively address drug userelated harm and HIV prevention in Russia."
KARSTEN LUNZE,Community advisory board members’ perspectives on their contributions to a large multistate cluster RCT: a mixed methods study,"BACKGROUND: Community advisory boards (CABs) are an established approach to ensuring research reflects community priorities. This paper examines two CABs that are part of the HEALing Communities Study which aims to reduce overdose mortality. This analysis aimed to understand CAB members’ expectations, experiences, and perspectives on CAB structure, communication, facilitation, and effectiveness during the first year of an almost fully remote CAB implementation. Current literature exploring these perspectives is limited. METHODS: We collected qualitative and survey data simultaneously from members (n = 53) of two sites’ CABs in the first 9 months of CAB development. The survey assessed trust, communication, and relations; we also conducted 32 semi-structured interviews. We analyzed the survey results descriptively. The qualitative data were analyzed using a deductive codebook based on the RE-AIM PRISM framework. Themes were drawn from the combined qualitative data and triangulated with survey results to further enrich the findings. RESULTS: CAB members expressed strong commitment to overall study goals and valued the representation of occupational sectors. The qualitative data described a dissonance between CAB members’ commitment to the mission and unmet expectations for influencing the study within an advisory role. Survey results indicated lower satisfaction with the research teams’ ability to create a mutually beneficial process, clear communication, and sharing of power. CONCLUSION: Building a CAB on a remote platform, within a study utilizing a community engagement strategy, still presents challenges to fully realizing the potential of a CAB. These findings can inform more effective operationalizing of community-engaged research through enhanced CAB engagement."
GEORGE J MURPHY,Asthma-Susceptibility Variants Identified Using Probands in Case-Control and Family-Based Analyses,"BACKGROUND: Asthma is a chronic respiratory disease whose genetic basis has been explored for over two decades, most recently via genome-wide association studies. We sought to find asthma-susceptibility variants by using probands from a single population in both family-based and case-control association designs. METHODS: We used probands from the Childhood Asthma Management Program (CAMP) in two primary genome-wide association study designs: (1) probands were combined with publicly available population controls in a case-control design, and (2) probands and their parents were used in a family-based design. We followed a two-stage replication process utilizing three independent populations to validate our primary findings. RESULTS: We found that single nucleotide polymorphisms with similar case-control and family-based association results were more likely to replicate in the independent populations, than those with the smallest p-values in either the case-control or family-based design alone. The single nucleotide polymorphism that showed the strongest evidence for association to asthma was rs17572584, which replicated in 2/3 independent populations with an overall p-value among replication populations of 3.5E-05. This variant is near a gene that encodes an enzyme that has been implicated to act coordinately with modulators of Th2 cell differentiation and is expressed in human lung. CONCLUSIONS: Our results suggest that using probands from family-based studies in case-control designs, and combining results of both family-based and case-control approaches, may be a way to augment our ability to find SNPs associated with asthma and other complex diseases."
GEORGE J MURPHY,Very regular high-frequency pulsation modes in young intermediate-mass stars,"Asteroseismology probes the internal structures of stars by using their natural pulsation frequencies1. It relies on identifying sequences of pulsation modes that can be compared with theoretical models, which has been done successfully for many classes of pulsators, including low-mass solar-type stars2, red giants3, high-mass stars4 and white dwarfs5. However, a large group of pulsating stars of intermediate mass-the so-called δ Scuti stars-have rich pulsation spectra for which systematic mode identification has not hitherto been possible6,7. This arises because only a seemingly random subset of possible modes are excited and because rapid rotation tends to spoil regular patterns8-10. Here we report the detection of remarkably regular sequences of high-frequency pulsation modes in 60 intermediate-mass main-sequence stars, which enables definitive mode identification. The space motions of some of these stars indicate that they are members of known associations of young stars, as confirmed by modelling of their pulsation spectra."
NOORA LORI,A political economy of global security approach to migration and border control,"Population movements have causes and consequences for both global security and the economic and security considerations of states. Migration itself is inexorably intertwined with global security outcomes, in the form of instability, state fragility, transnational terrorism and crime, and the radicalization (or perceived radicalization) of migrants and host societies.While modern states may have monopolized the authority over legitimate movement, they have never fully captured the management and enforcement of migration flows. Instead, market actors play key roles in determining migration outcomes—including the scale, direction, and violence associated with migration flows. Migration outcomes are, thus, critically constituted by two key forces—the security priorities of states and the complementary and competing forces of privatization and profit-making. While market forces undermine state control over migration, states have buffered and further consolidated their power over mobility by harnessing private actors and markets toward migration management and border control. We situate migration management and border control as a political economy of security issue, arguing that migration outcomes cannot be explained without examining the interaction between state security imperatives, private actors, and market forces."
NOORA LORI,Time and its miscounting: methodological challenges in the study of citizenship boundaries,"One would think that, after years of fieldwork and writing, I would be able to answer a pretty simple and straightforward question about who exactly I interviewed for my study of citizenship boundaries in the UAE: “Do you have any notion of the proportions [of interlocuters] of the different ethnic or descent lines that you spoke to?” This essay is about why it is so difficult to answer this question and the insights into citizenship that unfolded as I searched for an empirical answer. Spoiler alert: Answers to questions about “national” or “ethnic” origin are entirely dependent upon how we count—and miscount—time."
JASON YUST,Tonal prisms: iterated quantization in chromatic tonality and Ravel's 'Ondine',"The mathematics of second-order maximal evenness has far-reaching potential for application in music analysis. One of its assets is its foundation in an inherently continuous conception of pitch, a feature it shares with voice-leading geometries. This paper reformulates second-order maximal evenness as iterated quantization in voice-leading spaces, discusses the implications of viewing diatonic triads as second-order maximally even sets for the understanding of nineteenth-century modulatory schemes, and applies a second-order maximally even derivation of acoustic collections in an in-depth analysis of Ravel's ‘Ondine’. In the interaction between these two very different applications, the paper generalizes the concepts and analytical methods associated with iterated quantization and also pursues a broader argument about the mutual dependence of mathematical music theory and music analysis."
JASON YUST,Testing Schenkerian theory: an experiment on the perception of key distances,"The lack of attention given to Schenkerian theory by empirical research in music is striking when compared to its status in music theory as a standard account of tonality. In this paper I advocate a different way of thinking of Schenkerian theory that can lead to empirically testable claims, and report on an experiment that shows how hypotheses derived from Schenker’s theories explain features of listener’s perception of key relationships. To be relevant to empirical research, Schenker’s theory must be treated as a collection of interrelated but independent theoretical claims rather than a comprehensive analytical method. These discrete theoretical claims can then lead to hypotheses that we can test through empirical methods. This makes it possible for Schenkerian theory improve our scientific understanding of how listeners understand tonal music. At the same time, it opens the possibility of challenging the usefulness of certain aspects of the theory. This paper exemplifies the empirical project with an experiment on the perception of key distance. The results show that two features of Schenkerian theory predict how listeners rate stimuli in terms of key distance. The first is the Schenkerian principle of “composing out” a harmony, and the second is the theory of “voice-leading prolongations.” In a regression analysis, both of these principles significantly improve upon a model of distance ratings based on change of scalar collection alone."
JASON YUST,Restoring the structural status of keys through DFT phase space,"One of the reasons for the widely felt influence of Schenker’s theory is his idea of long-range voice-leading structure. However, an implicit premise, that voice leading is necessarily a relationship between chords, leads Schenker to a reductive method that undermines the structural status of keys. This leads to analytical mistakes as demonstrated by Schenker’s analysis of Brahms’s Second Cello Sonata. Using a spatial concept of harmony based on DFT phase space, this paper shows that Schenker’s implicit premise is in fact incorrect: it is possible to model long-range voice-leading relationships between objects other than chords. The concept of voice leading derived from DFT phases is explained by means of triadic orbits. Triadic orbits are then applied in an analysis of Beethoven’s Heiliger Dankgesang, giving a way to understand the ostensibly “Lydian” tonality and the tonal relationship between the chorale sections and “Neue Kraft” sections."
JASON YUST,Geometric generalizations of the Tonnetz and their relation to Fourier phase space,"Some recent work on generalized Tonnetze has examined the topologies resulting from Richard Cohn’s common-tone based formulation, while Tymoczko has reformulated the Tonnetz as a network of voice-leading relationships and investigated the resulting geometries. This paper adopts the original common-tone based formulation and takes a geometrical approach, showing that Tonnetze can always be realized in toroidal spaces,and that the resulting spaces always correspond to one of the possible Fourier phase spaces. We can therefore use the DFT to optimize the given Tonnetz to the space (or vice-versa). I interpret two-dimensional Tonnetze as triangulations of the 2-torus into regions associated with the representatives of a single trichord type. The natural generalization to three dimensions is therefore a triangulation of the 3-torus. This means that a three-dimensional Tonnetze is, in the general case, a network of three tetrachord-types related by shared trichordal subsets. Other Tonnetze that have been proposed with bounded or otherwise non-toroidal topologies, including Tymoczko’s voice-leading Tonnetze, can be under-stood as the embedding of the toroidal Tonnetze in other spaces, or as foldings of toroidal Tonnetze with duplicated interval types."
JASON YUST,Analysis of analysis: importance of different musical parameters for Schenkerian analysis,"While criteria for Schenkerian analysis have been much discussed, such discussions have generally not been informed by data. Kirlin [Kirlin, Phillip B., 2014 “A Probabilistic Model of Hierarchical Music Analysis.” Ph.D. thesis, University of Massachusetts Amherst] has begun to fill this vacuum with a corpus of textbook Schenkerian analyses encoded using data structures suggested byYust [Yust, Jason, 2006 “Formal Models of Prolongation.” Ph.D. thesis, University of Washington] and a machine learning algorithm based on this dataset that can produce analyses with a reasonable degree of accuracy. In this work, we examine what musical features (scale degree, harmony, metrical weight) are most significant in the performance of Kirlin's algorithm."
JASON YUST,"Michael Haydn, Mozart, and the invention of Sonata-Rondo",
JASON YUST,Probing questions about keys: tonal distributions through the DFT,"Pitch-class distributions are central to much of the computational and psychological research on musical keys. This paper looks at pitch-class distributions through the DFT on pitch-class sets, drawing upon recent theory that has exploited this technique. Corpus-derived distributions consistently exhibit a prominence of three DFT components, 𝑓5, 𝑓3, and 𝑓2, so that we might simplify tonal relationships by viewing them within two- or three-dimensional phase space utilizing just these components. More generally, this simplification, or filtering, of distributional information may be an essential feature of tonal hearing. The DFTs of probe-tone distributions reveal a subdominant bias imposed by the temporal aspect of the behavioral paradigm (as compared to corpus data). The phases of 𝑓5, 𝑓3, and 𝑓2 also exhibit a special linear dependency in tonal music giving rise to the idea of a tonal index."
JASON YUST,Schubert's harmonic language and Fourier phase space,"This article introduces a type of harmonic geometry, Fourier phase space, and uses it to advance the understanding of Schubert’s tonal language and comment upon current topics in Schubert analysis. The space derives from the discrete Fourier transform on pitch-class sets developed by David Lewin and Ian Quinn but uses primarily the phases of Fourier components, unlike Lewin and Quinn, who focus more on the magnitudes. The space defined by phases of the third and fifth components closely resembles the Tonnetz and has a similar common-tone basis to its topology but is continuous and takes a wider domain of harmonic objects. A number of musical examples show how expanding the domain enables us to extend and refine some the conclusions of neo-Riemannian theory about Schubert’s harmony. Through analysis of the Trio and Adagio from Schubert’s String Quintet and other works using the geometry, the article develops a number of concepts for the analysis of chromatic harmony, including a geometric concept of interval as direction (intervallic axis), a novel approach to triadic voice leading (triadic orbits), and theories of tonal regions."
JASON YUST,"Distorted continuity: chromatic harmony, uniform sequences, and quantized voice leadings","This article introduces uniform patterns, voice-leading patterns that are purely regular when represented with generic intervals. Generic intervals are continuous-valued intervals that are converted to real intervals through quantization. Various kinds of chromatic and diatonic sequences are uniform patterns. Uniform patterns provide a way of precisely and quantitatively comparing different kinds of chromatic patterns to diatonic ones by drawing upon the kind of robust, continuous metrics associated with voice-leading spaces. The possibility of deriving chromatic and diatonic logics from common principles suggests a new perspective on the “integration” problem of nineteenth-century harmony—the question of whether chromaticism represents a radical break or an evolution from conventional tonal harmony. The theory of uniform patterns and generic intervals is applied in analysis of the first movement of Schubert's String Quartet No. 15 and other passages from Schubert and Liszt."
JASON YUST,Applications of DFT to the theory of twentieth-century harmony,"Music theorists have only recently, following groundbreaking work by Quinn, recognized the potential for the DFT on pcsets, initially proposed by Lewin, to serve as the foundation of a theory of harmony for the twentieth century. This paper investigates pcset “arithmetic” – subset structure, transpositional combination, and interval content – through the lens of the DFT. It discusses relationships between interval classes and DFT magnitudes, considers special properties of dyads, pcset products, and generated collections, and suggest methods of using the DFT in analysis, including interpreting DFT magnitudes, using phase spaces to understand subset structure, and interpreting the DFT of Lewin’s interval function. Webern’s op. 5/4 and Bartok’s String Quartet 4, iv, are discussed."
JASON YUST,Mathematical approaches to scale degrees and harmonic functions in analytical dialogue,
JASON YUST,Fourier phase and pitch-class sum,"Music theorists have proposed two very different geometric models of musical objects, one based on voice leading and the other based on the Fourier transform. On the surface these models are completely different, but they converge in special cases, including many geometries that are of particular analytical interest."
JASON YUST,"Generalized Tonnetze and Zeitnetze, and the topology of music concepts","The music-theoretic idea of a Tonnetz can be generalized at different levels: as a network of chords relating by maximal intersection, a simplicial complex in which vertices represent notes and simplices represent chords, and as a triangulation of a manifold or other geometrical space. The geometrical construct is of particular interest, in that allows us to represent inherently topological aspects to important musical concepts. Two kinds of music-theoretical geometry have been proposed that can house Tonnetze: geometrical duals of voice-leading spaces and Fourier phase spaces. Fourier phase spaces are particularly appropriate for Tonnetze in that their objects are pitch-class distributions (real-valued weightings of the 12 pitch classes) and proximity in these space relates to shared pitch-class content. They admit of a particularly general method of constructing a geometrical Tonnetz that allows for interval and chord duplications in a toroidal geometry. This article examines how these duplications can relate to important musical concepts such as key or pitch height, and details a method of removing such redundancies and the resulting changes to the homology of the space. The method also transfers to the rhythmic domain, defining Zeitnetze for cyclic rhythms. A number of possible Tonnetze are illustrated: on triads, seventh chords, ninth chords, scalar tetrachords, scales, etc., as well as Zeitnetze on common cyclic rhythms or timelines. Their different topologies – whether orientable, bounded, manifold, etc. – reveal some of the topological character of musical concepts."
JASON YUST,Ganymed's heavenly descent,"Schubert's song “Ganymed” has attracted a great deal of interest from analysts due to its progressive tonal plan, often seen as a challenge to Schenkerian theories of tonal structure, and evocative text. This article draws upon a spatial theory of tonal meaning which helps both to resolve the epistemological impasse faced by reductive theories of tonal structure, and to better access Schubert’s interpretation of Goethe’s text through spatial metaphors that derive from the harmony of the song. It also highlights an allusion to Beethoven's Op. 53 “Waldstein” Piano Sonata in the song that has previously gone unremarked, and identifies this as part of a network of references to Beethoven’s sonata that act both as homage to and critique of Beethoven's middle-period style. These serve both as a window into the song, and into Schubert’s aesthetic stance vis-à-vis his most pre-eminent musical forebear. The theory of tonal space draws upon previous publications, but is re-explained in music-theoretical terms relating to diatonicity and triadicity here. It realizes latent directional metaphors in the diatonic sharp-flat and triadic dominant-subdominant dimensions, which are of hermeneutic value for tonal music. Such a theory helps us interpret Schubert’s tonal plan, explain his choices of keys, and better understand his reading of Goethe's text and aesthetic priorities in setting it to music."
JASON YUST,"Wreaths for Rahn, and valuable exchanges",
JASON YUST,Decontextualizing contextual inversion,"Contextual inversion, introduced as an analytical tool by David Lewin, is a concept of wide reach and value in music theory and analysis, at the root of neo-Riemannian theory as well as serial theory, and useful for a range of analytical applications. A shortcoming of contextual inversion as it is currently understood, however, is, as implied by the name, that the transformation has to be defined anew for each application. This is potentially a virtue, requiring the analyst to invest the transformational system with meaning in order to construct it in the first place. However, there are certainly instances where new transformational systems are continually redefined for essentially the same purposes. This paper explores some of the most common theoretical bases for contextual inversion groups and considers possible definitions of inversion operators that can apply across set class types, effectively decontextualizing contextual inversions."
JASON YUST,"'From where do these chords come?': Theoretical Traditions In The Enlightenment Boston University, 23 October 2015",
JASON YUST,A space for inflections: following up on JMM's special issue on mathematical theories of voice leading,"Journal of Mathematics and Music's recent special issue 7(2) reveals substantial common ground between mathematical theories of harmony advanced by Tymoczko, Hook, Plotkin, and Douthett. This paper develops a theory of scalar inflection as a kind of voice-leading distance using quantization in voice-leading geometries, which combines the best features of different approaches represented in the special issue: it is grounded in the concrete sense of voice-leading distance promoted by Tymoczko, invokes scalar contexts in a similar way as filtered point-symmetry, and abstracts the circle of fifths like Hook's signature transformations. The paper expands upon Tymoczko's ‘generalized signature transform’ showing the deep significance of generalized circles of fifths to voice-leading properties of all collections. Analysis of Schubert's Notturno for Piano Trio and ‘Nacht und Träume’ demonstrate the musical significance of inflection as a kind of voice leading, and the value of a robust geometrical understanding of it."
JASON YUST,Special collections: renewing set theory,"The discrete Fourier transform on pitch-class sets, proposed by David Lewin and advanced by Ian Quinn, may provide a new lease on life for Allen Forte's idea of a general theory of harmony for the twentieth century based on the intervallic content of pitch-class collections. This article proposes the use of phase spaces and Quinn's harmonic qualities in analysis of a wide variety of twentieth-century styles. The main focus is on how these ideas relate to scale-theoretic concepts and the repertoires to which they are applied, such as the music of Debussy, Satie, Stravinsky, Ravel, and Shostakovich. Diatonicity, one of the harmonic qualities, is a basic concern for all of these composers. Phase spaces and harmonic qualities also help to explain the “scale-network wormhole” phenomenon in Debussy and Ravel and better pinpoint the role of octatonicism in Stravinsky's and Ravel's music."
JASON YUST,"Harmonic qualities in Debussy's ""Les sons et les parfums tournent dans l'air du soir""","This analysis of the fourth piece from Debussy's Préludes Book I illustrates typical harmonic techniques of Debussy as manipulations of harmonic qualities. We quantify harmonic qualities via the magnitudes and squared-magnitudes of the coefficients of the discrete Fourier transform (DFT) of pitch class sets, following Ian Quinn. The principal activity of the piece occurs in the fourth and fifth coefficients, the octatonic and diatonic qualities, respectively. The development of harmonic ideas can therefore be mapped out in a two-dimensional octatonic/diatonic phase space. Whole-tone material, representative of the sixth coefficient of the DFT, also plays an important role. I discuss Debussy's motivic work, how features of tonality – diatonicity and harmonic function – relate to his musical language, and the significance of perfectly balanced set classes, which are a special case of nil DFT coefficients."
JASON YUST,Multileveled rhythmic structure of ragtime,"Syncopation in ragtime music has been defined in multiple ways. In this study we propose a method using the Hadamard transform. We extract four-measure phrases from a corpus of ragtime pieces by Scott Joplin, James Scott, and Joseph Lamb, and convert them to 32-element binary onset vectors. The Hadamard transform converts this to another 32-element vector that can be interpreted as representing syncopation at various metrical levels. This method is closely related to a similar application of the discrete Fourier transform. Using the Hadamard representation, we show that syncopation is strongest at the quarter-note level, and that tresillo-like rhythms are especially characteristic of the genre. We identify a number of significant differences based on the position of a phrase in a sixteen-measure strain, the position of the strain in the rag, and the composer. The Hadamard representation also facilitates discovery of relationship between different levels of rhythmic organization."
JASON YUST,Meter networks: a categorical framework for metrical analysis,"This paper develops a framework based on category theory which unifies the simultaneous consideration of timepoints, metrical relations, and meter inclusion founded on the category Rel of sets and binary relations. Metrical relations are defined as binary relations on the set of timepoints, and the subsequent use of the monoid they generate and of the corresponding functor to Rel allows us to define meter networks, i.e. networks of timepoints (or sets of timepoints) related by metrical relations. We compare this to existing theories of metrical conflict, such as those of Harald Krebs and Richard Cohn, and illustrate that these tools help to more effectively combine displacement and grouping dissonance and reflect analytical claims concerning nineteenth-century examples of complex hemiola and twentieth-century polymeter. We show that meter networks can be transformed into each other through meter network morphisms, which allows us to describe both meter displacements and meter inclusions. These networks are applied to various examples from the nineteenth and twentieth century."
JASON YUST,Dimensions of atonality: a response and extension of von Hippel and Huron (2020),"This commentary addresses von Hippel and Huron's (2020) work on ""tonal and anti-tonal"" structures in twelve-tone music and offers a possible extension making use of discrete Fourier transforms."
JASON YUST,"Wreaths for Rahn, and valuable exchanges",
JASON YUST,Steve Reich’s signature rhythm and an introduction to rhythmic qualities,"The rhythm of Steve Reich’s Clapping Music (1972) features in so many of his pieces that it can be understood as a rhythmic signature. A theory of rhythmic qualities allows us to identify the signature rhythm’s significant features and relate it to other cyclic rhythms like the Central/West African “standard pattern,” from which it probably originates. Rhythmic qualities derive from the discrete Fourier transform, whose mathematical properties make the theory particularly robust. One property, described by the convolution theorem, predicts the effects of Reich’s diverse rhythmic canons. I apply the theory to Music for Pieces of Wood (1973) and Nagoya Marimbas (1994)."
JASON YUST,A clustering-based approach to automatic harmonic analysis: an exploratory study of harmony and form in Mozart’s piano sonatas,"We implement a novel approach to automatic harmonic analysis using a clustering method on pitch-class vectors (chroma vectors). The advantage of this method is its lack of top-down assumptions, allowing us to objectively validate the basic music theory premise of a chord lexicon consisting of triads and seventh chords, which is presumed by most research in automatic harmonic analysis. We use the discrete Fourier transform and hierarchical clustering to analyse features of the clustering solutions and illustrate associations between the features and the distribution of clusters over sections of the sonata forms. We also analyse the transition matrix, recovering elements of harmonic function theory."
JASON YUST,Analysis of analysis: using machine learning to evaluate the importance of music parameters for Schenkerian analysis,"While criteria for Schenkerian analysis have been much discussed, such discussions have generally not been informed by data. Kirlin [Kirlin, Phillip B., 2014 “A Probabilistic Model of Hierarchical Music Analysis.” Ph.D. thesis, University of Massachusetts Amherst] has begun to fill this vacuum with a corpus of textbook Schenkerian analyses encoded using data structures suggested byYust [Yust, Jason, 2006 “Formal Models of Prolongation.” Ph.D. thesis, University of Washington] and a machine learning algorithm based on this dataset that can produce analyses with a reasonable degree of accuracy. In this work, we examine what musical features (scale degree, harmony, metrical weight) are most significant in the performance of Kirlin's algorithm."
JASON YUST,Voice-leading transformation and generative theories of tonal structure,"Numerous generative approaches to explaining tonal structure and/or Schenker’s theories have been proposed since Babbitt noted a resemblance between Schenker’s analytical method and Chomskian generative grammars in 1965. One of the more challenging features of Schenker’s theory to replicate in a generative system is the interaction of counterpoint and hierarchy. Many theorists, such as Lerdahl and Jackendoff, skirt the problem by developing non-contrapuntal systems, meaning ones that do not allow for layers with conflicting hierarchical descriptions. This article tackles the counterpoint problem by first proposing a dynamic model for tonal hierarchy, which matches the usage of basic Schenkerian symbols (slurs and beams), and differs from the representational model used by Lerdahl and Jackendoff and others. I then summarize Schenker’s argument for a contrapuntal theory of tonal structure and show that this implies a relativity of contrapuntal voices to structural level which necessitates a theory of voice-leading transformation. This concept of voice-leading transformation marks a crucial turning point in Schenker’s analytical practice leading directly to his theory of levels, and is fundamental to understanding his late theory. The article also operationalizes the idea of voice-leading transformations within a generative system, and illustrates it with short analyses of themes from Bach’sPartitasand an extended analysis of the Menuetto from Beethoven’s Op. 21 Piano Sonata. In the latter analysis the concept of voice-leading transformation facilitates the discovery of an exceptional feature in the deep middleground of the piece."
JASON YUST,Stylistic information in pitch-class distributions,"This study examines pitch-class distributions in a large body of tonal music from the seventeenth, eighteenth and nineteenth centuries using the DFT on pitch-class sets. The DFT, applied over the pitch-class domain rather than a temporal domain, is able to isolate significant and salient qualities characteristic of tonal pitch-class distributions, such as diatonicity and triadicity. The data reveal distinct historical trends in tonal distributions, the most significant of these is a marked decrease in diatonicity in the eighteenth and nineteenth centuries. Comparing distributions for beginnings, endings, and whole pieces reveals a strong similarity between beginnings and whole pieces. Endings, by contrast, are more distinct in the properties of their distributions overall and show some historical trends not shared by beginnings and whole pieces, whose differences do not appear to interact with composer date."
JASON YUST,Restoring the structural status of keys through DFT phase space,
MELISSA M KIBBE,Children’s use of reasoning by exclusion to track identities of occluded objects,"Reasoning by exclusion allows us to infer properties of unobserved objects from currently observed objects, formalized by P or Q, not P, therefore Q. Previous work suggested that, by age 3, children can use this kind of reasoning to infer the location of a hidden object after learning that another location is empty (e.g. Mody & Carey, 2016). In the current study, we asked whether children could use reasoning by exclusion to infer the identities of previously unobserved occluded objects in a task that required them to track the locations of multiple occluded objects. Forty-nine 4-7-yearolds viewed animated arrays of virtual “cards” depicting images which were then hidden by occluders. The occluders then swapped locations during the maintenance period. Children were asked to select which card was hidden in a probed location. During the encoding period, we manipulated whether children saw all the card faces (Face-up block) or all but one of the card faces (Exclusion block), for which children had to reason by exclusion to infer the target in half of the trials. We found that all children succeeded in the Face-up block, but only 6-year-olds succeed in the Exclusion block when they had to deploy logical reasoning to identify a previously-unseen hidden target. Our results suggest that children’s ability to reason by exclusion to infer the identity of a hidden target while tracking multiple objects and locations may undergo protracted development."
MELISSA M KIBBE,Two-year-olds use past memories to accomplish novel goals,"Memory-guided planning involves retrieving relevant memories and applying that information in service of a goal. Previous studies have shown substantial development in this ability from 3 to 4 years of age. We investigated the emergence of memory-guided planning by asking whether 2-year-olds could draw on episodic memories of past experiences to generate and execute plans. In Experiments 1 and 2 (N = 32, ds > .7), 2-year-olds successfully did so, and this ability developed significantly across the third year of life. Furthermore, in Experiment 3 (N = 19, d = 0.63), 2-year-olds successfully applied episodic memories to guide plans in a novel problem context, suggesting flexibility in this ability. Together, these results suggest that some form of memory-guided planning emerges during the third year of life and may form the cognitive basis for episodic prospection later in development."
TREVOR SIGGERS,Transcription factor NF-κB is modulated by symbiotic status in a sea anemone model of cnidarian bleaching.,"Transcription factor NF-κB plays a central role in immunity from fruit flies to humans, and NF-κB activity is altered in many human diseases. To investigate a role for NF-κB in immunity and disease on a broader evolutionary scale we have characterized NF-κB in a sea anemone (Exaiptasia pallida; called Aiptasia herein) model for cnidarian symbiosis and dysbiosis (i.e., ""bleaching""). We show that the DNA-binding site specificity of Aiptasia NF-κB is similar to NF-κB proteins from a broad expanse of organisms. Analyses of NF-κB and IκB kinase proteins from Aiptasia suggest that non-canonical NF-κB processing is an evolutionarily ancient pathway, which can be reconstituted in human cells. In Aiptasia, NF-κB protein levels, DNA-binding activity, and tissue expression increase when loss of the algal symbiont Symbiodinium is induced by heat or chemical treatment. Kinetic analysis of NF-κB levels following loss of symbiosis show that NF-κB levels increase only after Symbiodinium is cleared. Moreover, introduction of Symbiodinium into naïve Aiptasia larvae results in a decrease in NF-κB expression. Our results suggest that Symbiodinium suppresses NF-κB in order to enable establishment of symbiosis in Aiptasia. These results are the first to demonstrate a link between changes in the conserved immune regulatory protein NF-κB and cnidarian symbiotic status."
TREVOR SIGGERS,Survey of variation in human transcription factors reveals prevalent DNA binding changes,"Sequencing of exomes and genomes has revealed abundant genetic variation affecting the coding sequences of human transcription factors (TFs), but the consequences of such variation remain largely unexplored. We developed a computational, structure-based approach to evaluate TF variants for their impact on DNA binding activity and used universal protein-binding microarrays to assay sequence-specific DNA binding activity across 41 reference and 117 variant alleles found in individuals of diverse ancestries and families with Mendelian diseases. We found 77 variants in 28 genes that affect DNA binding affinity or specificity and identified thousands of rare alleles likely to alter the DNA binding activity of human sequence-specific TFs. Our results suggest that most individuals have unique repertoires of TF DNA binding activities, which may contribute to phenotypic variation."
TREVOR SIGGERS,Varied effects of algal symbionts on transcription factor NF-κB in a sea anemone and a coral: possible roles in symbiosis and thermotolerance,"Many cnidarians, including the reef-building corals, undergo symbiotic mutualisms with photosynthetic dinoflagellate algae of the family Symbiodiniaceae. These partnerships are sensitive to temperature extremes, which cause symbiont loss and increased coral mortality. Previous studies have implicated host immunity and specifically immunity transcription factor NF-κB as having a role in the maintenance of the cnidarian-algal symbiosis. Here we have further investigated a possible role for NF-κB in establishment and loss of symbiosis in various strains of the anemone Exaiptasia (Aiptasia) and in the coral Pocillopora damicornis. Our results show that NF-κB expression is reduced in Aiptasia larvae and adults that host certain algae strains. Treatment of Aiptasia larvae with a known symbiosis-promoting cytokine, transforming growth factor β, also led to decreased NF-κB expression. We also show that aposymbiotic Aiptasia (with high NF-κB expression) have increased survival following infection with the pathogenic bacterium Serratia marcescens as compared to symbiotic Aiptasia (low NF-κB expression). Furthermore, a P. damicornis coral colony hosting Durusdinium spp. (formerly clade D) symbionts had higher basal NF-κB expression and decreased heat-induced bleaching as compared to two individuals hosting Cladocopium spp. (formerly clade C) symbionts. Lastly, genome-wide gene expression profiling and genomic promoter analysis identified putative NF-κB target genes that may be involved in thermal bleaching, symbiont maintenance, and/or immune protection in P. damicornis. Our results provide further support for the hypothesis that modulation of NF-κB and immunity plays a role in some, but perhaps not all, cnidarian-Symbiodiniaceae partnerships as well as in resistance to pathogens and bleaching."
TREVOR SIGGERS,Widespread perturbation of ETS factor binding sites in cancer,"Although >90% of somatic mutations reside in non-coding regions, few have been reported as cancer drivers. To predict driver non-coding variants (NCVs), we present a transcription factor (TF)-aware burden test based on a model of coherent TF function in promoters. We apply this test to NCVs from the Pan-Cancer Analysis of Whole Genomes cohort and predict 2555 driver NCVs in the promoters of 813 genes across 20 cancer types. These genes are enriched in cancer-related gene ontologies, essential genes, and genes associated with cancer prognosis. We find that 765 candidate driver NCVs alter transcriptional activity, 510 lead to differential binding of TF-cofactor regulatory complexes, and that they primarily impact the binding of ETS factors. Finally, we show that different NCVs within a promoter often affect transcriptional activity through shared mechanisms. Our integrated computational and experimental approach shows that cancer NCVs are widespread and that ETS factors are commonly disrupted."
JERRY CHEN,A forward genetic screen identifies modifiers of rocaglate responsiveness,"Rocaglates are a class of eukaryotic translation initiation inhibitors that are being explored as chemotherapeutic agents. They function by targeting eukaryotic initiation factor (eIF) 4A, an RNA helicase critical for recruitment of the 40S ribosome (and associated factors) to mRNA templates. Rocaglates perturb eIF4A activity by imparting a gain-of-function activity to eIF4A and mediating clamping to RNA. To appreciate how rocaglates could best be enabled in the clinic, an understanding of resistance mechanisms is important, as this could inform on strategies to bypass such events as well as identify responsive tumor types. Here, we report on the results of a positive selection, ORFeome screen aimed at identifying cDNAs capable of conferring resistance to rocaglates. Two of the most potent modifiers of rocaglate response identified were the transcription factors FOXP3 and NR1I3, both of which have been implicated in ABCB1 regulation-the gene encoding P-glycoprotein (Pgp). Pgp has previously been implicated in conferring resistance to silvestrol, a naturally occurring rocaglate, and we show here that this extends to additional synthetic rocaglate derivatives. In addition, FOXP3 and NR1I3 impart a multi-drug resistant phenotype that is reversed upon inhibition of Pgp, suggesting a potential therapeutic combination strategy."
ANTHONY PETRO,"Race, Gender, Sexuality, and Religion in North America","The history of religion in the United States cannot be understood without attending to histories of race, gender, and sexuality. Since the 1960s, social and political movements for civil rights have ignited interest in the politics of identity, especially those tied to movements for racial justice, women’s rights, and LGBT rights. These movements have in turn informed scholarly practice, not least by prompting the formation of new academic fields, such as Women’s Studies and African American studies, and new forms of analysis, such as intersectionality, critical race theory, and feminist and queer theory. These movements have transformed how scholars of religion in colonial North America and the United States approach intersections of race, gender, and sexuality. From the colonial period to the present, these discourses of difference have shaped religious practice and belief. Religion has likewise shaped how people understand race, gender, and sexuality. The way that most people in the United States think about identity, especially in terms of race, gender, or sexuality, has a longer history forged out of encounters among European Christians, Native Americans, and people of African descent in the colonial world. European Christians brought with them a number of assumptions about the connection between civilization and Christian ideals of gender and sexuality. Many saw their role in the Americas as one of Christianization, a process that included not only religious but also sexual and cultural conversion, as these went hand in hand. Assumptions about religion and sexuality proved central to how European colonists understood the people they encountered as “heathens” or “pagans.” Religion likewise informed how they interpreted the enslavement of Africans, which was often justified through theological readings of the Bible. Native Americans and African Americans also drew upon religion to understand and to resist the violence of European colonialism and enslavement. In the modern United States, languages of religion, race, gender, and sexuality continue to inform one another as they define the boundaries of normative “modernity,” including the role of religion in politics and the relationship between religious versus secular arguments about race, gender, and sexuality."
ANTHONY PETRO,"Sex, art, and moral panic",
ANDREW KURTZ,Ge/Si as a tracer for Si in paired catchments of the Luquillo CZO,"Catchment lithology is a significant factor influencing the generation and transport of solutes in the critical zone. In the Luquillo Mountains of Puerto Rico, the Quebrada Guaba and Bisley catchments are studied to understand how lithology affects concentration-discharge (C-Q) relationships. Ge/Si ratios in pore water and stream samples are used to identify sources of Si to streams in the Bisley 1 watershed. Quebrada Guaba is underlain by quartz diorite and is characterized by strong Si dilution behavior (power law slope = -0.47)^1. During baseflow, Ge/Si = 0.27-0.47 μmol mol^-1 due to weathering of plagioclase and precipitation of Ge enriched kaolinite in the bedrock-saprolite interface2. During storms, hydrologic pathways shift to shallower flow paths with lower Si concentrations and higher Ge/Si (1.0-4.0 μmol mol^-1)^3. The shift to saprolite-dominated flow paths carrying dilute Si end-members drives the Si-Q pattern in this catchment. The volcaniclastic sub-catchment of Bisley 1 has a more chemostatic Si-Q relationship (power law slope of = -0.30)^1. In this study, lysemeters at the Bisley sites of B1S1, B1S2 and B1R show higher Si pore water concentrations than the LG sites at Quebrada Guaba. Ge/Si ratios for Bisley are lower than Guaba except for 200-300 cm depth were ratios increase to 2.87 μmol mol^-1 (B1S1). Dissolved Si concentrations increase markedly from 200 cm to the surface at B1S1 and B1S2. Ge/Si shows the opposite trend with ratios decreasing from 2.87 to 0.86 μmol mol^-1. This pattern of increased pore water Si and low Ge/Si may be due to phytolith dissolution also observed in Quebrada Guaba^2,4. Bisleys greater Si depletion near the surface may result in more sensitivity to phytolith inputs. Stream samples from Bisley 1 will be analyzed for major cations and Ge/Si to understand how pore water or other shallow surface reservoirs influence Si-Q patterns in this catchment."
ANDREW KURTZ,Soil warming accelerates biogeochemical silica cycling in a temperate forest,"Biological cycling of silica plays an important role in terrestrial primary production. Soil warming stemming from climate change can alter the cycling of elements, such as carbon and nitrogen, in forested ecosystems. However, the effects of soil warming on the biogeochemical cycle of silica in forested ecosystems remain unexplored. Here we examine long-term forest silica cycling under ambient and warmed conditions over a 15-year period of experimental soil warming at Harvard Forest (Petersham, MA). Specifically, we measured silica concentrations in organic and mineral soils, and in the foliage and litter of two dominant species (Acer rubrum and Quercus rubra), in a large (30 × 30 m) heated plot and an adjacent control plot (30 × 30 m). In 2016, we also examined effects of heating on dissolved silica in the soil solution, and conducted a litter decomposition experiment using four tree species (Acer rubrum, Quercus rubra, Betula lenta, Tsuga canadensis) to examine effects of warming on the release of biogenic silica (BSi) from plants to soils. We find that tree foliage maintained constant silica concentrations in the control and warmed plots, which, coupled with productivity enhancements under warming, led to an increase in total plant silica uptake. We also find that warming drove an acceleration in the release of silica from decaying litter in three of the four species we examined, and a substantial increase in the silica dissolved in soil solution. However, we observe no changes in soil BSi stocks with warming. Together, our data indicate that warming increases the magnitude of silica uptake by vegetation and accelerates the internal cycling of silica in in temperate forests, with possible, and yet unresolved, effects on the delivery of silica from terrestrial to marine systems."
JEREMY MENCHIK,Woodrow Wilson and the spirit of liberal internationalism,"Woodrow Wilson is among most influential presidents in U.S. foreign policy history, and the most pious. The challenge for scholars is joining Wilson's faith and his foreign policies. What was the role of religion in Wilson's worldview? What is the place of religion in Wilsonianism? This article uses original archival sources and a synthesis of historical research to intervene in IR theory, demonstrating that Wilsonianism is a product of Wilson's specifically Southern Presbyterian upbringing, his admiration for other Christian idealists, and the influence of the budding movement of the Social Gospel. This finding raises a historiographic puzzle: why did late twentieth century IR scholars erase religion from theories of liberal internationalism? The article suggests Wilson's religion has been erased as part of the broader project of desacralizing and universalizing liberal internationalism. Wilson's worldview was a mirror for the kind of social and political order he witnessed and propagated in America, a Janus-faced spirit of universalism and exceptionalism, internationalism and parochialism, that continues to motivate the liberal internationalist project. Unearthing the Protestant origins of Wilsonianism helps us to explicate the missionary spirit driving the liberal internationalist project."
JEREMY MENCHIK,Muslim moderates and democratic breakdown in Indonesia,"For much of the 2000s, scholars and activists lauded Indonesia’s surprisingly successful transition to democracy. Recent years, however, have made imperfections in Indonesian democracy visible to the point where the death of Indonesian democracy is imaginable if not yet underway. This article outlines the role that Indonesian Islamic civil society may play in the death of Indonesian democracy. Drawing on original survey data and interviews, as well as case studies in which the preferences of Nahdlatul Ulama (NU) and Muhammadiyah leaders have become visible, this paper argues that their values are compatible with both democracy and authoritarianism. While NU and Muhammadiyah exemplify the civic associational ties and democratic culture that are necessary for making democracy work, civic pluralism is not their only value. NU and Muhammadiyah have a hierarchy of values that they promote and defend, including many anti-democratic values. They are willing to forgo civic pluralism in order to combat blasphemy against Islam, ensure Muslim control over overwhelmingly Muslim regions, and limit political expression concerning heterodox approaches to Islam or non-Muslim involvement in matters of aqidah (faith). If Indonesian democracy dies, it will likely be a result of a coalition of Islamists and autocrats appealing to these anti-democratic values in order to capture the lower classes and moderate Muslims, including many members of NU and Muhammadiyah."
KAMAL SEN,First M87 Event Horizon Telescope results. III. Data processing and calibration,"We present the calibration and reduction of Event Horizon Telescope (EHT) 1.3 mm radio wavelength observations of the supermassive black hole candidate at the center of the radio galaxy M87 and the quasar 3C 279, taken during the 2017 April 5–11 observing campaign. These global very long baseline interferometric observations include for the first time the highly sensitive Atacama Large Millimeter/submillimeter Array (ALMA); reaching an angular resolution of 25 μas, with characteristic sensitivity limits of ~1 mJy on baselines to ALMA and ~10 mJy on other baselines. The observations present challenges for existing data processing tools, arising from the rapid atmospheric phase fluctuations, wide recording bandwidth, and highly heterogeneous array. In response, we developed three independent pipelines for phase calibration and fringe detection, each tailored to the specific needs of the EHT. The final data products include calibrated total intensity amplitude and phase information. They are validated through a series of quality assurance tests that show consistency across pipelines and set limits on baseline systematic errors of 2% in amplitude and 1° in phase. The M87 data reveal the presence of two nulls in correlated flux density at ~3.4 and ~8.3 Gλ and temporal evolution in closure quantities, indicating intrinsic variability of compact structure on a timescale of days, or several light-crossing times for a few billion solar-mass black hole. These measurements provide the first opportunity to image horizon-scale structure in M87."
KAMAL SEN,First M87 Event Horizon Telescope results. V. Physical origin of the asymmetric ring,"The Event Horizon Telescope (EHT) has mapped the central compact radio source of the elliptical galaxy M87 at 1.3 mm with unprecedented angular resolution. Here we consider the physical implications of the asymmetric ring seen in the 2017 EHT data. To this end, we construct a large library of models based on general relativistic magnetohydrodynamic (GRMHD) simulations and synthetic images produced by general relativistic ray tracing. We compare the observed visibilities with this library and confirm that the asymmetric ring is consistent with earlier predictions of strong gravitational lensing of synchrotron emission from a hot plasma orbiting near the black hole event horizon. The ring radius and ring asymmetry depend on black hole mass and spin, respectively, and both are therefore expected to be stable when observed in future EHT campaigns. Overall, the observed image is consistent with expectations for the shadow of a spinning Kerr black hole as predicted by general relativity. If the black hole spin and M87's large scale jet are aligned, then the black hole spin vector is pointed away from Earth. Models in our library of non-spinning black holes are inconsistent with the observations as they do not produce sufficiently powerful jets. At the same time, in those models that produce a sufficiently powerful jet, the latter is powered by extraction of black hole spin energy through mechanisms akin to the Blandford-Znajek process. We briefly consider alternatives to a black hole for the central compact object. Analysis of existing EHT polarization data and data taken simultaneously at other wavelengths will soon enable new tests of the GRMHD models, as will future EHT campaigns at 230 and 345 GHz."
KAMAL SEN,First M87 Event Horizon Telescope results. VI. The shadow and mass of the central black hole,"We present measurements of the properties of the central radio source in M87 using Event Horizon Telescope data obtained during the 2017 campaign. We develop and fit geometric crescent models (asymmetric rings with interior brightness depressions) using two independent sampling algorithms that consider distinct representations of the visibility data. We show that the crescent family of models is statistically preferred over other comparably complex geometric models that we explore. We calibrate the geometric model parameters using general relativistic magnetohydrodynamic (GRMHD) models of the emission region and estimate physical properties of the source. We further fit images generated from GRMHD models directly to the data. We compare the derived emission region and black hole parameters from these analyses with those recovered from reconstructed images. There is a remarkable consistency among all methods and data sets. We find that >50% of the total flux at arcsecond scales comes from near the horizon, and that the emission is dramatically suppressed interior to this region by a factor >10, providing direct evidence of the predicted shadow of a black hole. Across all methods, we measure a crescent diameter of 42 ± 3 μas and constrain its fractional width to be <0.5. Associating the crescent feature with the emission surrounding the black hole shadow, we infer an angular gravitational radius of GM/Dc^2 = 3.8 ± 0.4 μas. Folding in a distance measurement of {16.8}_{-0.7}^{+0.8}{Mpc} gives a black hole mass of M = 6.5 ± 0.2{| }_{stat} ± 0.7{| }_{sys} × {10}^{9} {M}_{odot }. This measurement from lensed emission near the event horizon is consistent with the presence of a central Kerr black hole, as predicted by the general theory of relativity."
KAMAL SEN,Cortical gamma rhythms modulate NMDAR-mediated spike timing dependent plasticity in a biophysical model,"Spike timing dependent plasticity (STDP) has been observed experimentally in vitro and is a widely studied neural algorithm for synaptic modification. While the functional role of STDP has been investigated extensively, the effect of rhythms on the precise timing of STDP has not been characterized as well. We use a simplified biophysical model of a cortical network that generates pyramidal interneuronal gamma rhythms (PING). Plasticity via STDP is investigated at the excitatory pyramidal cell synapse from a gamma frequency (30–90 Hz) input independent of the network gamma rhythm. The input may represent a corticocortical or an information-specific thalamocortical connection. This synapse is mediated by N-methyl-D-aspartate receptor mediated (NMDAR) currents. For distinct network and input frequencies, the model shows robust frequency regimes of potentiation and depression, providing a mechanism by which responses to certain inputs can potentiate while responses to other inputs depress. For potentiating regimes, the model suggests an optimal amount and duration of plasticity that can occur, which depends on the time course for the decay of the postsynaptic NMDAR current. Prolonging the duration of the input beyond this optimal time results in depression. Inserting pauses in the input can increase the total potentiation. The optimal pause length corresponds to the decay time of the NMDAR current. Thus, STDP in this model provides a mechanism for potentiation and depression depending on input frequency and suggests that the slow NMDAR current decay helps to regulate the optimal amplitude and duration of the plasticity. The optimal pause length is comparable to the time scale of the negative phase of a modulatory theta rhythm, which may pause gamma rhythm spiking. Our pause results may suggest a novel role for this theta rhythm in plasticity. Finally, we discuss our results in the context of auditory thalamocortical plasticity."
KAMAL SEN,Interactions across multiple stimulus dimensions in primary auditory cortex,
KAMAL SEN,First Sagittarius A* Event Horizon Telescope results. V. Testing astrophysical models of the galactic center black hole,"In this paper we provide a first physical interpretation for the Event Horizon Telescope's (EHT) 2017 observations of Sgr A*. Our main approach is to compare resolved EHT data at 230 GHz and unresolved non-EHT observations from radio to X-ray wavelengths to predictions from a library of models based on time-dependent general relativistic magnetohydrodynamics simulations, including aligned, tilted, and stellar-wind-fed simulations; radiative transfer is performed assuming both thermal and nonthermal electron distribution functions. We test the models against 11 constraints drawn from EHT 230 GHz data and observations at 86 GHz, 2.2 μm, and in the X-ray. All models fail at least one constraint. Light-curve variability provides a particularly severe constraint, failing nearly all strongly magnetized (magnetically arrested disk (MAD)) models and a large fraction of weakly magnetized models. A number of models fail only the variability constraints. We identify a promising cluster of these models, which are MAD and have inclination i ≤ 30°. They have accretion rate (5.2–9.5) × 10−9 M ⊙ yr−1, bolometric luminosity (6.8–9.2) × 1035 erg s−1, and outflow power (1.3–4.8) × 1038 erg s−1. We also find that all models with i ≥ 70° fail at least two constraints, as do all models with equal ion and electron temperature; exploratory, nonthermal model sets tend to have higher 2.2 μm flux density; and the population of cold electrons is limited by X-ray constraints due to the risk of bremsstrahlung overproduction. Finally, we discuss physical and numerical limitations of the models, highlighting the possible importance of kinetic effects and duration of the simulations."
KAMAL SEN,Resolving the inner parsec of the blazar J1924–2914 with the event horizon telescope,"The blazar J1924–2914 is a primary Event Horizon Telescope (EHT) calibrator for the Galactic center’s black hole Sagittarius A*. Here we present the first total and linearly polarized intensity images of this source obtained with the unprecedented 20 μas resolution of the EHT. J1924–2914 is a very compact flat-spectrum radio source with strong optical variability and polarization. In April 2017 the source was observed quasi-simultaneously with the EHT (April 5–11), the Global Millimeter VLBI Array (April 3), and the Very Long Baseline Array (April 28), giving a novel view of the source at four observing frequencies, 230, 86, 8.7, and 2.3 GHz. These observations probe jet properties from the subparsec to 100 pc scales. We combine the multifrequency images of J1924–2914 to study the source morphology. We find that the jet exhibits a characteristic bending, with a gradual clockwise rotation of the jet projected position angle of about 90° between 2.3 and 230 GHz. Linearly polarized intensity images of J1924–2914 with the extremely fine resolution of the EHT provide evidence for ordered toroidal magnetic fields in the blazar compact core."
KAMAL SEN,A physiologically inspired model for solving the cocktail party problem.,"At a cocktail party, we can broadly monitor the entire acoustic scene to detect important cues (e.g., our names being called, or the fire alarm going off), or selectively listen to a target sound source (e.g., a conversation partner). It has recently been observed that individual neurons in the avian field L (analog to the mammalian auditory cortex) can display broad spatial tuning to single targets and selective tuning to a target embedded in spatially distributed sound mixtures. Here, we describe a model inspired by these experimental observations and apply it to process mixtures of human speech sentences. This processing is realized in the neural spiking domain. It converts binaural acoustic inputs into cortical spike trains using a multi-stage model composed of a cochlear filter-bank, a midbrain spatial-localization network, and a cortical network. The output spike trains of the cortical network are then converted back into an acoustic waveform, using a stimulus reconstruction technique. The intelligibility of the reconstructed output is quantified using an objective measure of speech intelligibility. We apply the algorithm to single and multi-talker speech to demonstrate that the physiologically inspired algorithm is able to achieve intelligible reconstruction of an ""attended"" target sentence embedded in two other non-attended masker sentences. The algorithm is also robust to masker level and displays performance trends comparable to humans. The ideas from this work may help improve the performance of hearing assistive devices (e.g., hearing aids and cochlear implants), speech-recognition technology, and computational algorithms for processing natural scenes cluttered with spatially distributed acoustic objects."
KAMAL SEN,"Cortical transformation of spatial processing for solving the cocktail party problem: a computational model(1,2,3).","In multisource, ""cocktail party"" sound environments, human and animal auditory systems can use spatial cues to effectively separate and follow one source of sound over competing sources. While mechanisms to extract spatial cues such as interaural time differences (ITDs) are well understood in precortical areas, how such information is reused and transformed in higher cortical regions to represent segregated sound sources is not clear. We present a computational model describing a hypothesized neural network that spans spatial cue detection areas and the cortex. This network is based on recent physiological findings that cortical neurons selectively encode target stimuli in the presence of competing maskers based on source locations (Maddox et al., 2012). We demonstrate that key features of cortical responses can be generated by the model network, which exploits spatial interactions between inputs via lateral inhibition, enabling the spatial separation of target and interfering sources while allowing monitoring of a broader acoustic space when there is no competition. We present the model network along with testable experimental paradigms as a starting point for understanding the transformation and organization of spatial information from midbrain to cortex. This network is then extended to suggest engineering solutions that may be useful for hearing-assistive devices in solving the cocktail party problem."
KAMAL SEN,A universal power-law prescription for variability from synthetic images of black hole accretion flows,"We present a framework for characterizing the spatiotemporal power spectrum of the variability expected from the horizon-scale emission structure around supermassive black holes, and we apply this framework to a library of general relativistic magnetohydrodynamic (GRMHD) simulations and associated general relativistic ray-traced images relevant for Event Horizon Telescope (EHT) observations of Sgr A*. We find that the variability power spectrum is generically a red-noise process in both the temporal and spatial dimensions, with the peak in power occurring on the longest timescales and largest spatial scales. When both the time-averaged source structure and the spatially integrated light-curve variability are removed, the residual power spectrum exhibits a universal broken power-law behavior. On small spatial frequencies, the residual power spectrum rises as the square of the spatial frequency and is proportional to the variance in the centroid of emission. Beyond some peak in variability power, the residual power spectrum falls as that of the time-averaged source structure, which is similar across simulations; this behavior can be naturally explained if the variability arises from a multiplicative random field that has a steeper high-frequency power-law index than that of the time-averaged source structure. We briefly explore the ability of power spectral variability studies to constrain physical parameters relevant for the GRMHD simulations, which can be scaled to provide predictions for black holes in a range of systems in the optically thin regime. We present specific expectations for the behavior of the M87* and Sgr A* accretion flows as observed by the EHT."
KAMAL SEN,Millimeter light curves of Sagittarius A* observed during the 2017 Event Horizon Telescope campaign,"The Event Horizon Telescope (EHT) observed the compact radio source, Sagittarius A* (Sgr A*), in the Galactic Center on 2017 April 5–11 in the 1.3 mm wavelength band. At the same time, interferometric array data from the Atacama Large Millimeter/submillimeter Array and the Submillimeter Array were collected, providing Sgr A* light curves simultaneous with the EHT observations. These data sets, complementing the EHT very long baseline interferometry, are characterized by a cadence and signal-to-noise ratio previously unattainable for Sgr A* at millimeter wavelengths, and they allow for the investigation of source variability on timescales as short as a minute. While most of the light curves correspond to a low variability state of Sgr A*, the April 11 observations follow an X-ray flare and exhibit strongly enhanced variability. All of the light curves are consistent with a red-noise process, with a power spectral density (PSD) slope measured to be between −2 and −3 on timescales between 1 minute and several hours. Our results indicate a steepening of the PSD slope for timescales shorter than 0.3 hr. The spectral energy distribution is flat at 220 GHz, and there are no time lags between the 213 and 229 GHz frequency bands, suggesting low optical depth for the event horizon scale source. We characterize Sgr A*’s variability, highlighting the different behavior observed just after the X-ray flare, and use Gaussian process modeling to extract a decorrelation timescale and a PSD slope. We also investigate the systematic calibration uncertainties by analyzing data from independent data reduction pipelines."
KAMAL SEN,Cortical Gamma Rhythms Modulate NMDAR-Mediated Spike Timing Dependent Plasticity in a Biophysical Model,"Spike timing dependent plasticity (STDP) has been observed experimentally in vitro and is a widely studied neural algorithm for synaptic modification. While the functional role of STDP has been investigated extensively, the effect of rhythms on the precise timing of STDP has not been characterized as well. We use a simplified biophysical model of a cortical network that generates pyramidal interneuronal gamma rhythms (PING). Plasticity via STDP is investigated at the excitatory pyramidal cell synapse from a gamma frequency (30–90 Hz) input independent of the network gamma rhythm. The input may represent a corticocortical or an information-specific thalamocortical connection. This synapse is mediated by N-methyl-D-aspartate receptor mediated (NMDAR) currents. For distinct network and input frequencies, the model shows robust frequency regimes of potentiation and depression, providing a mechanism by which responses to certain inputs can potentiate while responses to other inputs depress. For potentiating regimes, the model suggests an optimal amount and duration of plasticity that can occur, which depends on the time course for the decay of the postsynaptic NMDAR current. Prolonging the duration of the input beyond this optimal time results in depression. Inserting pauses in the input can increase the total potentiation. The optimal pause length corresponds to the decay time of the NMDAR current. Thus, STDP in this model provides a mechanism for potentiation and depression depending on input frequency and suggests that the slow NMDAR current decay helps to regulate the optimal amplitude and duration of the plasticity. The optimal pause length is comparable to the time scale of the negative phase of a modulatory theta rhythm, which may pause gamma rhythm spiking. Our pause results may suggest a novel role for this theta rhythm in plasticity. Finally, we discuss our results in the context of auditory thalamocortical plasticity. Author Summary Rhythms are well studied phenomena in many animal species. Brain rhythms in the gamma frequency range (30–90 Hz) are thought to play a role in attention and memory. In this paper, we are interested in how cortical gamma rhythms interact with information specific inputs that also have a significant gamma frequency component. The results from our computational model show that plasticity associated with learning depends on the specific frequencies of the input and cortical gamma rhythms. The results show a mechanism by which both increases and decreases in the strength of the input connection can occur, depending on the specific frequency of the input. A current mediated by NMDA receptors may be responsible for the temporal course of the plasticity seen in these brain regions. We discuss the implications of our results for conditioning paradigms applied to auditory learning."
KAMAL SEN,First Sagittarius A* Event Horizon Telescope results. VI. Testing the black hole metric,"Astrophysical black holes are expected to be described by the Kerr metric. This is the only stationary, vacuum, axisymmetric metric, without electromagnetic charge, that satisfies Einstein’s equations and does not have pathologies outside of the event horizon. We present new constraints on potential deviations from the Kerr prediction based on 2017 EHT observations of Sagittarius A* (Sgr A*). We calibrate the relationship between the geometrically defined black hole shadow and the observed size of the ring-like images using a library that includes both Kerr and non-Kerr simulations. We use the exquisite prior constraints on the mass-to-distance ratio for Sgr A* to show that the observed image size is within ∼10% of the Kerr predictions. We use these bounds to constrain metrics that are parametrically different from Kerr, as well as the charges of several known spacetimes. To consider alternatives to the presence of an event horizon, we explore the possibility that Sgr A* is a compact object with a surface that either absorbs and thermally reemits incident radiation or partially reflects it. Using the observed image size and the broadband spectrum of Sgr A*, we conclude that a thermal surface can be ruled out and a fully reflective one is unlikely. We compare our results to the broader landscape of gravitational tests. Together with the bounds found for stellar-mass black holes and the M87 black hole, our observations provide further support that the external spacetimes of all black holes are described by the Kerr metric, independent of their mass."
KAMAL SEN,"First Sagittarius A* Event Horizon Telescope results. IV. Variability, morphology, and black hole mass","In this paper we quantify the temporal variability and image morphology of the horizon-scale emission from Sgr A*, as observed by the EHT in 2017 April at a wavelength of 1.3 mm. We find that the Sgr A* data exhibit variability that exceeds what can be explained by the uncertainties in the data or by the effects of interstellar scattering. The magnitude of this variability can be a substantial fraction of the correlated flux density, reaching ∼100% on some baselines. Through an exploration of simple geometric source models, we demonstrate that ring-like morphologies provide better fits to the Sgr A* data than do other morphologies with comparable complexity. We develop two strategies for fitting static geometric ring models to the time-variable Sgr A* data; one strategy fits models to short segments of data over which the source is static and averages these independent fits, while the other fits models to the full data set using a parametric model for the structural variability power spectrum around the average source structure. Both geometric modeling and image-domain feature extraction techniques determine the ring diameter to be 51.8 ± 2.3 μas (68% credible intervals), with the ring thickness constrained to have an FWHM between ∼30% and 50% of the ring diameter. To bring the diameter measurements to a common physical scale, we calibrate them using synthetic data generated from GRMHD simulations. This calibration constrains the angular size of the gravitational radius to be 4.8_-0.7^+1.4 μas, which we combine with an independent distance measurement from maser parallaxes to determine the mass of Sgr A* to be 4.0_-0.6^+10^6 M⊙."
KAMAL SEN,AIM: a network model of attention in auditory cortex,
KAMAL SEN,"First Sagittarius A* Event Horizon Telescope results. II. EHT and multiwavelength observations, data processing, and calibration","We present Event Horizon Telescope (EHT) 1.3 mm measurements of the radio source located at the position of the supermassive black hole Sagittarius A* (Sgr A*), collected during the 2017 April 5–11 campaign. The observations were carried out with eight facilities at six locations across the globe. Novel calibration methods are employed to account for Sgr A*'s flux variability. The majority of the 1.3 mm emission arises from horizon scales, where intrinsic structural source variability is detected on timescales of minutes to hours. The effects of interstellar scattering on the image and its variability are found to be subdominant to intrinsic source structure. The calibrated visibility amplitudes, particularly the locations of the visibility minima, are broadly consistent with a blurred ring with a diameter of ∼50 μas, as determined in later works in this series. Contemporaneous multiwavelength monitoring of Sgr A* was performed at 22, 43, and 86 GHz and at near-infrared and X-ray wavelengths. Several X-ray flares from Sgr A* are detected by Chandra, one at low significance jointly with Swift on 2017 April 7 and the other at higher significance jointly with NuSTAR on 2017 April 11. The brighter April 11 flare is not observed simultaneously by the EHT but is followed by a significant increase in millimeter flux variability immediately after the X-ray outburst, indicating a likely connection in the emission physics near the event horizon. We compare Sgr A*’s broadband flux during the EHT campaign to its historical spectral energy distribution and find that both the quiescent emission and flare emission are consistent with its long-term behavior."
KAMAL SEN,Event Horizon Telescope imaging of the archetypal blazar 3C 279 at an extreme 20 microarcsecond resolution,"3C 279 is an archetypal blazar with a prominent radio jet that show broadband flux density variability across the entire electromagnetic spectrum. We use an ultra-high angular resolution technique – global Very Long Baseline Interferometry (VLBI) at 1.3 mm (230 GHz) – to resolve the innermost jet of 3C 279 in order to study its fine-scale morphology close to the jet base where highly variable γ-ray emission is thought to originate, according to various models. The source was observed during four days in April 2017 with the Event Horizon Telescope at 230 GHz, including the phased Atacama Large Millimeter/submillimeter Array (ALMA), at an angular resolution of ∼20 μas (at a redshift of z = 0.536 this corresponds to ∼0.13 pc  ∼ 1700 Schwarzschild radii with a black hole mass M<jats:sub>BH</jats:sub> = 8 × 10^8 M_⊙). Imaging and model-fitting techniques were applied to the data to parameterize the fine-scale source structure and its variation. We find a multicomponent inner jet morphology with the northernmost component elongated perpendicular to the direction of the jet, as imaged at longer wavelengths. The elongated nuclear structure is consistent on all four observing days and across different imaging methods and model-fitting techniques, and therefore appears robust. Owing to its compactness and brightness, we associate the northern nuclear structure as the VLBI “core”. This morphology can be interpreted as either a broad resolved jet base or a spatially bent jet. We also find significant day-to-day variations in the closure phases, which appear most pronounced on the triangles with the longest baselines. Our analysis shows that this variation is related to a systematic change of the source structure. Two inner jet components move non-radially at apparent speeds of ∼15 c and ∼20 c (∼1.3 and ∼1.7 μas day^−1, respectively), which more strongly supports the scenario of traveling shocks or instabilities in a bent, possibly rotating jet. The observed apparent speeds are also coincident with the 3C 279 large-scale jet kinematics observed at longer (cm) wavelengths, suggesting no significant jet acceleration between the 1.3 mm core and the outer jet. The intrinsic brightness temperature of the jet components are ≲10^10 K, a magnitude or more lower than typical values seen at ≥7 mm wavelengths. The low brightness temperature and morphological complexity suggest that the core region of 3C 279 becomes optically thin at short (mm) wavelengths."
KAMAL SEN,First M87 Event Horizon Telescope results. II. Array and instrumentation,"The Event Horizon Telescope (EHT) is a very long baseline interferometry (VLBI) array that comprises millimeter- and submillimeter-wavelength telescopes separated by distances comparable to the diameter of the Earth. At a nominal operating wavelength of ~1.3 mm, EHT angular resolution (λ/D) is ~25 μas, which is sufficient to resolve nearby supermassive black hole candidates on spatial and temporal scales that correspond to their event horizons. With this capability, the EHT scientific goals are to probe general relativistic effects in the strong-field regime and to study accretion and relativistic jet formation near the black hole boundary. In this Letter we describe the system design of the EHT, detail the technology and instrumentation that enable observations, and provide measures of its performance. Meeting the EHT science objectives has required several key developments that have facilitated the robust extension of the VLBI technique to EHT observing wavelengths and the production of instrumentation that can be deployed on a heterogeneous array of existing telescopes and facilities. To meet sensitivity requirements, high-bandwidth digital systems were developed that process data at rates of 64 gigabit s−1, exceeding those of currently operating cm-wavelength VLBI arrays by more than an order of magnitude. Associated improvements include the development of phasing systems at array facilities, new receiver installation at several sites, and the deployment of hydrogen maser frequency standards to ensure coherent data capture across the array. These efforts led to the coordination and execution of the first Global EHT observations in 2017 April, and to event-horizon-scale imaging of the supermassive black hole candidate in M87."
KAMAL SEN,First M87 Event Horizon Telescope results. I. The shadow of the supermassive black hole,"When surrounded by a transparent emission region, black holes are expected to reveal a dark shadow caused by gravitational light bending and photon capture at the event horizon. To image and study this phenomenon, we have assembled the Event Horizon Telescope, a global very long baseline interferometry array observing at a wavelength of 1.3 mm. This allows us to reconstruct event-horizon-scale images of the supermassive black hole candidate in the center of the giant elliptical galaxy M87. We have resolved the central compact radio source as an asymmetric bright emission ring with a diameter of 42 ± 3 μas, which is circular and encompasses a central depression in brightness with a flux ratio gsim10:1. The emission ring is recovered using different calibration and imaging schemes, with its diameter and width remaining stable over four different observations carried out in different days. Overall, the observed image is consistent with expectations for the shadow of a Kerr black hole as predicted by general relativity. The asymmetry in brightness in the ring can be explained in terms of relativistic beaming of the emission from a plasma rotating close to the speed of light around a black hole. We compare our images to an extensive library of ray-traced general-relativistic magnetohydrodynamic simulations of black holes and derive a central mass of M = (6.5 ± 0.7) × 10^9 M ⊙. Our radio-wave observations thus provide powerful evidence for the presence of supermassive black holes in centers of galaxies and as the central engines of active galactic nuclei. They also present a new tool to explore gravity in its most extreme limit and on a mass scale that was so far not accessible."
KAMAL SEN,First Sagittarius A* Event Horizon Telescope results. III. Imaging of the Galactic center supermassive black hole,"We present the first event-horizon-scale images and spatiotemporal analysis of Sgr A* taken with the Event Horizon Telescope in 2017 April at a wavelength of 1.3 mm. Imaging of Sgr A* has been conducted through surveys over a wide range of imaging assumptions using the classical CLEAN algorithm, regularized maximum likelihood methods, and a Bayesian posterior sampling method. Different prescriptions have been used to account for scattering effects by the interstellar medium toward the Galactic center. Mitigation of the rapid intraday variability that characterizes Sgr A* has been carried out through the addition of a “variability noise budget” in the observed visibilities, facilitating the reconstruction of static full-track images. Our static reconstructions of Sgr A* can be clustered into four representative morphologies that correspond to ring images with three different azimuthal brightness distributions and a small cluster that contains diverse nonring morphologies. Based on our extensive analysis of the effects of sparse (u, v)-coverage, source variability, and interstellar scattering, as well as studies of simulated visibility data, we conclude that the Event Horizon Telescope Sgr A* data show compelling evidence for an image that is dominated by a bright ring of emission with a ring diameter of ∼50 μas, consistent with the expected “shadow” of a 4 × 106 M⊙ black hole in the Galactic center located at a distance of 8 kpc."
KAMAL SEN,Characterizing and mitigating intraday variability: reconstructing source structure in accreting black holes with mm-VLBI,"The extraordinary physical resolution afforded by the Event Horizon Telescope has opened a window onto the astrophysical phenomena unfolding on horizon scales in two known black holes, M87* and Sgr A*. However, with this leap in resolution has come a new set of practical complications. Sgr A* exhibits intraday variability that violates the assumptions underlying Earth aperture synthesis, limiting traditional image reconstruction methods to short timescales and data sets with very sparse (u, v) coverage. We present a new set of tools to detect and mitigate this variability. We develop a data-driven, model-agnostic procedure to detect and characterize the spatial structure of intraday variability. This method is calibrated against a large set of mock data sets, producing an empirical estimator of the spatial power spectrum of the brightness fluctuations. We present a novel Bayesian noise modeling algorithm that simultaneously reconstructs an average image and statistical measure of the fluctuations about it using a parameterized form for the excess variance in the complex visibilities not otherwise explained by the statistical errors. These methods are validated using a variety of simulated data, including general relativistic magnetohydrodynamic simulations appropriate for Sgr A* and M87*. We find that the reconstructed source structure and variability are robust to changes in the underlying image model. We apply these methods to the 2017 EHT observations of M87*, finding evidence for variability across the EHT observing campaign. The variability mitigation strategies presented are widely applicable to very long baseline interferometry observations of variable sources generally, for which they provide a data-informed averaging procedure and natural characterization of inter-epoch image consistency."
KAMAL SEN,First Sagittarius A* Event Horizon Telescope results. I. The shadow of the supermassive black hole in the center of the Milky Way,"We present the first Event Horizon Telescope (EHT) observations of Sagittarius A* (Sgr A*), the Galactic center source associated with a supermassive black hole. These observations were conducted in 2017 using a global interferometric array of eight telescopes operating at a wavelength of λ = 1.3 mm. The EHT data resolve a compact emission region with intrahour variability. A variety of imaging and modeling analyses all support an image that is dominated by a bright, thick ring with a diameter of 51.8 ± 2.3 μas (68% credible interval). The ring has modest azimuthal brightness asymmetry and a comparatively dim interior. Using a large suite of numerical simulations, we demonstrate that the EHT images of Sgr A* are consistent with the expected appearance of a Kerr black hole with mass ∼4 × 106 M ⊙, which is inferred to exist at this location based on previous infrared observations of individual stellar orbits, as well as maser proper-motion studies. Our model comparisons disfavor scenarios where the black hole is viewed at high inclination (i &gt; 50°), as well as nonspinning black holes and those with retrograde accretion disks. Our results provide direct evidence for the presence of a supermassive black hole at the center of the Milky Way, and for the first time we connect the predictions from dynamical measurements of stellar orbits on scales of 103–105 gravitational radii to event-horizon-scale images and variability. Furthermore, a comparison with the EHT results for the supermassive black hole M87* shows consistency with the predictions of general relativity spanning over three orders of magnitude in central mass."
KAMAL SEN,A biologically orientated algorithm for spatial sound segregation,"Listening in an acoustically cluttered scene remains a difficult task for both machines and hearing-impaired listeners. Normal-hearing listeners accomplish this task with relative ease by segregating the scene into its constituent sound sources, then selecting and attending to a target source. An assistive listening device that mimics the biological mechanisms underlying this behavior may provide an effective solution for those with difficulty listening in acoustically cluttered environments (e.g., a cocktail party). Here, we present a binaural sound segregation algorithm based on a hierarchical network model of the auditory system. In the algorithm, binaural sound inputs first drive populations of neurons tuned to specific spatial locations and frequencies. The spiking response of neurons in the output layer are then reconstructed into audible waveforms via a novel reconstruction method. We evaluate the performance of the algorithm with a speech-on-speech intelligibility task in normal-hearing listeners. This two-microphone-input algorithm is shown to provide listeners with perceptual benefit similar to that of a 16-microphone acoustic beamformer. These results demonstrate the promise of this biologically inspired algorithm for enhancing selective listening in challenging multi-talker scenes."
MEGAN M SULLIVAN,Search for heavy neutrinos with the T2K near detector ND280,"This paper reports on the search for heavy neutrinos with masses in the range 140<MN<493  MeV/c^2 using the off-axis near detector ND280 of the T2K experiment. These particles can be produced from kaon decays in the standard neutrino beam and then subsequently decay in ND280. The decay modes under consideration are N→ℓ±απ∓ and N→ℓ+αℓ−β(−)ν(α,β=e,μ). A search for such events has been made using the Time Projection Chambers of ND280, where the background has been reduced to less than two events in the current dataset in all channels. No excess has been observed in the signal region. A combined Bayesian statistical approach has been applied to extract upper limits on the mixing elements of heavy neutrinos to electron-, muon- and tau- flavored currents (U^2e, U^2μ, U^2τ) as a function of the heavy neutrino mass, e.g., U^2e<10−9 at 90% C.L. for a mass of 390  MeV/c^2. These constraints are competitive with previous experiments."
JOHN R FINNERTY,Transcription factor NF-κB is modulated by symbiotic status in a sea anemone model of cnidarian bleaching.,"Transcription factor NF-κB plays a central role in immunity from fruit flies to humans, and NF-κB activity is altered in many human diseases. To investigate a role for NF-κB in immunity and disease on a broader evolutionary scale we have characterized NF-κB in a sea anemone (Exaiptasia pallida; called Aiptasia herein) model for cnidarian symbiosis and dysbiosis (i.e., ""bleaching""). We show that the DNA-binding site specificity of Aiptasia NF-κB is similar to NF-κB proteins from a broad expanse of organisms. Analyses of NF-κB and IκB kinase proteins from Aiptasia suggest that non-canonical NF-κB processing is an evolutionarily ancient pathway, which can be reconstituted in human cells. In Aiptasia, NF-κB protein levels, DNA-binding activity, and tissue expression increase when loss of the algal symbiont Symbiodinium is induced by heat or chemical treatment. Kinetic analysis of NF-κB levels following loss of symbiosis show that NF-κB levels increase only after Symbiodinium is cleared. Moreover, introduction of Symbiodinium into naïve Aiptasia larvae results in a decrease in NF-κB expression. Our results suggest that Symbiodinium suppresses NF-κB in order to enable establishment of symbiosis in Aiptasia. These results are the first to demonstrate a link between changes in the conserved immune regulatory protein NF-κB and cnidarian symbiotic status."
JOHN R FINNERTY,"The Cnidarian-Bilaterian Ancestor Possessed at Least 56 Homeoboxes: Evidence from the Starlet Sea Anemone, Nematostella vectensis","The first near-complete set of homeodomains from a non-bilaterian animal is described. BACKGROUND. Homeodomain transcription factors are key components in the developmental toolkits of animals. While this gene superclass predates the evolutionary split between animals, plants, and fungi, many homeobox genes appear unique to animals. The origin of particular homeobox genes may, therefore, be associated with the evolution of particular animal traits. Here we report the first near-complete set of homeodomains from a basal (diploblastic) animal. RESULTS. Phylogenetic analyses were performed on 130 homeodomains from the sequenced genome of the sea anemone Nematostella vectensis along with 228 homeodomains from human and 97 homeodomains from Drosophila. The Nematostella homeodomains appear to be distributed among established homeodomain classes in the following fashion: 72 ANTP class; one HNF class; four LIM class; five POU class; 33 PRD class; five SINE class; and six TALE class. For four of the Nematostella homeodomains, there is disagreement between neighbor-joining and Bayesian trees regarding their class membership. A putative Nematostella CUT class gene is also identified. CONCLUSION. The homeodomain superclass underwent extensive radiations prior to the evolutionary split between Cnidaria and Bilateria. Fifty-six homeodomain families found in human and/or fruit fly are also found in Nematostella, though seventeen families shared by human and fly appear absent in Nematostella. Homeodomain loss is also apparent in the bilaterian taxa: eight homeodomain families shared by Drosophila and Nematostella appear absent from human (CG13424, EMXLX, HOMEOBRAIN, MSXLX, NK7, REPO, ROUGH, and UNC4), and six homeodomain families shared by human and Nematostella appear absent from fruit fly (ALX, DMBX, DUX, HNF, POU1, and VAX)."
JOHN R FINNERTY,"A Conserved Cluster of Three PRD-class Homeobox Genes (Homeobrain, Rx and Orthopedia) in the Cnidaria and Protostomia","BACKGROUND. Homeobox genes are a superclass of transcription factors with diverse developmental regulatory functions, which are found in plants, fungi and animals. In animals, several Antennapedia (ANTP)-class homeobox genes reside in extremely ancient gene clusters (for example, the Hox, ParaHox, and NKL clusters) and the evolution of these clusters has been implicated in the morphological diversification of animal bodyplans. By contrast, similarly ancient gene clusters have not been reported among the other classes of homeobox genes (that is, the LIM, POU, PRD and SIX classes). RESULTS. Using a combination of in silico queries and phylogenetic analyses, we found that a cluster of three PRD-class homeobox genes (Homeobrain (hbn), Rax (rx) and Orthopedia (otp)) is present in cnidarians, insects and mollusks (a partial cluster comprising hbn and rx is present in the placozoan Trichoplax adhaerens). We failed to identify this 'HRO' cluster in deuterostomes; in fact, the Homeobrain gene appears to be missing from the chordate genomes we examined, although it is present in hemichordates and echinoderms. To illuminate the ancestral organization and function of this ancient cluster, we mapped the constituent genes against the assembled genome of a model cnidarian, the sea anemone Nematostella vectensis, and characterized their spatiotemporal expression using in situ hybridization. In N. vectensis, these genes reside in a span of 33 kb with the same gene order as previously reported in insects. Comparisons of genomic sequences and expressed sequence tags revealed the presence of alternative transcripts of Nv-otp and two highly unusual protein-coding polymorphisms in the terminal helix of the Nv-rx homeodomain. A population genetic survey revealed the Rx polymorphisms to be widespread in natural populations. During larval development, all three genes are expressed in the ectoderm, in non-overlapping territories along the oral-aboral axis, with distinct temporal expression. CONCLUSION. We report the first evidence for a PRD-class homeobox cluster that appears to have been conserved since the time of the cnidarian-bilaterian ancestor, and possibly even earlier, given the presence of a partial cluster in the placozoan Trichoplax. Very similar clusters comprising these three genes exist in Nematostella and diverse protostomes. Interestingly, in chordates, one member of the ancestral cluster (homeobrain) has apparently been lost, and there is no linkage between rx and orthopedia in any of the vertebrates. In Nematostella, the spatial expression of these three genes along the body column is not colinear with their physical order in the cluster but the temporal expression is, therefore, using the terminology that has been applied to the Hox cluster genes, the HRO cluster would appear to exhibit temporal but not spatial colinearity. It remains to be seen whether the mechanisms responsible for the evolutionary conservation of the HRO cluster are the same mechanisms responsible for cohesion of the Hox cluster and other ANTP-class homeobox clusters that have been widely conserved throughout animal evolution."
JOHN R FINNERTY,The impact of autotrophic versus heterotrophic nutritional pathways on colony health and wound recovery in corals,"For animals that harbor photosynthetic symbionts within their tissues, such as corals, the different relative contributions of autotrophy versus heterotrophy to organismal energetic requirements have direct impacts on fitness. This is especially true for facultatively symbiotic corals, where the balance between host‐caught and symbiont‐produced energy can be altered substantially to meet the variable demands of a shifting environment. In this study, we utilized a temperate coral–algal system (the northern star coral, Astrangia poculata, and its photosynthetic endosymbiont, Symbiodinium psygmophilum) to explore the impacts of nutritional sourcing on the host's health and ability to regenerate experimentally excised polyps. For fed and starved colonies, wound healing and total colony tissue cover were differentially impacted by heterotrophy versus autotrophy. There was an additive impact of positive nutritional and symbiotic states on a coral's ability to initiate healing, but a greater influence of symbiont state on the recovery of lost tissue at the lesion site and complete polyp regeneration. On the other hand, regardless of symbiont state, fed corals maintained a higher overall colony tissue cover, which also enabled more active host behavior (polyp extension) and endosymbiont behavior (photosynthetic ability of Symbiondinium). Overall, we determined that the impact of nutritional state and symbiotic state varied between biological functions, suggesting a diversity in energetic sourcing for each of these processes."
JOHN R FINNERTY,Two alleles of NF-kappaB in the sea anemone Nematostella vectensis are widely dispersed in nature and encode proteins with distinct activities,"BACKGROUND: NF-kappaB is an evolutionarily conserved transcription factor that controls the expression of genes involved in many key organismal processes, including innate immunity, development, and stress responses. NF-kappaB proteins contain a highly conserved DNA-binding/dimerization domain called the Rel homology domain. METHODS/PRINCIPAL FINDINGS: We characterized two NF-kappaB alleles in the sea anemone Nematostella vectensis that differ at nineteen single-nucleotide polymorphisms (SNPs). Ten of these SNPs result in amino acid substitutions, including six within the Rel homology domain. Both alleles are found in natural populations of Nematostella. The relative abundance of the two NF-kappaB alleles differs between populations, and departures from Hardy-Weinberg equilibrium within populations indicate that the locus may be under selection. The proteins encoded by the two Nv-NF-kappaB alleles have different molecular properties, in part due to a Cys/Ser polymorphism at residue 67, which resides within the DNA recognition loop. In nearly all previously characterized NF-kappaB proteins, the analogous residue is fixed for Cys, and conversion of human RHD proteins from Cys to Ser at this site has been shown to increase DNA-binding ability and increase resistance to inhibition by thiol-reactive compounds. However, the naturally-occurring Nematostella variant with Cys at position 67 binds DNA with a higher affinity than the Ser variant. On the other hand, the Ser variant activates transcription in reporter gene assays more effectively, and it is more resistant to inhibition by a thiol-reactive compound. Reciprocal Cys<->Ser mutations at residue 67 of the native Nv-NF-kappaB proteins affect DNA binding as in human NF-kappaB proteins, e.g., a Cys->Ser mutation increases DNA binding of the native Cys variant. CONCLUSIONS/SIGNIFICANCE: These results are the first demonstration of a naturally occurring and functionally significant polymorphism in NF-kappaB in any species. The functional differences between these alleles and their uneven distribution in the wild suggest that different genotypes could be favored in different environments, perhaps environments that vary in their levels of peroxides or thiol-reactive compounds."
JOHN R FINNERTY,"Upgrades to StellaBase Facilitate Medical and Genetic Studies on the Starlet Sea Anemone, Nematostella Vectensis","The starlet sea anemone, Nematostella vectensis, is a basal metazoan organism that has recently emerged as an important model system in developmental biology and evolutionary genomics. StellaBase, the Nematostella Genomics Database (http://stellabase.org), was developed in 2005 as a resource to support the Nematostella research community. Recently, it has become apparent that Nematostella may be a particularly useful system for studying (i) microevolutionary variation in natural populations, and (ii) the functional evolution of human disease genes. We have developed two new databases that will foster such studies: StellaBase Disease (http://stellabase.org/disease) is a relational database that houses 155 904 invertebrate homologous isoforms of human disease genes from four leading genomic model systems (fly, worm, yeast and Nematostella), including 14 874 predicted genes from the sea anemone itself. StellaBase SNP (http://stellabase.org/SNP) is a relational database that describes the location and underlying type of mutation for 20 063 single nucleotide polymorphisms."
JOHN R FINNERTY,The Evolutionary Diversification of LSF and Grainyhead Transcription Factors Preceded the Radiation of Basal Animal Lineages,"BACKGROUND. The transcription factors of the LSF/Grainyhead (GRH) family are characterized by the possession of a distinctive DNA-binding domain that bears no clear relationship to other known DNA-binding domains, with the possible exception of the p53 core domain. In triploblastic animals, the LSF and GRH subfamilies have diverged extensively with respect to their biological roles, general expression patterns, and mechanism of DNA binding. For example, Grainyhead (GRH) homologs are expressed primarily in the epidermis, and they appear to play an ancient role in maintaining the epidermal barrier. By contrast, LSF homologs are more widely expressed, and they regulate general cellular functions such as cell cycle progression and survival in addition to cell-lineage specific gene expression. RESULTS. To illuminate the early evolution of this family and reconstruct the functional divergence of LSF and GRH, we compared homologs from 18 phylogenetically diverse taxa, including four basal animals (Nematostella vectensis, Vallicula multiformis, Trichoplax adhaerens, and Amphimedon queenslandica), a choanoflagellate (Monosiga brevicollis) and several fungi. Phylogenetic and bioinformatic analyses of these sequences indicate that (1) the LSF/GRH gene family originated prior to the animal-fungal divergence, and (2) the functional diversification of the LSF and GRH subfamilies occurred prior to the divergence between sponges and eumetazoans. Aspects of the domain architecture of LSF/GRH proteins are well conserved between fungi, choanoflagellates, and metazoans, though within the Metazoa, the LSF and GRH families are clearly distinct. We failed to identify a convincing LSF/GRH homolog in the sequenced genomes of the algae Volvox carteri and Chlamydomonas reinhardtii or the amoebozoan Dictyostelium purpureum. Interestingly, the ancestral GRH locus has become split into two separate loci in the sea anemone Nematostella, with one locus encoding a DNA binding domain and the other locus encoding the dimerization domain. CONCLUSIONS. In metazoans, LSF and GRH proteins play a number of roles that are essential to achieving and maintaining multicellularity. It is now clear that this protein family already existed in the unicellular ancestor of animals, choanoflagellates, and fungi. However, the diversification of distinct LSF and GRH subfamilies appears to be a metazoan invention. Given the conserved role of GRH in maintaining epithelial integrity in vertebrates, insects, and nematodes, it is noteworthy that the evolutionary origin of Grh appears roughly coincident with the evolutionary origin of the epithelium."
JOHN R FINNERTY,Intraspecific variation in oxidative stress tolerance in a model cnidarian: differences in peroxide sensitivity between and within populations of Nematostella vectensis,"Nematostella vectensis is a member of the phylum Cnidaria, a lineage that includes anemones, corals, hydras, and jellyfishes. This estuarine anemone is an excellent model system for investigating the evolution of stress tolerance because it is easy to collect in its natural habitat and to culture in the laboratory, and it has a sequenced genome. Additionally, there is evidence of local adaptation to environmental stress in different N. vectensis populations, and abundant protein-coding polymorphisms have been identified, including polymorphisms in proteins that are implicated in stress responses. N. vectensis can tolerate a wide range of environmental parameters, and has recently been shown to have substantial intraspecific variation in temperature preference. We investigated whether different clonal lines of anemones also exhibit differential tolerance to oxidative stress. N. vectensis populations are continually exposed to reactive oxygen species (ROS) generated during cellular metabolism and by other environmental factors. Fifteen clonal lines of N. vectensis collected from four different estuaries were exposed to hydrogen peroxide. Pronounced differences in survival and regeneration were apparent between clonal lines collected from Meadowlands, NJ, Baruch, SC, and Kingsport, NS, as well as among 12 clonal lines collected from a single Cape Cod marsh. To our knowledge, this is the first example of intraspecific variability in oxidative stress resistance in cnidarians or in any marine animal. As oxidative stress often accompanies heat stress in marine organisms, resistance to oxidative stress could strongly influence survival in warming oceans. For example, while elevated temperatures trigger bleaching in corals, oxidative stress is thought to be the proximal trigger of bleaching at the cellular level."
JOHN R FINNERTY,"Sex-specific and developmental expression of Dmrt genes in the starlet sea anemone, Nematostella vectensis","BACKGROUND: The molecular mechanisms underlying sex determination and differentiation in animals are incredibly diverse. The Dmrt (doublesex and mab-3 related transcription factor) gene family is an evolutionary ancient group of transcription factors dating to the ancestor of metazoans that are, in part, involved in sex determination and differentiation in numerous bilaterian animals and thus represents a potentially conserved mechanism for differentiating males and females dating to the protostome-deuterostome ancestor. Recently, the diversity of this gene family throughout animals has been described, but the expression and potential function for Dmrt genes is not well understood outside the bilaterians. RESULTS: Here, we report sex- and developmental-specific expression of all 11 Dmrts in the starlet sea anemone Nematostella vectensis. Nine out of the eleven Dmrts showed significant differences in developmental expression, with the highest expression typically in the adult stage and, in some cases, with little or no expression measured during embryogenesis. When expression was compared in females and males, seven of the eleven Dmrt genes had significant differences in expression with higher expression in males than in females for six of the genes. Lastly, expressions of two Dmrt genes with differential expression in each sex are located in the mesenteries and into the pharynx in polyps. CONCLUSIONS: Our results show that the phylogenetic diversity of Dmrt genes in N. vectensis is matched by an equally diverse pattern of expression during development and in each sex. This dynamic expression suggests multiple functions for Dmrt genes likely present in early diverging metazoans. Detailed functional analyses of individual genes will inform hypotheses regarding the antiquity of function for these transcription factors."
JOHN R FINNERTY,Two Alleles of NF-κB in the Sea Anemone Nematostella vectensis Are Widely Dispersed in Nature and Encode Proteins with Distinct Activities,"BACKGROUND. NF-κB is an evolutionarily conserved transcription factor that controls the expression of genes involved in many key organismal processes, including innate immunity, development, and stress responses. NF-κB proteins contain a highly conserved DNA-binding/dimerization domain called the Rel homology domain. METHODS/PRINCIPAL FINDINGS. We characterized two NF-κB alleles in the sea anemone Nematostella vectensis that differ at nineteen single-nucleotide polymorphisms (SNPs). Ten of these SNPs result in amino acid substitutions, including six within the Rel homology domain. Both alleles are found in natural populations of Nematostella. The relative abundance of the two NF-κB alleles differs between populations, and departures from Hardy-Weinberg equilibrium within populations indicate that the locus may be under selection. The proteins encoded by the two Nv-NF-κB alleles have different molecular properties, in part due to a Cys/Ser polymorphism at residue 67, which resides within the DNA recognition loop. In nearly all previously characterized NF-κB proteins, the analogous residue is fixed for Cys, and conversion of human RHD proteins from Cys to Ser at this site has been shown to increase DNA-binding ability and increase resistance to inhibition by thiol-reactive compounds. However, the naturally-occurring Nematostella variant with Cys at position 67 binds DNA with a higher affinity than the Ser variant. On the other hand, the Ser variant activates transcription in reporter gene assays more effectively, and it is more resistant to inhibition by a thiol-reactive compound. Reciprocal Cys<->Ser mutations at residue 67 of the native Nv-NF-κB proteins affect DNA binding as in human NF-κB proteins, e.g., a Cys->Ser mutation increases DNA binding of the native Cys variant. CONCLUSIONS/SIGNIFICANCE. These results are the first demonstration of a naturally occurring and functionally significant polymorphism in NF-κB in any species. The functional differences between these alleles and their uneven distribution in the wild suggest that different genotypes could be favored in different environments, perhaps environments that vary in their levels of peroxides or thiol-reactive compounds."
JOHN R FINNERTY,"Domain Duplication, Divergence, and Loss Events in Vertebrate Msx Paralogs Reveal Phylogenomically Informed Disease Markers","BACKGROUND. Msx originated early in animal evolution and is implicated in human genetic disorders. To reconstruct the functional evolution of Msx and inform the study of human mutations, we analyzed the phylogeny and synteny of 46 metazoan Msx proteins and tracked the duplication, diversification and loss of conserved motifs. RESULTS. Vertebrate Msx sequences sort into distinct Msx1, Msx2 and Msx3 clades. The sister-group relationship between MSX1 and MSX2 reflects their derivation from the 4p/5q chromosomal paralogon, a derivative of the original ""MetaHox"" cluster. We demonstrate physical linkage between Msx and other MetaHox genes (Hmx, NK1, Emx) in a cnidarian. Seven conserved domains, including two Groucho repression domains (N- and C-terminal), were present in the ancestral Msx. In cnidarians, the Groucho domains are highly similar. In vertebrate Msx1, the N-terminal Groucho domain is conserved, while the C-terminal domain diverged substantially, implying a novel function. In vertebrate Msx2 and Msx3, the C-terminal domain was lost. MSX1 mutations associated with ectodermal dysplasia or orofacial clefting disorders map to conserved domains in a non-random fashion. CONCLUSION. Msx originated from a MetaHox ancestor that also gave rise to Tlx, Demox, NK, and possibly EHGbox, Hox and ParaHox genes. Duplication, divergence or loss of domains played a central role in the functional evolution of Msx. Duplicated domains allow pleiotropically expressed proteins to evolve new functions without disrupting existing interaction networks. Human missense sequence variants reside within evolutionarily conserved domains, likely disrupting protein function. This phylogenomic evaluation of candidate disease markers will inform clinical and functional studies."
JOHN R FINNERTY,The Evolutionary Origin of the Runx/CBFbeta Transcription Factors – Studies of the Most Basal Metazoans,"BACKGROUND. Members of the Runx family of transcriptional regulators, which bind DNA as heterodimers with CBFβ, are known to play critical roles in embryonic development in many triploblastic animals such as mammals and insects. They are known to regulate basic developmental processes such as cell fate determination and cellular potency in multiple stem-cell types, including the sensory nerve cell progenitors of ganglia in mammals. RESULTS. In this study, we detect and characterize the hitherto unexplored Runx/CBFβ genes of cnidarians and sponges, two basal animal lineages that are well known for their extensive regenerative capacity. Comparative structural modeling indicates that the Runx-CBFβ-DNA complex from most cnidarians and sponges is highly similar to that found in humans, with changes in the residues involved in Runx-CBFβ dimerization in either of the proteins mirrored by compensatory changes in the binding partner. In situ hybridization studies reveal that Nematostella Runx and CBFβ are expressed predominantly in small isolated foci at the base of the ectoderm of the tentacles in adult animals, possibly representing neurons or their progenitors. CONCLUSION. These results reveal that Runx and CBFβ likely functioned together to regulate transcription in the common ancestor of all metazoans, and the structure of the Runx-CBFβ-DNA complex has remained extremely conserved since the human-sponge divergence. The expression data suggest a hypothesis that these genes may have played a role in nerve cell differentiation or maintenance in the common ancestor of cnidarians and bilaterians."
JOHN R FINNERTY,"Pre-Bilaterian Origins of the Hox Cluster and the Hox Code: Evidence from the Sea Anemone, Nematostella Vectensis","BACKGROUND. Hox genes were critical to many morphological innovations of bilaterian animals. However, early Hox evolution remains obscure. Phylogenetic, developmental, and genomic analyses on the cnidarian sea anemone Nematostella vectensis challenge recent claims that the Hox code is a bilaterian invention and that no ""true"" Hox genes exist in the phylum Cnidaria. METHODOLOGY/PRINCIPAL FINDINGS. Phylogenetic analyses of 18 Hox-related genes from Nematostella identify putative Hox1, Hox2, and Hox9+ genes. Statistical comparisons among competing hypotheses bolster these findings, including an explicit consideration of the gene losses implied by alternate topologies. In situ hybridization studies of 20 Hox-related genes reveal that multiple Hox genes are expressed in distinct regions along the primary body axis, supporting the existence of a pre-bilaterian Hox code. Additionally, several Hox genes are expressed in nested domains along the secondary body axis, suggesting a role in ""dorsoventral"" patterning. CONCLUSIONS/SIGNIFICANCE. A cluster of anterior and posterior Hox genes, as well as ParaHox cluster of genes evolved prior to the cnidarian-bilaterian split. There is evidence to suggest that these clusters were formed from a series of tandem gene duplication events and played a role in patterning both the primary and secondary body axes in a bilaterally symmetrical common ancestor. Cnidarians and bilaterians shared a common ancestor some 570 to 700 million years ago, and as such, are derived from a common body plan. Our work reveals several conserved genetic components that are found in both of these diverse lineages. This finding is consistent with the hypothesis that a set of developmental rules established in the common ancestor of cnidarians and bilaterians is still at work today."
JOHN R FINNERTY,StellaBase: The Nematostella Vectensis Genomics Database,"StellaBase, the Nematostella vectensis Genomics Database, is a web-based resource that will facilitate desktop and bench-top studies of the starlet sea anemone. Nematostella is an emerging model organism that has already proven useful for addressing fundamental questions in developmental evolution and evolutionary genomics. StellaBase allows users to query the assembled Nematostella genome, a confirmed gene library, and a predicted genome using both keyword and homology based search functions. Data provided by these searches will elucidate gene family evolution in early animals. Unique research tools, including a Nematostella genetic stock library, a primer library, a literature repository and a gene expression library will provide support to the burgeoning Nematostella research community. The development of StellaBase accompanies significant upgrades to CnidBase, the Cnidarian Evolutionary Genomics Database. With the completion of the first sequenced cnidarian genome, genome comparison tools have been added to CnidBase. In addition, StellaBase provides a framework for the integration of additional species-specific databases into CnidBase. StellaBase is available at http://www. stellabase.org."
JOHN R FINNERTY,"Genomic comparison of the temperate coral Astrangia poculata with tropical corals yields insights into winter quiescence, innate immunity, and sexual reproduction","Facultatively symbiotic corals provide important experimental models to explore the establishment, maintenance, and breakdown of the mutualism between corals and members of the algal family Symbiodiniaceae. The temperate coral Astrangia poculata is one such model as it is not only facultatively symbiotic, but also occurs across a broad temperature and latitudinal gradient. Here, we report the de novo chromosome-scale assembly and annotation of the A. poculata genome. Though widespread segmental/tandem duplications of genomic regions were detected, we did not find strong evidence of a whole genome duplication (WGD) event. Comparison of the gene arrangement between A. poculata and the tropical coral Acropora millepora revealed 56.38% of the orthologous genes were conserved in syntenic blocks despite ~415 million years of divergence. Gene families related to sperm hyperactivation and innate immunity, including lectins, were found to contain more genes in A. millepora relative to A. poculata. Sperm hyperactivation in A. millepora is expected given the extreme requirements of gamete competition during mass spawning events in tropical corals, while lectins are important in the establishment of coral-algal symbiosis. By contrast, gene families involved in sleep promotion, feeding suppression, and circadian sleep/wake cycle processes were expanded in A. poculata. These expanded gene families may play a role in A. poculata’s ability to enter a dormancy-like state (“winter quiescence”) to survive freezing temperatures at the northern edges of the species’ range."
JOHN R FINNERTY,"Distinct phenotypes associated with mangrove and lagoon habitats in two widespread caribbean corals, porites astreoides and porites divaricata","AbstractAs coral reefs experience dramatic declines in coral cover throughout the tropics, there is an urgent need to understand the role that non-reef habitats, such as mangroves, play in the ecological niche of corals. Mangrove habitats present a challenge to reef-dwelling corals because they can differ dramatically from adjacent reef habitats with respect to key environmental parameters, such as light. Because variation in light within reef habitats is known to drive intraspecific differences in coral phenotype, we hypothesized that coral species that can exploit both reef and mangrove habitats will exhibit predictable differences in phenotypes between habitats. To investigate how intraspecific variation, driven by either local adaptation or phenotypic plasticity, might enable particular coral species to exploit these two qualitatively different habitat types, we compared the phenotypes of two widespread Caribbean corals, Porites divaricata and Porites astreoides, in mangrove versus lagoon habitats on Turneffe Atoll, Belize. We document significant differences in colony size, color, structural complexity, and corallite morphology between habitats. In every instance, the phenotypic differences between mangrove prop root and lagoon corals exhibited consistent trends in both P. divaricata and P. astreoides. We believe this study is the first to document intraspecific phenotypic diversity in corals occupying mangrove prop root versus lagoonal patch reef habitats. A difference in the capacity to adopt an alternative phenotype that is well suited to the mangrove habitat may explain why some reef coral species can exploit mangroves, while others cannot."
KEVIN M MONAHAN,Buildout and integration of an automated high-throughput CLIA laboratory for SARS-CoV-2 testing on a large urban campus,"In 2019, the first cases of SARS-CoV-2 were detected in Wuhan, China, and by early 2020 the first cases were identified in the United States. SARS-CoV-2 infections increased in the US causing many states to implement stay-at-home orders and additional safety precautions to mitigate potential outbreaks. As policies changed throughout the pandemic and restrictions lifted, there was an increase in demand for COVID-19 testing which was costly, difficult to obtain, or had long turn-around times. Some academic institutions, including Boston University (BU), created an on-campus COVID-19 screening protocol as part of a plan for the safe return of students, faculty, and staff to campus with the option for in-person classes. At BU, we put together an automated high-throughput clinical testing laboratory with the capacity to run 45,000 individual tests weekly by Fall of 2020, with a purpose-built clinical testing laboratory, a multiplexed reverse transcription PCR (RT-qPCR) test, robotic instrumentation, and trained staff. There were many challenges including supply chain issues for personal protective equipment and testing materials in addition to equipment that were in high demand. The BU Clinical Testing Laboratory (CTL) was operational at the start of Fall 2020 and performed over 1 million SARS-CoV-2 PCR tests during the 2020-2021 academic year."
KIRILL KOROLEV,Inferring microbial co-occurrence networks from amplicon data: a systematic evaluation,"Microbes commonly organize into communities consisting of hundreds of species involved in complex interactions with each other. 16S ribosomal RNA (16S rRNA) amplicon profiling provides snapshots that reveal the phylogenies and abundance profiles of these microbial communities. These snapshots, when collected from multiple samples, can reveal the co-occurrence of microbes, providing a glimpse into the network of associations in these communities. However, the inference of networks from 16S data involves numerous steps, each requiring specific tools and parameter choices. Moreover, the extent to which these steps affect the final network is still unclear. In this study, we perform a meticulous analysis of each step of a pipeline that can convert 16S sequencing data into a network of microbial associations. Through this process, we map how different choices of algorithms and parameters affect the co-occurrence network and identify the steps that contribute substantially to the variance. We further determine the tools and parameters that generate robust co-occurrence networks and develop consensus network algorithms based on benchmarks with mock and synthetic data sets. The Microbial Co-occurrence Network Explorer, or MiCoNE (available at https://github.com/segrelab/MiCoNE) follows these default tools and parameters and can help explore the outcome of these combinations of choices on the inferred networks. We envisage that this pipeline could be used for integrating multiple data sets and generating comparative analyses and consensus networks that can guide our understanding of microbial community assembly in different biomes. IMPORTANCE Mapping the interrelationships between different species in a microbial community is important for understanding and controlling their structure and function. The surge in the high-throughput sequencing of microbial communities has led to the creation of thousands of data sets containing information about microbial abundances. These abundances can be transformed into co-occurrence networks, providing a glimpse into the associations within microbiomes. However, processing these data sets to obtain co-occurrence information relies on several complex steps, each of which involves numerous choices of tools and corresponding parameters. These multiple options pose questions about the robustness and uniqueness of the inferred networks. In this study, we address this workflow and provide a systematic analysis of how these choices of tools affect the final network and guidelines on appropriate tool selection for a particular data set. We also develop a consensus network algorithm that helps generate more robust co-occurrence networks based on benchmark synthetic data sets."
KIRILL KOROLEV,Chirality provides a direct fitness advantage and facilitates intermixing in cellular aggregates,"Chirality in shape and motility can evolve rapidly in microbes and cancer cells. To determine how chirality affects cell fitness, we developed a model of chiral growth in compact aggregates such as microbial colonies and solid tumors. Our model recapitulates previous experimental findings and shows that mutant cells can invade by increasing their chirality or switching their handedness. The invasion results either in a takeover or stable coexistence between the mutant and the ancestor depending on their relative chirality. For large chiralities, the coexistence is accompanied by strong intermixing between the cells, while spatial segregation occurs otherwise. We show that the competition within the aggregate is mediated by bulges in regions where the cells with different chiralities meet. The two-way coupling between aggregate shape and natural selection is described by the chiral Kardar-Parisi-Zhang equation coupled to the Burgers’ equation with multiplicative noise. We solve for the key features of this theory to explain the origin of selection on chirality. Overall, our work suggests that chirality could be an important ecological trait that mediates competition, invasion, and spatial structure in cellular populations."
KIRILL KOROLEV,A simple rule for the evolution of fast dispersal at the edge of expanding populations,"Evolution by natural selection is commonly perceived as a process that favors those that replicate faster to leave more offspring; nature, however, seem to abound with examples where organisms forgo some replicative potential to disperse faster. When does selection favor invasion of the fastest? Motivated by evolution experiments with swarming bacteria we searched for a simple rule. In experiments, a fast hyperswarmer mutant that pays a reproductive cost to make many copies of its flagellum invades a population of mono-flagellated bacteria by reaching the expanding population edge; a two-species mathematical model explains that invasion of the edge occurs only if the invasive species' expansion rate, v₂, which results from the combination of the species growth rate and its dispersal speed (but not its carrying capacity), exceeds the established species', v₁. The simple rule that we derive, v₂ > v₁, appears to be general: less favorable initial conditions, such as smaller initial sizes and longer distances to the population edge, delay but do not entirely prevent invasion. Despite intricacies of the swarming system, experimental tests agree well with model predictions suggesting that the general theory should apply to other expanding populations with trade-offs between growth and dispersal, including non-native invasive species and cancer metastases."
KIRILL KOROLEV,Femtosecond photonic viral inactivation probed using solid-state nanopores,"We report on detection of virus inactivation using femtosecond laser radiation by measuring the conductance of a solid state nanopore designed for detecting single particles. Conventional methods of assaying for viral inactivation based on plaque forming assays require 24–48 h for bacterial growth. Nanopore conductance measurements provide information on morphological changes at a single virion level.We show that analysis of a time series of nanopore conductance can quantify the detection of inactivation, requiring only a few minutes from collection to analysis. Morphological changes were verified by dynamic light scattering. Statistical analysis maximizing the information entropy provides a measure of the log reduction value. This work provides a rapid method for assaying viral inactivation with femtosecond lasers using solid-state nanopores."
KIRILL KOROLEV,Fungal dysbiosis predicts the diagnosis of pediatric Crohn's disease,"AIM: To investigate the accuracy of fungal dysbiosis in mucosa and stool for predicting the diagnosis of Crohn’s disease (CD). METHODS: Children were prospectively enrolled in two medical centers: one university hospital and one private gastroenterology clinic in the city of Riyadh, Kingdom of Saudi Arabia. The children with confirmed diagnosis of CD by standard guidelines were considered cases, and the others were considered non-inflammatory bowel disease controls. Mucosal and stool samples were sequenced utilizing Illumina MiSeq chemistry following the manufacturer’s protocols, and abundance and diversity of fungal taxa in mucosa and stool were analyzed. Sparse logistic regression was used to predict the diagnosis of CD. The accuracy of the classifier was tested by computing the receiver operating characteristic curves with 5-fold stratified cross-validation under 100 permutations of the training data partition and the mean area under the curve (AUC) was calculated. RESULTS: All the children were Saudi nationals. There were 15 children with CD and 20 controls. The mean age was 13.9 (range: 6.7-17.8) years for CD children and 13.9 (3.25-18.6) years for controls, and 10/15 (67%) of the CD and 13/20 (65%) of the control subjects were boys. CD locations at diagnosis were ileal (L1) in 4 and colonic (L3) in 11 children, while CD behavior was non-stricturing and non-penetrating (B1) in 12 and stricturing (B2) in 3 children. The mean AUC for the fungal dysbiosis classifier was significantly higher in stools (AUC = 0.85 ± 0.057) than in mucosa (AUC = 0.71 ± 0.067) (P < 0.001). Most fungal species were significantly more depleted in stools than mucosal samples, except for Saccharomyces cerevisiae and S. bayanus, which were significantly more abundant. Diversity was significantly more reduced in stools than in mucosa. CONCLUSION: We found high AUC of fungal dysbiosis in fecal samples of children with CD, suggesting high accuracy in predicting diagnosis of CD. Key Words: Fungiome, Mycobiome, Crohn’s disease, Inflammation, Saudi children Core tip: We found high accuracy of fungal dysbiosis in predicting diagnosis of Crohn’s disease (CD), a finding similar to bacterial dysbiosis. However, the higher area under the curve for the fungal dysbiosis classifier in stool (0.85 ± 0.057) than in mucosa (0.71 ± 0.067) (P < 0.001), contrasts with bacterial studies, suggesting higher accuracy of stool samples. Although the clinical application of this finding is limited at present by the high cost of fungal analysis, such information is important from a scientific viewpoint, to increase the understanding of the role of fungal flora in CD and to stimulate further studies."
KIRILL KOROLEV,"Available energy fluxes drive a phase transition in the diversity, stability, and functional structure of microbial communities","A fundamental goal of microbial ecology is to understand what determines the diversity, stability, and structure of microbial ecosystems. The microbial context poses special conceptual challenges because of the strong mutual influences between the microbes and their chemical environment through the consumption and production of metabolites. By analyzing a generalized consumer resource model that explicitly includes cross-feeding, stochastic colonization, and thermodynamics, we show that complex microbial communities generically exhibit a transition as a function of available energy fluxes from a “resource-limited” regime where community structure and stability is shaped by energetic and metabolic considerations to a diverse regime where the dominant force shaping microbial communities is the overlap between species’ consumption preferences. These two regimes have distinct species abundance patterns, different functional profiles, and respond differently to environmental perturbations. Our model reproduces large-scale ecological patterns observed across multiple experimental settings such as nestedness and differential beta diversity patterns along energy gradients. We discuss the experimental implications of our results and possible connections with disorder-induced phase transitions in statistical physics."
KIRILL KOROLEV,Ecological landscapes guide the assembly of optimal microbial communities,"Assembling optimal microbial communities is key for various applications in biofuel production, agriculture, and human health. Finding the optimal community is challenging because the number of possible communities grows exponentially with the number of species, and so an exhaustive search cannot be performed even for a dozen species. A heuristic search that improves community function by adding or removing one species at a time is more practical, but it is unknown whether this strategy can discover an optimal or nearly optimal community. Using consumer-resource models with and without cross-feeding, we investigate how the efficacy of search depends on the distribution of resources, niche overlap, cross-feeding, and other aspects of community ecology. We show that search efficacy is determined by the ruggedness of the appropriately-defined ecological landscape. We identify specific ruggedness measures that are both predictive of search performance and robust to noise and low sampling density. The feasibility of our approach is demonstrated using experimental data from a soil microbial community. Overall, our results establish the conditions necessary for the success of the heuristic search and provide concrete design principles for building high-performing microbial consortia."
KIRILL KOROLEV,Growth instabilities shape morphology and genetic diversity of microbial colonies,"Cellular populations assume an incredible variety of shapes ranging from circular molds to irregular tumors. While we understand many of the mechanisms responsible for these spatial patterns, little is known about how the shape of a population influences its ecology and evolution. Here, we investigate this relationship in the context of microbial colonies grown on hard agar plates. This a well-studied system that exhibits a transition from smooth circular disks to more irregular and rugged shapes as either the nutrient concentration or cellular motility is decreased. Starting from a mechanistic model of colony growth, we identify two dimensionless quantities that determine how morphology and genetic diversity of the population depend on the model parameters. Our simulations further reveal that population dynamics cannot be accurately described by the commonly-used surface growth models. Instead, one has to explicitly account for the emergent growth instabilities and demographic fluctuations. Overall, our work links together environmental conditions, colony morphology, and evolution. This link is essential for a rational design of concrete, biophysical perturbations to steer evolution in the desired direction."
KIRILL KOROLEV,Fungal microbiota profile in newly-diagnosed treatment-naïve children with Crohn's disease,"BACKGROUND & AIMS: although increasing evidence suggests a role for fungi in inflammatory bowel disease (IBD), data are scarce and mostly from adults. Our aim was to define the characteristics of fungal microbiota in newly-diagnosed treatment-naïve children with Crohn disease (CD). METHODS: The children referred for colonoscopy were prospectively enrolled in the study at King Khalid University Hospital, King Saud University and Al Mofarreh Polyclinics in Riyadh. Tissue and stool samples were collected and frozen till sequencing analysis. The children with confirmed CD diagnosis were designated as cases and the others as non- IBD controls. 78 samples were collected from 35 children (15 CD and 20 controls). Statistical analysis was performed to investigate CD associations and diversity. RESULTS: CD-associated fungi varied with the level of phylogenetic tree. There was no significant difference in abundance between normal and inflamed mucosa. Significantly abundant CD-associated taxa included Psathyrellaceae (p=0.01), Cortinariaceae (p= 0.04), Psathyrella (p= 0.004), and Gymnopilus (p=0.03).Monilinia was significantly depleted (p=0.03), whereas other depleted taxa, although not statistically significant, included Leotiomycetes (p= 0.06), Helotiales (p=0.08), Sclerotiniaceae (p=0.07). There was no significant difference in fungal diversity between CD and controls. CONCLUSIONS: We report highly significant fungal dysbiosis in newly diagnosed treatment naïve CD children. Depleted and more abundant taxa suggest anti-inflammatory and proinflamatory potentials respectively. Further studies with larger sample size including functional analysis are needed to clarify the significance of the fungal community in the pathogenesis of CD."
KEITH BROWN,A Music index of periodicals for the first six months of 1948 /,
KEITH BROWN,Specialized sledge dogs accompanied Inuit dispersal across the North American Arctic,"Domestic dogs have been central to life in the North American Arctic for millennia. The ancestors of the Inuit were the first to introduce the widespread usage of dog sledge transportation technology to the Americas, but whether the Inuit adopted local Palaeo-Inuit dogs or introduced a new dog population to the region remains unknown. To test these hypotheses, we generated mitochondrial DNA and geometric morphometric data of skull and dental elements from a total of 922 North American Arctic dogs and wolves spanning over 4500 years. Our analyses revealed that dogs from Inuit sites dating from 2000 BP possess morphological and genetic signatures that distinguish them from earlier Palaeo-Inuit dogs, and identified a novel mitochondrial clade in eastern Siberia and Alaska. The genetic legacy of these Inuit dogs survives today in modern Arctic sledge dogs despite phenotypic differences between archaeological and modern Arctic dogs. Together, our data reveal that Inuit dogs derive from a secondary pre-contact migration of dogs distinct from Palaeo-Inuit dogs, and probably aided the Inuit expansion across the North American Arctic beginning around 1000 BP."
KEITH BROWN,Data for autonomous discovery of tough structures,"This dataset contains the experimental data for the research paper ""Autonomous Discovery of Tough Structure"" which is currently in the peer review process. The document contains the record of physical experiments performed over the course of two years by a self-driving lab called the BEAR (Bayesian Autonomous Experimental Researcher). The BEAR consists of five FFF 3d printers, a scale, and an Instron. A UR5 robot arm moves samples for testing."
KEITH BROWN,A Bayesian experimental autonomous researcher for mechanical design,"While additive manufacturing (AM) has facilitated the production of complex structures, it has also highlighted the immense challenge inherent in identifying the optimum AM structure for a given application. Numerical methods are important tools for optimization, but experiment remains the gold standard for studying nonlinear, but critical, mechanical properties such as toughness. To address the vastness of AM design space and the need for experiment, we develop a Bayesian experimental autonomous researcher (BEAR) that combines Bayesian optimization and high-throughput automated experimentation. In addition to rapidly performing experiments, the BEAR leverages iterative experimentation by selecting experiments based on all available results. Using the BEAR, we explore the toughness of a parametric family of structures and observe an almost 60-fold reduction in the number of experiments needed to identify high-performing structures relative to a grid-based search. These results show the value of machine learning in experimental fields where data are sparse."
KEITH BROWN,What is missing in autonomous discovery: open challenges for the community,"Self-driving labs (SDLs) leverage combinations of artificial intelligence, automation, and advanced computing to accelerate scientific discovery."
KEITH BROWN,Driving school for self-driving labs,Self-driving labs benefit from occasional and asynchronous human interventions. We present a heuristic framework for how self-driving lab operators can interpret progress and make changes during a campaign.
KEITH BROWN,Bayesian reconstruction of magnetic resonance images using Gaussian processes,"A central goal of modern magnetic resonance imaging (MRI) is to reduce the time required to produce high-quality images. Efforts have included hardware and software innovations such as parallel imaging, compressed sensing, and deep learning-based reconstruction. Here, we propose and demonstrate a Bayesian method to build statistical libraries of magnetic resonance (MR) images in k-space and use these libraries to identify optimal subsampling paths and reconstruction processes. Specifically, we compute a multivariate normal distribution based upon Gaussian processes using a publicly available library of T1-weighted images of healthy brains. We combine this library with physics-informed envelope functions to only retain meaningful correlations in k-space. This covariance function is then used to select a series of ring-shaped subsampling paths using Bayesian optimization such that they optimally explore space while remaining practically realizable in commercial MRI systems. Combining optimized subsampling paths found for a range of images, we compute a generalized sampling path that, when used for novel images, produces superlative structural similarity and error in comparison to previously reported reconstruction processes (i.e. 96.3% structural similarity and < 0.003 normalized mean squared error from sampling only 12.5% of the k-space data). Finally, we use this reconstruction process on pathological data without retraining to show that reconstructed images are clinically useful for stroke identification. Since the model trained on images of healthy brains could be directly used for predictions in pathological brains without retraining, it shows the inherent transferability of this approach and opens doors to its widespread use."
KEITH BROWN,Conformal electrodeposition of ultrathin polymeric films with tunable properties from dual-functional monomers,"Conformal functional thin films are obtained from self-limiting electrodeposition of a dual-functional molecule with tailorable control over film thickness, permeability, and dielectric properties only by variation of the deposition conditions."
KEITH BROWN,"Data for ""a Bayesian experimental autonomous researcher for mechanical design""",
KEITH BROWN,"Data for ""designing lattices for impact protection using transfer learning""",
KEITH BROWN,"Data for ""using simulation to accelerate autonomous experimentation: a case study using mechanics""",
KEITH BROWN,"Bostonia: 2003-2004, no. 1-4",
KEITH BROWN,"Data for ""a physics-informed impact model refined by multi-fidelity transfer learning""","This folder contains the experimental data for the research paper ""A physics-informed impact model refined by multi-fidelity transfer learning"" which is scheduled to be published in Extreme Mechanics Letters. The designs are broken up into several categories: TPU 1-6: Figures 1-3 TPU 7-8: Figure 4 TPU Foaming 1-14: Figure 5 Both STL and Gcode files are available for each design. Note that spiral/vase mode is used when slicing, so the part will be hollow when sliced. The proper extrusion multiplier must be used to reach the mass target for each design. The slicer settings are included in the Gcode at the end of the file. The raw data for physical experiments performed in both constant velocity tests in a universal testing machine (UTM) and impact tests using a drop tower are also included. They use the following naming structure: UTM tests: <material>_V<velocity>_<trial>.csv Note that velocity is in mm/min and trial is either a, b, or c. Only 2 mm/min velocity tests contain b and c trials. Impact tests: <material>_V<velocity>.csv Note that velocity is in m/s and goes to two decimal places."
DANIEL FULFORD,Effort-based decision-making and gross motor performance: are they linked?,"The purpose of this study was to investigate the relationship between effort-based decision making and gross motor performance. Effort-based decision making was measured using a modified version of the Effort Expenditure for Rewards Task (EEfRT), in which participants pressed a button on a keyboard to fill a bar on a screen for monetary reward. Participants received monetary rewards that were commensurate with the level of effort that they were willing to expend. Gross motor performance was measured with a walking task, in which participants matched their steps to the beat of an audio metronome; they walked to metronome beats that were slower and also faster than their normal walking pace. We hypothesized that increased effort during the effort-based decision making task would be paired with an increase in steps taken per minute during the gross motor task. However, the results of this study indicated a lack of a statistically significant relationship between the effort-based decision making task and the gross motor task. Planning rather than decision-making may have been the cognitive construct that governed our gross motor task. These findings can be beneficial when thinking about potential interventions for populations who experience deficits in motor performance and cognition as well as for understanding the relationship between both cognitive and motor performance in healthy adults."
DANIEL FULFORD,How did that interaction make you feel? The relationship between quality of everyday social experiences and emotion in people with and without schizophrenia,"People with schizophrenia report positive emotion during social interactions in ecological momentary assessment (EMA) studies; however, few of these studies examine the qualities of social interactions (e.g., intimacy) that may affect emotion experience. In the current EMA study, people with (n = 20) and without schizophrenia (n = 15) answered questions about the quality of their social interactions, including their emotion experiences. We also explored the relationship between EMA-reported social experiences and trait loneliness, negative symptoms, and social functioning. People with and without schizophrenia did not differ in EMA-reported proportion of time spent with others, extent of involvement during social interactions, intimacy of interactions, or average number of social interactions. Both people with and without schizophrenia reported more positive than negative emotion during social experiences. However, people with schizophrenia reported more loneliness, more severe negative symptoms, and impaired social functioning compared to people without schizophrenia. Further, specific qualities of social interactions (intimacy of interaction, involvement during interaction) were related to happiness during interactions only in people without schizophrenia. These results suggest that while people with and without schizophrenia report similar rates of in-the-moment social emotion experiences, the impact of social interaction quality on emotion may differ between groups."
DANIEL FULFORD,"Smartphone-based neuropsychological assessment in Parkinson's disease: feasibility, validity, and contextually driven variability in cognition","OBJECTIVES: The prevalence of neurodegenerative disorders demands methods of accessible assessment that reliably captures cognition in daily life contexts. We investigated the feasibility of smartphone cognitive assessment in people with Parkinson's disease (PD), who may have cognitive impairment in addition to motor-related problems that limit attending in-person clinics. We examined how daily-life factors predicted smartphone cognitive performance and examined the convergent validity of smartphone assessment with traditional neuropsychological tests. METHODS: Twenty-seven nondemented individuals with mild-moderate PD attended one in-lab session and responded to smartphone notifications over 10 days. The smartphone app queried participants 5x/day about their location, mood, alertness, exercise, and medication state and administered mobile games of working memory and executive function. RESULTS: Response rate to prompts was high, demonstrating feasibility of the approach. Between-subject reliability was high on both cognitive games. Within-subject variability was higher for working memory than executive function. Strong convergent validity was seen between traditional tests and smartphone working memory but not executive function, reflecting the latter's ceiling effects. Participants performed better on mobile working memory tasks when at home and after recent exercise. Less self-reported daytime sleepiness and lower PD symptom burden predicted a stronger association between later time of day and higher smartphone test performance. CONCLUSIONS: These findings support feasibility and validity of repeat smartphone assessments of cognition and provide preliminary evidence of the effects of context on cognitive variability in PD. Further development of this accessible assessment method could increase sensitivity and specificity regarding daily cognitive dysfunction for PD and other clinical populations."
DANIEL FULFORD,Adult siblings who have a brother or sister with autism: between-family and within-family variations in sibling relationships,"Prior research on the sibling relationship in the context of autism spectrum disorder (ASD) has included only one sibling per family. We used multi-level modeling to examine aspects of the sibling relationship in 207 adults who have a brother or sister with ASD from 125 families, investigating variability in sibling relationship quality and pessimism within and between families. We found that there was greater variability in aspects of the sibling relationship with the brother or sister with ASD within families than between families. Sibling individual-level factors were associated with positive affect in the sibling relationship, while family-level factors were associated with the sibling’s pessimism about their brother or sister’s future. The findings illustrate the unique experiences of siblings within families."
DANIEL FULFORD,"""Skip the Small Talk"" virtual event intended to promote social connection during a global pandemic: online survey study","BACKGROUND: Social distancing measures meant to prevent the spread of COVID-19 in the past year have exacerbated loneliness and depression in the United States. While virtual tools exist to improve social connections, there have been limited attempts to assess community-based, virtual methods to promote new social connections. OBJECTIVE: In this proof-of-concept study, we examined the extent to which Skip the Small Talk (STST)-a business dedicated to hosting events to facilitate structured, vulnerable conversations between strangers-helped reduce loneliness in a virtual format in the early months of the 2020 COVID-19 pandemic. We predicted that participants who attended STST virtual events would show a reduction in loneliness, improvement in positive affect, and reduction in negative affect after attending an event. We were also interested in exploring the role of depression symptoms on these results as well as the types of goals participants accomplished by attending STST events. METHODS: Adult participants who registered for an STST virtual event between March 25 and June 30, 2020, completed a survey before attending the event (pre-event survey; N=64) and a separate survey after attending the event (postevent survey; n=25). Participants reported on their depression symptoms, loneliness, and positive and negative affect. Additionally, participants reported the goals they wished to accomplish as well as those they actually accomplished by attending the STST event. RESULTS: The four most cited goals that participants hoped to accomplish before attending the STST event included the following: ""to make new friends,"" ""to have deeper/better conversations with other people,"" ""to feel less lonely,"" and ""to practice social skills."" A total of 34% (20/58) of participants who completed the pre-event survey reported depression symptoms that indicated a high risk of a major depressive episode in the preceding 2 weeks. Of the 25 participants who completed the pre- and postevent surveys, participants reported a significant reduction in loneliness (P=.03, Cohen d=0.48) and negative affect (P<.001, Cohen d=1.52) after attending the STST event compared to before the event. Additionally, depressive symptoms were significantly positively correlated with change in negative affect (P=.03), suggesting that the higher the depression score was prior to attending the STST event, the higher the reduction in negative affect was following the event. Finally, 100% of the participants who wished to reduce their loneliness (11/11) or feel less socially anxious (5/5) prior to attending the STST event reported that they accomplished those goals after the event. CONCLUSIONS: Our preliminary assessment suggests that the virtual format of STST was helpful for reducing loneliness and negative affect for participants, including those experiencing depression symptoms, during the COVID-19 pandemic. While encouraging, additional research is necessary to demonstrate whether STST has benefits when compared to other social events and interventions and whether such benefits persist beyond the events themselves."
DANIEL FULFORD,Do cognitive impairments limit treatment gains in a standalone digital intervention for psychosis? A test of the digital divide,"Digital mental health interventions, such as those provided by smartphone applications (apps), show promise as cost-effective approaches to increasing access to evidence-based psychosocial interventions for psychosis. Although it is well known that limited financial resources can reduce the benefits of digital approaches to mental healthcare, the extent to which cognitive functioning in this population could impact capacity to engage in and benefit from these interventions is less studied. In the current study we examined the extent to which cognitive functioning (premorbid cognitive abilities and social cognition) were related to treatment engagement and outcome in a standalone digital intervention for social functioning. Premorbid cognitive abilities generally showed no association with aggregated treatment engagement markers, including proportion of notifications responded to and degree of interest in working on app content, though there was a small positive association with improvements in social functioning. Social cognition, as measured using facial affect recognition ability, was unrelated to treatment engagement or outcome. These preliminary findings suggest that cognitive functioning is generally not associated with engagement or outcomes in a standalone digital intervention designed for and with people with schizophrenia spectrum disorders."
DANIEL FULFORD,Test-retest reliability of task-based measures of voluntary persistence,
DANIEL FULFORD,"Design of the WHIP-PD study: a phase II, twelve-month, dual-site, randomized controlled trial evaluating the effects of a cognitive-behavioral approach for promoting enhanced walking activity using mobile health technology in people with Parkinson-disease","BACKGROUND: Parkinson disease (PD) is a debilitating and chronic neurodegenerative disease resulting in ambulation difficulties. Natural walking activity often declines early in disease progression despite the relative stability of motor impairments. In this study, we propose a paradigm shift with a ""connected behavioral approach"" that targets real-world walking using cognitive-behavioral training and mobile health (mHealth) technology. METHODS/DESIGN: The Walking and mHealth to Increase Participation in Parkinson Disease (WHIP-PD) study is a twelve-month, dual site, two-arm, randomized controlled trial recruiting 148 participants with early to mid-stage PD. Participants will be randomly assigned to connected behavioral or active control conditions. Both conditions will include a customized program of goal-oriented walking, walking-enhancing strengthening exercises, and eight in-person visits with a physical therapist. Participants in the connected behavioral condition also will (1) receive cognitive-behavioral training to promote self-efficacy for routine walking behavior and (2) use a mHealth software application to manage their program and communicate remotely with their physical therapist. Active control participants will receive no cognitive-behavioral training and manage their program on paper. Evaluations will occur at baseline, three-, six-, and twelve-months and include walking assessments, self-efficacy questionnaires, and seven days of activity monitoring. Primary outcomes will include the change between baseline and twelve months in overall amount of walking activity (mean number of steps per day) and amount of moderate intensity walking activity (mean number of minutes per day in which > 100 steps were accumulated). Secondary outcomes will include change in walking capacity as measured by the six-minute walk test and ten-meter walk test. We also will examine if self-efficacy mediates change in amount of walking activity and if change in amount of walking activity mediates change in walking capacity. DISCUSSION: We expect this study to show the connected behavioral approach will be more effective than the active control condition in increasing the amount and intensity of real-world walking activity and improving walking capacity. Determining effective physical activity interventions for persons with PD is important for preserving mobility and essential for maintaining quality of life. Clinical trials registration NCT03517371, May 7, 2018. TRIAL REGISTRATION: ClinicalTrials.gov: NCT03517371. Date of registration: May 7, 2018. Protocol version: Original."
ALANA T BRENNAN,Shifting to tenofovir use in first-line antiretroviral therapy for HIV-positive adults in public sector treatment programs in sub-Saharan Africa,"The success of scale up of antiretroviral therapy (ART) in low- and middle-income countries (LMICs) is in large part due to the introduction of a “public health approach” to access advocated by the World Health Organization (WHO) which emphasized standardized treatment regimens that could be purchased in large quantities and delivered at scale. In 2010 the WHO updated their global HIV treatment guidelines recommending the substitution of stavudine with tenofovir (both of which are members of the non-nucleoside reverse transcriptase inhibitor (NRTI) class of drugs) in first-line antiretroviral therapy (ART). Given the size of treatment programs in sub-Saharan Africa, changing the NRTI used in first-line therapy for HIV could have a substantial impact on treatment outcomes. We conducted three prospective cohort studies using clinical datasets from several sub-Saharan African countries to answer questions surrounding the impacts of exposure to tenofovir in first-line therapy. The first study examines the frequency of stavudine use and single-drug substitutions (substituting the NRTI in first-line ART) in three regions in sub-Saharan Africa by calendar year, 2004–2014. We found a total of 33,441 (8.9%; 95% CI: 8.7–8.9%) single-drug substitutions occurred among 377,656 patients in the first 24 months on ART, close to 40% of which were amongst patients on stavudine. The decrease in single-drug substitutions corresponded with the phasing out of stavudine. We saw an 80% reduction in the risk of single-drug substitutions when comparing tenofovir to stavudine and close to a 70% reduction in the risk when comparing zidovudine to stavudine. The second study uses a regression discontinuity design to evaluate the impact of national HIV treatment guideline changes in South Africa and Zambia recommending tenofovir in first-line ART on treatment outcomes. We found that updated WHO guidelines increased the proportion of patients initiating tenofovir (risk difference (RD) (South Africa): 81%; 95% CI: 73%, 89%; RD (Zambia): 42%; 95% CI: 38%, 45%). Intent to treat estimates showed a decrease in single-drug substitutions in South Africa (RD: -15%; 95% CI: -18%, -12%) and Zambia (RD: -2.0%; 95% CI: -3.6%, -0.3%). In both countries, there was no effect on mortality, attrition or viral load failure (South Africa only). The third study investigates the effect of the 2012 tenofovir stock shortage in South Africa on provider and patient level outcomes, using data from four public-sector Right to Care clinics, two of which experienced a tenofovir stock shortage and two that did not. While imprecise, our results suggest a potential shift in how providers managed patients during the period of the shortage, mainly, a noticeable decrease in the average number of days between visits during the shortage compare to before or after at all four clinics and a significant difference in the proportion of patients missing visits. Difference-in-difference regression results showed a small, but significant, increase in the risk of missed visits during the shortage compared to after (RD: 1.2%; 95% CI: 0.5%, 2.0%), mainly driven by ACTs clinic. No significant difference was seen in other outcomes. Great strides have been made to extend access to ART as well as increase the quality of the services provided to patients in sub-Saharan Africa. Continued access to and a consistent supply of tenofovir in this setting is necessary for patients to receive drugs that are comparable to those used for HIV treatment in high-income countries, as we show that phasing out of stavudine and for either zidovudine or tenofovir potentially reduced toxicities and potentially improved quality of life in multiple regions throughout sub-Saharan Africa. While we show little effect on treatment outcomes when comparing patients accessing care and treatment during the shortage of tenofovir compared to those that did not, this most likely reflects the clinics’ ability to offset the crisis by continuing to initiate newly diagnosed and eligible patients on treatment and keep treatment experienced patients on their current regimen."
ALANA T BRENNAN,"Research report: ""Using what you have to get what you want"": Vulnerability to HIV and prevention needs of female post‐secondary students engaged in transactional sex in Kumasi, Ghana","This report presents findings from a qualitative study examining vulnerability to HIV of female post‐secondary students engaged in transactional sex in Kumasi, Ghana and their prevention needs. The study was conducted by Boston University’s Center for Global and Health and Development (CGHD) and the Kwame Nkrumah University of Science and Technology (KNUST) as part of Project SEARCH funded by the United States Agency for International Development Ghana. Participants were recruited from five post‐secondary institutions in the greater Kumasi area. Our objective is to provide academic institutions, the Ghana AIDS Commission (GAC), the National AIDS Control Program, donors, and other stakeholders with rich data to inform research and programmatic efforts in Kumasi specifically, as well as academic institutions in general. We set out to document what forms of transactional sex female students are engaging in, who their partners are, and what motivates them to participate. We asked students about the individual and structural vulnerabilities for HIV reported by female post‐secondary students involved in transactional sex and what their prevention needs are. We also interviewed a small sample of faculty, residence hall matrons, and hotel staff to get their perspective on the behavior of female students practicing transactional sex that might put them at risk for HIV. The findings of this study can be used as well to inform the design of future studies of young women engaging in transactional sex in Ghana. With such limited understanding of HIV transmission among young female post‐secondary students engaged in transactional sex, research is needed to determine how this group contributes to the overall HIV epidemic. The Ghana AIDS Commission has recognized the need for further research among communities engaged in less well‐defined risky sex practices in the National Strategic Plan for Most‐at – Risk Populations (MARP) 2011‐2015.4 This study attempts to fill in gaps in the research regarding transactional sex, taking into account the complexities and nuances of the practice, in addition to examining the needs of female students for targeted HIV prevention programs."
ALANA T BRENNAN,Systematic differences between Cochrane and non-Cochrane meta-analyses on the same topic: a matched pair analysis,"BACKGROUND: Meta-analyses conducted via the Cochrane Collaboration adhere to strict methodological and reporting standards aiming to minimize bias, maximize transparency/reproducibility, and improve the accuracy of summarized data. Whether this results in differences in the results reported by meta-analyses on the same topic conducted outside the Cochrane Collaboration is an open question. METHODS: We conducted a matched-pair analysis with individual meta-analyses as the unit of analysis, comparing Cochrane and non-Cochrane reviews. Using meta-analyses from the cardiovascular literature, we identified pairs that matched on intervention and outcome. The pairs were contrasted in terms of how frequently results disagreed between the Cochrane and non-Cochrane reviews, whether effect sizes and statistical precision differed systematically, and how these differences related to the frequency of secondary citations of those reviews. RESULTS: Our search yielded 40 matched pairs of reviews. The two sets were similar in terms of which was first to publication, how many studies were included, and average sample sizes. The paired reviews included a total of 344 individual clinical trials: 111 (32.3%) studies were included only in a Cochrane review, 104 (30.2%) only in a non-Cochrane review, and 129 (37.5%) in both. Stated another way, 62.5% of studies were only included in one or the other meta-analytic literature. Overall, 37.5% of pairs had discrepant results. The most common involved shifts in the width of 95% confidence intervals that would yield a different statistical interpretation of the significance of results (7 pairs). Additionally, 20% differed in the direction of the summary effect size (5 pairs) or reported greater than a 2-fold difference in its magnitude (3 pairs). Non-Cochrane reviews reported significantly higher effect sizes (P < 0.001) and lower precision (P < 0.001) than matched Cochrane reviews. Reviews reporting an effect size at least 2-fold greater than their matched pair were cited more frequently. CONCLUSIONS: Though results between topic-matched Cochrane and non-Cochrane reviews were quite similar, discrepant results were frequent, and the overlap of included studies was surprisingly low. Non-Cochrane reviews report larger effect sizes with lower precision than Cochrane reviews, indicating systematic differences, likely reflective of methodology, between the two types of reviews that could generate different interpretations of the interventions under question."
ALANA T BRENNAN,Treatment outcomes and costs of providing antiretroviral therapy at a primary health clinic versus a hospital-based HIV clinic in South Africa,"BACKGROUND:In 2010 South Africa revised its HIV treatment guidelines to allow the initiation and management of patients on antiretroviral therapy (ART) by nurses, rather than solely doctors, under a program called NIMART (Nurse Initiated and Managed Antiretroviral Therapy). We compared the outcomes and costs of NIMART between the two major public sector HIV treatment delivery models in use in South Africa today, primary health clinics and hospital-based HIV clinics. METHODS AND FINDINGS:The study was conducted at one hospital-based outpatient HIV clinic and one primary health clinic (PHC) in Gauteng Province. A retrospective cohort of adult patients initiated on ART at the PHC was propensity-score matched to patients initiated at the hospital outpatient clinic. Each patient was assigned a 12-month outcome of alive and in care or died/lost to follow up. Costs were estimated from the provider perspective for the 12 months after ART initiation. The proportion of patients alive and in care at 12 months did not differ between the PHC (76.5%) and the hospital-based site (74.2%). The average annual cost per patient alive and in care at 12 months after ART initiation was significantly lower at the PHC (US$238) than at the hospital outpatient clinic (US$428). CONCLUSIONS: Initiating and managing ART patients at PHCs under NIMART is producing equally good outcomes as hospital-based HIV clinic care at much lower cost. Evolution of hospital-based clinics into referral facilities that serve complicated patients, while investing most program expansion resources into PHCs, may be a preferred strategy for achieving treatment coverage targets."
ALANA T BRENNAN,"Uptake of same-day initiation of HIV treatment among adult men and women in Malawi, South Africa, and Zambia: the SPRINT retrospective cohort study [version 1; peer review: 4 approved with reservations]","Background: Since 2017 global guidelines have recommended “same-day initiation” (SDI) of antiretroviral treatment (ART) for patients considered ready for treatment on the day of HIV diagnosis. Many countries have incorporated a SDI option into national guidelines, but SDI uptake is not well documented. We estimated average time to ART initiation at 12 public healthcare facilities in Malawi, five in South Africa, and 12 in Zambia. Methods: We sequentially enrolled patients eligible to start ART between January 2018 and June 2019 and reviewed their medical records from the point of HIV diagnosis or first HIV-related interaction with the clinic to the earlier date of treatment initiation or 6 months. We estimated the proportion of patients initiating ART on the same day or within 7, 14, 30, or 180 days of baseline. Results: We enrolled 826 patients in Malawi, 534 in South Africa, and 1,984 in Zambia. Overall, 88% of patients in Malawi, 57% in South Africa, and 91% in Zambia were offered and accepted SDI. In Malawi, most who did not receive SDI had not initiated ART ≤6 months. In South Africa, an additional 13% initiated ≤1 week, but 21% had no record of initiation ≤6 months. Among those who did initiate within 6 months in Zambia, most started ≤1 week. There were no major differences by sex. WHO Stage III/IV and tuberculosis symptoms were associated with delays in ART initiation. Conclusions: As of 2020, SDI of ART was widespread, if not nearly universal, in Malawi and Zambia but considerably less common in South Africa. Limitations of the study include pre-COVID-19 data that do not reflect pandemic adaptations and potentially missing data for Zambia. South Africa may be able to increase overall ART coverage by reducing numbers of patients who do not initiate ≤6 months. Registration: Clinicaltrials.gov (NCT04468399; NCT04170374; NCT04470011)."
ALANA T BRENNAN,Simplified clinical algorithm for identifying patints eligible for immediate initiation of antiretroviral therapy for HIV (SLATE): protocol for a randomised evaluation,"INTRODUCTION: African countries are rapidly adopting guidelines to offer antiretroviral therapy (ART) to all HIV-infected individuals, regardless of CD4 count. For this policy of 'treat all' to succeed, millions of new patients must be initiated on ART as efficiently as possible. Studies have documented high losses of treatment-eligible patients from care before they receive their first dose of antiretrovirals (ARVs), due in part to a cumbersome, resource-intensive process for treatment initiation, requiring multiple clinic visits over a several-week period. METHODS AND ANALYSIS: The Simplified Algorithm for Treatment Eligibility (SLATE) study is an individually randomised evaluation of a simplified clinical algorithm for clinicians to reliably determine a patient's eligibility for immediate ART initiation without waiting for laboratory results or additional clinic visits. SLATE will enroll and randomize (1:1) 960 adult, HIV-positive patients who present for HIV testing or care and are not yet on ART in South Africa and Kenya. Patients randomized to the standard arm will receive routine, standard of care ART initiation from clinic staff. Patients randomized to the intervention arm will be administered a symptom report, medical history, brief physical exam and readiness assessment. Patients who have positive (satisfactory) results for all four components of SLATE will be dispensed ARVs immediately, at the same clinic visit. Patients who have any negative results will be referred for further clinical investigation, counseling, tests or other services prior to being dispensed ARVs. After the initial visit, follow-up will be by passive medical record review. The primary outcomes will be ART initiation ≤28 days and retention in care 8 months after study enrollment. ETHICS AND DISSEMINATION: Ethics approval has been provided by the Boston University Institutional Review Board, the University of the Witwatersrand Human Research Ethics Committee (Medical) and the KEMRI Scientific and Ethics Review Unit. Results will be published in peer-reviewed journals and made widely available through presentations and briefing documents."
ALANA T BRENNAN,"Integration of point-of-care screening for type 2 diabetes mellitus and hypertension with COVID-19 rapid antigen screening in Johannesburg, South Africa","Aims: We sought to evaluate the yield and linkage-to-care for diabetes and hypertension screening alongside a study assessing the use of rapid antigen tests for COVID-19 in taxi ranks in Johannesburg, South Africa. Methods: Participants were recruited from Germiston taxi rank. We recorded results of blood glucose (BG), blood pressure (BP), waist circumference, smoking status, height, and weight. Participants who had elevated BG (fasting>7.0; random>11.1mmol/L) and/or BP (diastolic>90 and systolic>140mmHg) were referred to their clinic and phoned to confirm linkage. Results: 1169 participants were enrolled and screened for diabetes and hypertension. Combining participants with a previous diagnosis of diabetes (n=23, 2%; 95% CI:1.3-2.9%) and those that had an elevated BG measurement (n=60, 5.2%; 95%CI:4.1-6.6%) at study enrollment, we estimated an overall indicative prevalence of diabetes of 7.1% (95% CI:5.7-8.7%). When combining those with known hypertension at study enrollment (n=124, 10.6%; 95%CI:8.9-12.5%) and those with elevated BP (n=202; 17.3%; 95%CI:15.2-19.5%), we get an overall prevalence of hypertension of 27.9% (95% CI:25.4-30.1%). Only 31.7% of those with elevated BG and 16.0% of those with elevated BP linked-to-care. Conclusion: By opportunistically leveraging existing COVID-19 screening in South Africa to screen for diabetes and hypertension, 24% of participants received a potential new diagnosis. We had poor linkage-to-care following screening. Future research should evaluate options for improving linkage-to-care, and evaluate the large-scale feasibility of this simple screening tool."
ALANA T BRENNAN,Causal language and strength of inference in academic and media articles shared in social media (CLAIMS): a systematic review,"BACKGROUND: The pathway from evidence generation to consumption contains many steps which can lead to overstatement or misinformation. The proliferation of internet-based health news may encourage selection of media and academic research articles that overstate strength of causal inference. We investigated the state of causal inference in health research as it appears at the end of the pathway, at the point of social media consumption. METHODS: We screened the NewsWhip Insights database for the most shared media articles on Facebook and Twitter reporting about peer-reviewed academic studies associating an exposure with a health outcome in 2015, extracting the 50 most-shared academic articles and media articles covering them. We designed and utilized a review tool to systematically assess and summarize studies’ strength of causal inference, including generalizability, potential confounders, and methods used. These were then compared with the strength of causal language used to describe results in both academic and media articles. Two randomly assigned independent reviewers and one arbitrating reviewer from a pool of 21 reviewers assessed each article. RESULTS: We accepted the most shared 64 media articles pertaining to 50 academic articles for review, representing 68% of Facebook and 45% of Twitter shares in 2015. Thirty-four percent of academic studies and 48% of media articles used language that reviewers considered too strong for their strength of causal inference. Seventy percent of academic studies were considered low or very low strength of inference, with only 6% considered high or very high strength of causal inference. The most severe issues with academic studies’ causal inference were reported to be omitted confounding variables and generalizability. Fifty-eight percent of media articles were found to have inaccurately reported the question, results, intervention, or population of the academic study. CONCLUSIONS: We find a large disparity between the strength of language as presented to the research consumer and the underlying strength of causal inference among the studies most widely shared on social media. However, because this sample was designed to be representative of the articles selected and shared on social media, it is unlikely to be representative of all academic and media work. More research is needed to determine how academic institutions, media organizations, and social network sharing patterns impact causal inference and language as received by the research consumer."
ALANA T BRENNAN,Has the phasing out of stavudine in accordance with changes in WHO guidelines led to a decrease in single-drug substitutions in first-line antiretroviral therapy for HIV in sub-Saharan Africa?,"OBJECTIVE: We assessed the relationship between phasing out stavudine in first-line antiretroviral therapy (ART) in accordance with WHO 2010 policy and single-drug substitutions (SDS) (substituting the nucleoside reverse transcriptase inhibitor in first-line ART) in sub-Saharan Africa. DESIGN: Prospective cohort analysis (International epidemiological Databases to Evaluate AIDS-Multiregional) including ART-naive, HIV-infected patients aged at least 16 years, initiating ART between January 2005 and December 2012. Before April 2010 (July 2007 in Zambia) national guidelines called for patients to initiate stavudine-based or zidovudine-based regimen, whereas thereafter tenofovir or zidovudine replaced stavudine in first-line ART. METHODS: We evaluated the frequency of stavudine use and SDS by calendar year 2004-2014. Competing risk regression was used to assess the association between nucleoside reverse transcriptase inhibitor use and SDS in the first 24 months on ART. RESULTS: In all, 33 441 (8.9%; 95% confience interval 8.7-8.9%) SDS occurred among 377 656 patients in the first 24 months on ART, close to 40% of which were amongst patients on stavudine. The decrease in SDS corresponded with the phasing out of stavudine. Competing risks regression models showed that patients on tenofovir were 20-95% less likely to require a SDS than patients on stavudine, whereas patients on zidovudine had a 75-85% decrease in the hazards of SDS when compared to stavudine. CONCLUSION: The decline in SDS in the first 24 months on treatment appears to be associated with phasing out stavudine for zidovudine or tenofovir in first-line ART in our study. Further efforts to decrease the cost of tenofovir and zidovudine for use in this setting is warranted to substitute all patients still receiving stavudine."
ALANA T BRENNAN,Economic Outcomes of Patients Receiving Antiretroviral Therapy for HIV/AIDS in South Africa Are Sustained through Three Years on Treatment,"BACKGROUND. Although the medical outcomes of antiretroviral therapy (ART) for HIV/AIDS are well described, less is known about how ART affects patients' economic activities and quality of life, especially after the first year on ART. We assessed symptom prevalence, general health, ability to perform normal activities, and employment status among adult antiretroviral therapy patients in South Africa over three full years following ART initiation. METHODOLOGY/PRINCIPAL FINDINGS. A cohort of 855 adult pre-ART patients and patients on ART for <6 months was enrolled and interviewed an average of 4.4 times each during routine clinic visits for up to three years after treatment initiation using an instrument designed for the study. The probability of pain in the previous week fell from 74% before ART initiation to 32% after three years on ART, fatigue from 66% to 12%, nausea from 28% to 4%, and skin problems from 55% to 10%. The probability of not feeling well physically yesterday fell from 46% to 23%. Before starting ART, 39% of subjects reported not being able to perform their normal activities sometime during the previous week; after three years, this proportion fell to 10%. Employment rose from 27% to 42% of the cohort. Improvement in all outcomes was sustained over 3 years and for some outcomes increased in the second and third year. CONCLUSIONS/SIGNIFICANCE. Improvements in adult ART patients' symptom prevalence, general health, ability to perform normal activities, and employment status were large and were sustained through the first three years on treatment. These results suggest that some of the positive economic and social externalities anticipated as a result of large-scale treatment provision, such as increases in workforce participation and productivity and the ability of patients to carry on normal lives, may indeed be accruing."
ALANA T BRENNAN,"Timing of pregnancy, postpartum risk of virologic failure and loss to follow-up among HIV-positive women.","BACKGROUND: We assessed the association between the timing of pregnancy with the risk of postpartum virologic failure and loss from HIV care in South Africa. METHODS: The incidence of virologic failure (two consecutive viral load measurements of >1000 copies/ml) and loss to follow-up (>3 months late for a visit) during 24 months postpartum were assessed using Cox proportional hazards modelling. RESULTS: The rate of postpartum virologic failure was higher following an incident pregnancy on ART [adjusted hazard ratio 1.8, 95% confidence interval (CI): 1.1-2.7] than among women who initiated ART during pregnancy. This difference was sustained among women with CD4 cell count less than 350 cells/μl at delivery (adjusted hazard ratio 1.8, 95% CI: 1.1-3.0). Predictors of postpartum virologic failure were being viremic, longer time on ART, being 25 or less years old and low CD4 cell count and anaemia at delivery, as well as initiating ART on stavudine-containing or abacavir-containing regimen. There was no difference postpartum loss to follow-up rates between the incident pregnancies group (hazard ratio 0.9, 95% CI: 0.7-1.1) and those who initiated ART in pregnancy. CONCLUSION: The risk of virologic failure remains high among postpartum women, particularly those who conceive on ART. The results highlight the need to provide adequate support for HIV-positive women with fertility intention after ART initiation and to strengthen monitoring and retention efforts for postpartum women to sustain the benefits of ART."
ALANA T BRENNAN,The Importance of Clinic Attendance in the First Six Months on Antiretroviral Treatment: A Retrospective Analysis at a Large Public Sector HIV Clinic in South Africa,"BACKGROUND Adherence to care and treatment are essential for HIV-infected individuals to benefit from antiretroviral therapy (ART). We sought to quantify the effects on treatment outcomes of missing visits soon after initiating ART. METHODS We analyzed data from HIV-infected patients initiating ART at Themba Lethu Clinic, Johannesburg, South Africa, from April 2004 to August 2008. We used log-binomial regression to evaluate the relative risk of missing visits during the first six months of ART on immunological response and virologic suppression. Cox models were used to evaluate the relationship between missed visits and mortality and loss to follow up over 12 months. RESULTS Of 4476 patients, 65% missed no visits, while 26% missed one visit, 7% missed two and 1.6% missed three or more visits during the first six months on treatment. Patients who missed three or more medical or antiretroviral (ARV) visits had a two-fold increased risk of poor CD4 response by six months, while the risk of failing to achieve virologic suppression by six months increased two- to five-fold among patients who missed two and three or more medical or ARV visits. Adjusted Cox models showed that patients who missed two (HR 2.1; 95% CI: 1.0-4.3) and three or more (HR 4.7; 95% CI: 1.4-16.2) medical visits had an increased risk of death, while those who missed two ARV (HR 3.8; 95% CI: 2.5-5.8) or three or more medical (HR 3.0; 95% CI: 1.1-8.1) visits had an increased risk of loss to follow up. CONCLUSIONS Thirty-five percent of patients missed one or more visits in the first six months on treatment, increasing their risk of poorer outcomes. These patients could be targeted for additional adherence counselling to help improve ART outcomes."
ALANA T BRENNAN,"Cohort profile: the Right to Care Clinical HIV Cohort, South Africa","PURPOSE: The research objectives of the Right to Care Clinical HIV Cohort analyses are to: (1) monitor treatment outcomes (including death, loss to follow-up, viral suppression and CD4 count gain among others) for patients on antiretroviral therapy (ART); (2) evaluate the impact of changes in the national treatment guidelines around when to initiate ART on HIV treatment outcomes; (3) evaluate the impact of changes in the national treatment guidelines around what ART regimens to initiate on drug switches; (4) evaluate the cost and cost-effectiveness of HIV treatment delivery models; (5) evaluate the need for and outcomes on second-line and third-line ART; (6) evaluate the impact of comorbidity with non-communicable diseases on HIV treatment outcomes and (7) evaluate the impact of the switch to initiating all patients onto ART regardless of CD4 count. PARTICIPANTS: The Right to Care Clinical HIV Cohort is an open cohort of data from 10 clinics in two provinces within South Africa. All clinics include data from 2004 onwards. The cohort currently has data on over 115 000 patients initiated on HIV treatment and patients are followed up every 3–6 months for clinical and laboratory monitoring. FINDINGS TO DATE: Cohort data includes information on demographics, clinical visit, laboratory data, medication history and clinical diagnoses. The data have been used to identify rates and predictors of first-line failure, to identify predictors of mortality for patients on second-line (eg, low CD4 counts) and to show that adolescents and young adults are at increased risk of unsuppressed viral loads compared with adults. FUTURE PLANS: Future analyses will inform national models of HIV care and treatment to improve HIV care policy in South Africa."
ALANA T BRENNAN,"Program brief: ""Using what you have to get what you want: HIV vulnerability and prevention needs of female post‐secondary students engaged in transactional sex in Kumasi, Ghana","HIV prevalence among young Ghanaian men and women aged 15–24 years old is estimated at 1.7%.1 HIV prevalence in the specific population of female post-secondary students is unknown. The Ghana AIDS Commission (GAC) recognizes the need for further research in communities participating in less well-defined risky sex practices. This study was conducted by Boston University’s Center for Global Health and Development and the Kwame Nkrumah University of Science and Technology with funding from the United States Agency for International Development/Ghana. The objective was to provide academic institutions, the GAC, the National AIDS Control Program, donors, and other stakeholders with data to inform research and programmatic efforts in Kumasi, specifically, as well as academic institutions, in general. Study participants were recruited from five post-secondary institutions in the greater Kumasi area. Data were collected on students’ perceptions of transactional sex (TS) on campus, individual and structural HIV vulnerabilities, and prevention needs through in-depth interviews with seven female post-secondary students involved in TS and focus groups with twenty-nine female and male students. Key informant interviews were also conducted with faculty, residence hall matrons, and hotel staff. Non-commercial transactional sex is defined here as engaging in sex for the purposeof obtaining material goods, financial support, or grades."
ALANA T BRENNAN,Changing the South African national antiretroviral therapy guidelines: The role of cost modelling,"Background We were tasked by the South African Department of Health to assess the cost implications to the largest ART programme in the world of adopting sets of ART guidelines issued by the World Health Organization between 2010 to 2016. Methods Using data from large South African ART clinics (n = 24,244 patients), projections of patients in need of ART, and cost data from bottom-up cost analyses, we constructed a population-level health-state transition model with 6-monthly transitions between health states depending on patients’ age, CD4 cell count/ percentage, and, for adult first-line ART, time on treatment. Findings For each set of guidelines, the modelled increase in patient numbers as a result of prevalence and uptake was substantially more than the increase resulting from additional eligibility. Under each set of guidelines, the number of people on ART was projected to increase by 31-133% over the next seven years, and cost by 84-175%, while increased eligibility led to 1-26% more patients, and 1-17% higher cost. The projected increases in treatment cost due to the 2010 and the 2015 WHO guidelines could be offset in their entirety by the introduction of cost-saving measures such as opening the drug tenders for international competition and task-shifting. Under universal treatment, annual costs of the treatment programme will decrease for the first time from 2024 onwards. Conclusions Annual budgetary requirements for ART will continue to increase in South Africa until universal treatment is taken to full scale. Model results were instrumental in changing South African ART guidelines, more than tripling the population on treatment between 2009 and 2017, and reducing the per-patient cost of treatment by 64%."
VANESSA XANTHAKIS,Associations of accelerometer-measured physical activity and sedentary time with chronic kidney disease: The Framingham Heart Study,"BACKGROUND: Few studies examined the individual and conjoint associations of accelerometer-measured physical activity (PA) and sedentary times with the prevalence of chronic kidney disease (CKD) among older adults. METHODS: We evaluated 1,268 Framingham Offspring Study participants (mean age 69.2 years, 53.8% women) between 2011 and 2014. CKD was defined as an estimated glomerular filtration rate (eGFR) <60 ml/min/1.732 and/or urine albumin-to-creatinine ratio (UACR) ≥25/35 μg/mg (men/women). We used multivariable logistic regression models to relate time spent being sedentary and active with the odds of CKD. We then performed compositional data analysis to estimate the change in the eGFR and UACR when a fixed proportion of time in one activity behavior (among the following: moderate to vigorous physical activity [MVPA], light intensity physical activity [LIPA], and sedentary) is reallocated to another activity behavior. RESULTS: Overall, 258 participants had prevalent CKD (20.4%; 120 women). Higher total PA ([MVPA+LIPA], adjusted-odds ratio [OR] per 30 minutes/day increase, 0.86; 95% CI, 0.78-0.96) and higher LIPA (OR per 30 minutes/day increase, 0.87; 95% CI, 0.76-0.99) were associated with lower odds of CKD. Additionally, higher sedentary time (OR per 30 minutes/day increase, 1.16; 95% CI, 1.04-1.29) was associated with higher odds of CKD. Reallocating 5% of the time from LIPA to sedentary was associated with the largest predicted difference in eGFR (-1.06 ml/min/1.73m2). Reallocating 1% of time spent in MVPA to sedentary status predicted the largest difference in UACR (14.37 μg/mg). CONCLUSION: The findings suggest that increasing LIPA and maintaining MVPA at the expense of sedentary time may be associated with a lower risk of CKD in community-based older adults."
SARAH FREDERICK,"Introduction - Peter Schwartz, Cheryl Crowley, Sarah Frederick & Anita Patterson",
SARAH FREDERICK,Mountains and rivers on her desk: novelist Yoshiya Nobuko's Haiku Diary (1944-1973),"Well known as a writer of popular serialized novels, little known is Yoshiya Nobuko (1896-1973)'s deep engagement with haiku, particularly during the Pacific War. Takahama Kyoshi, mentored by Shiki in Matsuyama took over the haiku journal Hototogisu after his death, later moving to Kamakura south of Tokyo. Yoshiya too moved to Kamakura during the war and she came to participate in Kyoshi's ku-kai gatherings there. Once misunderstanding that the meeting was canceled, she showed up in her monpe pantaloons and fire raid safety hat, only to realize she would be a haiku ""group"" of one that day. By her own account, she found it difficult to write novels near the end of the war and focused on haiku instead, an experience she turned into the novel Kacho (Flowers and Birds, 1948) and a number of biographical sketches of women haiku poets. She also filled many small datebooks with haiku, which I have looked at in her archive and many of which find their way into a posthumous collection edited by her partner. The presentation will discuss materials from Yoshiya's wartime ""haiku diary"" and relationships among her haiku, novels, and wartime experiences."
SARAH FREDERICK,"""Kyo ni tsukeru yuube"" no digitaru chizu: Soseki to jinbungaku no dijitaru jidai. (A digital map of arriving at Kyoto one evening: Soseki and the era of the digital humanities)",
SARAH FREDERICK,The eighteenth data release of the Sloan Digital Sky Surveys: targeting and first spectra from SDSS-V,"The eighteenth data release (DR18) of the Sloan Digital Sky Survey (SDSS) is the first one for SDSS-V, the fifth generation of the survey. SDSS-V comprises three primary scientific programs or “Mappers”: the Milky Way Mapper (MWM), the Black Hole Mapper (BHM), and the Local Volume Mapper. This data release contains extensive targeting information for the two multiobject spectroscopy programs (MWM and BHM), including input catalogs and selection functions for their numerous scientific objectives. We describe the production of the targeting databases and their calibration and scientifically focused components. DR18 also includes ∼25,000 new SDSS spectra and supplemental information for X-ray sources identified by eROSITA in its eFEDS field. We present updates to some of the SDSS software pipelines and preview changes anticipated for DR19. We also describe three value-added catalogs (VACs) based on SDSS-IV data that have been published since DR17, and one VAC based on the SDSS-V data in the eFEDS field."
DAVID LAGAKOS,Urban-rural gaps in the developing world: does internal migration offer opportunities?,"This article provides an overview of the growing literature on urban-rural gaps in the developing world. I begin with recent evidence on the size of the gaps as measured by consumption, income, and wages, and argue that the gaps are real rather than just nominal. I then discuss the role of sorting more able workers into urban areas and review an array of recent evidence on outcomes from rural-urban migration. Overall, migrants do experience substantial gains on average, though smaller than suggested by the cross-sectional gaps. I conclude that future work should help further explore the frictions—in particular, information, financial, and in land markets—that hold back rural-urban migration and may help explain the persistence of urban-rural gaps."
DAVID LAGAKOS,Electricity and firm productivity: a general-equilibrium approach,"Many policymakers view power outages as a major constraint on firm productivity in developing countries. Yet empirical studies find modest short-run effects of outages on firm performance. This paper builds a dynamic macroeconomic model to study the long-run general-equilibrium effects of power outages on productivity. Outages lower productivity in the model by creating idle resources, depressing the scale of incumbent firms and reducing entry of new firms. Consistent with the empirical literature, the model predicts small shortrun effects of eliminating outages. However, the long-run general-equilibrium effects are much larger, supporting the view that eliminating outages is an important development objective."
DAVID LAGAKOS,Protecting lives and livelihoods during the COVID-19 pandemic by shielding elderly populations,
DAVID LAGAKOS,Migration costs and observational returns to migration in the developing world,"Recent studies find that observational returns to rural-urban migration are near zero in three developing countries. We revisit this result using panel tracking surveys from six countries, finding higher returns on average. We then interpret these returns in a multi-region Roy model with heterogeneity in migration costs. In the model, the observational return to migration confounds the urban premium and the individual benefits of migrants, and is not directly informative about the welfare gain from lowering migration costs. Patterns of regional heterogeneity in returns, and a comparison of experimental to observational returns, are consistent with the model’s predictions."
DAVID LAGAKOS,Lockdowns in developing countries should focus on shielding the elderly,"The COVID-19 pandemic has led to dramatic policy responses in most advanced economies, and in particular sustained lockdowns matched with sizable transfers to workers. This column discuss the extent to which developing countries should try to replicate these policies. Due to differences in labour market informality, fiscal capacity, healthcare infrastructure, and demographics, blanket lockdowns appear less effective in developing countries. Age-targeted policies – where the young are allowed to work while the old are shielded from the virus – can potentially save both more lives and livelihoods."
DAVID LAGAKOS,Reopening schools too early could spread COVID-19 even faster – especially in the developing world,"Low-income countries face a very different set of circumstances to high-income countries when it comes to reopening schools after lockdown. In developing countries, adults and the elderly generally have more contact with children than those in advanced economies. A new study predicts that delaying school openings in developing countries could save lives."
DAVID LAGAKOS,How should policy responses to the COVID-19 pandemic differ in the developing world?,"This paper quantitatively analyzes how policy responses to the COVID-19 pandemic should differ in developing countries. To do so we build an incomplete-markets macroeconomic model with heterogeneous agents and epidemiological dynamics that features several of the key distinctions between advanced and developing economies germane to the pandemic. We focus in particular on differences in: age structure, fiscal capacity, healthcare capacity, informality, and the frequency of contacts between individuals at home, work, school and other locations. The model predicts that blanket lockdowns are less effective in developing countries, saving fewer lives per unit of lost GDP. In contrast, age-specific policies are even more effective, since they focus scarce public funds on shielding the smaller population of older individuals. School closures are also more effective at saving lives in developing countries, providing a greater reduction in secondary transmissions between children and older adults at home."
CHRISTOPHER GRANT,Searching for solar KDAR with DUNE,"The observation of 236 MeV muon neutrinos from kaon-decay-at-rest (KDAR) originating in the core of the Sun would provide a unique signature of dark matter annihilation. Since excellent angle and energy reconstruction are necessary to detect this monoenergetic, directional neutrino flux, DUNE with its vast volume and reconstruction capabilities, is a promising candidate for a KDAR neutrino search. In this work, we evaluate the proposed KDAR neutrino search strategies by realistically modeling both neutrino-nucleus interactions and the response of DUNE. We find that, although reconstruction of the neutrino energy and direction is difficult with current techniques in the relevant energy range, the superb energy resolution, angular resolution, and particle identification offered by DUNE can still permit great signal/background discrimination. Moreover, there are non-standard scenarios in which searches at DUNE for KDAR in the Sun can probe dark matter interactions."
CHRISTOPHER GRANT,The mini-CAPTAIN liquid argon time projection chamber,
CHRISTOPHER GRANT,Imaging X-ray polarimetry explorer: prelaunch,"Launched on 2021 December 9, the Imaging X-ray Polarimetry Explorer (IXPE) is a NASA Small Explorer Mission in collaboration with the Italian Space Agency (ASI). The mission will open a new window of investigation—imaging x-ray polarimetry. The observatory features three identical telescopes, each consisting of a mirror module assembly with a polarization-sensitive imaging x-ray detector at the focus. A coilable boom, deployed on orbit, provides the necessary 4-m focal length. The observatory utilizes a three-axis-stabilized spacecraft, which provides services such as power, attitude determination and control, commanding, and telemetry to the ground. During its 2-year baseline mission, IXPE will conduct precise polarimetry for samples of multiple categories of x-ray sources, with follow-on observations of selected targets."
CHRISTOPHER GRANT,Optical calibration of the SNO+ detector in the water phase with deployed sources,"SNO+ is a large-scale liquid scintillator experiment with the primary goal of searching for neutrinoless double beta decay, and is located approximately 2 km underground in SNOLAB, Sudbury, Canada. The detector acquired data for two years as a pure water Cherenkov detector, starting in May 2017. During this period, the optical properties of the detector were measured in situ using a deployed light diffusing sphere, with the goal of improving the detector model and the energy response systematic uncertainties. The measured parameters included the water attenuation coefficients, effective attenuation coefficients for the acrylic vessel, and the angular response of the photomultiplier tubes and their surrounding light concentrators, all across different wavelengths. The calibrated detector model was validated using a deployed tagged gamma source, which showed a 0.6% variation in energy scale across the primary target volume."
CHRISTOPHER GRANT,Multiple Independent Loci at Chromosome 15q25.1 Affect Smoking Quantity: a Meta-Analysis and Comparison with Lung Cancer and COPD,"Recently, genetic association findings for nicotine dependence, smoking behavior, and smoking-related diseases converged to implicate the chromosome 15q25.1 region, which includes the CHRNA5-CHRNA3-CHRNB4 cholinergic nicotinic receptor subunit genes. In particular, association with the nonsynonymous CHRNA5 SNP rs16969968 and correlates has been replicated in several independent studies. Extensive genotyping of this region has suggested additional statistically distinct signals for nicotine dependence, tagged by rs578776 and rs588765. One goal of the Consortium for the Genetic Analysis of Smoking Phenotypes (CGASP) is to elucidate the associations among these markers and dichotomous smoking quantity (heavy versus light smoking), lung cancer, and chronic obstructive pulmonary disease (COPD). We performed a meta-analysis across 34 datasets of European-ancestry subjects, including 38,617 smokers who were assessed for cigarettes-per-day, 7,700 lung cancer cases and 5,914 lung-cancer-free controls (all smokers), and 2,614 COPD cases and 3,568 COPD-free controls (all smokers). We demonstrate statistically independent associations of rs16969968 and rs588765 with smoking (mutually adjusted p-values<10−35 and >10−8 respectively). Because the risk alleles at these loci are negatively correlated, their association with smoking is stronger in the joint model than when each SNP is analyzed alone. Rs578776 also demonstrates association with smoking after adjustment for rs16969968 (p<10−6). In models adjusting for cigarettes-per-day, we confirm the association between rs16969968 and lung cancer (p<10−20) and observe a nominally significant association with COPD (p = 0.01); the other loci are not significantly associated with either lung cancer or COPD after adjusting for rs16969968. This study provides strong evidence that multiple statistically distinct loci in this region affect smoking behavior. This study is also the first report of association between rs588765 (and correlates) and smoking that achieves genome-wide significance; these SNPs have previously been associated with mRNA levels of CHRNA5 in brain and lung tissue. Author Summary Nicotine binds to cholinergic nicotinic receptors, which are composed of a variety of subunits. Genetic studies for smoking behavior and smoking-related diseases have implicated a genomic region that encodes the alpha5, alpha3, and beta4 subunits. We examined genetic data across this region for over 38,000 smokers, a subset of which had been assessed for lung cancer or chronic obstructive pulmonary disease. We demonstrate strong evidence that there are at least two statistically independent loci in this region that affect risk for heavy smoking. One of these loci represents a change in the protein structure of the alpha5 subunit. This work is also the first to report strong evidence of association between smoking and a group of genetic variants that are of biological interest because of their links to expression of the alpha5 cholinergic nicotinic receptor subunit gene. These advances in understanding the genetic influences on smoking behavior are important because of the profound public health burdens caused by smoking and nicotine addiction."
CHRISTOPHER GRANT,Search for solar flare neutrinos with the KamLAND detector,"We report the result of a search for neutrinos in coincidence with solar flares from the GOES flare database. The search was performed on a 10.8 kton-year exposure of KamLAND collected from 2002 to 2019. This large exposure allows us to explore previously unconstrained parameter space for solar flare neutrinos. We found no statistical excess of neutrinos and established 90% confidence level upper limits of 8.4 × 10^7 cm^−2 (3.0 × 10^9 cm^−2) on the electron antineutrino (electron neutrino) fluence at 20 MeV normalized to the X12 flare, assuming that the neutrino fluence is proportional to the X-ray intensity."
CHRISTOPHER GRANT,KamNet: an integrated spatiotemporal deep neural network for rare event searches in KamLAND-Zen,"Rare event searches allow us to search for new physics at energy scales inaccessible with other means by leveraging specialized large-mass detectors. Machine learning provides a new tool to maximize the information provided by these detectors. The information is sparse, which forces these algorithms to start from the lowest level data and exploit all symmetries in the detector to produce results. In this work we present KamNet, which harnesses breakthroughs in geometric deep learning and spatiotemporal data analysis to maximize the physics reach of KamLAND-Zen, a kiloton scale spherical liquid scintillator detector searching for 0νββ. Using a simplified background model for KamLAND, we show that KamNet outperforms a conventional convolutional neural network (CNN) on benchmarking Monte Carlo simulations with an increasing level of robustness. Using simulated data, we then demonstrate KamNet's ability to increase KamLAND-Zen's sensitivity to 0νββ and 2νββ decay to excited states. A key component of this work is the addition of an attention mechanism to elucidate the underlying physics KamNet is using for the background rejection."
CHRISTOPHER GRANT,Search for the Majorana nature of neutrinos in the inverted mass ordering region with KamLAND-Zen,"The KamLAND-Zen experiment has provided stringent constraints on the neutrinoless double-beta (0νββ) decay half-life in ^136Xe using a xenon-loaded liquid scintillator. We report an improved search using an upgraded detector with almost double the amount of xenon and an ultralow radioactivity container, corresponding to an exposure of 970 kg yr of ^136Xe. These new data provide valuable insight into backgrounds, especially from cosmic muon spallation of xenon, and have required the use of novel background rejection techniques. We obtain a lower limit for the 0νββ decay half-life of T_1/2^0ν>2.3×10^26  yr at 90% C.L., corresponding to upper limits on the effective Majorana neutrino mass of 36-156 meV using commonly adopted nuclear matrix element calculations."
CHRISTOPHER GRANT,The SNO+ experiment,
CHRISTOPHER GRANT,Reproductive inequality in humans and other mammals,"To address claims of human exceptionalism, we determine where humans fit within the greater mammalian distribution of reproductive inequality. We show that humans exhibit lower reproductive skew (i.e., inequality in the number of surviving offspring) among males and smaller sex differences in reproductive skew than most other mammals, while nevertheless falling within the mammalian range. Additionally, female reproductive skew is higher in polygynous human populations than in polygynous nonhumans mammals on average. This patterning of skew can be attributed in part to the prevalence of monogamy in humans compared to the predominance of polygyny in nonhuman mammals, to the limited degree of polygyny in the human societies that practice it, and to the importance of unequally held rival resources to women's fitness. The muted reproductive inequality observed in humans appears to be linked to several unusual characteristics of our species-including high levels of cooperation among males, high dependence on unequally held rival resources, complementarities between maternal and paternal investment, as well as social and legal institutions that enforce monogamous norms."
CHRISTOPHER GRANT,Current status and future prospects of the SNO+ experiment,"SNO+ is a large liquid scintillator-based experiment located 2 km underground at SNOLAB, Sudbury, Canada. It reuses the Sudbury Neutrino Observatory detector, consisting of a 12 m diameter acrylic vessel which will be filled with about 780 tonnes of ultra-pure liquid scintillator. Designed as a multipurpose neutrino experiment, the primary goal of SNO+ is a search for the neutrinoless double-beta decay (0νββ) of ^130Te. In Phase I, the detector will be loaded with 0.3% natural tellurium, corresponding to nearly 800 kg of ^130Te, with an expected effective Majorana neutrino mass sensitivity in the region of 55–133 meV, just above the inverted mass hierarchy. Recently, the possibility of deploying up to ten times more natural tellurium has been investigated, which would enable SNO+ to achieve sensitivity deep into the parameter space for the inverted neutrino mass hierarchy in the future. Additionally, SNO+ aims to measure reactor antineutrino oscillations, low energy solar neutrinos, and geoneutrinos, to be sensitive to supernova neutrinos, and to search for exotic physics. A first phase with the detector filled with water will begin soon, with the scintillator phase expected to start after a few months of water data taking. The 0νββ Phase I is foreseen for 2017."
CHRISTOPHER GRANT,Scintillation light detection in the 6-m drift-length ProtoDUNE Dual Phase liquid argon TPC,"DUNE is a dual-site experiment for long-baseline neutrino oscillation studies, neutrino astrophysics and nucleon decay searches. ProtoDUNE Dual Phase (DP) is a 6  ×  6  ×  6 m 3 liquid argon time-projection-chamber (LArTPC) that recorded cosmic-muon data at the CERN Neutrino Platform in 2019-2020 as a prototype of the DUNE Far Detector. Charged particles propagating through the LArTPC produce ionization and scintillation light. The scintillation light signal in these detectors can provide the trigger for non-beam events. In addition, it adds precise timing capabilities and improves the calorimetry measurements. In ProtoDUNE-DP, scintillation and electroluminescence light produced by cosmic muons in the LArTPC is collected by photomultiplier tubes placed up to 7 m away from the ionizing track. In this paper, the ProtoDUNE-DP photon detection system performance is evaluated with a particular focus on the different wavelength shifters, such as PEN and TPB, and the use of Xe-doped LAr, considering its future use in giant LArTPCs. The scintillation light production and propagation processes are analyzed and a comparison of simulation to data is performed, improving understanding of the liquid argon properties."
CHRISTOPHER GRANT,Prospects for beyond the standard model physics searches at the deep underground neutrino experiment: DUNE collaboration,"The Deep Underground Neutrino Experiment (DUNE) will be a powerful tool for a variety of physics topics. The high-intensity proton beams provide a large neutrino flux, sampled by a near detector system consisting of a combination of capable precision detectors, and by the massive far detector system located deep underground. This configuration sets up DUNE as a machine for discovery, as it enables opportunities not only to perform precision neutrino measurements that may uncover deviations from the present three-flavor mixing paradigm, but also to discover new particles and unveil new interactions and symmetries beyond those predicted in the Standard Model (SM). Of the many potential beyond the Standard Model (BSM) topics DUNE will probe, this paper presents a selection of studies quantifying DUNE's sensitivities to sterile neutrino mixing, heavy neutral leptons, non-standard interactions, CPT symmetry violation, Lorentz invariance violation, neutrino trident production, dark matter from both beam induced and cosmogenic sources, baryon number violation, and other new physics topics that complement those at high-energy colliders and significantly extend the present reach."
CHRISTOPHER GRANT,Identification and reconstruction of low-energy electrons in the ProtoDUNE-SP detector,
CHRISTOPHER GRANT,The long-baseline neutrino experiment: exploring fundamental symmetries of the universe,"The preponderance of matter over antimatter in the early Universe, the dynamics of the supernova bursts that produced the heavy elements necessary for life and whether protons eventually decay --- these mysteries at the forefront of particle physics and astrophysics are key to understanding the early evolution of our Universe, its current state and its eventual fate. The Long-Baseline Neutrino Experiment (LBNE) represents an extensively developed plan for a world-class experiment dedicated to addressing these questions. LBNE is conceived around three central components: (1) a new, high-intensity neutrino source generated from a megawatt-class proton accelerator at Fermi National Accelerator Laboratory, (2) a near neutrino detector just downstream of the source, and (3) a massive liquid argon time-projection chamber deployed as a far detector deep underground at the Sanford Underground Research Facility. This facility, located at the site of the former Homestake Mine in Lead, South Dakota, is approximately 1,300 km from the neutrino source at Fermilab -- a distance (baseline) that delivers optimal sensitivity to neutrino charge-parity symmetry violation and mass ordering effects. This ambitious yet cost-effective design incorporates scalability and flexibility and can accommodate a variety of upgrades and contributions. With its exceptional combination of experimental configuration, technical capabilities, and potential for transformative discoveries, LBNE promises to be a vital facility for the field of particle physics worldwide, providing physicists from around the globe with opportunities to collaborate in a twenty to thirty year program of exciting science. In this document we provide a comprehensive overview of LBNE's scientific objectives, its place in the landscape of neutrino physics worldwide, the technologies it will incorporate and the capabilities it will possess."
IGOR KRAMNIK,Fine-tuning of macrophage activation using synthetic rocaglate derivatives.,"Drug-resistant bacteria represent a significant global threat. Given the dearth of new antibiotics, host-directed therapies (HDTs) are especially desirable. As IFN-gamma (IFNγ) plays a central role in host resistance to intracellular bacteria, including Mycobacterium tuberculosis, we searched for small molecules to augment the IFNγ response in macrophages. Using an interferon-inducible nuclear protein Ipr1 as a biomarker of macrophage activation, we performed a high-throughput screen and identified molecules that synergized with low concentration of IFNγ. Several active compounds belonged to the flavagline (rocaglate) family. In primary macrophages a subset of rocaglates 1) synergized with low concentrations of IFNγ in stimulating expression of a subset of IFN-inducible genes, including a key regulator of the IFNγ network, Irf1; 2) suppressed the expression of inducible nitric oxide synthase and type I IFN and 3) induced autophagy. These compounds may represent a basis for macrophage-directed therapies that fine-tune macrophage effector functions to combat intracellular pathogens and reduce inflammatory tissue damage. These therapies would be especially relevant to fighting drug-resistant pathogens, where improving host immunity may prove to be the ultimate resource."
IGOR KRAMNIK,Channeling macrophage polarization by rocaglates increases macrophage resistance to Mycobacterium tuberculosis,"Macrophages contribute to host immunity and tissue homeostasis via alternative activation programs. M1-like macrophages control intracellular bacterial pathogens and tumor progression. In contrast, M2-like macrophages shape reparative microenvironments that can be conducive for pathogen survival or tumor growth. An imbalance of these macrophages phenotypes may perpetuate sites of chronic unresolved inflammation, such as infectious granulomas and solid tumors. We have found that plant-derived and synthetic rocaglates sensitize macrophages to low concentrations of the M1-inducing cytokine IFN-gamma and inhibit their responsiveness to IL-4, a prototypical activator of the M2-like phenotype. Treatment of primary macrophages with rocaglates enhanced phagosome-lysosome fusion and control of intracellular mycobacteria. Thus, rocaglates represent a novel class of immunomodulators that can direct macrophage polarization toward the M1-like phenotype in complex microenvironments associated with hypofunction of type 1 and/or hyperactivation of type 2 immunity, e.g., chronic bacterial infections, allergies, and, possibly, certain tumors."
ANDREW WILSON,The attitude of the I.W.W. (i.e. International Workers of the World) toward religion,
ANDREW WILSON,Genetic Analysis Workshop 14: Microsatellite and Single-Nucleotide Polymorphism Marker Loci for Genome-Wide Scans,
ANDREW WILSON,The eighteenth data release of the Sloan Digital Sky Surveys: targeting and first spectra from SDSS-V,"The eighteenth data release (DR18) of the Sloan Digital Sky Survey (SDSS) is the first one for SDSS-V, the fifth generation of the survey. SDSS-V comprises three primary scientific programs or “Mappers”: the Milky Way Mapper (MWM), the Black Hole Mapper (BHM), and the Local Volume Mapper. This data release contains extensive targeting information for the two multiobject spectroscopy programs (MWM and BHM), including input catalogs and selection functions for their numerous scientific objectives. We describe the production of the targeting databases and their calibration and scientifically focused components. DR18 also includes ∼25,000 new SDSS spectra and supplemental information for X-ray sources identified by eROSITA in its eFEDS field. We present updates to some of the SDSS software pipelines and preview changes anticipated for DR19. We also describe three value-added catalogs (VACs) based on SDSS-IV data that have been published since DR17, and one VAC based on the SDSS-V data in the eFEDS field."
ANDREW WILSON,First radial velocity results from the MINiature Exoplanet Radial Velocity Array (MINERVA),"The MINiature Exoplanet Radial Velocity Array (MINERVA) is a dedicated observatory of four 0.7 m robotic telescopes fiber-fed to a KiwiSpec spectrograph. The MINERVA mission is to discover super-Earths in the habitable zones of nearby stars. This can be accomplished with MINERVA's unique combination of high precision and high cadence over long time periods. In this work, we detail changes to the MINERVA facility that have occurred since our previous paper. We then describe MINERVA's robotic control software, the process by which we perform 1D spectral extraction, and our forward modeling Doppler pipeline. In the process of improving our forward modeling procedure, we found that our spectrograph's intrinsic instrumental profile is stable for at least nine months. Because of that, we characterized our instrumental profile with a time-independent, cubic spline function based on the profile in the cross dispersion direction, with which we achieved a radial velocity precision similar to using a conventional ""sum-of-Gaussians"" instrumental profile: 1.8 m s−1 over 1.5 months on the RV standard star HD 122064. Therefore, we conclude that the instrumental profile need not be perfectly accurate as long as it is stable. In addition, we observed 51 Peg and our results are consistent with the literature, confirming our spectrograph and Doppler pipeline are producing accurate and precise radial velocities."
ANDREW WILSON,Training children's theory-of-mind: A meta-analysis of controlled studies,"BACKGROUND: Theory-of-mind (ToM) refers to knowledge and awareness of mental states in oneself and others. Various training programs have been developed to improve ToM in children. OBJECTIVES: In the present study, we conducted a quantitative review of ToM training programs that have been tested in controlled studies. DATA SOURCES: A literature search was conducted using PubMed, PsycInfo, the Cochrane Library, and manual searches. REVIEW METHODS: We identified 32 papers with 45 studies or experiments that included 1529 children with an average age of 63 months (SD=28.7). RESULTS: ToM training procedures were more effective than control procedures and their aggregate effect size was moderately strong (Hedges' g=0.75, CI=0.60-0.89, p<.001). Moderator analyses revealed that although ToM training programs were generally effective, ToM skill-related outcomes increased with length of training sessions and were significantly higher in active control studies. CONCLUSION: ToM training procedures can effectively enhance ToM in children."
ANDREW WILSON,Scintillation light detection in the 6-m drift-length ProtoDUNE Dual Phase liquid argon TPC,"DUNE is a dual-site experiment for long-baseline neutrino oscillation studies, neutrino astrophysics and nucleon decay searches. ProtoDUNE Dual Phase (DP) is a 6  ×  6  ×  6 m 3 liquid argon time-projection-chamber (LArTPC) that recorded cosmic-muon data at the CERN Neutrino Platform in 2019-2020 as a prototype of the DUNE Far Detector. Charged particles propagating through the LArTPC produce ionization and scintillation light. The scintillation light signal in these detectors can provide the trigger for non-beam events. In addition, it adds precise timing capabilities and improves the calorimetry measurements. In ProtoDUNE-DP, scintillation and electroluminescence light produced by cosmic muons in the LArTPC is collected by photomultiplier tubes placed up to 7 m away from the ionizing track. In this paper, the ProtoDUNE-DP photon detection system performance is evaluated with a particular focus on the different wavelength shifters, such as PEN and TPB, and the use of Xe-doped LAr, considering its future use in giant LArTPCs. The scintillation light production and propagation processes are analyzed and a comparison of simulation to data is performed, improving understanding of the liquid argon properties."
ANDREW WILSON,Prospects for beyond the standard model physics searches at the deep underground neutrino experiment: DUNE collaboration,"The Deep Underground Neutrino Experiment (DUNE) will be a powerful tool for a variety of physics topics. The high-intensity proton beams provide a large neutrino flux, sampled by a near detector system consisting of a combination of capable precision detectors, and by the massive far detector system located deep underground. This configuration sets up DUNE as a machine for discovery, as it enables opportunities not only to perform precision neutrino measurements that may uncover deviations from the present three-flavor mixing paradigm, but also to discover new particles and unveil new interactions and symmetries beyond those predicted in the Standard Model (SM). Of the many potential beyond the Standard Model (BSM) topics DUNE will probe, this paper presents a selection of studies quantifying DUNE's sensitivities to sterile neutrino mixing, heavy neutral leptons, non-standard interactions, CPT symmetry violation, Lorentz invariance violation, neutrino trident production, dark matter from both beam induced and cosmogenic sources, baryon number violation, and other new physics topics that complement those at high-energy colliders and significantly extend the present reach."
ANDREW WILSON,Identification and reconstruction of low-energy electrons in the ProtoDUNE-SP detector,
ANDREW WILSON,The long-baseline neutrino experiment: exploring fundamental symmetries of the universe,"The preponderance of matter over antimatter in the early Universe, the dynamics of the supernova bursts that produced the heavy elements necessary for life and whether protons eventually decay --- these mysteries at the forefront of particle physics and astrophysics are key to understanding the early evolution of our Universe, its current state and its eventual fate. The Long-Baseline Neutrino Experiment (LBNE) represents an extensively developed plan for a world-class experiment dedicated to addressing these questions. LBNE is conceived around three central components: (1) a new, high-intensity neutrino source generated from a megawatt-class proton accelerator at Fermi National Accelerator Laboratory, (2) a near neutrino detector just downstream of the source, and (3) a massive liquid argon time-projection chamber deployed as a far detector deep underground at the Sanford Underground Research Facility. This facility, located at the site of the former Homestake Mine in Lead, South Dakota, is approximately 1,300 km from the neutrino source at Fermilab -- a distance (baseline) that delivers optimal sensitivity to neutrino charge-parity symmetry violation and mass ordering effects. This ambitious yet cost-effective design incorporates scalability and flexibility and can accommodate a variety of upgrades and contributions. With its exceptional combination of experimental configuration, technical capabilities, and potential for transformative discoveries, LBNE promises to be a vital facility for the field of particle physics worldwide, providing physicists from around the globe with opportunities to collaborate in a twenty to thirty year program of exciting science. In this document we provide a comprehensive overview of LBNE's scientific objectives, its place in the landscape of neutrino physics worldwide, the technologies it will incorporate and the capabilities it will possess."
LYNN EUSTIS,Using online platforms to create community in the voice studio: lessons from the pandemic,"Remote teaching has come a long way since the first panicked days back in March 2020. At the beginning of the pandemic many of us were scrambling to figure out how to move voice lessons to a fully remote format. We found ourselves in Zoom classrooms staring at frightened, displaced students. Eventually we learned how to share files and links in the chat, how to draw using the Whiteboard function, and how to say “You’re on mute” approximately 35 times a day without going insane. By the summer we were all settling into the dreaded new normal: our FaceBook feeds were full of posts about SoundJack, Cleanfeed, open-back headphones, and external microphones. The effectiveness of remote voice lessons and the range of available technologies for studio teaching have been discussed elsewhere. This article will not endeavor to offer technical instruction but rather to suggest ways we might use technology to create community for our students, with a particular focus on the voice studio class."
NANCY SCOTT,Components of clean delivery kits and newborn mortality in the Zambia Chlorhexidine Application Trial (ZamCAT): an observational study,"BACKGROUND: Infection, a leading cause of neonatal death in low- and middle-income countries, is often caused by pathogens acquired during childbirth. Clean delivery kits (CDKs) have shown efficacy in reducing infection-related perinatal and neonatal mortality. However, there remain gaps in our current knowledge, including the effect of individual components, timeline of protection, and benefit of CDKs in home and facility-based deliveries. METHODS AND FINDINGS: A post-hoc, secondary analysis was performed using non-randomized data from the Zambia Chlorhexidine Application Trial (ZamCAT), a community-based, cluster-randomized controlled trial of chlorhexidine umbilical cord care in Southern Province of Zambia from February 2011 to January 2013. CDKs, containing soap, gloves, cord clamp, plastic sheet, razor blade, matches, and candles, were provided to all participants. Field monitors made home-based visit to each participant 4 days post-partum, during which CDK use and newborn outcomes were ascertained. Logistic regression was used to study the association between different CDK components and newborn mortality rate (NMR).Of 38,579 deliveries recorded during the study, 36,996 newborns were analyzed after excluding stillbirths and missing information. Gloves, cord clamp, and plastic sheets were the most frequently used CDK item combinations in both home and facility deliveries. Each of the 7 CDK components was associated with lower NMR in users versus non-users. Adjusted logistic regression showed that use of gloves (OR: 0.33, CI: 0.24-0.46), cord clamp (OR: 0.51, CI: 0.38-0.68), plastic sheets (OR: 0.46, CI: 0.34-0.63), and razor blades (OR: 0.69, CI: 0.53-0.89) were associated with lower risk of newborn mortality. Use of gloves and cord clamp was associated with reduced risk of immediate newborn death (<24 hours). Reduction in risk of early newborn death (1-7 days) was associated with use of gloves, cord clamp, plastic sheets, and razor blades. In examining perinatal mortality, similar patterns were observed. There was no significant reduction in risk of late newborn mortality (7-28 days) with CDK use. Study limitations included potential for potential recall bias of CDK use and inability to establish causality as a secondary observational study. CONCLUSIONS: CDK use was associated with reductions in early newborn mortality at both home and facility deliveries, especially when certain kit components were used. While causality could not be established in this non-randomized secondary analysis, given these beneficial associations, scaling up the use of CDKs in rural areas of sub-Saharan Africa may improve neonatal outcomes."
NANCY SCOTT,Orphans in Zambia: program monitoring and evaluation practices and the association of external support with education status and psychosocial wellbeing,"Problem: The Government of the Republic of Zambia (GRZ) adopted a community-based strategy to support a growing number of orphans and other vulnerable children (OVC). However, the impact of community-based support programs remains unclear. This dissertation examines one OVC program to answer three questions: 1) are orphans disadvantaged compared to non-orphans in educational outcomes and psychosocial wellbeing, 2) are differences associated with receipt of external support, and 3) what can current programs learn from one project's monitoring and evaluation (M&E) experience? Methods: This study used mixed-methods. We administered quantitative household surveys to 204 households at the close of a community-based project and again one year later. Additionally, we conducted 4 focus group discussions (FGDs) with caregivers and 4 FGDs with adolescents. Finally, we conducted in depth interviews (IDIs) with 26 project staff and reviewed project documents. Bivariate and multivariate regressions were used to analyze the quantitative data. Grounded theory analysis was conducted on the FGD transcripts and content analysis was conducted on the IDIs. Results: Orphanhood was not a significant predictor of worse educational outcomes or psychosocial wellbeing. However, loss of external psychosocial support was associated with worse psychosocial outcomes as measured by the Strengths and Difficulties Questionnaire. Project staff had varied perceptions, priorities and capacity regarding 1) Quality of M&E Systems, 2) Project Evaluation, and 3) Data Analysis and Use, resulting in an M&E system that could not adequately capture complexities and measure success. Conclusions: In future programs, implementers should: 1) develop strong M&E systems that are responsive to donor mandates and inclusive of community-defined measures of success, 2) prioritize baseline capacity assessment of all partners and community needs assessment to inform program design, 3) consider alternative targeting strategies with less emphasis on orphan status, and 4) be cognizant of potential negative impacts on a child, particularly psychosocial wellbeing, from the removal of external support. Funders and policymakers should: 1) increase implementer accountability to project plans, 2) invest in integrating measures of quality into reporting frameworks, 3) generate an evidence-base by encouraging the development of strong program M&E systems 4) consider allowing implementers to select realistic targets that are responsive to community needs."
NANCY SCOTT,"Dataset for ""A Qualitative Assessment of Community Acceptability and Use of a Locally Developed Children’s Book to Increase Shared Reading and Parent-Child Interactions in Rural Zambia""",
NANCY SCOTT,"Dataset for ""Barriers and facilitators to facility-based delivery in rural Zambia: A qualitative study of women’s perceptions after implementation of an improved Maternity Waiting Homes intervention""","Objectives: Women in sub-Saharan Africa face well-documented barriers to facility-based deliveries. An improved maternity waiting homes (MWH) model was implemented in rural Zambia to bring pregnant women closer to facilities for delivery. We qualitatively assessed whether MWHs changed perceived barriers to facility delivery among remote-living women. Design: We administered in-depth interviews (IDIs) to a randomly-selected subsample of women in intervention (n=78) and control (n=80) groups who participated in the primary quasi-experimental evaluation of an improved MWH model. The IDIs explored perceptions and preferences of delivery location. We conducted content analysis to understand perceived barriers and facilitators to facility delivery. Setting and participants: Participants lived in villages 10+ kilometers from the health facility and had delivered a baby in the previous 12 months. Intervention: The improved MWH model was implemented at 20 rural health facilities. Results: Over 96% of participants in the intervention arm and 90% in the control arm delivered their last baby at a health facility. Key barriers to facility delivery were distance and transportation, and costs associated with delivery. Facilitators included no user fees, penalties for home delivery, desire for safe delivery, and availability of MWHs. Most themes were similar between study arms. Both discussed the role MWHs have in improving access to facility-based delivery. Intervention arm participants expressed that the improved MWH model encourages use and helps overcome the distance barrier. Control arm participants either expressed a desire for an improved MWH model or did not consider it in their decision-making. Conclusions: Even in areas with high facility-based delivery rates in rural Zambia, barriers to access persist. MWHs may be useful to address the distance challenge, but no single intervention is likely to address all barriers experienced by rural, low-resourced populations. MWHs should be considered in a broader systems approach to improving access in remote areas. Trial Registration: ClinicalTrials.gov Identifier: NCT02620436"
NANCY SCOTT,MAHMAZ maternity waiting home: setup cost dataset,"These datasets detail 1) the setup costs expended to set up 10 maternity waiting homes in rural Zambia and 2) the monthly occupancy of the maternity waiting homes. The former includes the date of purchase, cost category, and the purchase amount in Kwacha. The latter describes how many patients visited the maternity waiting home in the last year of our project. We utilized this data to create a manuscript describing the setup costs of these homes, and the cost per admission to the homes, to serve as a guide for future implementors."
NANCY SCOTT,"Dataset for ""If we build it, will they come? Results of a quasi-experimental study assessing the impact of maternity waiting homes on facility-based childbirth and maternity care in Zambia""",
NANCY SCOTT,High Uptake of Exclusive Breastfeeding and Reduced Early Post-Natal HIV Transmission,"BACKGROUND. Empirical data showing the clear benefits of exclusive breastfeeding (EBF) for HIV prevention are needed to encourage implementation of lactation support programs for HIV-infected women in low resource settings among whom replacement feeding is unsafe. We conducted a prospective, observational study in Lusaka, Zambia, to test the hypothesis that EBF is associated with a lower risk of postnatal HIV transmission than non-EBF. METHODS AND RESULTS. As part of a randomized trial of early weaning, 958 HIV-infected women and their infants were recruited and all were encouraged to breastfeed exclusively to 4 months. Single-dose nevirapine was provided to prevent transmission. Regular samples were collected from infants to 24 months of age and tested by PCR. Detailed measurements of actual feeding behaviors were collected to examine, in an observational analysis, associations between feeding practices and postnatal HIV transmission. Uptake of EBF was high with 84% of women reporting only EBF cumulatively to 4 months. Post-natal HIV transmission before 4 months was significantly lower (p = 0.004) among EBF (0.040 95% CI: 0.024–0.055) than non-EBF infants (0.102 95% CI: 0.047–0.157); time-dependent Relative Hazard (RH) of transmission due to non-EBF = 3.48 (95% CI: 1.71–7.08). There were no significant differences in the severity of disease between EBF and non-EBF mothers and the association remained significant (RH = 2.68 95% CI: 1.28–5.62) after adjusting for maternal CD4 count, plasma viral load, syphilis screening results and low birth weight. CONCLUSIONS. Non-EBF more than doubles the risk of early postnatal HIV transmission. Programs to support EBF should be expanded universally in low resource settings. EBF is an affordable, feasible, acceptable, safe and sustainable practice that also reduces HIV transmission providing HIV-infected women with a means to protect their children's lives. TRIAL REGISTRATION. ClinicalTrials.gov NCT00310726"
NANCY SCOTT,Preferences for services in a patient’s first six months on antiretroviral therapy for HIV in South Africa and Zambia (PREFER): research protocol for a prospective observational cohort study,"BACKGROUND: For patients on HIV treatment in sub-Saharan Africa (SSA), the highest risk for loss from care consistently remains the first six months after antiretroviral (ART) initiation, when patients are not yet eligible for most existing differentiated service delivery (DSD) models. To reduce disengagement from care during this period, we must gain a comprehensive understanding of patients’ needs, concerns, resources, and preferences for service delivery during this period. The PREFER study will use a sequential mixed-methods approach to survey a sample of patients in South Africa and Zambia 0-6 months after ART initiation to develop a detailed profile of patient characteristics and needs. PROTOCOL: PREFER is an observational, prospective cohort study of adult patients on ART for ≤6 months at 12 public sector healthcare facilities in Zambia and 18 in South Africa that aims to inform the design of DSD models for the early HIV treatment period. It has four components: 1) survey of clients 0-6 months after ART initiation; 2) follow up through routinely collected medical records for <12 or <24 months after enrollment; 3) focus group discussions to explore specific issues raised in the survey; and 4) in South Africa only, collection of blood samples self-reported naïve participants to assess the prevalence of ARV metabolites indicating prior ART use. Results will include demographic and clinical characteristics of patients, self-reported HIV care histories, preferences for treatment delivery, and predictors of disengagement. CONCLUSIONS: PREFER aims to understand why the early treatment period is so challenging and how service delivery can be amended to address the obstacles that lead to early disengagement from care and to distinguish the barriers encountered by naïve patients to those facing re-initiators. The information collected by PREFER will help respond to patients’ needs and design better strategies for service delivery and improve resource allocation going forward."
NANCY SCOTT,Dataset: observational study of the clinical performance of a Public-Private Partnership national referral hospital network in Lesotho: Do improvements last over time?,"Public-private partnerships (PPP) may increase healthcare quality but lack longitudinal evidence for success. The Queen ‘Mamohato Memorial Hospital (QMMH) in Lesotho is one of Africa's first healthcare PPPs. We compare data from 2012 and 2018 on capacity, utilization, quality, and outcomes to understand if early documented successes have been sustained using the same measures over time. In this observational study using administrative and clinical data, we assessed beds, admissions, average length of stay (ALOS), outpatient visits, and patient outcomes. We measured triage time and crash cart stock through direct observation in 2013 and 2020. Operational hospital beds increased from 390 to 410. Admissions decreased (-5.3%) while outpatient visits increased (3.8%). ALOS increased from 5.1 to 6.5 days. Occupancy increased from 82% to 99%; half of the wards had occupancy rates ≥90%, and Neonatal ward occupancy was 209%. The proportion of crash cart stock present (82.9% to 73.8%) and timely triage (84.0% to 27.6%) decreased. While overall mortality decreased (8.0% to 6.5%) and neonatal mortality overall decreased (18.0% to 16.3%), mortality among very low birth weight neonates increased (30.2% to 36.8%). Declines in overall hospital mortality are promising. Yet, continued high occupancy could compromise infection control and impede response to infections, such as COVID-19. High occupancy in the Neonatal ward suggests that the population need for neonatal care outpaces QMMH capacity; improvements should be addressed at the hospital and systemic levels. The increase in ALOS is acceptable for a hospital meant to take the most critical cases. The decline in crash cart stock completeness and timely triage may affect access to emergency treatment. While the partnership itself ended earlier than anticipated, our evaluation suggests that generally the hospital under the PPP was operational, providing high-level, critically needed services, and continued to improve patient outcomes. Quality at QMMH remained substantially higher than at the former Queen Elizabeth II hospital."
BRIAN MICHAEL WALSH,"Bostonia: 1999-2000, no. 1-4",
BRIAN MICHAEL WALSH,Carbon Free Boston: Buildings Technical Report,"OVERVIEW: Boston is known for its historic iconic buildings, from the Paul Revere House in the North End, to City Hall in Government Center, to the Old South Meeting House in Downtown Crossing, to the African Meeting House on Beacon Hill, to 200 Clarendon (the Hancock Tower) in Back Bay, to Abbotsford in Roxbury. In total, there are over 86,000 buildings that comprise more than 647 million square feet of area. Most of these buildings will still be in use in 2050. Floorspace (square footage) is almost evenly split between residential and non-residential uses, but residential buildings account for nearly 80,000 (93 percent) of the 86,000 buildings. Boston’s buildings are used for a diverse range of activities that include homes, offices, hospitals, factories, laboratories, schools, public service, retail, hotels, restaurants, and convention space. Building type strongly influences energy use; for example, restaurants, hospitals, and laboratories have high energy demands compared to other commercial uses. Boston’s building stock is characterized by thousands of turn-of-the-20th century homes and a postWorld War II building boom that expanded both residential buildings and commercial space. Boston is in the midst of another boom in building construction that is transforming neighborhoods across the city. [TRUNCATED]"
BRIAN MICHAEL WALSH,The cusp plasma imaging detector (CuPID) cubesat observatory: instrumentation,"The Cusp Plasma Imaging Detector (CuPID) CubeSat observatory is a 6U CubeSat designed to observe solar wind charge exchange in magnetospheric cusps to test competing theories of magnetic reconnection at the Earth's magnetopause. The CuPID is equipped with three instruments, namely, a wide field-of-view (4.6° × 4.6°) soft x-ray telescope, a micro-dosimeter suite, and an engineering magnetometer optimized for the science operation. The instrument suite has been tested and calibrated in relevant environments, demonstrating successful design. The testing and calibration of these instruments produced metrics and coefficients that will be used to create the CuPID mission's data product."
BRIAN MICHAEL WALSH,Estimating the subsolar magnetopause position from soft X-ray images using a low-pass image filter,
BRIAN MICHAEL WALSH,On the need for International Solar Terrestrial Program Next (ISTPNext),
BRIAN MICHAEL WALSH,"Bostonia: 2001-2002, no. 1-4",
BRIAN MICHAEL WALSH,Exploring solar-terrestrial interactions via multiple imaging observers,"How does solar wind energy flow through the Earth’s magnetosphere, how is it converted and distributed? is the question we want to address. We need to understand how geomagnetic storms and substorms start and grow, not just as a matter of scientific curiosity, but to address a clear and pressing practical problem: space weather, which can influence the performance and reliability of our technological systems, in space and on the ground, and can endanger human life and health. Much knowledge has already been acquired over the past decades, particularly by making use of multiple spacecraft measuring conditions in situ, but the infant stage of space weather forecasting demonstrates that we still have a vast amount of learning to do. A novel global approach is now being taken by a number of space imaging missions which are under development and the first tantalising results of their exploration will be available in the next decade. In this White Paper, submitted to ESA in response to the Voyage 2050 Call, we propose the next step in the quest for a complete understanding of how the Sun controls the Earth’s plasma environment: a tomographic imaging approach comprising two spacecraft in highly inclined polar orbits, enabling global imaging of magnetopause and cusps in soft X-rays, of auroral regions in FUV, of plasmasphere and ring current in EUV and ENA (Energetic Neutral Atoms), alongside in situ measurements. Such a mission, encompassing the variety of physical processes determining the conditions of geospace, will be crucial on the way to achieving scientific closure on the question of solar-terrestrial interactions."
EMILY RYAN,"Boston University Pre-Law Review: Volume XXIII, Issue 1, Spring 2014",
EMILY RYAN,Calibration of computational models with categorical parameters and correlated outputs via Bayesian smoothing spline ANOVA,"It has become commonplace to use complex computer models to predict outcomes in regions where data do not exist. Typically these models need to be calibrated and validated using some experimental data, which often consists of multiple correlated outcomes. In addition, some of the model parameters may be categorical in nature, such as a pointer variable to alternate models (or submodels) for some of the physics of the system. Here, we present a general approach for calibration in such situations where an emulator of the computationally demanding models and a discrepancy term from the model to reality are represented within a Bayesian smoothing spline (BSS) ANOVA framework. The BSS-ANOVA framework has several advantages over the traditional Gaussian process, including ease of handling categorical inputs and correlated outputs, and improved computational efficiency. Finally, this framework is then applied to the problem that motivated its design; a calibration of a computational fluid dynamics (CFD) model of a bubbling fluidized which is used as an absorber in a CO2 capture system. Supplementary materials for this article are available online."
EMILY RYAN,Engineering light-inducible molecular tools from fluorophore-binding photoactivatable domains,"During development, gene expression profiles are tightly regulated in order to ensure the correct assembly and differentiation of cells into organized multicellular and tissue assemblies. Part of this regulation is mediated via juxtacrine and paracrine signaling pathways, which coordinate in order to provide instructive signals that direct differential gene expression patterns over space and time. In particular, the function of juxtacrine signaling pathways—such as the Notch signaling pathway—serves to inform cells regarding their spatial positioning with respect to adjacent cells. In recent years, researchers have designed synthetic strategies in order to mimic developmental signaling programs and determine the molecular mechanisms involved in dysregulated signaling and disease. Such strategies have involved the implementation of synthetic gene circuits, artificial morphogen gradients, as well as engineered tissue microenvironments. These systems have provided powerful approaches for studying intercellular communication, enabling researchers to test hypotheses regarding natural mechanisms of cell-cell communication and to uncover the “design” principles underlying signal reception and propagation during tissue morphogenesis. In addition to their applications in basic science, these systems also possesses powerful synthetic utility, with the potential for realizing the promise of tissue engineering for biomedicine. Despite the sophistication of current DNA-encoded tool systems, the ability to direct pattern formation within synthetic multicellular assemblies remains limited. Indeed, in order to more closely recapitulate the intricate and complex assembly patterns that are observed in vivo, novel molecular tools that can be precisely actuated in space and time are required. In particular, tools that can be used to facilitate dynamic gene expression control, to encode the formation of cell-cell interactions, and to drive signal propagation across organized cellular assemblies, will be especially powerful in the realization of artificial tissue synthesis. In this thesis, I describe novel synthetic biology tools which have been designed in order to enable precise spatiotemporal control over gene expression programs within mammalian cells. By combining chemical, optical, and genetic techniques, a versatile light-inducible platform has been devised in which the activation of synthetic Notch (“SynNotch”) receptors can be controlled. In this approach, light is used to control the ability of our engineered SynNotch receptor to recognize, bind to, and subsequently activate in the presence of an optochemical ligand, fluorescein, and it’s photocaged derivatives. Herein, I describe the development, validation, and characterization of this system in order to achieve versatile optochemical control. In addition, I describe strategies by which chemogenetic control was integrated into the receptor platform in order to facilitate light-controlled activation of gene expression that can be subsequently down regulated upon administration of drug. Furthermore, through the incorporation of characterized split fluorescent protein components, we successfully rationally designed a SynNotch activation reporter system that depends on subcellular localization of proteins of interest and is capable of detecting SynNotch activation in under an hour. Overall, these systems represent a programable and tunable framework in which optogenetic and chemogenetic approaches are combined in order to provide the field with light-inducible molecular tools allowing for enhanced spatiotemporal control over proteins of interest. The future implementation and further adaptation of these tools will provide a powerful approach for dissecting how isogenic cells interact to propagate signals, coordinate protein expression patterns, and direct the formation of distinct multicellular phenotypes throughout development."
EMILY RYAN,Glass-fiber-reinforced polymeric film as an efficient protecting layer for stable Li metal electrodes,"[SUMMARY] With numerous reports on protecting films for stable lithium (Li) metal electrodes, the key attributes for how to construct these efficient layers have rarely been fully investigated. Here, we report a rationally designed hybrid protective layer (HPL) with each component aligning with one key attribute; i.e., cross-linked poly(dimethylsiloxane) (PDMS) enhances flexibility, polyethylene glycol (PEG) provides homogeneous ion-conducting channels, and glass fiber (GF) affords mechanical robustness. A significant improvement of the electrochemical performance of HPL-modified electrodes can be achieved in Li/HPL@Cu half cells, HPL@Li/HPL@Li symmetric cells, and HPL@Li/LiFePO4 full cells. Even with an industrial standard LiFePO4 cathode (96.8 wt % active material), the assembled cell still exhibits a capacity retention of 90% after 100 cycles at 1 C. More importantly, the functionality of each component has been studied comprehensively via electrochemical and physical experiments and simulations, which will provide useful guidance on how to construct efficient protective layers for next-generation energy storage devices."
EMILY RYAN,Interfacial studies on the effects of patterned anodes for guided lithium deposition in lithium metal batteries,"The lifetime and health of lithium metal batteries are greatly hindered by nonuniform deposition and growth of lithium at the anode-electrolyte interface, which leads to dendrite formation, efficiency loss, and short circuiting. Lithium deposition is influenced by several factors including local current densities, overpotentials, surface heterogeneity, and lithium-ion concentrations. However, due to the embedded, dynamic nature of this interface, it is difficult to observe the complex physics operando. Here, we present a detailed model of the interface that implements Butler-Volmer kinetics to investigate the effects of overpotential and surface heterogeneities on dendrite growth. A high overpotential has been proposed as a contributing factor in increased nucleation and growth of dendrites. Using computational methods, we can isolate the aspects of the complex physics at the interface to gain better insight into how each component affects the overall system. In addition, studies have shown that mechanical modifications to the anode surface, such as micropatterning, are a potential way of controlling deposition and increasing Coulombic efficiency. Micropatterns on the anode surface are explored along with deformations in the solid-electrolyte interface layer to understand their effects on the dendritic growth rates and morphology. The study results show that at higher overpotentials, more dendritic growth and a more branched morphology are present in comparison to low overpotentials, where more uniform and denser growth is observed. In addition, the results suggest that there is a relationship between surface chemistries and anode geometries."
EMILY RYAN,Inhibition of lithium dendrite formation in lithium metal batteries via regulated cation transport through ultrathin sub‐nanometer porous carbon nanomembranes,"Suppressing Li dendrite growth has gained research interest due to the high theoretical capacity of Li metal anodes. Traditional Celgard membranes which are currently used in Li metal batteries fall short in achieving uniform Li flux at the electrode/electrolyte interface due to their inherent irregular pore sizes. Here, the use of an ultrathin (≈1.2 nm) carbon nanomembrane (CNM) which contains sub-nanometer sized pores as an interlayer to regulate the mass transport of Li-ions is demonstrated. Symmetrical cell analysis reveals that the cell with CNM interlayer cycles over 2x longer than the control experiment without the formation of Li dendrites. Further investigation on the Li plating morphology on Cu foil reveals highly dense deposits of Li metal using a standard carbonate electrolyte. A smoothed-particle hydrodynamics simulation of the mass transport at the anode–electrolyte interface elucidates the effect of the CNM in promoting the formation of highly dense Li deposits and inhibiting the formation of dendrites. A lithium metal battery fabricated using the LiFePO4 cathode exhibits a stable, flat voltage profile with low polarization for over 300 cycles indicating the effect of regulated mass transport."
EMILY RYAN,Modeling the effects of pulse plating on dendrite growth in lithium metal batteries,
EMILY RYAN,Smoothed particle hydrodynamics modeling of electrodeposition and dendritic growth under migration- and diffusion-controlled mass transport,"In many electrochemical processes, the transport of charged species is governed by the Nernst–Planck equation, which includes terms for both diffusion and electrochemical migration. In this work, a multi-physics, multi-species model based on the smoothed particle hydrodynamics (SPH) method is presented to model the Nernst–Planck equation in systems with electrodeposition. Electrodeposition occurs when ions are deposited onto an electrode. These deposits create complex boundary geometries, which can be challenging for numerical methods to resolve. SPH is a particularly effective numerical method for systems with moving and deforming boundaries due to its particle nature. This paper discusses the SPH implementation of the Nernst–Planck equations with electrodeposition and verifies the model with an analytical solution and a numerical integrator. A convergence study of migration and precipitation is presented to illustrate the model’s accuracy, along with comparisons of the deposition growth front to experimental results."
EMILY RYAN,Prospective on methods of design of experiments for limited data scenarios in materials design and engineering,
EMILY RYAN,"Bostonia: 2001-2002, no. 1-4",
EMILY RYAN,Reproductive inequality in humans and other mammals,"To address claims of human exceptionalism, we determine where humans fit within the greater mammalian distribution of reproductive inequality. We show that humans exhibit lower reproductive skew (i.e., inequality in the number of surviving offspring) among males and smaller sex differences in reproductive skew than most other mammals, while nevertheless falling within the mammalian range. Additionally, female reproductive skew is higher in polygynous human populations than in polygynous nonhumans mammals on average. This patterning of skew can be attributed in part to the prevalence of monogamy in humans compared to the predominance of polygyny in nonhuman mammals, to the limited degree of polygyny in the human societies that practice it, and to the importance of unequally held rival resources to women's fitness. The muted reproductive inequality observed in humans appears to be linked to several unusual characteristics of our species-including high levels of cooperation among males, high dependence on unequally held rival resources, complementarities between maternal and paternal investment, as well as social and legal institutions that enforce monogamous norms."
EMILY RYAN,"Bostonia: 2002-2003, no.1-4",
EMILY RYAN,"Concept paper on a curriculum initiative for energy, climate change, and sustainability at Boston University","[Summary] Boston University has made important contributions to the interconnected challenges of energy, climate change, and sustainability (ECS) through its research, teaching, and campus operations. This work reveals new opportunities to expand the scope of teaching and research and place the University at the forefront of ECS in higher education. This paper describes the framework for a University-wide curriculum initiative that moves us in that direction and that complements the University’s strategic plan. The central curricular objectives are to provide every undergraduate the opportunity be touched in some way in their educational program by exposure to some aspect of the ECS challenge, and to increase opportunities for every graduate student to achieve a focused competence in ECS. The initiative has six cornerstone initiatives. The first is the Campus as a Living Lab (CALL) program in which students, faculty and staff work together and use our urban campus and its community to study and implement ECS solutions. The second is a university-wide minor degree that helps students develop an integrated perspective of the economic, environmental, and social dimensions of sustainability. The third is one or more graduate certificate programs open to all graduate students. The fourth is an annual summer faculty workshop that develops new ECS curriculum and CALL opportunities. The fifth is web-based resource that underpins the construction of a vibrant knowledge network for the BU community and beyond. Finally, an enhanced sustainability alumni network will augment professional opportunities and generate other benefits. The learning outcomes of this initiative will be realized through the collaborative work of faculty, students, and staff from all 17 colleges and schools. The initiative will leverage existing BU student resources such as the Thurman Center, Build Lab, and Innovate@BU. Benefits of this initiative, beyond the curriculum, include acceleration towards the goals of our Climate Action Plan; improving the “sustainability brand” of BU; enhancing the ability to attract students and new faculty; strengthening our alumni and campus communities; deepening our ties with the city of Boston; and the potential to spin off new social and technological innovations."
EMILY RYAN,The first habitable-zone Earth-sized planet from TESS. II. Spitzer confirms TOI-700 d,"We present Spitzer 4.5 μm observations of the transit of TOI-700 d, a habitable-zone Earth-sized planet in a multiplanet system transiting a nearby M-dwarf star (TIC 150428135, 2MASS J06282325–6534456). TOI-700 d has a radius of 1.144_-0.061^+0.062R_⨁ and orbits within its host star's conservative habitable zone with a period of 37.42 days (T eq ~ 269 K). TOI-700 also hosts two small inner planets (R b = 1.037_-0.064^+0.065R_⨁ and R c = 2.65_-0.15^+0.16R_⨁) with periods of 9.98 and 16.05 days, respectively. Our Spitzer observations confirm the Transiting Exoplanet Survey Satellite (TESS) detection of TOI-700 d and remove any remaining doubt that it is a genuine planet. We analyze the Spitzer light curve combined with the 11 sectors of TESS observations and a transit of TOI-700 c from the LCOGT network to determine the full system parameters. Although studying the atmosphere of TOI-700 d is not likely feasible with upcoming facilities, it may be possible to measure the mass of TOI-700 d using state-of-the-art radial velocity (RV) instruments (expected RV semiamplitude of ~70 cm s^−1)."
MATTHEW ROBERT JONES,"Journal of African Christian Biography: v. 8, no. 4","[This issue of the Journal of African Christian Biography highlights some of the entries in the DACB that profile participants in the twentieth-century ecumenical movement in southern Africa. The overwhelming impression one gets of this subject is that of gaps: there is urgent need for more entries that address the myriad ways in which African Christian leaders engaged the ecumenical movement as a network through which to build social capital during the critical period after the Second World War. As African nations became independent of European colonial control, church-educated leaders often acted as global spokesmen for postcolonial visions of society. They cultivated international support structures and led regional independence movements. Ecumenical networks played crucial roles in maintaining structures for education and peace-building in conflictive situations. Nelson Mandela himself, for example, attended Healdtown, a Methodist mission that became the largest high school in the country and educated many of the most important black nationalist leaders at mid century. The entries highlighted in this issue are the tip of the iceberg of what needs to be researched and written. This issue, then, appeals for scholars and church leaders to step up and to provide biographies of “ecumenists”—those who located their commitment to the Body of Christ in an international vision of peace, equality, and justice, in collaboration with other Christians from across Africa and around the world, as well as those who worked at the local level of cooperative church movements.]"
MATTHEW ROBERT JONES,First radial velocity results from the MINiature Exoplanet Radial Velocity Array (MINERVA),"The MINiature Exoplanet Radial Velocity Array (MINERVA) is a dedicated observatory of four 0.7 m robotic telescopes fiber-fed to a KiwiSpec spectrograph. The MINERVA mission is to discover super-Earths in the habitable zones of nearby stars. This can be accomplished with MINERVA's unique combination of high precision and high cadence over long time periods. In this work, we detail changes to the MINERVA facility that have occurred since our previous paper. We then describe MINERVA's robotic control software, the process by which we perform 1D spectral extraction, and our forward modeling Doppler pipeline. In the process of improving our forward modeling procedure, we found that our spectrograph's intrinsic instrumental profile is stable for at least nine months. Because of that, we characterized our instrumental profile with a time-independent, cubic spline function based on the profile in the cross dispersion direction, with which we achieved a radial velocity precision similar to using a conventional ""sum-of-Gaussians"" instrumental profile: 1.8 m s−1 over 1.5 months on the RV standard star HD 122064. Therefore, we conclude that the instrumental profile need not be perfectly accurate as long as it is stable. In addition, we observed 51 Peg and our results are consistent with the literature, confirming our spectrograph and Doppler pipeline are producing accurate and precise radial velocities."
MATTHEW ROBERT JONES,Scintillation light detection in the 6-m drift-length ProtoDUNE Dual Phase liquid argon TPC,"DUNE is a dual-site experiment for long-baseline neutrino oscillation studies, neutrino astrophysics and nucleon decay searches. ProtoDUNE Dual Phase (DP) is a 6  ×  6  ×  6 m 3 liquid argon time-projection-chamber (LArTPC) that recorded cosmic-muon data at the CERN Neutrino Platform in 2019-2020 as a prototype of the DUNE Far Detector. Charged particles propagating through the LArTPC produce ionization and scintillation light. The scintillation light signal in these detectors can provide the trigger for non-beam events. In addition, it adds precise timing capabilities and improves the calorimetry measurements. In ProtoDUNE-DP, scintillation and electroluminescence light produced by cosmic muons in the LArTPC is collected by photomultiplier tubes placed up to 7 m away from the ionizing track. In this paper, the ProtoDUNE-DP photon detection system performance is evaluated with a particular focus on the different wavelength shifters, such as PEN and TPB, and the use of Xe-doped LAr, considering its future use in giant LArTPCs. The scintillation light production and propagation processes are analyzed and a comparison of simulation to data is performed, improving understanding of the liquid argon properties."
MATTHEW ROBERT JONES,Identification and reconstruction of low-energy electrons in the ProtoDUNE-SP detector,
MATTHEW ROBERT JONES,The long-baseline neutrino experiment: exploring fundamental symmetries of the universe,"The preponderance of matter over antimatter in the early Universe, the dynamics of the supernova bursts that produced the heavy elements necessary for life and whether protons eventually decay --- these mysteries at the forefront of particle physics and astrophysics are key to understanding the early evolution of our Universe, its current state and its eventual fate. The Long-Baseline Neutrino Experiment (LBNE) represents an extensively developed plan for a world-class experiment dedicated to addressing these questions. LBNE is conceived around three central components: (1) a new, high-intensity neutrino source generated from a megawatt-class proton accelerator at Fermi National Accelerator Laboratory, (2) a near neutrino detector just downstream of the source, and (3) a massive liquid argon time-projection chamber deployed as a far detector deep underground at the Sanford Underground Research Facility. This facility, located at the site of the former Homestake Mine in Lead, South Dakota, is approximately 1,300 km from the neutrino source at Fermilab -- a distance (baseline) that delivers optimal sensitivity to neutrino charge-parity symmetry violation and mass ordering effects. This ambitious yet cost-effective design incorporates scalability and flexibility and can accommodate a variety of upgrades and contributions. With its exceptional combination of experimental configuration, technical capabilities, and potential for transformative discoveries, LBNE promises to be a vital facility for the field of particle physics worldwide, providing physicists from around the globe with opportunities to collaborate in a twenty to thirty year program of exciting science. In this document we provide a comprehensive overview of LBNE's scientific objectives, its place in the landscape of neutrino physics worldwide, the technologies it will incorporate and the capabilities it will possess."
ERIN MURPHY,Introduction: Honoring Eve: a special issue on the work of Eve Kosofsky Sedgwick,"This special issue grew out of the event ""Honoring Eve: A Symposium celebrating the Work of Eve Kosofsky Sedgwick,"" which was held on October 31, 2009 at Boston University (BU), about six months after Sedgwick passed away on April 12, 2009. More than two hundred people came to the symposium from all over the United States and as far away as Spain and Israel. they were not just academics, but artists, musicians, writers, and many others who had been touched by Sedgwick's work. Within BU, faculty members from across the university prepared for the symposium by assigning Sedgwick's work in courses whose diversity testifies to the breadth of her influence: from ""Family Trouble: Contesting Kinship In Theory And Literature"" to ""Japanese Popular Culture"" to ""Buddhism in America"" and the ""New Testament Seminar on Gender and Christian Origins."" In honor of Sedgwick's commitment to pedagogy and activism, in the week before the event we also held two workshops at which faculty members and one hundred undergraduates gathered to discuss her essay ""How to Bring Your Kids up Gay."" Although this essay was written before many of these students were born, Sedgwick's fiery insistence that the existence of gay people be understood not just as a fact to be tolerated but as a ""positive desideratum, a needed condition of life"" remains just as powerful as when she wrote it in 1991."
DAN LI,First M87 Event Horizon Telescope results. III. Data processing and calibration,"We present the calibration and reduction of Event Horizon Telescope (EHT) 1.3 mm radio wavelength observations of the supermassive black hole candidate at the center of the radio galaxy M87 and the quasar 3C 279, taken during the 2017 April 5–11 observing campaign. These global very long baseline interferometric observations include for the first time the highly sensitive Atacama Large Millimeter/submillimeter Array (ALMA); reaching an angular resolution of 25 μas, with characteristic sensitivity limits of ~1 mJy on baselines to ALMA and ~10 mJy on other baselines. The observations present challenges for existing data processing tools, arising from the rapid atmospheric phase fluctuations, wide recording bandwidth, and highly heterogeneous array. In response, we developed three independent pipelines for phase calibration and fringe detection, each tailored to the specific needs of the EHT. The final data products include calibrated total intensity amplitude and phase information. They are validated through a series of quality assurance tests that show consistency across pipelines and set limits on baseline systematic errors of 2% in amplitude and 1° in phase. The M87 data reveal the presence of two nulls in correlated flux density at ~3.4 and ~8.3 Gλ and temporal evolution in closure quantities, indicating intrinsic variability of compact structure on a timescale of days, or several light-crossing times for a few billion solar-mass black hole. These measurements provide the first opportunity to image horizon-scale structure in M87."
DAN LI,First M87 Event Horizon Telescope results. V. Physical origin of the asymmetric ring,"The Event Horizon Telescope (EHT) has mapped the central compact radio source of the elliptical galaxy M87 at 1.3 mm with unprecedented angular resolution. Here we consider the physical implications of the asymmetric ring seen in the 2017 EHT data. To this end, we construct a large library of models based on general relativistic magnetohydrodynamic (GRMHD) simulations and synthetic images produced by general relativistic ray tracing. We compare the observed visibilities with this library and confirm that the asymmetric ring is consistent with earlier predictions of strong gravitational lensing of synchrotron emission from a hot plasma orbiting near the black hole event horizon. The ring radius and ring asymmetry depend on black hole mass and spin, respectively, and both are therefore expected to be stable when observed in future EHT campaigns. Overall, the observed image is consistent with expectations for the shadow of a spinning Kerr black hole as predicted by general relativity. If the black hole spin and M87's large scale jet are aligned, then the black hole spin vector is pointed away from Earth. Models in our library of non-spinning black holes are inconsistent with the observations as they do not produce sufficiently powerful jets. At the same time, in those models that produce a sufficiently powerful jet, the latter is powered by extraction of black hole spin energy through mechanisms akin to the Blandford-Znajek process. We briefly consider alternatives to a black hole for the central compact object. Analysis of existing EHT polarization data and data taken simultaneously at other wavelengths will soon enable new tests of the GRMHD models, as will future EHT campaigns at 230 and 345 GHz."
DAN LI,First M87 Event Horizon Telescope results. VI. The shadow and mass of the central black hole,"We present measurements of the properties of the central radio source in M87 using Event Horizon Telescope data obtained during the 2017 campaign. We develop and fit geometric crescent models (asymmetric rings with interior brightness depressions) using two independent sampling algorithms that consider distinct representations of the visibility data. We show that the crescent family of models is statistically preferred over other comparably complex geometric models that we explore. We calibrate the geometric model parameters using general relativistic magnetohydrodynamic (GRMHD) models of the emission region and estimate physical properties of the source. We further fit images generated from GRMHD models directly to the data. We compare the derived emission region and black hole parameters from these analyses with those recovered from reconstructed images. There is a remarkable consistency among all methods and data sets. We find that >50% of the total flux at arcsecond scales comes from near the horizon, and that the emission is dramatically suppressed interior to this region by a factor >10, providing direct evidence of the predicted shadow of a black hole. Across all methods, we measure a crescent diameter of 42 ± 3 μas and constrain its fractional width to be <0.5. Associating the crescent feature with the emission surrounding the black hole shadow, we infer an angular gravitational radius of GM/Dc^2 = 3.8 ± 0.4 μas. Folding in a distance measurement of {16.8}_{-0.7}^{+0.8}{Mpc} gives a black hole mass of M = 6.5 ± 0.2{| }_{stat} ± 0.7{| }_{sys} × {10}^{9} {M}_{odot }. This measurement from lensed emission near the event horizon is consistent with the presence of a central Kerr black hole, as predicted by the general theory of relativity."
DAN LI,"Tree transpiration and urban temperatures: current understanding, implications, and future research directions","The expansion of an urban tree canopy is a commonly proposed nature-based solution to combat excess urban heat. The influence trees have on urban climates via shading is driven by the morphological characteristics of trees, whereas tree transpiration is predominantly a physiological process dependent on environmental conditions and the built environment. The heterogeneous nature of urban landscapes, unique tree species assemblages, and land management decisions make it difficult to predict the magnitude and direction of cooling by transpiration. In the present article, we synthesize the emerging literature on the mechanistic controls on urban tree transpiration. We present a case study that illustrates the relationship between transpiration (using sap flow data) and urban temperatures. We examine the potential feed backs among urban canopy, the built environment, and climate with a focus on extreme heat events. Finally, we present modeled data demonstrating the influence of transpiration on temperatures with shifts in canopy extent and irrigation during a heat wave."
DAN LI,The Event Horizon general relativistic magnetohydrodynamic code comparison project,"Recent developments in compact object astrophysics, especially the discovery of merging neutron stars by LIGO, the imaging of the black hole in M87 by the Event Horizon Telescope, and high- precision astrometry of the Galactic Center at close to the event horizon scale by the GRAVITY experiment motivate the development of numerical source models that solve the equations of general relativistic magnetohydrodynamics (GRMHD). Here we compare GRMHD solutions for the evolution of a magnetized accretion flow where turbulence is promoted by the magnetorotational instability from a set of nine GRMHD codes: Athena++, BHAC, Cosmos++, ECHO, H-AMR, iharm3D, HARM-Noble, IllinoisGRMHD, and KORAL. Agreement among the codes improves as resolution increases, as measured by a consistently applied, specially developed set of code performance metrics. We conclude that the community of GRMHD codes is mature, capable, and consistent on these test problems."
DAN LI,Gravitational test beyond the first post-Newtonian order with the shadow of the M87 black hole,"The 2017 Event Horizon Telescope (EHT) observations of the central source in M87 have led to the first measurement of the size of a black-hole shadow. This observation offers a new and clean gravitational test of the black-hole metric in the strong-field regime. We show analytically that spacetimes that deviate from the Kerr metric but satisfy weak-field tests can lead to large deviations in the predicted black-hole shadows that are inconsistent with even the current EHT measurements. We use numerical calculations of regular, parametric, non-Kerr metrics to identify the common characteristic among these different parametrizations that control the predicted shadow size. We show that the shadow-size measurements place significant constraints on deviation parameters that control the second post-Newtonian and higher orders of each metric and are, therefore, inaccessible to weak-field tests. The new constraints are complementary to those imposed by observations of gravitational waves from stellar-mass sources."
DAN LI,First M87 Event Horizon Telescope results. IV. Imaging the central supermassive black hole,
DAN LI,Verification of radiative transfer schemes for the EHT,"The Event Horizon Telescope (EHT) Collaboration has recently produced the first resolved images of the central supermassive black hole in the giant elliptical galaxy M87. Here we report on tests of the consistency and accuracy of the general relativistic radiative transfer codes used within the collaboration to model M87* and Sgr A*. We compare and evaluate (1) deflection angles for equatorial null geodesics in a Kerr spacetime; (2) images calculated from a series of simple, parameterized matter distributions in the Kerr metric using simplified emissivities and absorptivities; (3) for a subset of codes, images calculated from general relativistic magnetohydrodynamics simulations using different realistic synchrotron emissivities and absorptivities; (4) observables for the 2017 configuration of EHT, including visibility amplitudes and closure phases. The error in total flux is of order 1% when the codes are run with production numerical parameters. The dominant source of discrepancies for small camera distances is the location and detailed setup of the software ""camera"" that each code uses to produce synthetic images. We find that when numerical parameters are suitably chosen and the camera is sufficiently far away the images converge and that for given transfer coefficients, numerical uncertainties are unlikely to limit parameter estimation for the current generation of EHT observations. The purpose of this paper is to describe a verification and comparison of EHT radiative transfer codes. It is not to verify EHT models more generally."
DAN LI,Monitoring the mmorphology of M87* in 2009–2017 with the Event Horizon Telescope,"The Event Horizon Telescope (EHT) has recently delivered the first resolved images of M87*, the supermassive black hole in the center of the M87 galaxy. These images were produced using 230 GHz observations performed in April 2017. Additional observations are required to investigate the persistence of the primary image feature – a ring with azimuthal brightness asymmetry – and to quantify the image variability on event horizon scales. To address this need, we analyze M87* data collected with prototype EHT arrays in 2009, 2011, 2012, and 2013. While these observations do not contain enough information to produce images, they are sufficient to constrain simple geometric models. We develop a modeling approach based on the framework utilized for the 2017 EHT data analysis and validate our procedures using synthetic data. Applying the same approach to the observational data sets, we find the M87* morphology in 2009–2017 to be consistent with a persistent asymmetric ring of 40 as diameter. The position angle of peak intensity varies in time. In particular, we find a significant difference between the position angle measured in 2013 and 2017. These variations are in broad agreement with predictions of a subset of general relativistic magnetohydrodynamic simulations. We show that quantifying the variability across multiple observational epochs has the potential to constrain physical properties of the source, such as the accretion state or the black hole spin."
DAN LI,THEMIS: a parameter estimation framework for the Event Horizon Telescope,"The Event Horizon Telescope (EHT) provides the unprecedented ability to directly resolve the structure and dynamics of black hole emission regions on scales smaller than their horizons. This has the potential to critically probe the mechanisms by which black holes accrete and launch outflows, and the structure of supermassive black hole spacetimes. However, accessing this information is a formidable analysis challenge for two reasons. First, the EHT natively produces a variety of data types that encode information about the image structure in nontrivial ways; these are subject to a variety of systematic effects associated with very long baseline interferometry and are supplemented by a wide variety of auxiliary data on the primary EHT targets from decades of other observations. Second, models of the emission regions and their interaction with the black hole are complex, highly uncertain, and computationally expensive to construct. As a result, the scientific utilization of EHT observations requires a flexible, extensible, and powerful analysis framework. We present such a framework, Themis, which defines a set of interfaces between models, data, and sampling algorithms that facilitates future development. We describe the design and currently existing components of Themis, how Themis has been validated thus far, and present additional analyses made possible by Themis that illustrate its capabilities. Importantly, we demonstrate that Themis is able to reproduce prior EHT analyses, extend these, and do so in a computationally efficient manner that can efficiently exploit modern high-performance computing facilities. Themis has already been used extensively in the scientific analysis and interpretation of the first EHT observations of M87."
DAN LI,First Sagittarius A* Event Horizon Telescope results. V. Testing astrophysical models of the galactic center black hole,"In this paper we provide a first physical interpretation for the Event Horizon Telescope's (EHT) 2017 observations of Sgr A*. Our main approach is to compare resolved EHT data at 230 GHz and unresolved non-EHT observations from radio to X-ray wavelengths to predictions from a library of models based on time-dependent general relativistic magnetohydrodynamics simulations, including aligned, tilted, and stellar-wind-fed simulations; radiative transfer is performed assuming both thermal and nonthermal electron distribution functions. We test the models against 11 constraints drawn from EHT 230 GHz data and observations at 86 GHz, 2.2 μm, and in the X-ray. All models fail at least one constraint. Light-curve variability provides a particularly severe constraint, failing nearly all strongly magnetized (magnetically arrested disk (MAD)) models and a large fraction of weakly magnetized models. A number of models fail only the variability constraints. We identify a promising cluster of these models, which are MAD and have inclination i ≤ 30°. They have accretion rate (5.2–9.5) × 10−9 M ⊙ yr−1, bolometric luminosity (6.8–9.2) × 1035 erg s−1, and outflow power (1.3–4.8) × 1038 erg s−1. We also find that all models with i ≥ 70° fail at least two constraints, as do all models with equal ion and electron temperature; exploratory, nonthermal model sets tend to have higher 2.2 μm flux density; and the population of cold electrons is limited by X-ray constraints due to the risk of bremsstrahlung overproduction. Finally, we discuss physical and numerical limitations of the models, highlighting the possible importance of kinetic effects and duration of the simulations."
DAN LI,First M87 Event Horizon Telescope results. VII. Polarization of the ring,"In 2017 April, the Event Horizon Telescope (EHT) observed the near-horizon region around the supermassive black hole at the core of the M87 galaxy. These 1.3 mm wavelength observations revealed a compact asymmetric ring-like source morphology. This structure originates from synchrotron emission produced by relativistic plasma located in the immediate vicinity of the black hole. Here we present the corresponding linear-polarimetric EHT images of the center of M87. We find that only a part of the ring is significantly polarized. The resolved fractional linear polarization has a maximum located in the southwest part of the ring, where it rises to the level of ∼15%. The polarization position angles are arranged in a nearly azimuthal pattern. We perform quantitative measurements of relevant polarimetric properties of the compact emission and find evidence for the temporal evolution of the polarized source structure over one week of EHT observations. The details of the polarimetric data reduction and calibration methodology are provided. We carry out the data analysis using multiple independent imaging and modeling techniques, each of which is validated against a suite of synthetic data sets. The gross polarimetric structure and its apparent evolution with time are insensitive to the method used to reconstruct the image. These polarimetric images carry information about the structure of the magnetic fields responsible for the synchrotron emission. Their physical interpretation is discussed in an accompanying publication."
DAN LI,First M87 Event Horizon Telescope results. VIII. Magnetic field structure near The Event Horizon,"Event Horizon Telescope (EHT) observations at 230 GHz have now imaged polarized emission around the supermassive black hole in M87 on event-horizon scales. This polarized synchrotron radiation probes the structure of magnetic fields and the plasma properties near the black hole. Here we compare the resolved polarization structure observed by the EHT, along with simultaneous unresolved observations with the Atacama Large Millimeter/submillimeter Array, to expectations from theoretical models. The low fractional linear polarization in the resolved image suggests that the polarization is scrambled on scales smaller than the EHT beam, which we attribute to Faraday rotation internal to the emission region. We estimate the average density n_e ∼ 10^4–7 cm^−3, magnetic field strength B ∼ 1–30 G, and electron temperature T_e ∼ (1–12) × 10^10 K of the radiating plasma in a simple one-zone emission model. We show that the net azimuthal linear polarization pattern may result from organized, poloidal magnetic fields in the emission region. In a quantitative comparison with a large library of simulated polarimetric images from general relativistic magnetohydrodynamic (GRMHD) simulations, we identify a subset of physical models that can explain critical features of the polarimetric EHT observations while producing a relativistic jet of sufficient power. The consistent GRMHD models are all of magnetically arrested accretion disks, where near-horizon magnetic fields are dynamically important. We use the models to infer a mass accretion rate onto the black hole in M87 of (3–20) × 10^−4 M ⊙ yr^−1."
DAN LI,Resolving the inner parsec of the blazar J1924–2914 with the event horizon telescope,"The blazar J1924–2914 is a primary Event Horizon Telescope (EHT) calibrator for the Galactic center’s black hole Sagittarius A*. Here we present the first total and linearly polarized intensity images of this source obtained with the unprecedented 20 μas resolution of the EHT. J1924–2914 is a very compact flat-spectrum radio source with strong optical variability and polarization. In April 2017 the source was observed quasi-simultaneously with the EHT (April 5–11), the Global Millimeter VLBI Array (April 3), and the Very Long Baseline Array (April 28), giving a novel view of the source at four observing frequencies, 230, 86, 8.7, and 2.3 GHz. These observations probe jet properties from the subparsec to 100 pc scales. We combine the multifrequency images of J1924–2914 to study the source morphology. We find that the jet exhibits a characteristic bending, with a gradual clockwise rotation of the jet projected position angle of about 90° between 2.3 and 230 GHz. Linearly polarized intensity images of J1924–2914 with the extremely fine resolution of the EHT provide evidence for ordered toroidal magnetic fields in the blazar compact core."
DAN LI,A universal power-law prescription for variability from synthetic images of black hole accretion flows,"We present a framework for characterizing the spatiotemporal power spectrum of the variability expected from the horizon-scale emission structure around supermassive black holes, and we apply this framework to a library of general relativistic magnetohydrodynamic (GRMHD) simulations and associated general relativistic ray-traced images relevant for Event Horizon Telescope (EHT) observations of Sgr A*. We find that the variability power spectrum is generically a red-noise process in both the temporal and spatial dimensions, with the peak in power occurring on the longest timescales and largest spatial scales. When both the time-averaged source structure and the spatially integrated light-curve variability are removed, the residual power spectrum exhibits a universal broken power-law behavior. On small spatial frequencies, the residual power spectrum rises as the square of the spatial frequency and is proportional to the variance in the centroid of emission. Beyond some peak in variability power, the residual power spectrum falls as that of the time-averaged source structure, which is similar across simulations; this behavior can be naturally explained if the variability arises from a multiplicative random field that has a steeper high-frequency power-law index than that of the time-averaged source structure. We briefly explore the ability of power spectral variability studies to constrain physical parameters relevant for the GRMHD simulations, which can be scaled to provide predictions for black holes in a range of systems in the optically thin regime. We present specific expectations for the behavior of the M87* and Sgr A* accretion flows as observed by the EHT."
DAN LI,Millimeter light curves of Sagittarius A* observed during the 2017 Event Horizon Telescope campaign,"The Event Horizon Telescope (EHT) observed the compact radio source, Sagittarius A* (Sgr A*), in the Galactic Center on 2017 April 5–11 in the 1.3 mm wavelength band. At the same time, interferometric array data from the Atacama Large Millimeter/submillimeter Array and the Submillimeter Array were collected, providing Sgr A* light curves simultaneous with the EHT observations. These data sets, complementing the EHT very long baseline interferometry, are characterized by a cadence and signal-to-noise ratio previously unattainable for Sgr A* at millimeter wavelengths, and they allow for the investigation of source variability on timescales as short as a minute. While most of the light curves correspond to a low variability state of Sgr A*, the April 11 observations follow an X-ray flare and exhibit strongly enhanced variability. All of the light curves are consistent with a red-noise process, with a power spectral density (PSD) slope measured to be between −2 and −3 on timescales between 1 minute and several hours. Our results indicate a steepening of the PSD slope for timescales shorter than 0.3 hr. The spectral energy distribution is flat at 220 GHz, and there are no time lags between the 213 and 229 GHz frequency bands, suggesting low optical depth for the event horizon scale source. We characterize Sgr A*’s variability, highlighting the different behavior observed just after the X-ray flare, and use Gaussian process modeling to extract a decorrelation timescale and a PSD slope. We also investigate the systematic calibration uncertainties by analyzing data from independent data reduction pipelines."
DAN LI,Selective dynamical imaging of interferometric data,"Recent developments in very long baseline interferometry (VLBI) have made it possible for the Event Horizon Telescope (EHT) to resolve the innermost accretion flows of the largest supermassive black holes on the sky. The sparse nature of the EHT’s (u, v)-coverage presents a challenge when attempting to resolve highly time-variable sources. We demonstrate that the changing (u, v)-coverage of the EHT can contain regions of time over the course of a single observation that facilitate dynamical imaging. These optimal time regions typically have projected baseline distributions that are approximately angularly isotropic and radially homogeneous. We derive a metric of coverage quality based on baseline isotropy and density that is capable of ranking array configurations by their ability to produce accurate dynamical reconstructions. We compare this metric to existing metrics in the literature and investigate their utility by performing dynamical reconstructions on synthetic data from simulated EHT observations of sources with simple orbital variability. We then use these results to make recommendations for imaging the 2017 EHT Sgr A* data set."
DAN LI,Multiple Independent Loci at Chromosome 15q25.1 Affect Smoking Quantity: a Meta-Analysis and Comparison with Lung Cancer and COPD,"Recently, genetic association findings for nicotine dependence, smoking behavior, and smoking-related diseases converged to implicate the chromosome 15q25.1 region, which includes the CHRNA5-CHRNA3-CHRNB4 cholinergic nicotinic receptor subunit genes. In particular, association with the nonsynonymous CHRNA5 SNP rs16969968 and correlates has been replicated in several independent studies. Extensive genotyping of this region has suggested additional statistically distinct signals for nicotine dependence, tagged by rs578776 and rs588765. One goal of the Consortium for the Genetic Analysis of Smoking Phenotypes (CGASP) is to elucidate the associations among these markers and dichotomous smoking quantity (heavy versus light smoking), lung cancer, and chronic obstructive pulmonary disease (COPD). We performed a meta-analysis across 34 datasets of European-ancestry subjects, including 38,617 smokers who were assessed for cigarettes-per-day, 7,700 lung cancer cases and 5,914 lung-cancer-free controls (all smokers), and 2,614 COPD cases and 3,568 COPD-free controls (all smokers). We demonstrate statistically independent associations of rs16969968 and rs588765 with smoking (mutually adjusted p-values<10−35 and >10−8 respectively). Because the risk alleles at these loci are negatively correlated, their association with smoking is stronger in the joint model than when each SNP is analyzed alone. Rs578776 also demonstrates association with smoking after adjustment for rs16969968 (p<10−6). In models adjusting for cigarettes-per-day, we confirm the association between rs16969968 and lung cancer (p<10−20) and observe a nominally significant association with COPD (p = 0.01); the other loci are not significantly associated with either lung cancer or COPD after adjusting for rs16969968. This study provides strong evidence that multiple statistically distinct loci in this region affect smoking behavior. This study is also the first report of association between rs588765 (and correlates) and smoking that achieves genome-wide significance; these SNPs have previously been associated with mRNA levels of CHRNA5 in brain and lung tissue. Author Summary Nicotine binds to cholinergic nicotinic receptors, which are composed of a variety of subunits. Genetic studies for smoking behavior and smoking-related diseases have implicated a genomic region that encodes the alpha5, alpha3, and beta4 subunits. We examined genetic data across this region for over 38,000 smokers, a subset of which had been assessed for lung cancer or chronic obstructive pulmonary disease. We demonstrate strong evidence that there are at least two statistically independent loci in this region that affect risk for heavy smoking. One of these loci represents a change in the protein structure of the alpha5 subunit. This work is also the first to report strong evidence of association between smoking and a group of genetic variants that are of biological interest because of their links to expression of the alpha5 cholinergic nicotinic receptor subunit gene. These advances in understanding the genetic influences on smoking behavior are important because of the profound public health burdens caused by smoking and nicotine addiction."
DAN LI,Cartilage Markers and Their Association with Cartilage Loss on Magnetic Resonance Imaging in Knee Osteoarthritis: The Boston Osteoarthritis Knee Study,"We used data from a longitudinal observation study to determine whether markers of cartilage turnover could serve as predictors of cartilage loss on magnetic resonance imaging (MRI). We conducted a study of data from the Boston Osteoarthritis of the Knee Study (BOKS), a completed natural history study of knee osteoarthritis (OA). All subjects in the study met American College of Rheumatology criteria for knee OA. Baseline and follow-up knee magnetic resonance images were scored for cartilage loss by means of the WORMS (Whole Organ Magnetic Resonance Imaging Score) semiquantitative grading scheme. Within the BOKS population, 80 subjects who experienced cartilage loss and 80 subjects who did not were selected for the purposes of this nested case control study. We assessed the baseline levels of cartilage degradation and synthesis products by means of assays for type I and II cleavage by collagenases (Col2:3/4Cshort or C1,2C), type II cleavage only with Col2:3/4Clongmono (C2C), type II synthesis (C-propeptide), the C-telopeptide of type II (Col2CTx), aggrecan 846 epitope, and cartilage oligomeric matrix protein (COMP). We performed a logistic regression to examine the relation of levels of each biomarker to the risk of cartilage loss in any knee. All analyses were adjusted for gender, age, and body mass index (BMI); results stratified by gender gave similar results. One hundred thirty-seven patients with symptomatic knee OA were assessed. At baseline, the mean (standard deviation) age was 67 (9) years and 54% were male. Seventy-six percent of the subjects had radiographic tibiofemoral OA (Kellgren & Lawrence grade of greater than or equal to 2) and the remainder had patellofemoral OA. With the exception of COMP, none of the other biomarkers was a statistically significant predictor of cartilage loss. For a 1-unit increase in COMP, the odds of cartilage loss increased 6.09 times (95% confidence interval [CI] 1.34 to 27.67). After the analysis of COMP was adjusted for age, gender, and BMI, the risk for cartilage loss was 6.35 (95% CI 1.36 to 29.65). Among subjects with symptomatic knee OA, a single measurement of increased COMP predicted subsequent cartilage loss on MRI. The other biochemical markers of cartilage synthesis and degradation do not facilitate prediction of cartilage loss. With the exception of COMP, if changes in cartilage turnover in patients with symptomatic knee OA are associated with cartilage loss, they do not appear to affect systemic biomarker levels."
DAN LI,First Sagittarius A* Event Horizon Telescope results. VI. Testing the black hole metric,"Astrophysical black holes are expected to be described by the Kerr metric. This is the only stationary, vacuum, axisymmetric metric, without electromagnetic charge, that satisfies Einstein’s equations and does not have pathologies outside of the event horizon. We present new constraints on potential deviations from the Kerr prediction based on 2017 EHT observations of Sagittarius A* (Sgr A*). We calibrate the relationship between the geometrically defined black hole shadow and the observed size of the ring-like images using a library that includes both Kerr and non-Kerr simulations. We use the exquisite prior constraints on the mass-to-distance ratio for Sgr A* to show that the observed image size is within ∼10% of the Kerr predictions. We use these bounds to constrain metrics that are parametrically different from Kerr, as well as the charges of several known spacetimes. To consider alternatives to the presence of an event horizon, we explore the possibility that Sgr A* is a compact object with a surface that either absorbs and thermally reemits incident radiation or partially reflects it. Using the observed image size and the broadband spectrum of Sgr A*, we conclude that a thermal surface can be ruled out and a fully reflective one is unlikely. We compare our results to the broader landscape of gravitational tests. Together with the bounds found for stellar-mass black holes and the M87 black hole, our observations provide further support that the external spacetimes of all black holes are described by the Kerr metric, independent of their mass."
DAN LI,Polarimetric properties of Event Horizon Telescope targets from ALMA,"We present the results from a full polarization study carried out with the Atacama Large Millimeter/submillimeter Array (ALMA) during the first Very Long Baseline Interferometry (VLBI) campaign, which was conducted in 2017 April in the λ3 mm and λ1.3 mm bands, in concert with the Global mm-VLBI Array (GMVA) and the Event Horizon Telescope (EHT), respectively. We determine the polarization and Faraday properties of all VLBI targets, including Sgr A*, M87, and a dozen radio-loud active galactic nuclei (AGNs), in the two bands at several epochs in a time window of 10 days. We detect high linear polarization fractions (2%–15%) and large rotation measures (RM &gt; 103.3–105.5 rad m−2), confirming the trends of previous AGN studies at millimeter wavelengths. We find that blazars are more strongly polarized than other AGNs in the sample, while exhibiting (on average) order-of-magnitude lower RM values, consistent with the AGN viewing angle unification scheme. For Sgr A* we report a mean RM of (−4.2 ± 0.3) × 105 rad m−2 at 1.3 mm, consistent with measurements over the past decade and, for the first time, an RM of (–2.1 ± 0.1) × 105 rad m−2 at 3 mm, suggesting that about half of the Faraday rotation at 1.3 mm may occur between the 3 mm photosphere and the 1.3 mm source. We also report the first unambiguous measurement of RM toward the M87 nucleus at millimeter wavelengths, which undergoes significant changes in magnitude and sign reversals on a one year timescale, spanning the range from −1.2 to 0.3 × 105 rad m−2 at 3 mm and −4.1 to 1.5 × 105 rad m−2 at 1.3 mm. Given this time variability, we argue that, unlike the case of Sgr A*, the RM in M87 does not provide an accurate estimate of the mass accretion rate onto the black hole. We put forward a two-component model, comprised of a variable compact region and a static extended region, that can simultaneously explain the polarimetric properties observed by both the EHT (on horizon scales) and ALMA (which observes the combined emission from both components). These measurements provide critical constraints for the calibration, analysis, and interpretation of simultaneously obtained VLBI data with the EHT and GMVA."
DAN LI,"Ozone and nitrogen dioxide pollution in a coastal urban environment: the role of sea breezes, and implications of their representation for remote sensing of local air quality","We present an analysis of sea breeze conditions for the Boston region and examine their impact on the concentration of local air pollutants over the past decade. Sea breezes occur about one-third of the days during the summer and play an important role in the spatial distribution and temporal evolution of NO2 and O3 across the urban area. Mornings preceding a sea breeze are characterized by low horizontal wind speeds, low background O3, and an accumulation of local primary emissions. Air pollution is recirculated inland during sea breezes, frequently coinciding with the highest O3 measured at the urban center. We use ""Ox"" (= NO2 + O3) to account for temporary O3 suppression by NO and find large horizontal gradients (differences in Ox greater than 30 ppb across less than 15 km), which are not observed on otherwise westerly or easterly prevailing days. This implies a challenge in surface monitoring networks to adequately represent the spatial variability of secondary air pollution in coastal urban areas. We investigate satellite-based climatologies of tropospheric NO2, and find evidence of selection biases due to cloud conditions, but show that sea breeze days are well observed due to the fair weather conditions generally associated with these events. The fine scale of the sea breeze in Boston is not reliably represented by meteorological reanalyses products commonly used in chemical transport models required to provide inputs for the satellite-based retrievals. This implies a higher systematic error in the operational retrievals on sea breeze days compared to other days."
DAN LI,"First Sagittarius A* Event Horizon Telescope results. IV. Variability, morphology, and black hole mass","In this paper we quantify the temporal variability and image morphology of the horizon-scale emission from Sgr A*, as observed by the EHT in 2017 April at a wavelength of 1.3 mm. We find that the Sgr A* data exhibit variability that exceeds what can be explained by the uncertainties in the data or by the effects of interstellar scattering. The magnitude of this variability can be a substantial fraction of the correlated flux density, reaching ∼100% on some baselines. Through an exploration of simple geometric source models, we demonstrate that ring-like morphologies provide better fits to the Sgr A* data than do other morphologies with comparable complexity. We develop two strategies for fitting static geometric ring models to the time-variable Sgr A* data; one strategy fits models to short segments of data over which the source is static and averages these independent fits, while the other fits models to the full data set using a parametric model for the structural variability power spectrum around the average source structure. Both geometric modeling and image-domain feature extraction techniques determine the ring diameter to be 51.8 ± 2.3 μas (68% credible intervals), with the ring thickness constrained to have an FWHM between ∼30% and 50% of the ring diameter. To bring the diameter measurements to a common physical scale, we calibrate them using synthetic data generated from GRMHD simulations. This calibration constrains the angular size of the gravitational radius to be 4.8_-0.7^+1.4 μas, which we combine with an independent distance measurement from maser parallaxes to determine the mass of Sgr A* to be 4.0_-0.6^+10^6 M⊙."
DAN LI,"First Sagittarius A* Event Horizon Telescope results. II. EHT and multiwavelength observations, data processing, and calibration","We present Event Horizon Telescope (EHT) 1.3 mm measurements of the radio source located at the position of the supermassive black hole Sagittarius A* (Sgr A*), collected during the 2017 April 5–11 campaign. The observations were carried out with eight facilities at six locations across the globe. Novel calibration methods are employed to account for Sgr A*'s flux variability. The majority of the 1.3 mm emission arises from horizon scales, where intrinsic structural source variability is detected on timescales of minutes to hours. The effects of interstellar scattering on the image and its variability are found to be subdominant to intrinsic source structure. The calibrated visibility amplitudes, particularly the locations of the visibility minima, are broadly consistent with a blurred ring with a diameter of ∼50 μas, as determined in later works in this series. Contemporaneous multiwavelength monitoring of Sgr A* was performed at 22, 43, and 86 GHz and at near-infrared and X-ray wavelengths. Several X-ray flares from Sgr A* are detected by Chandra, one at low significance jointly with Swift on 2017 April 7 and the other at higher significance jointly with NuSTAR on 2017 April 11. The brighter April 11 flare is not observed simultaneously by the EHT but is followed by a significant increase in millimeter flux variability immediately after the X-ray outburst, indicating a likely connection in the emission physics near the event horizon. We compare Sgr A*’s broadband flux during the EHT campaign to its historical spectral energy distribution and find that both the quiescent emission and flare emission are consistent with its long-term behavior."
DAN LI,Broadband multi-wavelength properties of M87 during the 2017 Event Horizon Telescope campaign,"In 2017, the Event Horizon Telescope (EHT) Collaboration succeeded in capturing the first direct image of the center of the M87 galaxy. The asymmetric ring morphology and size are consistent with theoretical expectations for a weakly accreting supermassive black hole of mass ∼6.5 × 109 M ⊙. The EHTC also partnered with several international facilities in space and on the ground, to arrange an extensive, quasi-simultaneous multi-wavelength campaign. This Letter presents the results and analysis of this campaign, as well as the multi-wavelength data as a legacy data repository. We captured M87 in a historically low state, and the core flux dominates over HST-1 at high energies, making it possible to combine core flux constraints with the more spatially precise very long baseline interferometry data. We present the most complete simultaneous multi-wavelength spectrum of the active nucleus to date, and discuss the complexity and caveats of combining data from different spatial scales into one broadband spectrum. We apply two heuristic, isotropic leptonic single-zone models to provide insight into the basic source properties, but conclude that a structured jet is necessary to explain M87’s spectrum. We can exclude that the simultaneous γ-ray emission is produced via inverse Compton emission in the same region producing the EHT mm-band emission, and further conclude that the γ-rays can only be produced in the inner jets (inward of HST-1) if there are strongly particle-dominated regions. Direct synchrotron emission from accelerated protons and secondaries cannot yet be excluded."
DAN LI,Event Horizon Telescope imaging of the archetypal blazar 3C 279 at an extreme 20 microarcsecond resolution,"3C 279 is an archetypal blazar with a prominent radio jet that show broadband flux density variability across the entire electromagnetic spectrum. We use an ultra-high angular resolution technique – global Very Long Baseline Interferometry (VLBI) at 1.3 mm (230 GHz) – to resolve the innermost jet of 3C 279 in order to study its fine-scale morphology close to the jet base where highly variable γ-ray emission is thought to originate, according to various models. The source was observed during four days in April 2017 with the Event Horizon Telescope at 230 GHz, including the phased Atacama Large Millimeter/submillimeter Array (ALMA), at an angular resolution of ∼20 μas (at a redshift of z = 0.536 this corresponds to ∼0.13 pc  ∼ 1700 Schwarzschild radii with a black hole mass M<jats:sub>BH</jats:sub> = 8 × 10^8 M_⊙). Imaging and model-fitting techniques were applied to the data to parameterize the fine-scale source structure and its variation. We find a multicomponent inner jet morphology with the northernmost component elongated perpendicular to the direction of the jet, as imaged at longer wavelengths. The elongated nuclear structure is consistent on all four observing days and across different imaging methods and model-fitting techniques, and therefore appears robust. Owing to its compactness and brightness, we associate the northern nuclear structure as the VLBI “core”. This morphology can be interpreted as either a broad resolved jet base or a spatially bent jet. We also find significant day-to-day variations in the closure phases, which appear most pronounced on the triangles with the longest baselines. Our analysis shows that this variation is related to a systematic change of the source structure. Two inner jet components move non-radially at apparent speeds of ∼15 c and ∼20 c (∼1.3 and ∼1.7 μas day^−1, respectively), which more strongly supports the scenario of traveling shocks or instabilities in a bent, possibly rotating jet. The observed apparent speeds are also coincident with the 3C 279 large-scale jet kinematics observed at longer (cm) wavelengths, suggesting no significant jet acceleration between the 1.3 mm core and the outer jet. The intrinsic brightness temperature of the jet components are ≲10^10 K, a magnitude or more lower than typical values seen at ≥7 mm wavelengths. The low brightness temperature and morphological complexity suggest that the core region of 3C 279 becomes optically thin at short (mm) wavelengths."
DAN LI,First M87 Event Horizon Telescope results. II. Array and instrumentation,"The Event Horizon Telescope (EHT) is a very long baseline interferometry (VLBI) array that comprises millimeter- and submillimeter-wavelength telescopes separated by distances comparable to the diameter of the Earth. At a nominal operating wavelength of ~1.3 mm, EHT angular resolution (λ/D) is ~25 μas, which is sufficient to resolve nearby supermassive black hole candidates on spatial and temporal scales that correspond to their event horizons. With this capability, the EHT scientific goals are to probe general relativistic effects in the strong-field regime and to study accretion and relativistic jet formation near the black hole boundary. In this Letter we describe the system design of the EHT, detail the technology and instrumentation that enable observations, and provide measures of its performance. Meeting the EHT science objectives has required several key developments that have facilitated the robust extension of the VLBI technique to EHT observing wavelengths and the production of instrumentation that can be deployed on a heterogeneous array of existing telescopes and facilities. To meet sensitivity requirements, high-bandwidth digital systems were developed that process data at rates of 64 gigabit s−1, exceeding those of currently operating cm-wavelength VLBI arrays by more than an order of magnitude. Associated improvements include the development of phasing systems at array facilities, new receiver installation at several sites, and the deployment of hydrogen maser frequency standards to ensure coherent data capture across the array. These efforts led to the coordination and execution of the first Global EHT observations in 2017 April, and to event-horizon-scale imaging of the supermassive black hole candidate in M87."
DAN LI,First M87 Event Horizon Telescope results. I. The shadow of the supermassive black hole,"When surrounded by a transparent emission region, black holes are expected to reveal a dark shadow caused by gravitational light bending and photon capture at the event horizon. To image and study this phenomenon, we have assembled the Event Horizon Telescope, a global very long baseline interferometry array observing at a wavelength of 1.3 mm. This allows us to reconstruct event-horizon-scale images of the supermassive black hole candidate in the center of the giant elliptical galaxy M87. We have resolved the central compact radio source as an asymmetric bright emission ring with a diameter of 42 ± 3 μas, which is circular and encompasses a central depression in brightness with a flux ratio gsim10:1. The emission ring is recovered using different calibration and imaging schemes, with its diameter and width remaining stable over four different observations carried out in different days. Overall, the observed image is consistent with expectations for the shadow of a Kerr black hole as predicted by general relativity. The asymmetry in brightness in the ring can be explained in terms of relativistic beaming of the emission from a plasma rotating close to the speed of light around a black hole. We compare our images to an extensive library of ray-traced general-relativistic magnetohydrodynamic simulations of black holes and derive a central mass of M = (6.5 ± 0.7) × 10^9 M ⊙. Our radio-wave observations thus provide powerful evidence for the presence of supermassive black holes in centers of galaxies and as the central engines of active galactic nuclei. They also present a new tool to explore gravity in its most extreme limit and on a mass scale that was so far not accessible."
DAN LI,First Sagittarius A* Event Horizon Telescope results. III. Imaging of the Galactic center supermassive black hole,"We present the first event-horizon-scale images and spatiotemporal analysis of Sgr A* taken with the Event Horizon Telescope in 2017 April at a wavelength of 1.3 mm. Imaging of Sgr A* has been conducted through surveys over a wide range of imaging assumptions using the classical CLEAN algorithm, regularized maximum likelihood methods, and a Bayesian posterior sampling method. Different prescriptions have been used to account for scattering effects by the interstellar medium toward the Galactic center. Mitigation of the rapid intraday variability that characterizes Sgr A* has been carried out through the addition of a “variability noise budget” in the observed visibilities, facilitating the reconstruction of static full-track images. Our static reconstructions of Sgr A* can be clustered into four representative morphologies that correspond to ring images with three different azimuthal brightness distributions and a small cluster that contains diverse nonring morphologies. Based on our extensive analysis of the effects of sparse (u, v)-coverage, source variability, and interstellar scattering, as well as studies of simulated visibility data, we conclude that the Event Horizon Telescope Sgr A* data show compelling evidence for an image that is dominated by a bright ring of emission with a ring diameter of ∼50 μas, consistent with the expected “shadow” of a 4 × 106 M⊙ black hole in the Galactic center located at a distance of 8 kpc."
DAN LI,Characterizing and mitigating intraday variability: reconstructing source structure in accreting black holes with mm-VLBI,"The extraordinary physical resolution afforded by the Event Horizon Telescope has opened a window onto the astrophysical phenomena unfolding on horizon scales in two known black holes, M87* and Sgr A*. However, with this leap in resolution has come a new set of practical complications. Sgr A* exhibits intraday variability that violates the assumptions underlying Earth aperture synthesis, limiting traditional image reconstruction methods to short timescales and data sets with very sparse (u, v) coverage. We present a new set of tools to detect and mitigate this variability. We develop a data-driven, model-agnostic procedure to detect and characterize the spatial structure of intraday variability. This method is calibrated against a large set of mock data sets, producing an empirical estimator of the spatial power spectrum of the brightness fluctuations. We present a novel Bayesian noise modeling algorithm that simultaneously reconstructs an average image and statistical measure of the fluctuations about it using a parameterized form for the excess variance in the complex visibilities not otherwise explained by the statistical errors. These methods are validated using a variety of simulated data, including general relativistic magnetohydrodynamic simulations appropriate for Sgr A* and M87*. We find that the reconstructed source structure and variability are robust to changes in the underlying image model. We apply these methods to the 2017 EHT observations of M87*, finding evidence for variability across the EHT observing campaign. The variability mitigation strategies presented are widely applicable to very long baseline interferometry observations of variable sources generally, for which they provide a data-informed averaging procedure and natural characterization of inter-epoch image consistency."
DAN LI,Taking the pulse of Earth's tropical forests using networks of highly distributed plots,"Tropical forests are the most diverse and productive ecosystems on Earth. While better understanding of these forests is critical for our collective future, until quite recently efforts to measure and monitor them have been largely disconnected. Networking is essential to discover the answers to questions that transcend borders and the horizons of funding agencies. Here we show how a global community is responding to the challenges of tropical ecosystem research with diverse teams measuring forests tree-by-tree in thousands of long-term plots. We review the major scientific discoveries of this work and show how this process is changing tropical forest science. Our core approach involves linking long-term grassroots initiatives with standardized protocols and data management to generate robust scaled-up results. By connecting tropical researchers and elevating their status, our Social Research Network model recognises the key role of the data originator in scientific discovery. Conceived in 1999 with RAINFOR (South America), our permanent plot networks have been adapted to Africa (AfriTRON) and Southeast Asia (T-FORCES) and widely emulated worldwide. Now these multiple initiatives are integrated via ForestPlots.net cyber-infrastructure, linking colleagues from 54 countries across 24 plot networks. Collectively these are transforming understanding of tropical forests and their biospheric role. Together we have discovered how, where and why forest carbon and biodiversity are responding to climate change, and how they feedback on it. This long-term pan-tropical collaboration has revealed a large long-term carbon sink and its trends, as well as making clear which drivers are most important, which forest processes are affected, where they are changing, what the lags are, and the likely future responses of tropical forests as the climate continues to change. By leveraging a remarkably old technology, plot networks are sparking a very modern revolution in tropical forest science. In the future, humanity can benefit greatly by nurturing the grassroots communities now collectively capable of generating unique, long-term understanding of Earth's most precious forests."
DAN LI,The polarized image of a synchrotron-emitting ring of gas orbiting a black hole,"Synchrotron radiation from hot gas near a black hole results in a polarized image. The image polarization is determined by effects including the orientation of the magnetic field in the emitting region, relativistic motion of the gas, strong gravitational lensing by the black hole, and parallel transport in the curved spacetime. We explore these effects using a simple model of an axisymmetric, equatorial accretion disk around a Schwarzschild black hole. By using an approximate expression for the null geodesics derived by Beloborodov and conservation of the Walker–Penrose constant, we provide analytic estimates for the image polarization. We test this model using currently favored general relativistic magnetohydrodynamic simulations of M87*, using ring parameters given by the simulations. For a subset of these with modest Faraday effects, we show that the ring model broadly reproduces the polarimetric image morphology. Our model also predicts the polarization evolution for compact flaring regions, such as those observed from Sgr A* with GRAVITY. With suitably chosen parameters, our simple model can reproduce the EVPA pattern and relative polarized intensity in Event Horizon Telescope images of M87*. Under the physically motivated assumption that the magnetic field trails the fluid velocity, this comparison is consistent with the clockwise rotation inferred from total intensity images."
DAN LI,First Sagittarius A* Event Horizon Telescope results. I. The shadow of the supermassive black hole in the center of the Milky Way,"We present the first Event Horizon Telescope (EHT) observations of Sagittarius A* (Sgr A*), the Galactic center source associated with a supermassive black hole. These observations were conducted in 2017 using a global interferometric array of eight telescopes operating at a wavelength of λ = 1.3 mm. The EHT data resolve a compact emission region with intrahour variability. A variety of imaging and modeling analyses all support an image that is dominated by a bright, thick ring with a diameter of 51.8 ± 2.3 μas (68% credible interval). The ring has modest azimuthal brightness asymmetry and a comparatively dim interior. Using a large suite of numerical simulations, we demonstrate that the EHT images of Sgr A* are consistent with the expected appearance of a Kerr black hole with mass ∼4 × 106 M ⊙, which is inferred to exist at this location based on previous infrared observations of individual stellar orbits, as well as maser proper-motion studies. Our model comparisons disfavor scenarios where the black hole is viewed at high inclination (i &gt; 50°), as well as nonspinning black holes and those with retrograde accretion disks. Our results provide direct evidence for the presence of a supermassive black hole at the center of the Milky Way, and for the first time we connect the predictions from dynamical measurements of stellar orbits on scales of 103–105 gravitational radii to event-horizon-scale images and variability. Furthermore, a comparison with the EHT results for the supermassive black hole M87* shows consistency with the predictions of general relativity spanning over three orders of magnitude in central mass."
DAN LI,The variability of the black hole image in M87 at the dynamical timescale,"The black hole images obtained with the Event Horizon Telescope (EHT) are expected to be variable at the dynamical timescale near their horizons. For the black hole at the center of the M87 galaxy, this timescale (5–61 days) is comparable to the 6 day extent of the 2017 EHT observations. Closure phases along baseline triangles are robust interferometric observables that are sensitive to the expected structural changes of the images but are free of station-based atmospheric and instrumental errors. We explored the day-to-day variability in closure-phase measurements on all six linearly independent nontrivial baseline triangles that can be formed from the 2017 observations. We showed that three triangles exhibit very low day-to-day variability, with a dispersion of ∼3°–5°. The only triangles that exhibit substantially higher variability (∼90°–180°) are the ones with baselines that cross the visibility amplitude minima on the u–v plane, as expected from theoretical modeling. We used two sets of general relativistic magnetohydrodynamic simulations to explore the dependence of the predicted variability on various black hole and accretion-flow parameters. We found that changing the magnetic field configuration, electron temperature model, or black hole spin has a marginal effect on the model consistency with the observed level of variability. On the other hand, the most discriminating image characteristic of models is the fractional width of the bright ring of emission. Models that best reproduce the observed small level of variability are characterized by thin ring-like images with structures dominated by gravitational lensing effects and thus least affected by turbulence in the accreting plasmas."
DAN LI,Constraints on black-hole charges with the 2017 EHT observations of M87*,
DAN LI,SYMBA: an end-to-end VLBI synthetic data generation pipeline,"CONTEXT: Realistic synthetic observations of theoretical source models are essential for our understanding of real observational data. In using synthetic data, one can verify the extent to which source parameters can be recovered and evaluate how various data corruption effects can be calibrated. These studies are the most important when proposing observations of new sources, in the characterization of the capabilities of new or upgraded instruments, and when verifying model-based theoretical predictions in a direct comparison with observational data. AIMS: We present the SYnthetic Measurement creator for long Baseline Arrays (SYMBA), a novel synthetic data generation pipeline for Very Long Baseline Interferometry (VLBI) observations. SYMBA takes into account several realistic atmospheric, instrumental, and calibration effects. METHODS: We used SYMBA to create synthetic observations for the Event Horizon Telescope (EHT), a millimetre VLBI array, which has recently captured the first image of a black hole shadow. After testing SYMBA with simple source and corruption models, we study the importance of including all corruption and calibration effects, compared to the addition of thermal noise only. Using synthetic data based on two example general relativistic magnetohydrodynamics (GRMHD) model images of M 87, we performed case studies to assess the image quality that can be obtained with the current and future EHT array for different weather conditions. RESULTS: Our synthetic observations show that the effects of atmospheric and instrumental corruptions on the measured visibilities are significant. Despite these effects, we demonstrate how the overall structure of our GRMHD source models can be recovered robustly with the EHT2017 array after performing calibration steps, which include fringe fitting, a priori amplitude and network calibration, and self-calibration. With the planned addition of new stations to the EHT array in the coming years, images could be reconstructed with higher angular resolution and dynamic range. In our case study, these improvements allowed for a distinction between a thermal and a non-thermal GRMHD model based on salient features in reconstructed images."
DAN LI,The long-baseline neutrino experiment: exploring fundamental symmetries of the universe,"The preponderance of matter over antimatter in the early Universe, the dynamics of the supernova bursts that produced the heavy elements necessary for life and whether protons eventually decay --- these mysteries at the forefront of particle physics and astrophysics are key to understanding the early evolution of our Universe, its current state and its eventual fate. The Long-Baseline Neutrino Experiment (LBNE) represents an extensively developed plan for a world-class experiment dedicated to addressing these questions. LBNE is conceived around three central components: (1) a new, high-intensity neutrino source generated from a megawatt-class proton accelerator at Fermi National Accelerator Laboratory, (2) a near neutrino detector just downstream of the source, and (3) a massive liquid argon time-projection chamber deployed as a far detector deep underground at the Sanford Underground Research Facility. This facility, located at the site of the former Homestake Mine in Lead, South Dakota, is approximately 1,300 km from the neutrino source at Fermilab -- a distance (baseline) that delivers optimal sensitivity to neutrino charge-parity symmetry violation and mass ordering effects. This ambitious yet cost-effective design incorporates scalability and flexibility and can accommodate a variety of upgrades and contributions. With its exceptional combination of experimental configuration, technical capabilities, and potential for transformative discoveries, LBNE promises to be a vital facility for the field of particle physics worldwide, providing physicists from around the globe with opportunities to collaborate in a twenty to thirty year program of exciting science. In this document we provide a comprehensive overview of LBNE's scientific objectives, its place in the landscape of neutrino physics worldwide, the technologies it will incorporate and the capabilities it will possess."
PANKAJ TANDON,The identity of Prakāśāditya,"This presentation summarized recent research that has solved a long-standing puzzle in ancient Indian history: the identity of the king who identifies himself on the reverse of his gold coins with the epithet prakāśāditya. Most authors have assumed Prakāśāditya to be a Gupta king. In contrast, Göbl 1990 suggested on stylistic grounds that Prakāśāditya was not a Gupta at all, but a Hun. However, for reasons that are not at all clear, most authors have continued to treat Prakāśāditya as a Gupta king. In any case, Göbl was unable to establish Prakāśāditya’s identity more specifically, speculating without any real evidence that he might have been the Hun king Toramāṇa. Thus the issue of his identity was still an open question. Part of the reason for the uncertainty around the identity of Prakāśāditya is that the obverse legend on his coins had not yet been read. Gupta coins generally carry an epithet or biruda of the king on the reverse, but his name is typically revealed in the obverse legend. The parts of the legend so far read on the obverse of Prakāśāditya’s coins had not contained any parts of his real name. In Tandon 2015, in presenting the first near-complete reading of the obverse legend of the coin, I established that Prakāśāditya was in fact Toramāṇa, as Göbl had speculated."
PANKAJ TANDON,New evidence on the date of Candragupta III,
PANKAJ TANDON,On the unique dated tetradrachm of Antiochus I,
PANKAJ TANDON,Coins of the Eastern Gangas ruler Anantavarman Chodaganga,"Attributing the coins of the Eastern Gangas is a difficult task because the coins do not name the ruler, but only are dated in what are thought to be regnal years. Many authors in the past have tended to attribute the coins to the most prominent king of the dynasty, Anantavarman Chodaganga (1078-1147) (hereafter AC), but without any real justification. 2 In a recent paper, I proposed a method of attribution, based on the regnal lengths of the different kings, which would assign a sizable group of the known coins to the last four kings of the dynasty. 3 Coins attributable on a sound basis to AC remained unknown."
PANKAJ TANDON,The identity of Prakāśāditya,"One of the enduring open questions in ancient Indian history is the identity of the king who identifies himself on the reverse of his gold coins as prakāśāditya. Most authors have assumed that he was a Gupta king. This paper reviews the various proposals on the identity of Prakāśāditya, arguing why we can be quite sure, as suggested by Robert Göbl, that he was in fact a Hun king and not a Gupta. Then, by presenting a near-complete reading of the obverse legend, it is shown that it is virtually certain that he was in fact the Hun king Toramāṇa, as Göbl had speculated. Implications of this finding are then considered."
PANKAJ TANDON,"Treasure, trade and tradition: post-Kidarite coins of the Gangetic Plains and the Punjab Foothills, 590–820 ce. By John S. Deyell. pp. 228. New Delhi, Manohar Publishers, 2017.",
PANKAJ TANDON,Two newly-identified Hun kings and a hoard from Pushkalavati,
PANKAJ TANDON,Bilingual coins of Amir Sulayman: a Samid ruler of medieval Multan,
PANKAJ TANDON,Tentative reading of an unread “Pāratarāja” coin,
PANKAJ TANDON,Are these the earliest Greek coins of Bactria?,"Numismatists have long been interested in the question of whether any Greek coins had been issued in Bactria prior to the arrival there in 329 BCE of Alexander the Great. Various scholars have attempted to assign coins to this period, including the Bactrian imitations of Athenian owls, the so-called “Eagle” series, and the coins of Sophytes. However, modern scholarship generally rejects these attempts, and the prevailing view is that all of these coins were issued in either the late 4th century or the 3rd century, after the time of Alexander. Recently, however, a number of small obol sized silver coins have been emerging from the area of Balkh that call for a re-opening of this question. This paper argues that there is at least a possibility, and maybe even a probability, that these coins were issued in the late 5th and 4th centuries, and that the likely issuers were the Branchidae, the priestly clan who administered the temple of Apollo in Didyma. Thus the coins not only suggest an answer to the question first posed here, but also may provide physical evidence of the presence in Bactria of the Branchidae."
PANKAJ TANDON,Monetary aspects of Bahmani copper coinage in light of the Akola hoard,
PANKAJ TANDON,The Bahmani “currency reform” of the early fifteenth century in light of the Akola hoard,
PANKAJ TANDON,A new coin of Amyntas and some Apollophanes forgeries,
PANKAJ TANDON,Attribution of the nameless coins of the archer type,
PANKAJ TANDON,"Book review: Kushan, Kushano-Sasanian, and Kidarite coins: a catalogue of coins from the American Numismatic Society by David Jongeward and Joe Cribb with Peter Donovan",
PANKAJ TANDON,The evidence of metal content for the attribution of the coins in the name of Chandra(gupta),Two-day international conference on oriental numismatics in celebration of the 50th anniversary of the Society
PANKAJ TANDON,Metal analysis of Gupta gold coins,
PANKAJ TANDON,The numismatic trail of the Huns in south Asia,
PANKAJ TANDON,Reattributing some (more) coins of Candragupta II to Candragupta III,
PANKAJ TANDON,The Paratarajas,
PANKAJ TANDON,Some new coin types from Surasena,
PANKAJ TANDON,New evidence on Parataraja chronology,This paper introduces two new coins of the Paratarajas that help to solidify the relative chronology of that dynasty that had been proposed in earlier work. They demonstrate that the Kharoshthi series followed the Brahmi series and that Kozana was followed not by his son Koziya but by Bhimarjuna.
PANKAJ TANDON,The evidence of gold content for the attribution of the coins in the name of Candragupta,
PANKAJ TANDON,Book review: Kushan Mystique by David Jongeward,
PANKAJ TANDON,New evidence on Parataraja chronology,This paper introduces two new coins of the Paratarajas that help to solidify the relative chronology of that dynasty that had been proposed in earlier work. They demonstrate that the Kharoshthi series followed the Brahmi series and that Kozana was followed not by his son Koziya but by Bhimarjuna.
JAMES R PERKINS,The long-baseline neutrino experiment: exploring fundamental symmetries of the universe,"The preponderance of matter over antimatter in the early Universe, the dynamics of the supernova bursts that produced the heavy elements necessary for life and whether protons eventually decay --- these mysteries at the forefront of particle physics and astrophysics are key to understanding the early evolution of our Universe, its current state and its eventual fate. The Long-Baseline Neutrino Experiment (LBNE) represents an extensively developed plan for a world-class experiment dedicated to addressing these questions. LBNE is conceived around three central components: (1) a new, high-intensity neutrino source generated from a megawatt-class proton accelerator at Fermi National Accelerator Laboratory, (2) a near neutrino detector just downstream of the source, and (3) a massive liquid argon time-projection chamber deployed as a far detector deep underground at the Sanford Underground Research Facility. This facility, located at the site of the former Homestake Mine in Lead, South Dakota, is approximately 1,300 km from the neutrino source at Fermilab -- a distance (baseline) that delivers optimal sensitivity to neutrino charge-parity symmetry violation and mass ordering effects. This ambitious yet cost-effective design incorporates scalability and flexibility and can accommodate a variety of upgrades and contributions. With its exceptional combination of experimental configuration, technical capabilities, and potential for transformative discoveries, LBNE promises to be a vital facility for the field of particle physics worldwide, providing physicists from around the globe with opportunities to collaborate in a twenty to thirty year program of exciting science. In this document we provide a comprehensive overview of LBNE's scientific objectives, its place in the landscape of neutrino physics worldwide, the technologies it will incorporate and the capabilities it will possess."
ERIC J BRAUDE,Incremental UML for Agile development: embedding UML class models in source code,"Agile methods favor ""working software over comprehensive documentation."" The latter presumably includes Unified Modeling Language. UML is expensive to maintain, and it lacks good drill-down mechanisms, however, UML affords very useful visualizations. This paper describes a discipline for incrementally embedding graphical UML class models within source code for continuous agile development. The approach consists of identifying a main function, and having it drive the piece-wise creation of UML by explicitly including in its postconditions the placement of functions corresponding directly to requirements. The approach thus introduces higher order pre-and postconditions. A specific process is provided for carrying this out, together with examples. It enables UML class model visualization in rapid development, especially when tool-supported."
GEOFFREY POISTER,Exploring the effect of the Looking China Student Film Project on its participants,"I wrote and presented a 22-page research paper at the annual symposium of the Academy for International Communication of Chinese Culture, November 26, 2016. The paper, titled ""Exploring the Effect of the Looking China Youth Film Project on its Participants"" analyzed data I collected from past participants in the Looking China Program and drew conclusions concerning the formation of a cultural image, and how the process of making a documentary film enhances certain observational skills. The paper was subsequently published in the academic journal, ""International Communication of Chinese Culture,"" Beijing Normal University Press, China."
JOSEPH SCOTT BUNCH,Voltage gated inter-cation selective ion channels from graphene nanopores,"With the ability to selectively control ionic flux, biological protein ion channels perform a fundamental role in many physiological processes. For practical applications that require the functionality of a biological ion channel, graphene provides a promising solid-state alternative, due to its atomic thinness and mechanical strength. Here, we demonstrate that nanopores introduced into graphene membranes, as large as 50 nm in diameter, exhibit inter-cation selectivity with a ∼20× preference for K+ over divalent cations and can be modulated by an applied gate voltage. Liquid atomic force microscopy of the graphene devices reveals surface nanobubbles near the pore to be responsible for the observed selective behavior. Molecular dynamics simulations indicate that translocation of ions across the pore likely occurs via a thin water layer at the edge of the pore and the nanobubble. Our results demonstrate a significant improvement in the inter-cation selectivity displayed by a solid-state nanopore device and by utilizing the pores in a de-wetted state, offers an approach to fabricate selective graphene membranes that does not rely on the fabrication of sub-nm pores."
ANTHONY JACK,Genetic Analysis Workshop 16: Strategies for Genome-Wide Association Study Analyses,
ANTHONY JACK,The graduate school pipeline and first-generation/working-class inequalities,"Sociological research has long been interested in inequalities generated by and within educational institutions. Although relatively rich as a literature, less analytic focus has centered on educational mobility and inequality experiences within graduate training specifically. In this article, we draw on a combination of survey and open-ended qualitative data from approximately 450 graduate students in the discipline of sociology to analyze graduate school pipeline divergences for first-generation and working-class students and the implications for inequalities in tangible resources, advising and support, and a sense of isolation. Our results point to an important connection between private undergraduate institutional enrollment and higher-status graduate program attendance—a pattern that undercuts social-class mobility in graduate training and creates notable precarities in debt, advising, and sense of belonging for first-generation and working-class graduate students. We conclude by discussing the unequal pathways revealed and their implications for merit and mobility, graduate training, and opportunity within our and other disciplines."
ANTHONY JACK,"(No) harm in asking: class, acquired cultural capital, and academic engagement at an elite university","How do undergraduates engage authority figures in college? Existing explanations predict class-based engagement strategies. Using in-depth interviews with 89 undergraduates at an elite university, I show how undergraduates with disparate precollege experiences differ in their orientations toward and strategies for engaging authority figures in college. Middle-class undergraduates report being at ease in interacting with authority figures and are proactive in doing so. Lower-income undergraduates, however, are split. The privileged poor—lower-income undergraduates who attended boarding, day, and preparatory high schools—enter college primed to engage professors and are proactive in doing so. By contrast, the doubly disadvantaged—lower-income undergraduates who remained tied to their home communities and attended local, typically distressed high schools—are more resistant to engaging authority figures in college and tend to withdraw from them. Through documenting the heterogeneity among lower-income undergraduates, I show how static understandings of individuals’ cultural endowments derived solely from family background homogenize the experiences of lower-income undergraduates. In so doing, I shed new light on the cultural underpinnings of education processes in higher education and extend previous analyses of how informal university practices exacerbate class differences among undergraduates."
ANTHONY JACK,Belonging and boundaries at an elite university,"Scholars posit that lower-income undergraduates experience “cultural mismatch,” which undermines their sense of belonging, promotes withdrawal from campus, and limits mobility upon graduation. Drawing on in-depth interviews with 103 undergraduates at an elite university, we examine how students’ diverse trajectories to college affect how they identify as members of the community and modulate the relationship between social class and sense of belonging. While upper-income undergraduates find commonalities between themselves and college peers and integrate into the community, lower-income students offer divergent accounts. The doubly disadvantaged—lower-income undergraduates who attended local, typically distressed public high schools—felt a heightened sense of difference, drew moral boundaries, and withdrew from campus life. Alternatively, the privileged poor—lower-income undergraduates who attended boarding, day, and preparatory high schools—adopted a cosmopolitan approach focused on continued expansion of horizons and integrated into campus. Through detailing this overlooked diversity among lower-income undergraduates, our findings expand theoretical frameworks for examining sense of belonging to include boundary work that shapes students’ agendas, thereby deepening our understanding of the reproduction of inequality in college."
ANTHONY JACK,Mobility and inequality in the professoriate: how and why first-generation and working-class backgrounds matter,"Social science research has long recognized the relevance of socioeconomic background for mobility and inequality. In this article we interrogate how and why working-class and first-generation backgrounds are especially meaningful and take as our case in point the professoriate and the discipline of sociology, – i.e., a field that intellectually prioritizes attention to group inequality and that arguably offers a conservative empirical test compared to other academic fields. Our analyses, which draw on unique survey items and open-ended qualitative materials from nearly 1,000 academic sociologists, reveal significant background divergences in academic job attainment, tied partly to educational background. Moreover, and especially unique and important, findings demonstrate significant consequences across several dimensions of inequality including compensation and economic precarity, professional visibility, and isolation at departmental, college or university, and professional levels. We conclude by highlighting how our discussion and results contribute in important ways to broader sociological concerns surrounding mobility, group disadvantage, and social closure."
ANTHONY JACK,"Bostonia: 1998-1999, no. 1, 3-4",
ANTHONY JACK,The long-baseline neutrino experiment: exploring fundamental symmetries of the universe,"The preponderance of matter over antimatter in the early Universe, the dynamics of the supernova bursts that produced the heavy elements necessary for life and whether protons eventually decay --- these mysteries at the forefront of particle physics and astrophysics are key to understanding the early evolution of our Universe, its current state and its eventual fate. The Long-Baseline Neutrino Experiment (LBNE) represents an extensively developed plan for a world-class experiment dedicated to addressing these questions. LBNE is conceived around three central components: (1) a new, high-intensity neutrino source generated from a megawatt-class proton accelerator at Fermi National Accelerator Laboratory, (2) a near neutrino detector just downstream of the source, and (3) a massive liquid argon time-projection chamber deployed as a far detector deep underground at the Sanford Underground Research Facility. This facility, located at the site of the former Homestake Mine in Lead, South Dakota, is approximately 1,300 km from the neutrino source at Fermilab -- a distance (baseline) that delivers optimal sensitivity to neutrino charge-parity symmetry violation and mass ordering effects. This ambitious yet cost-effective design incorporates scalability and flexibility and can accommodate a variety of upgrades and contributions. With its exceptional combination of experimental configuration, technical capabilities, and potential for transformative discoveries, LBNE promises to be a vital facility for the field of particle physics worldwide, providing physicists from around the globe with opportunities to collaborate in a twenty to thirty year program of exciting science. In this document we provide a comprehensive overview of LBNE's scientific objectives, its place in the landscape of neutrino physics worldwide, the technologies it will incorporate and the capabilities it will possess."
C. JAMES MCKNIGHT,NRXN3 Is a Novel Locus for Waist Circumference: A Genome-Wide Association Study from the CHARGE Consortium,"Central abdominal fat is a strong risk factor for diabetes and cardiovascular disease. To identify common variants influencing central abdominal fat, we conducted a two-stage genome-wide association analysis for waist circumference (WC). In total, three loci reached genome-wide significance. In stage 1, 31,373 individuals of Caucasian descent from eight cohort studies confirmed the role of FTO and MC4R and identified one novel locus associated with WC in the neurexin 3 gene [NRXN3 (rs10146997, p = 6.4×10−7)]. The association with NRXN3 was confirmed in stage 2 by combining stage 1 results with those from 38,641 participants in the GIANT consortium (p = 0.009 in GIANT only, p = 5.3×10−8 for combined analysis, n = 70,014). Mean WC increase per copy of the G allele was 0.0498 z-score units (0.65 cm). This SNP was also associated with body mass index (BMI) [p = 7.4×10−6, 0.024 z-score units (0.10 kg/m2) per copy of the G allele] and the risk of obesity (odds ratio 1.13, 95% CI 1.07–1.19; p = 3.2×10−5 per copy of the G allele). The NRXN3 gene has been previously implicated in addiction and reward behavior, lending further evidence that common forms of obesity may be a central nervous system-mediated disorder. Our findings establish that common variants in NRXN3 are associated with WC, BMI, and obesity. Author Summary Obesity is a major health concern worldwide. In the past two years, genome-wide association studies of DNA markers known as SNPs (single nucleotide polymorphisms) have identified two novel genetic factors that may help scientists better understand why some people may be more susceptible to obesity. Similarly, this paper describes results from a large scale genome-wide association analysis for obesity susceptibility genes that includes 31,373 individuals from 8 separate studies. We uncovered a new gene influencing waist circumference, the neurexin 3 gene (NRXN3), which has been previously implicated in studies of addiction and reward behavior. These findings lend further evidence that our genes may influence our desire and consumption of food and, in turn, our susceptibility to obesity."
C. JAMES MCKNIGHT,Molecular Model of the Microvillar Cytoskeleton and Organization of the Brush Border,"BACKGROUND. Brush border microvilli are ~1-µm long finger-like projections emanating from the apical surfaces of certain, specialized absorptive epithelial cells. A highly symmetric hexagonal array of thousands of these uniformly sized structures form the brush border, which in addition to aiding in nutrient absorption also defends the large surface area against pathogens. Here, we present a molecular model of the protein cytoskeleton responsible for this dramatic cellular morphology. METHODOLOGY/PRINCIPAL FINDINGS. The model is constructed from published crystallographic and microscopic structures reported by several groups over the last 30+ years. Our efforts resulted in a single, unique, self-consistent arrangement of actin, fimbrin, villin, brush border myosin (Myo1A), calmodulin, and brush border spectrin. The central actin core bundle that supports the microvillus is nearly saturated with fimbrin and villin cross-linkers and has a density similar to that found in protein crystals. The proposed model accounts for all major proteinaceous components, reproduces the experimentally determined stoichiometry, and is consistent with the size and morphology of the biological brush border membrane. CONCLUSIONS/SIGNIFICANCE. The model presented here will serve as a structural framework to explain many of the dynamic cellular processes occurring over several time scales, such as protein diffusion, association, and turnover, lipid raft sorting, membrane deformation, cytoskeletal-membrane interactions, and even effacement of the brush border by invading pathogens. In addition, this model provides a structural basis for evaluating the equilibrium processes that result in the uniform size and structure of the highly dynamic microvilli."
CATHERINE L CALDWELL-HARRIS,Language learning following immigration: modeling choices and challenges,"No agent-based model exists of language learning following immigration to a new country. Language learning has features that make it a good fit to ABMs, such as diffusion/adoption effects: people learn language via social interaction and are influenced by other social actors about how and when to invest in learning. Language learning involves positive and negative feedback loops, such that poor progress early in learning can spiral into negativity and avoidance, while early success can accelerate learning. Most importantly, the question of why language learning is difficult for adults is controversial. Should implementers program into models the equations that match the robust age effects observed in data, or should these patterns emerge from multiple factors and actors? To address this, the large literature on foreign language acquisition was reviewed as part of the background of making modeling decisions. Decisions were sufficiently challenging that it was decided to begin with a narrative description, using the Overview, Design Concepts and Details protocol (ODD). The ODD protocol provided an organizing framework in which many details were worked out. These included identifying outcome variables (frequency of use and fluency in the two languages), basic entities (representing individuals, families, neighborhood, global environment), defining rules for initiating and continuing conversation, and rules for agents to move to new locations. Considerable narrative space was used to discuss the rationale for simplifications, as well as decisions that were left for future extensions. Given the complexity of the domain, the narrative description was a necessary foundation to smooth the way for a working simulation."
ROBERTO TRON,On the Lagrangian biduality of sparsity minimization problems,"Recent results in Compressive Sensing have shown that, under certain conditions, the solution to an underdetermined system of linear equations with sparsity-based regularization can be accurately recovered by solving convex relaxations of the original problem. In this work, we present a novel primal-dual analysis on a class of sparsity minimization problems. We show that the Lagrangian bidual (i.e., the Lagrangian dual of the Lagrangian dual) of the sparsity minimization problems can be used to derive interesting convex relaxations: the bidual of the ℓ0-minimization problem is the ℓ1-minimization problem; and the bidual of the ℓ0,1-minimization problem for enforcing group sparsity on structured data is the ℓ1,∞-minimization problem. The analysis provides a means to compute per-instance non-trivial lower bounds on the (group) sparsity of the desired solutions. In a real-world application, the bidual relaxation improves the performance of a sparsity-based classification framework applied to robust face recognition."
ROBERTO TRON,Riemannian consensus for manifolds with bounded curvature,"Consensus algorithms are popular distributed algorithms for computing aggregate quantities, such as averages, in ad-hoc wireless networks. However, existing algorithms mostly address the case where the measurements lie in Euclidean space. In this work we propose Riemannian consensus, a natural extension of existing averaging consensus algorithms to the case of Riemannian manifolds. Unlike previous generalizations, our algorithm is intrinsic and, in principle, can be applied to any complete Riemannian manifold. We give sufficient convergence conditions on Riemannian manifolds with bounded curvature and we analyze the differences with respect to the Euclidean case. We test the proposed algorithms on synthetic data sampled from the space of rotations, the sphere and the Grassmann manifold."
ROBERTO TRON,Masquerade attack detection through observation planning for multi-robot systems,"The increasing adoption of autonomous mobile robots comes with a rising concern over the security of these systems. In this work, we examine the dangers that an adversary could pose in a multi-agent robot system. We show that conventional multi-agent plans are vulnerable to strong attackers masquerading as a properly functioning agent. We propose a novel technique to incorporate attack detection into the multi-agent path-finding problem through the simultaneous synthesis of observation plans. We show that by specially crafting the multi-agent plan, the induced inter-agent observations can provide introspective monitoring guarantees; we achieve guarantees that any adversarial agent that plans to break the system-wide security specification must necessarily violate the induced observation plan."
ROBERTO TRON,On the convergence of gradient descent for finding the Riemannian center of mass,"We study the problem of finding the global Riemannian center of mass of a set of data points on a Riemannian manifold. Specifically, we investigate the convergence of constant step-size gradient descent algorithms for solving this problem. The challenge is that often the underlying cost function is neither globally differentiable nor convex, and despite this one would like to have guaranteed convergence to the global minimizer. After some necessary preparations we state a conjecture which we argue is the best (in a sense described) convergence condition one can hope for. The conjecture specifies conditions on the spread of the data points, step-size range, and the location of the initial condition (i.e., the region of convergence) of the algorithm. These conditions depend on the topology and the curvature of the manifold and can be conveniently described in terms of the injectivity radius and the sectional curvatures of the manifold. For manifolds of constant nonnegative curvature (e.g., the sphere and the rotation group in ℝ3) we show that the conjecture holds true (we do this by proving and using a comparison theorem which seems to be of a different nature from the standard comparison theorems in Riemannian geometry). For manifolds of arbitrary curvature we prove convergence results which are weaker than the conjectured one (but still superior over the available results). We also briefly study the effect of the configuration of the data points on the speed of convergence."
ROBERTO TRON,Joint estimation and localization in sensor networks,"This paper addresses the problem of collaborative tracking of dynamic targets in wireless sensor networks. A novel distributed linear estimator, which is a version of a distributed Kalman filter, is derived. We prove that the filter is mean square consistent in the case of static target estimation. When large sensor networks are deployed, it is common that the sensors do not have good knowledge of their locations, which affects the target estimation procedure. Unlike most existing approaches for target tracking, we investigate the performance of our filter when the sensor poses need to be estimated by an auxiliary localization procedure. The sensors are localized via a distributed Jacobi algorithm from noisy relative measurements. We prove strong convergence guarantees for the localization method and in turn for the joint localization and target estimation approach. The performance of our algorithms is demonstrated in simulation on environmental monitoring and target tracking tasks."
ROBERTO TRON,Technical report on Optimization-Based Bearing-Only Visual Homing with Applications to a 2-D Unicycle Model,"We consider the problem of bearing-based visual homing: Given a mobile robot which can measure bearing directions with respect to known landmarks, the goal is to guide the robot toward a desired ""home"" location. We propose a control law based on the gradient field of a Lyapunov function, and give sufficient conditions for global convergence. We show that the well-known Average Landmark Vector method (for which no convergence proof was known) can be obtained as a particular case of our framework. We then derive a sliding mode control law for a unicycle model which follows this gradient field. Both controllers do not depend on range information. Finally, we also show how our framework can be used to characterize the sensitivity of a home location with respect to noise in the specified bearings. This is an extended version of the conference paper [1]."
ROBERTO TRON,A factorization approach to inertial affine structure from motion,"We consider the problem of reconstructing a 3-D scene from a moving camera with high frame rate using the affine projection model. This problem is traditionally known as Affine Structure from Motion (Affine SfM), and can be solved using an elegant low-rank factorization formulation. In this paper, we assume that an accelerometer and gyro are rigidly mounted with the camera, so that synchronized linear acceleration and angular velocity measurements are available together with the image measurements. We extend the standard Affine SfM algorithm to integrate these measurements through the use of image derivatives."
ROBERTO TRON,A survey on rotation optimization in structure from motion,"We consider the problem of robust rotation optimization in Structure from Motion applications. A number of different approaches have been recently proposed, with solutions that are at times incompatible, and at times complementary. The goal of this paper is to survey and compare these ideas in a unified manner, and to benchmark their robustness against the presence of outliers. In all, we have tested more than forty variants of a these methods (including novel ones), and we find the best performing combination."
ROBERTO TRON,A distributed optimization framework for localization and formation control: applications to vision-based measurements,"Multiagent systems have been a major area of research for the last 15 years. This interest has been motivated by tasks that can be executed more rapidly in a collaborative manner or that are nearly impossible to carry out otherwise. To be effective, the agents need to have the notion of a common goal shared by the entire network (for instance, a desired formation) and individual control laws to realize the goal. The common goal is typically centralized, in the sense that it involves the state of all the agents at the same time. On the other hand, it is often desirable to have individual control laws that are distributed, in the sense that the desired action of an agent depends only on the measurements and states available at the node and at a small number of neighbors. This is an attractive quality because it implies an overall system that is modular and intrinsically more robust to communication delays and node failures."
ROBERTO TRON,The space of essential matrices as a Riemannian quotient manifold,"The essential matrix, which encodes the epipolar constraint between points in two projective views, is a cornerstone of modern computer vision. Previous works have proposed different characterizations of the space of essential matrices as a Riemannian manifold. However, they either do not consider the symmetric role played by the two views, or do not fully take into account the geometric peculiarities of the epipolar constraint. We address these limitations with a characterization as a quotient manifold which can be easily interpreted in terms of camera poses. While our main focus in on theoretical aspects, we include applications to optimization problems in computer vision."
ROBERTO TRON,"Bearing-only formation control with auxiliary distance measurements, leaders, and collision avoidance","We address the controller synthesis problem for distributed formation control. Our solution requires only relative bearing measurements (as opposed to full translations), and is based on the exact gradient of a Lyapunov function with only global minimizers (independently from the formation topology). These properties allow a simple proof of global asymptotic convergence, and extensions for including distance measurements, leaders and collision avoidance. We validate our approach through simulations and comparison with other stateof-the-art algorithms."
ROBERTO TRON,Bearing-based formation control with second-order agent dynamics,"We consider the distributed formation control problem for a network of agents using visual measurements. We propose solutions that are based on bearing (and optionally distance) measurements, and agents with double integrator dynamics. We assume that a subset of the agents can track, in addition to their neighbors, a set of static features in the environment. These features are not considered to be part of the formation, but they are used to asymptotically control the velocity of the agents. We analyze the convergence properties of the proposed protocols analytically and through simulations."
ROBERTO TRON,Non-natural metrics on the tangent bundle,"Natural metrics provide a way to induce a metric on the tangent bundle from the metric on its base manifold. The most studied type is the Sasaki metric, which applies the base metric separately to the vertical and horizontal components. We study a more general class of metrics which introduces interactions between the vertical and horizontal components, with scalar weights. Additionally, we explicitly clarify how to apply our and other induced metrics on the tangent bundle to vector fields where the vertical component is not constant along the fibers. We give application to the Special Orthogonal Group SO(3) as an example."
ROBERTO TRON,Resilience of multi-robot systems to physical masquerade attacks,"The advent of autonomous mobile multi-robot systems has driven innovation in both the industrial and defense sectors. The integration of such systems in safety-and security-critical applications has raised concern over their resilience to attack. In this work, we investigate the security problem of a stealthy adversary masquerading as a properly functioning agent. We show that conventional multi-agent pathfinding solutions are vulnerable to these physical masquerade attacks. Furthermore, we provide a constraint-based formulation of multi-agent pathfinding that yields multi-agent plans that are provably resilient to physical masquerade attacks. This formalization leverages inter-agent observations to facilitate introspective monitoring to guarantee resilience."
ROBERTO TRON,Reactive and safe co-navigation with haptic guidance,
ROBERTO TRON,Fast multi-image matching via density-based clustering,"We consider the problem of finding consistent matches across multiple images. Previous state-of-the-art solutions use constraints on cycles of matches together with convex optimization, leading to computationally intensive iterative algorithms. In this paper, we propose a clustering-based formulation. We first rigorously show its equivalence with the previous one, and then propose QuickMatch, a novel algorithm that identifies multi-image matches from a density function in feature space. We use the density to order the points in a tree, and then extract the matches by breaking this tree using feature distances and measures of distinctiveness. Our algorithm outperforms previous state-of-the-art methods (such as MatchALS) in accuracy, and it is significantly faster (up to 62 times faster on some bechmarks), and can scale to large datasets (with more than twenty thousands features)."
CATHERINE CONNELL,Contemporary life as revealed in recent Irish drama,"Contemporary Life as Revealed in Recent Irish Drama is a compilation and discussion of the various aspects of contemporary Irish life as expressed in plays by Irish dramatists, John M. Synge, Paul V. Carroll, Lennox Robinson, Sean O'Casey, and Seumas O'Brien. The work begins with a statement of the purpose of the thesis and the methods used. Chapter I covers the history of the development of the Abbey Theatre in Dublin, Ireland, with the following features discussed: The purpose of the organization shows that the Abbey Theatre was first and foremost a theatrical, not a literary movement. Many dramatists of ability, and at least one, John M. Synge, of genius, was discovered. Most of the founders were bound together by their enthusiasm. The next feature of this theatrical movement was the foreign influence, in which is revealed Antoine's revolt against the Parisian Theatre in 1887 and the London Independent Theatre in 1891. Then the national influence on this theatrical organization is presented with the following aspects: A new interest in Gaelic sprung up with the formation of a Gaelic League in 1893, followed by the formation of an Irish Literary Theatre in Dublin, in which Lady Gregory, William B. Yeats, Edward Martyn, and George Moore were particularly active. The Countess Cathleen was presented in 1894, and soon afterwards the formation of the first company of Irish actors came. This group chose Deirdre as the first play to be presented in St. Teresa's Temperance Society Hall. Next came the formation of the Irish National Theatre in 1902, of which William B. Yeats was president. The Hour-Glass and Twenty-Five were presented with success, and the Dublin Press became more friendly. This chapter ends with a presentation of the best year of this theatre group, in which John M. Synge was discovered as a playwright, Sara Allgood, as an outstanding actress, and Miss Horniman of England, as a fine patron, who offered to invest in an Irish theatre. The play Deirdre was revived in 1903, and this producti on was followed by Riders to the Sea. In this year, theater fire regulations were so tightened that many Dublin buildings were closed. Then Mechanics Institute was taken over as a theater by the group under Miss Horniman's sponsorship. This place was called the Abbey Theatre, the first repertory theater in the world. On February, 1905, J. E. Synge's The Well of the Saints was produced. As John M. Synge links chapter one, which covers the history of The Abbey Theatre, with the more modern Irish dramatists, it seemed fitting to have chapter two present his view of peasant life in Wicklow, in which the following features are given: The fair and the tinkers. The next chapter discusses the country life in Western Ireland as presented by Lennox Robinson. The first play, The Whiteheaded Boy produced in 1921, reveals the middle class life, in which the follov1ing features were stressed: The matches, through which many marriages in Ireland have been arranged by the parents or older brothers of the families. In line with this problem of marriage arrangement is the place that the favorite son in the Irish family holds. Then come the pretensions and love of imitation that are found in this group of society which is especially affected by repertory players from the city. A picture of hotel life and country humor terminates this discusion of middle class life. The next phase of life in Western Ireland is that of the gentry, that Robinson reveals in his play, Killycreggs in Twilight, in which are found these various characteristics: The gentry pride, their pretensions, their tragedies. The following chapter presents the rectory life in Ireland as revealed in Paul V. Carroll's plays, Shadow and Substance and The White Steed, produced respectively in 1937 and 1939, which introduce us to the following features: The modern Canon, his country curates, the rectory housekeeper, the village school which the Canon dominates; the village school master, the old-fashioned Canon, who disapproves of the vigilant committees, the native's love of country, the home of an Irish peasant, and a countryman's view of Dublin. The final chapter, which depicts Sean O'Casey's view of the tenement life of Dublin, where he was reared, is divided into three parts. The first section concerns tenement life in Dublin from 1915 to 1916, and The Plough and The Stars gives us a pictures of that class of society. The following phases are presented: The tenement dweller's reaction to his surroundings and his desire to improve his conditions. Then comes a description of a typical tenement with the resulting ravages of disease on the people of this area, caused by the lack of sunshine, proper food and care. Amid the tribulations is found the strong faith of these dwellers. A wake and funeral are sadly described amid the street-fighting in the district. Then comes a description of landmarks in Dublin where much of this fighting occurred. A revelation of the means of transportation, the humor of the people amid strife, and the tenement landlord and his problems complete part one of this phase of Irish life. The second part of this chapter presents tenement life in Dublin from 1917 to 1923. Sean O'Casey's observations of tenement life in 1922 is first presented, followed by Padraic Colum's comments on Dublin of that era. Then appears a description of the various types of characters found in this district of Dublin: the militarists, the street vendors, and a typical tenement neighbor. Then the third part of this final chapter gives a view of modern tenement life in Dublin with the following aspects: The poetic workman of modern Dublin's tenement life, who desires to improve his mind even though he has had no benefit of formal education. Next are found O'Casey's criticism of the housing conditions in Dublin with their dubious activities. Then follows a description of the street vendors and their threat, because of their poor working conditions, to the safety of the city. The final picture presented is that of an Irish mother, whom O'Casey has described with love and pity, for she has sacrificed so much during her life for her children. This mother in reality represents his own mother, to whom he owes so much, in his autobiography, I Knock at the Door."
BRIAN J YUN,Reproductive inequality in humans and other mammals,"To address claims of human exceptionalism, we determine where humans fit within the greater mammalian distribution of reproductive inequality. We show that humans exhibit lower reproductive skew (i.e., inequality in the number of surviving offspring) among males and smaller sex differences in reproductive skew than most other mammals, while nevertheless falling within the mammalian range. Additionally, female reproductive skew is higher in polygynous human populations than in polygynous nonhumans mammals on average. This patterning of skew can be attributed in part to the prevalence of monogamy in humans compared to the predominance of polygyny in nonhuman mammals, to the limited degree of polygyny in the human societies that practice it, and to the importance of unequally held rival resources to women's fitness. The muted reproductive inequality observed in humans appears to be linked to several unusual characteristics of our species-including high levels of cooperation among males, high dependence on unequally held rival resources, complementarities between maternal and paternal investment, as well as social and legal institutions that enforce monogamous norms."
BRIAN J YUN,The long-baseline neutrino experiment: exploring fundamental symmetries of the universe,"The preponderance of matter over antimatter in the early Universe, the dynamics of the supernova bursts that produced the heavy elements necessary for life and whether protons eventually decay --- these mysteries at the forefront of particle physics and astrophysics are key to understanding the early evolution of our Universe, its current state and its eventual fate. The Long-Baseline Neutrino Experiment (LBNE) represents an extensively developed plan for a world-class experiment dedicated to addressing these questions. LBNE is conceived around three central components: (1) a new, high-intensity neutrino source generated from a megawatt-class proton accelerator at Fermi National Accelerator Laboratory, (2) a near neutrino detector just downstream of the source, and (3) a massive liquid argon time-projection chamber deployed as a far detector deep underground at the Sanford Underground Research Facility. This facility, located at the site of the former Homestake Mine in Lead, South Dakota, is approximately 1,300 km from the neutrino source at Fermilab -- a distance (baseline) that delivers optimal sensitivity to neutrino charge-parity symmetry violation and mass ordering effects. This ambitious yet cost-effective design incorporates scalability and flexibility and can accommodate a variety of upgrades and contributions. With its exceptional combination of experimental configuration, technical capabilities, and potential for transformative discoveries, LBNE promises to be a vital facility for the field of particle physics worldwide, providing physicists from around the globe with opportunities to collaborate in a twenty to thirty year program of exciting science. In this document we provide a comprehensive overview of LBNE's scientific objectives, its place in the landscape of neutrino physics worldwide, the technologies it will incorporate and the capabilities it will possess."
SOLESNE BOURGUIN,Functional Gaussian approximations in Hilbert spaces: the non-diffusive case,"We develop a functional Stein-Malliavin method in a non-diffusive Poissonian setting, thus obtaining a) quantitative central limit theorems for approximation of arbitrary nondegenerate Gaussian random elements taking values in a separable Hilbert space and b) fourth moment bounds for approximating sequences with finite chaos expansion. Our results rely on an infinite-dimensional version of Stein’s method of exchangeable pairs combined with the so-called Gamma calculus. Two applications are included: Brownian approximation of Poisson processes in Besov-Liouville spaces and a functional limit theorem for an edge-counting statistic of a random geometric graph."
SOLESNE BOURGUIN,Quantitative fluctuation analysis of multiscale diffusion systems via Malliavin calculus,
SHI YANG,Identification and reconstruction of low-energy electrons in the ProtoDUNE-SP detector,
KARIN HENDRICKS,"International Research Symposium on Talent Education, Part 4: The joys and benefits of Suzuki group class","This is the fourth article in a series reporting the findings of a large-scale demographic study of Suzuki teachers in Canada and the United States. Previous articles introduced the research, reporting on basic demographic statistics, teacher training, studio size, and structure of group classes. In this article we report on the results of an open-ended response question regarding the benefits of student participation in Suzuki group class."
KARIN HENDRICKS,Pedagogical content knowledge and preparation of string teachers,"In the past few decades, there has been an increase in the percentage of non-string specialists teaching string classes. In this article, we review literature about subject-specific pedagogical content knowledge (PCK) in general and music education settings, to better understand the challenges that teachers with limited knowledge of string-specific content may face when teaching strings students. Included in this review are discussions concerning trends in the string teacher workforce, PCK in education and music, acquisition of PCK in general settings and music teacher preparation programs, and relationships between teacher content knowledge and instructional effectiveness, both in general and string education settings. Based on this review, we recommend that preservice and professional development curricula for music teachers include comprehensive preparation in both content-specific and pedagogical-specific knowledge for teaching strings."
KARIN HENDRICKS,"International Research Symposium on Talent Education, Part 6: Parent education in Suzuki studios","This is the sixth installment in a series of articles reporting on a large‐scale demographic survey of North American Suzuki teachers. The previous article in this series examined some of the perceived challenges of group class. In this article, we will review teachers' descriptions of the parent education offerings within their studios. Teachers were asked to provide information about the structure, content, and intensity of their parent education programs. The survey questions included both initial education for new families entering their studios, as well as ongoing education for returning families."
KARIN HENDRICKS,Eclectic styles and classical performance: Motivation and self-efficacy belief at two summer music camps,"String teachers and scholars have suggested that classically-trained students may be motivated to engage in eclectic (e.g., rock, pop, jazz, groove, folk) styles. However, we do not fully understand the ways in which students’ motivations to engage in new musics might be influenced by their perceptions of competence in those styles. In this mixed-method study we draw upon quantitative, qualitative, and arts-based data from 120 middle and high school students at two camps (one emphasizing classical music, the other emphasizing eclectic styles), to explore various ways in which students develop self-efficacy beliefs and motivation to perform in a variety of musical approaches. According to analysis of all data, students at both camps generally expressed having positive musical and social experiences. Negative experiences, while less common, stemmed from confusion or frustration with music learning, boredom with music that was too easy or not interesting, and competitive comparison with others. Based on findings from qualitative and arts-based data, we suggest that these students may have benefitted from additional teacher support when encountering new musical techniques"
KARIN HENDRICKS,"Collective efficacy belief, within-group agreement, and performance quality among instrumental chamber ensembles","We examined collective efficacy beliefs, including levels of within - group agreement and correlation with performance quality, of instrumental chamber ensembles (70 musicians, representing 18 ensembles). Participants were drawn from collegiate programs and intensive summer music festivals located in the No rthwestern and Western regions of the United States. Individuals completed a 5 - item survey gauging confidence in their group’s performance abilities; each ensemble’s aggregated results represented its collective efficacy score. Ensembles provided a video - r ecorded performance excerpt that was rated by a panel of four string specialists. Analyses revealed moderately strong levels of collective efficacy belief and uniformly high within - group agreement. There was a significant, moderately strong correlation bet ween collective efficacy belief and within - group agreement ( r S = .67, p < .01). We found no relationship between collective efficacy belief and performance quality across the total sample, but those factors correlated significantly for festival - based ensem bles ( r S = .82, p < .05). Reliability estimates suggest that our collective efficacy survey may be suitable for use with string chamber ensembles. Correlational findings provide partial support for the theorized link between efficacy belief and performance quality in chamber music settings, suggesting the importance for music educators to ensure that positive efficacy beliefs become well founded through quality instruction."
KARIN HENDRICKS,Investing time: Teacher research observing the influence of music history and theory lessons upon student engagement and expressive performance of an advanced high school string quartet,"This teacher-conducted research observes the influence of music history and theory instruction upon motivation, engagement, and expressive performance of the author’s high school string students. Two diverse teaching approaches were introduced sequentially as students learned two movements of Schubert’s ""Death and the Maiden"" Quartet (D810). The first movement was taught using performance-based instruction only, while the second movement was taught with a combination of performance-based instruction and music history and theory lessons. Student comments and teacher observations revealed that the incorporation of music history and theory lessons into performance instruction was (a) motivational to students, (b) a catalyst for expressive performance, and (c) an effective use of rehearsal time. Independent adjudicator scores were higher for the second movement than for the first, although several additional explanations are given that may also explain the variation in scores. Pedagogical recommendations are provided for incorporating music history/theory lessons into performance rehearsals."
KARIN HENDRICKS,"International Research Symposium on Talent Education, Part 5: The challenges of offering group class","This is the fifth installment in a series of articles reporting on a large‐scale demographic survey of North American Suzuki teachers. The last article in this series examined some of the perceived benefits of group class. In this article, we will review participants’ perceptions of the challenges of group class. Participating teachers were asked to respond to the open‐ended question, ""What is the greatest challenge of group class?"" Their responses were coded and analyzed for important themes."
KARIN HENDRICKS,Trying out popular and informal music learning approaches,
KARIN HENDRICKS,"International Research Symposium on Talent Education, Part 3: What do Suzuki studios look like?","This is the third article in a series reporting the findings of a large-scale demographic study of 1128 North American SAA member teachers. The first article introduced the International Research Symposium on Talent Education and the group's current research interests. The second installment in the series focused on Suzuki teachers and included basic demographic information and information on teachers' training. In this article, we will explore what Suzuki studios look like, examining data such as studio size and structure of group classes."
KARIN HENDRICKS,Competitive comparison in music: influences upon self-efficacy beliefs by gender,"This study profiles gender differences in instrumental performance self-efficacy perceptions of high school students (N = 87) over the course of a three-day orchestra festival in which students competed against one another for rank-based seating and then rehearsed and performed as a group. Reported self-beliefs rose significantly for the sample over the course of the festival. Self-efficacy beliefs of females were significantly lower than those of males before the seating audition and first rehearsal, but were no longer different by the midpoint of the festival. Survey free-response data were coded according to Bandura's (1997 Bandura, A. 1997. Self-efficacy: The Exercise of Control. New York: W. H. Freeman.) four sources of self-efficacy. A 52% drop in the frequency of student comments regarding competitive comparison appeared at the same point in which female self-efficacy beliefs were no longer different from those of males. Results support past research to suggest that males and females may respond differently to rank-based competition versus social support."
KARIN HENDRICKS,The sources of self-efficacy: Educational research and implications for music,"Music teachers can empower students with control over their own music ability development by helping them foster positive self-efficacy beliefs. This article reviews general education and music research concerning Bandura’s theoretical four sources of self-efficacy (enactive mastery experience, vicarious experience, verbal/social persuasion, and physiological and affective states), in order to guide music teachers in determining effective methods and approaches to help students develop a sense of music self-efficacy and subsequent music achievement. A brief summary of each self-efficacy source category is provided, along with a discussion of the means whereby self-efficacy perceptions can be developed within both general education and music learning environments. Each of these four sections reviews research and simultaneously provides corresponding practical suggestions for educators."
KARIN HENDRICKS,Pedagogical content knowledge for VIBRATO: More than a toolbox of tricks,
KARIN HENDRICKS,Pedagogical content knowledge for SHIFTING: More than a toolbox of tricks,"The heterogeneous string classroom can often present challenges to string teachers in knowing how to help a variety of students develop complex string technique such as shifting and vibrato. Just like teaching any skill in any subject, teaching string-specific technique requires specific types of knowledge, and long-term success depends largely on ensuring that technical fundamentals are well taught. In this two-part series, we will address the issues of pedagogical content knowledge (PCK)—the integration of content knowledge and pedagogical knowledge—in regard to shifting and vibrato in the heterogeneous string classroom, to demonstrate how knowledge of technique works hand-in-hand with knowledge of teaching. “We explore common shifting challenges and realistic teaching strategies that take into consideration the large heterogeneous string classroom.” In this first article, we focus on shifting technique, and in the second, we will discuss vibrato. Previous research suggests that teachers who have PCK to teach a concept or skill can help students deepen the understanding of complex skills and concepts. In this article, we discuss various teaching strategies from the pre-shifting exercises to early shifting exercises. We explore common shifting challenges and realistic teaching strategies that take into consideration the large heterogeneous string classroom."
KARIN HENDRICKS,Socio-musical connections and teacher identity development in a university methods course and community youth symphony partnership,"In this article we describe the experiences of nine preservice music teachers enrolled in the first semester of a newly designed instrumental methods course in which a traditional lecture format was replaced with experiential, student-driven, service-oriented activities. Students were entrusted with organizing and directing a community youth symphony, including sharing of teaching and all administrative responsibilities (e.g., recruiting, fundraising, repertoire selection, community outreach). While the first author was the professor and designer of the course, the second author acted as an outside observer, collecting data through rehearsal observations, student interviews, and study of course artifacts. Findings suggest that students benefitted from opportunities to observe and collaborate with the professor and classmates in real-world teaching settings. Furthermore, students demonstrated evidence of growth and maturation over the course of the semester in teaching skills, professional identity, and socio-musical connections. The article closes with a description of how student recommendations for course improvement were implemented in subsequent semesters."
KARIN HENDRICKS,Research to Practice: Issues of Relevance for Massachusetts Music Educators,
HONGWEI XI,Applied type system,"We present a type system that can effectively facilitate the use of types in capturing invariants in stateful programs that may involve (sophisticated) pointer manipulation. With its root in a recently developed framework Applied Type System (ATS), the type system imposes a level of abstraction on program states by introducing a novel notion of recursive stateful views and then relies on a form of linear logic to reason about such views. We consider the design and then the formalization of the type system to constitute the primary contribution of the paper. In addition, we mention a prototype implementation of the type system and then give a variety of examples that attests to the practicality of programming with recursive stateful views."
HONGWEI XI,Dependent types for multi-rate flows in synchronous programming,"Synchronous programming languages emerged in the 1980s as tools for implementing reactive systems, which interact with events from physical environments and often must do so under strict timing constraints. In this report, we encode inside ATS various real-time primitives in an experimental synchronous language called Prelude, where ATS is a statically typed language with an ML-like functional core that supports both dependent types (of DML-style) and linear types. We show that the verification requirements imposed on these primitives can be formally expressed in terms of dependent types in ATS. Moreover, we modify the Prelude compiler to automatically generate ATS code from Prelude source. This modified compiler allows us to solely rely on typechecking in ATS to discharge proof obligations originating from the need to typecheck Prelude code. Whereas ATS is typically used as a general purpose programming language, we hereby demonstrate that it can also be conveniently used to support some forms of advanced static checking in languages equipped with less expressive types."
HONGWEI XI,Linearly typed dyadic group sessions for building multiparty sessions,"Traditionally, each party in a (dyadic or multiparty) session implements exactly one role specified in the type of the session. We refer to this kind of session as an individual session (i-session). As a generalization of i-session, a group session (g-session) is one in which each party may implement a group of roles based on one channel. In particular, each of the two parties involved in a dyadic g-session implements either a group of roles or its complement. In this paper, we present a formalization of g-sessions in a multi-threaded lambda-calculus (MTLC) equipped with a linear type system, establishing for the MTLC both type preservation and global progress. As this formulated MTLC can be readily embedded into ATS, a full-fledged language with a functional programming core that supports both dependent types (of DML-style) and linear types, we obtain a direct implementation of linearly typed g-sessions in ATS. The primary contribution of the paper lies in both of the identification of g-sessions as a fundamental building block for multiparty sessions and the theoretical development in support of this identification."
HONGWEI XI,Propositions in linear multirole logic as multiparty session types,"We identify multirole logic as a new form of logic and formalize linear multirole logic (LMRL) as a natural generalization of classical linear logic (CLL). Among various meta-properties established for LMRL, we obtain one named multi-cut elimination stating that every cut between three (or more) sequents (as a generalization of a cut between two sequents) can be eliminated, thus extending the celebrated result of cut-elimination by Gentzen. We also present a variant of 𝜋-calculus for multiparty sessions that demonstrates a tight correspondence between process communication in this variant and multi-cut elimination in LMRL, thus extending some recent results by Caires and Pfenning (2010) and Wadler (2012), among others, along a similar line of work."
HONGWEI XI,Multirole logic (extended abstract),"We identify multirole logic as a new form of logic in which conjunction/disjunction is interpreted as an ultrafilter on the power set of some underlying set (of roles) and the notion of negation is generalized to endomorphisms on this underlying set. We formalize both multirole logic (MRL) and linear multirole logic (LMRL) as natural generalizations of classical logic (CL) and classical linear logic (CLL), respectively, and also present a filter-based interpretation for intuitionism in multirole logic. Among various meta-properties established for MRL and LMRL, we obtain one named multiparty cut-elimination stating that every cut involving one or more sequents (as a generalization of a (binary) cut involving exactly two sequents) can be eliminated, thus extending the celebrated result of cut-elimination by Gentzen."
HONGWEI XI,Applied type system: an approach to practical programming with theorem-proving,"The framework Pure Type System (PTS) offers a simple and general approach to designing and formalizing type systems. However, in the presence of dependent types, there often exist certain acute problems that make it difficult for PTS to directly accommodate many common realistic programming features such as general recursion, recursive types, effects (e.g., exceptions, references, input/output), etc. In this paper, Applied Type System (ATS) is presented as a framework for designing and formalizing type systems in support of practical programming with advanced types (including dependent types). In particular, it is demonstrated that ATS can readily accommodate a paradigm referred to as programming with theorem-proving (PwTP) in which programs and proofs are constructed in a syntactically intertwined manner, yielding a practical approach to internalizing constraint-solving needed during type-checking. The key salient feature of ATS lies in a complete separation between statics, where types are formed and reasoned about, and dynamics, where programs are constructed and evaluated. With this separation, it is no longer possible for a program to occur in a type as is otherwise allowed in PTS. The paper contains not only a formal development of ATS but also some examples taken from ats-lang.org, a programming language with a type system rooted in ATS, in support of employing ATS as a framework to formulate advanced type systems for practical programming."
HONGWEI XI,A robust and efficient method for estimating enzyme complex abundance and metabolic flux from expression data,"A major theme in constraint-based modeling is unifying experimental data, such as biochemical information about the reactions that can occur in a system or the composition and localization of enzyme complexes, with high-throughput data including expression data, metabolomics, or DNA sequencing. The desired result is to increase predictive capability and improve our understanding of metabolism. The approach typically employed when only gene (or protein) intensities are available is the creation of tissue-specific models, which reduces the available reactions in an organism model, and does not provide an objective function for the estimation of fluxes. We develop a method, flux assignment with LAD (least absolute deviation) convex objectives and normalization (FALCON), that employs metabolic network reconstructions along with expression data to estimate fluxes. In order to use such a method, accurate measures of enzyme complex abundance are needed, so we first present an algorithm that addresses quantification of complex abundance. Our extensions to prior techniques include the capability to work with large models and significantly improved run-time performance even for smaller models, an improved analysis of enzyme complex formation, the ability to handle large enzyme complex rules that may incorporate multiple isoforms, and either maintained or significantly improved correlation with experimentally measured fluxes. FALCON has been implemented in MATLAB and ATS, and can be downloaded from: https://github.com/bbarker/FALCON. ATS is not required to compile the software, as intermediate C source code is available. FALCON requires use of the COBRA Toolbox, also implemented in MATLAB."
HONGWEI XI,Session types in a linearly typed multi-threaded lambda-calculus,"We present a formalization of session types in a multi-threaded lambda-calculus (MTLC) equipped with a linear type system, establishing for the MTLC both type preservation and global progress. The latter (global progress) implies that the evaluation of a well-typed program in the MTLC can never reach a deadlock. As this formulated MTLC can be readily embedded into ATS, a full-fledged language with a functional programming core that supports both dependent types (of DML-style) and linear types, we obtain a direct implementation of session types in ATS. In addition, we gain immediate support for a form of dependent session types based on this embedding into ATS. Compared to various existing formalizations of session types, we see the one given in this paper is unique in its closeness to concrete implementation. In particular, we report such an implementation ready for practical use that generates Erlang code from well-typed ATS source (making use of session types), thus taking great advantage of the infrastructural support for distributed computing in Erlang."
WEN LI,First M87 Event Horizon Telescope results. III. Data processing and calibration,"We present the calibration and reduction of Event Horizon Telescope (EHT) 1.3 mm radio wavelength observations of the supermassive black hole candidate at the center of the radio galaxy M87 and the quasar 3C 279, taken during the 2017 April 5–11 observing campaign. These global very long baseline interferometric observations include for the first time the highly sensitive Atacama Large Millimeter/submillimeter Array (ALMA); reaching an angular resolution of 25 μas, with characteristic sensitivity limits of ~1 mJy on baselines to ALMA and ~10 mJy on other baselines. The observations present challenges for existing data processing tools, arising from the rapid atmospheric phase fluctuations, wide recording bandwidth, and highly heterogeneous array. In response, we developed three independent pipelines for phase calibration and fringe detection, each tailored to the specific needs of the EHT. The final data products include calibrated total intensity amplitude and phase information. They are validated through a series of quality assurance tests that show consistency across pipelines and set limits on baseline systematic errors of 2% in amplitude and 1° in phase. The M87 data reveal the presence of two nulls in correlated flux density at ~3.4 and ~8.3 Gλ and temporal evolution in closure quantities, indicating intrinsic variability of compact structure on a timescale of days, or several light-crossing times for a few billion solar-mass black hole. These measurements provide the first opportunity to image horizon-scale structure in M87."
WEN LI,First M87 Event Horizon Telescope results. V. Physical origin of the asymmetric ring,"The Event Horizon Telescope (EHT) has mapped the central compact radio source of the elliptical galaxy M87 at 1.3 mm with unprecedented angular resolution. Here we consider the physical implications of the asymmetric ring seen in the 2017 EHT data. To this end, we construct a large library of models based on general relativistic magnetohydrodynamic (GRMHD) simulations and synthetic images produced by general relativistic ray tracing. We compare the observed visibilities with this library and confirm that the asymmetric ring is consistent with earlier predictions of strong gravitational lensing of synchrotron emission from a hot plasma orbiting near the black hole event horizon. The ring radius and ring asymmetry depend on black hole mass and spin, respectively, and both are therefore expected to be stable when observed in future EHT campaigns. Overall, the observed image is consistent with expectations for the shadow of a spinning Kerr black hole as predicted by general relativity. If the black hole spin and M87's large scale jet are aligned, then the black hole spin vector is pointed away from Earth. Models in our library of non-spinning black holes are inconsistent with the observations as they do not produce sufficiently powerful jets. At the same time, in those models that produce a sufficiently powerful jet, the latter is powered by extraction of black hole spin energy through mechanisms akin to the Blandford-Znajek process. We briefly consider alternatives to a black hole for the central compact object. Analysis of existing EHT polarization data and data taken simultaneously at other wavelengths will soon enable new tests of the GRMHD models, as will future EHT campaigns at 230 and 345 GHz."
WEN LI,First M87 Event Horizon Telescope results. VI. The shadow and mass of the central black hole,"We present measurements of the properties of the central radio source in M87 using Event Horizon Telescope data obtained during the 2017 campaign. We develop and fit geometric crescent models (asymmetric rings with interior brightness depressions) using two independent sampling algorithms that consider distinct representations of the visibility data. We show that the crescent family of models is statistically preferred over other comparably complex geometric models that we explore. We calibrate the geometric model parameters using general relativistic magnetohydrodynamic (GRMHD) models of the emission region and estimate physical properties of the source. We further fit images generated from GRMHD models directly to the data. We compare the derived emission region and black hole parameters from these analyses with those recovered from reconstructed images. There is a remarkable consistency among all methods and data sets. We find that >50% of the total flux at arcsecond scales comes from near the horizon, and that the emission is dramatically suppressed interior to this region by a factor >10, providing direct evidence of the predicted shadow of a black hole. Across all methods, we measure a crescent diameter of 42 ± 3 μas and constrain its fractional width to be <0.5. Associating the crescent feature with the emission surrounding the black hole shadow, we infer an angular gravitational radius of GM/Dc^2 = 3.8 ± 0.4 μas. Folding in a distance measurement of {16.8}_{-0.7}^{+0.8}{Mpc} gives a black hole mass of M = 6.5 ± 0.2{| }_{stat} ± 0.7{| }_{sys} × {10}^{9} {M}_{odot }. This measurement from lensed emission near the event horizon is consistent with the presence of a central Kerr black hole, as predicted by the general theory of relativity."
WEN LI,The Event Horizon general relativistic magnetohydrodynamic code comparison project,"Recent developments in compact object astrophysics, especially the discovery of merging neutron stars by LIGO, the imaging of the black hole in M87 by the Event Horizon Telescope, and high- precision astrometry of the Galactic Center at close to the event horizon scale by the GRAVITY experiment motivate the development of numerical source models that solve the equations of general relativistic magnetohydrodynamics (GRMHD). Here we compare GRMHD solutions for the evolution of a magnetized accretion flow where turbulence is promoted by the magnetorotational instability from a set of nine GRMHD codes: Athena++, BHAC, Cosmos++, ECHO, H-AMR, iharm3D, HARM-Noble, IllinoisGRMHD, and KORAL. Agreement among the codes improves as resolution increases, as measured by a consistently applied, specially developed set of code performance metrics. We conclude that the community of GRMHD codes is mature, capable, and consistent on these test problems."
WEN LI,Juno Plasma Wave Observations at Ganymede.,"The Juno Waves instrument measured plasma waves associated with Ganymede's magnetosphere during its flyby on 7 June, day 158, 2021. Three distinct regions were identified including a wake, and nightside and dayside regions in the magnetosphere distinguished by their electron densities and associated variability. The magnetosphere includes electron cyclotron harmonic emissions including a band at the upper hybrid frequency, as well as whistler-mode chorus and hiss. These waves likely interact with energetic electrons in Ganymede's magnetosphere by pitch angle scattering and/or accelerating the electrons. The wake is accentuated by low-frequency turbulence and electrostatic solitary waves. Radio emissions observed before and after the flyby likely have their source in Ganymede's magnetosphere."
WEN LI,"Modeling electron scattering and acceleration by whistler mode chorus waves in Jupiter's magnetosphere: effects of magnetic field model, total electron density, and electron injections","We evaluate the energetic electron scattering and acceleration due to whistler mode chorus waves using realistic magnetic field and density models in Jupiter's magnetosphere, and study the potential effects of electron injections. The bounce-averaged diffusion coefficients are calculated using the total electron density from the diffusive equilibrium model and the magnetic field strength from the VIP4 internal magnetic field and CAN current sheet model. The electron phase space density evolution due to chorus wave is simulated at M=10 . The typical chorus waves could cause fast pitch angle scattering loss of electrons from tens to several hundred keV, and gradual acceleration of relativistic electrons at several MeV. The latitudinally varying density and VIP4+CAN magnetic field model leads to faster pitch angle scattering and acceleration of electrons at energies above 100 keV than the constant density and dipolar magnetic field model. The simulation is compared to the electron dynamics during an electron injection event observed by Juno on 29 October, 2018. The electron flux is enhanced at low energies during the injection event, and the Fokker Planck simulation indicates an enhanced electron acceleration due to chorus waves subsequent to the injections. The modeling indicates an electron flux increase by nearly 1 order of magnitude within 1 day, suggesting the potentially important role of chorus waves in forming Jupiter's radiation belts after injections."
WEN LI,Attenuation of plasmaspheric hiss associated with the enhanced magnetospheric electric field,"We report an attenuation of hiss wave intensity in the duskside of the outer plasmasphere in response to enhanced convection and a substorm based on Van Allen Probe observations. Using test particle codes, we simulate the dynamics of energetic electron fluxes based on a realistic magnetospheric electric field model driven by solar wind and subauroral polarization stream. We suggest that the enhanced magnetospheric electric field causes the outward and sunward motion of energetic electrons, corresponding to the decrease of energetic electron fluxes on the duskside, leading to the subsequent attenuation of hiss wave intensity. The results indicate that the enhanced electric field can significantly change the energetic electron distributions, which provide free energy for hiss wave amplification. This new finding is critical for understanding the generation of plasmaspheric hiss and its response to solar wind and substorm activity."
WEN LI,The attenuation of plasmaspheric hiss associated with the enhanced magnetospheric electric field,"We report an attenuation of hiss wave intensity in the duskside of the outer plasmasphere in response to enhanced convection and a substorm based on Van Allen Probe observations. Using test particle codes, we simulate the dynamics of energetic electron fluxes based on a realistic magnetospheric electric field model driven by solar wind and subauroral polarization stream. We suggest that the enhanced magnetospheric electric field causes the outward and sunward motion of energetic electrons, corresponding to the decrease of energetic electron fluxes on the duskside, leading to the subsequent attenuation of hiss wave intensity. The results indicate that the enhanced electric field can significantly change the energetic electron distributions, which provide free energy for hiss wave amplification. This new finding is critical for understanding the generation of plasmaspheric hiss and its response to solar wind and substorm activity."
WEN LI,Analysis on the relativistic electron precipitation in the midnight sector,"We analyze the precipitation of relativistic electrons occurring in the midnight sector, defined over 22–02 MLT. In the nightside, electron precipitation is primarily driven either by pitch angle scattering from interactions between electrons and plasma waves or by pitch angle scattering due to the stretching of magnetic field lines (also called “current sheet scattering”). We identified ~400 relativistic electron precipitation events and separated them into wave-driven (REPs) and CSS-driven (CSSs) events. Although REPs tend to occur at slightly lower L shells and CSSs are found at marginally higher L shells, there is not a clear separation in location between these two precipitation types. Furthermore, we show that REPs occur on smaller L shell scales at post-midnight and on wider L shell scales at pre-midnight, suggesting that the wave driver characteristics vary across midnight."
WEN LI,Gravitational test beyond the first post-Newtonian order with the shadow of the M87 black hole,"The 2017 Event Horizon Telescope (EHT) observations of the central source in M87 have led to the first measurement of the size of a black-hole shadow. This observation offers a new and clean gravitational test of the black-hole metric in the strong-field regime. We show analytically that spacetimes that deviate from the Kerr metric but satisfy weak-field tests can lead to large deviations in the predicted black-hole shadows that are inconsistent with even the current EHT measurements. We use numerical calculations of regular, parametric, non-Kerr metrics to identify the common characteristic among these different parametrizations that control the predicted shadow size. We show that the shadow-size measurements place significant constraints on deviation parameters that control the second post-Newtonian and higher orders of each metric and are, therefore, inaccessible to weak-field tests. The new constraints are complementary to those imposed by observations of gravitational waves from stellar-mass sources."
WEN LI,First M87 Event Horizon Telescope results. IV. Imaging the central supermassive black hole,
WEN LI,Verification of radiative transfer schemes for the EHT,"The Event Horizon Telescope (EHT) Collaboration has recently produced the first resolved images of the central supermassive black hole in the giant elliptical galaxy M87. Here we report on tests of the consistency and accuracy of the general relativistic radiative transfer codes used within the collaboration to model M87* and Sgr A*. We compare and evaluate (1) deflection angles for equatorial null geodesics in a Kerr spacetime; (2) images calculated from a series of simple, parameterized matter distributions in the Kerr metric using simplified emissivities and absorptivities; (3) for a subset of codes, images calculated from general relativistic magnetohydrodynamics simulations using different realistic synchrotron emissivities and absorptivities; (4) observables for the 2017 configuration of EHT, including visibility amplitudes and closure phases. The error in total flux is of order 1% when the codes are run with production numerical parameters. The dominant source of discrepancies for small camera distances is the location and detailed setup of the software ""camera"" that each code uses to produce synthetic images. We find that when numerical parameters are suitably chosen and the camera is sufficiently far away the images converge and that for given transfer coefficients, numerical uncertainties are unlikely to limit parameter estimation for the current generation of EHT observations. The purpose of this paper is to describe a verification and comparison of EHT radiative transfer codes. It is not to verify EHT models more generally."
WEN LI,Monitoring the mmorphology of M87* in 2009–2017 with the Event Horizon Telescope,"The Event Horizon Telescope (EHT) has recently delivered the first resolved images of M87*, the supermassive black hole in the center of the M87 galaxy. These images were produced using 230 GHz observations performed in April 2017. Additional observations are required to investigate the persistence of the primary image feature – a ring with azimuthal brightness asymmetry – and to quantify the image variability on event horizon scales. To address this need, we analyze M87* data collected with prototype EHT arrays in 2009, 2011, 2012, and 2013. While these observations do not contain enough information to produce images, they are sufficient to constrain simple geometric models. We develop a modeling approach based on the framework utilized for the 2017 EHT data analysis and validate our procedures using synthetic data. Applying the same approach to the observational data sets, we find the M87* morphology in 2009–2017 to be consistent with a persistent asymmetric ring of 40 as diameter. The position angle of peak intensity varies in time. In particular, we find a significant difference between the position angle measured in 2013 and 2017. These variations are in broad agreement with predictions of a subset of general relativistic magnetohydrodynamic simulations. We show that quantifying the variability across multiple observational epochs has the potential to constrain physical properties of the source, such as the accretion state or the black hole spin."
WEN LI,THEMIS: a parameter estimation framework for the Event Horizon Telescope,"The Event Horizon Telescope (EHT) provides the unprecedented ability to directly resolve the structure and dynamics of black hole emission regions on scales smaller than their horizons. This has the potential to critically probe the mechanisms by which black holes accrete and launch outflows, and the structure of supermassive black hole spacetimes. However, accessing this information is a formidable analysis challenge for two reasons. First, the EHT natively produces a variety of data types that encode information about the image structure in nontrivial ways; these are subject to a variety of systematic effects associated with very long baseline interferometry and are supplemented by a wide variety of auxiliary data on the primary EHT targets from decades of other observations. Second, models of the emission regions and their interaction with the black hole are complex, highly uncertain, and computationally expensive to construct. As a result, the scientific utilization of EHT observations requires a flexible, extensible, and powerful analysis framework. We present such a framework, Themis, which defines a set of interfaces between models, data, and sampling algorithms that facilitates future development. We describe the design and currently existing components of Themis, how Themis has been validated thus far, and present additional analyses made possible by Themis that illustrate its capabilities. Importantly, we demonstrate that Themis is able to reproduce prior EHT analyses, extend these, and do so in a computationally efficient manner that can efficiently exploit modern high-performance computing facilities. Themis has already been used extensively in the scientific analysis and interpretation of the first EHT observations of M87."
WEN LI,First Sagittarius A* Event Horizon Telescope results. V. Testing astrophysical models of the galactic center black hole,"In this paper we provide a first physical interpretation for the Event Horizon Telescope's (EHT) 2017 observations of Sgr A*. Our main approach is to compare resolved EHT data at 230 GHz and unresolved non-EHT observations from radio to X-ray wavelengths to predictions from a library of models based on time-dependent general relativistic magnetohydrodynamics simulations, including aligned, tilted, and stellar-wind-fed simulations; radiative transfer is performed assuming both thermal and nonthermal electron distribution functions. We test the models against 11 constraints drawn from EHT 230 GHz data and observations at 86 GHz, 2.2 μm, and in the X-ray. All models fail at least one constraint. Light-curve variability provides a particularly severe constraint, failing nearly all strongly magnetized (magnetically arrested disk (MAD)) models and a large fraction of weakly magnetized models. A number of models fail only the variability constraints. We identify a promising cluster of these models, which are MAD and have inclination i ≤ 30°. They have accretion rate (5.2–9.5) × 10−9 M ⊙ yr−1, bolometric luminosity (6.8–9.2) × 1035 erg s−1, and outflow power (1.3–4.8) × 1038 erg s−1. We also find that all models with i ≥ 70° fail at least two constraints, as do all models with equal ion and electron temperature; exploratory, nonthermal model sets tend to have higher 2.2 μm flux density; and the population of cold electrons is limited by X-ray constraints due to the risk of bremsstrahlung overproduction. Finally, we discuss physical and numerical limitations of the models, highlighting the possible importance of kinetic effects and duration of the simulations."
WEN LI,First M87 Event Horizon Telescope results. VII. Polarization of the ring,"In 2017 April, the Event Horizon Telescope (EHT) observed the near-horizon region around the supermassive black hole at the core of the M87 galaxy. These 1.3 mm wavelength observations revealed a compact asymmetric ring-like source morphology. This structure originates from synchrotron emission produced by relativistic plasma located in the immediate vicinity of the black hole. Here we present the corresponding linear-polarimetric EHT images of the center of M87. We find that only a part of the ring is significantly polarized. The resolved fractional linear polarization has a maximum located in the southwest part of the ring, where it rises to the level of ∼15%. The polarization position angles are arranged in a nearly azimuthal pattern. We perform quantitative measurements of relevant polarimetric properties of the compact emission and find evidence for the temporal evolution of the polarized source structure over one week of EHT observations. The details of the polarimetric data reduction and calibration methodology are provided. We carry out the data analysis using multiple independent imaging and modeling techniques, each of which is validated against a suite of synthetic data sets. The gross polarimetric structure and its apparent evolution with time are insensitive to the method used to reconstruct the image. These polarimetric images carry information about the structure of the magnetic fields responsible for the synchrotron emission. Their physical interpretation is discussed in an accompanying publication."
WEN LI,First M87 Event Horizon Telescope results. VIII. Magnetic field structure near The Event Horizon,"Event Horizon Telescope (EHT) observations at 230 GHz have now imaged polarized emission around the supermassive black hole in M87 on event-horizon scales. This polarized synchrotron radiation probes the structure of magnetic fields and the plasma properties near the black hole. Here we compare the resolved polarization structure observed by the EHT, along with simultaneous unresolved observations with the Atacama Large Millimeter/submillimeter Array, to expectations from theoretical models. The low fractional linear polarization in the resolved image suggests that the polarization is scrambled on scales smaller than the EHT beam, which we attribute to Faraday rotation internal to the emission region. We estimate the average density n_e ∼ 10^4–7 cm^−3, magnetic field strength B ∼ 1–30 G, and electron temperature T_e ∼ (1–12) × 10^10 K of the radiating plasma in a simple one-zone emission model. We show that the net azimuthal linear polarization pattern may result from organized, poloidal magnetic fields in the emission region. In a quantitative comparison with a large library of simulated polarimetric images from general relativistic magnetohydrodynamic (GRMHD) simulations, we identify a subset of physical models that can explain critical features of the polarimetric EHT observations while producing a relativistic jet of sufficient power. The consistent GRMHD models are all of magnetically arrested accretion disks, where near-horizon magnetic fields are dynamically important. We use the models to infer a mass accretion rate onto the black hole in M87 of (3–20) × 10^−4 M ⊙ yr^−1."
WEN LI,Resolving the inner parsec of the blazar J1924–2914 with the event horizon telescope,"The blazar J1924–2914 is a primary Event Horizon Telescope (EHT) calibrator for the Galactic center’s black hole Sagittarius A*. Here we present the first total and linearly polarized intensity images of this source obtained with the unprecedented 20 μas resolution of the EHT. J1924–2914 is a very compact flat-spectrum radio source with strong optical variability and polarization. In April 2017 the source was observed quasi-simultaneously with the EHT (April 5–11), the Global Millimeter VLBI Array (April 3), and the Very Long Baseline Array (April 28), giving a novel view of the source at four observing frequencies, 230, 86, 8.7, and 2.3 GHz. These observations probe jet properties from the subparsec to 100 pc scales. We combine the multifrequency images of J1924–2914 to study the source morphology. We find that the jet exhibits a characteristic bending, with a gradual clockwise rotation of the jet projected position angle of about 90° between 2.3 and 230 GHz. Linearly polarized intensity images of J1924–2914 with the extremely fine resolution of the EHT provide evidence for ordered toroidal magnetic fields in the blazar compact core."
WEN LI,Enabling controlling complex networks with local topological information,"Complex networks characterize the nature of internal/external interactions in real-world systems including social, economic, biological, ecological, and technological networks. Two issues keep as obstacles to fulflling control of large-scale networks: structural controllability which describes the ability to guide a dynamical system from any initial state to any desired fnal state in fnite time, with a suitable choice of inputs; and optimal control, which is a typical control approach to minimize the cost for driving the network to a predefned state with a given number of control inputs. For large complex networks without global information of network topology, both problems remain essentially open. Here we combine graph theory and control theory for tackling the two problems in one go, using only local network topology information. For the structural controllability problem, a distributed local-game matching method is proposed, where every node plays a simple Bayesian game with local information and local interactions with adjacent nodes, ensuring a suboptimal solution at a linear complexity. Starring from any structural controllability solution, a minimizing longest control path method can efciently reach a good solution for the optimal control in large networks. Our results provide solutions for distributed complex network control and demonstrate a way to link the structural controllability and optimal control together."
WEN LI,Oxygen ion dynamics in the Earth's ring current: Van Allen probes observations,"Oxygen (O+) enhancements in the inner magnetosphere are often observed during geomagnetically active times, such as geomagnetic storms. In this study, we quantitatively examine the difference in ring current dynamics with and without a substantial O+ ion population based on almost 6 years of Van Allen Probes observations. Our results have not only confirmed previous finding of the role of O+ ions to the ring current but also found that abundant O+ ions are always present during large storms when sym-H < -60 nT without exception, whilst having the pressure ratio (𝓡) between O+ and proton (H+) larger than 0.8 and occasionally even larger than 1 when L < 3. Simultaneously, the pressure anisotropy decreases with decreasing sym-H and increasing L shell. The pressure anisotropy decrease during the storm main phase is likely related to the pitch angle isotropization processes. In addition, we find that 𝓡 increases during the storm main phase and then decreases during the storm recovery phase, suggesting faster buildup and decay of O+ pressure compared to H+ ions, which are probably associated with some species dependent source and/or energization as well as loss processes in the inner magnetosphere."
WEN LI,Author correction: Enabling controlling complex networks with local topological information,
WEN LI,Skill complementarity enhances heterophily in collaboration networks,"Much empirical evidence shows that individuals usually exhibit significant homophily in social networks. We demonstrate, however, skill complementarity enhances heterophily in the formation of collaboration networks, where people prefer to forge social ties with people who have professions different from their own. We construct a model to quantify the heterophily by assuming that individuals choose collaborators to maximize utility. Using a huge database of online societies, we find evidence of heterophily in collaboration networks. The results of model calibration confirm the presence of heterophily. Both empirical analysis and model calibration show that the heterophilous feature is persistent along the evolution of online societies. Furthermore, the degree of skill complementarity is positively correlated with their production output. Our work sheds new light on the scientific research utility of virtual worlds for studying human behaviors in complex socioeconomic systems."
WEN LI,A universal power-law prescription for variability from synthetic images of black hole accretion flows,"We present a framework for characterizing the spatiotemporal power spectrum of the variability expected from the horizon-scale emission structure around supermassive black holes, and we apply this framework to a library of general relativistic magnetohydrodynamic (GRMHD) simulations and associated general relativistic ray-traced images relevant for Event Horizon Telescope (EHT) observations of Sgr A*. We find that the variability power spectrum is generically a red-noise process in both the temporal and spatial dimensions, with the peak in power occurring on the longest timescales and largest spatial scales. When both the time-averaged source structure and the spatially integrated light-curve variability are removed, the residual power spectrum exhibits a universal broken power-law behavior. On small spatial frequencies, the residual power spectrum rises as the square of the spatial frequency and is proportional to the variance in the centroid of emission. Beyond some peak in variability power, the residual power spectrum falls as that of the time-averaged source structure, which is similar across simulations; this behavior can be naturally explained if the variability arises from a multiplicative random field that has a steeper high-frequency power-law index than that of the time-averaged source structure. We briefly explore the ability of power spectral variability studies to constrain physical parameters relevant for the GRMHD simulations, which can be scaled to provide predictions for black holes in a range of systems in the optically thin regime. We present specific expectations for the behavior of the M87* and Sgr A* accretion flows as observed by the EHT."
WEN LI,Millimeter light curves of Sagittarius A* observed during the 2017 Event Horizon Telescope campaign,"The Event Horizon Telescope (EHT) observed the compact radio source, Sagittarius A* (Sgr A*), in the Galactic Center on 2017 April 5–11 in the 1.3 mm wavelength band. At the same time, interferometric array data from the Atacama Large Millimeter/submillimeter Array and the Submillimeter Array were collected, providing Sgr A* light curves simultaneous with the EHT observations. These data sets, complementing the EHT very long baseline interferometry, are characterized by a cadence and signal-to-noise ratio previously unattainable for Sgr A* at millimeter wavelengths, and they allow for the investigation of source variability on timescales as short as a minute. While most of the light curves correspond to a low variability state of Sgr A*, the April 11 observations follow an X-ray flare and exhibit strongly enhanced variability. All of the light curves are consistent with a red-noise process, with a power spectral density (PSD) slope measured to be between −2 and −3 on timescales between 1 minute and several hours. Our results indicate a steepening of the PSD slope for timescales shorter than 0.3 hr. The spectral energy distribution is flat at 220 GHz, and there are no time lags between the 213 and 229 GHz frequency bands, suggesting low optical depth for the event horizon scale source. We characterize Sgr A*’s variability, highlighting the different behavior observed just after the X-ray flare, and use Gaussian process modeling to extract a decorrelation timescale and a PSD slope. We also investigate the systematic calibration uncertainties by analyzing data from independent data reduction pipelines."
WEN LI,Selective dynamical imaging of interferometric data,"Recent developments in very long baseline interferometry (VLBI) have made it possible for the Event Horizon Telescope (EHT) to resolve the innermost accretion flows of the largest supermassive black holes on the sky. The sparse nature of the EHT’s (u, v)-coverage presents a challenge when attempting to resolve highly time-variable sources. We demonstrate that the changing (u, v)-coverage of the EHT can contain regions of time over the course of a single observation that facilitate dynamical imaging. These optimal time regions typically have projected baseline distributions that are approximately angularly isotropic and radially homogeneous. We derive a metric of coverage quality based on baseline isotropy and density that is capable of ranking array configurations by their ability to produce accurate dynamical reconstructions. We compare this metric to existing metrics in the literature and investigate their utility by performing dynamical reconstructions on synthetic data from simulated EHT observations of sources with simple orbital variability. We then use these results to make recommendations for imaging the 2017 EHT Sgr A* data set."
WEN LI,Relation between magnetosonic waves and pitch angle anisotropy of warm protons,"In the past decade, many observations of transversely heated low energy protons were reported in the inner magnetosphere. Interestingly, most of the time heated protons were observed along with magnetosonic waves. Due to the strong correlation, it was often assumed that magnetosonic waves were responsible for the heating of low energy protons. By performing a case study under unusually disturbed geomagnetic conditions, this paper unravels the controversial relationship between the observed pitch angle anisotropy of warm protons and the accompanying magnetosonic waves in the inner magnetosphere. We perform a comparative analysis involving two nearly identical cases of pitch angle anisotropy of warm protons in low L-shell region–one with magnetosonic waves and one without them. It is found that magnetosonic waves are not responsible for primary heating of low-energy protons and may just marginally alter the shape of the distribution of heated protons in the events analyzed. Based on the recent Cluster and POLAR observations, we also show how the recirculated polar wind plasma in the Earth’s magnetosphere can cause the concurrent appearance of heated protons and magnetosonic waves."
WEN LI,Simple spatial scaling rules behind complex cities,"Although most of wealth and innovation have been the result of human interaction and cooperation, we are not yet able to quantitatively predict the spatial distributions of three main elements of cities: population, roads, and socioeconomic interactions. By a simple model mainly based on spatial attraction and matching growth mechanisms, we reveal that the spatial scaling rules of these three elements are in a consistent framework, which allows us to use any single observation to infer the others. All numerical and theoretical results are consistent with empirical data from ten representative cities. In addition, our model can also provide a general explanation of the origins of the universal super- and sub-linear aggregate scaling laws and accurately predict kilometre-level socioeconomic activity. Our work opens a new avenue for uncovering the evolution of cities in terms of the interplay among urban elements, and it has a broad range of applications."
WEN LI,First Sagittarius A* Event Horizon Telescope results. VI. Testing the black hole metric,"Astrophysical black holes are expected to be described by the Kerr metric. This is the only stationary, vacuum, axisymmetric metric, without electromagnetic charge, that satisfies Einstein’s equations and does not have pathologies outside of the event horizon. We present new constraints on potential deviations from the Kerr prediction based on 2017 EHT observations of Sagittarius A* (Sgr A*). We calibrate the relationship between the geometrically defined black hole shadow and the observed size of the ring-like images using a library that includes both Kerr and non-Kerr simulations. We use the exquisite prior constraints on the mass-to-distance ratio for Sgr A* to show that the observed image size is within ∼10% of the Kerr predictions. We use these bounds to constrain metrics that are parametrically different from Kerr, as well as the charges of several known spacetimes. To consider alternatives to the presence of an event horizon, we explore the possibility that Sgr A* is a compact object with a surface that either absorbs and thermally reemits incident radiation or partially reflects it. Using the observed image size and the broadband spectrum of Sgr A*, we conclude that a thermal surface can be ruled out and a fully reflective one is unlikely. We compare our results to the broader landscape of gravitational tests. Together with the bounds found for stellar-mass black holes and the M87 black hole, our observations provide further support that the external spacetimes of all black holes are described by the Kerr metric, independent of their mass."
WEN LI,Polarimetric properties of Event Horizon Telescope targets from ALMA,"We present the results from a full polarization study carried out with the Atacama Large Millimeter/submillimeter Array (ALMA) during the first Very Long Baseline Interferometry (VLBI) campaign, which was conducted in 2017 April in the λ3 mm and λ1.3 mm bands, in concert with the Global mm-VLBI Array (GMVA) and the Event Horizon Telescope (EHT), respectively. We determine the polarization and Faraday properties of all VLBI targets, including Sgr A*, M87, and a dozen radio-loud active galactic nuclei (AGNs), in the two bands at several epochs in a time window of 10 days. We detect high linear polarization fractions (2%–15%) and large rotation measures (RM &gt; 103.3–105.5 rad m−2), confirming the trends of previous AGN studies at millimeter wavelengths. We find that blazars are more strongly polarized than other AGNs in the sample, while exhibiting (on average) order-of-magnitude lower RM values, consistent with the AGN viewing angle unification scheme. For Sgr A* we report a mean RM of (−4.2 ± 0.3) × 105 rad m−2 at 1.3 mm, consistent with measurements over the past decade and, for the first time, an RM of (–2.1 ± 0.1) × 105 rad m−2 at 3 mm, suggesting that about half of the Faraday rotation at 1.3 mm may occur between the 3 mm photosphere and the 1.3 mm source. We also report the first unambiguous measurement of RM toward the M87 nucleus at millimeter wavelengths, which undergoes significant changes in magnitude and sign reversals on a one year timescale, spanning the range from −1.2 to 0.3 × 105 rad m−2 at 3 mm and −4.1 to 1.5 × 105 rad m−2 at 1.3 mm. Given this time variability, we argue that, unlike the case of Sgr A*, the RM in M87 does not provide an accurate estimate of the mass accretion rate onto the black hole. We put forward a two-component model, comprised of a variable compact region and a static extended region, that can simultaneously explain the polarimetric properties observed by both the EHT (on horizon scales) and ALMA (which observes the combined emission from both components). These measurements provide critical constraints for the calibration, analysis, and interpretation of simultaneously obtained VLBI data with the EHT and GMVA."
WEN LI,"First Sagittarius A* Event Horizon Telescope results. IV. Variability, morphology, and black hole mass","In this paper we quantify the temporal variability and image morphology of the horizon-scale emission from Sgr A*, as observed by the EHT in 2017 April at a wavelength of 1.3 mm. We find that the Sgr A* data exhibit variability that exceeds what can be explained by the uncertainties in the data or by the effects of interstellar scattering. The magnitude of this variability can be a substantial fraction of the correlated flux density, reaching ∼100% on some baselines. Through an exploration of simple geometric source models, we demonstrate that ring-like morphologies provide better fits to the Sgr A* data than do other morphologies with comparable complexity. We develop two strategies for fitting static geometric ring models to the time-variable Sgr A* data; one strategy fits models to short segments of data over which the source is static and averages these independent fits, while the other fits models to the full data set using a parametric model for the structural variability power spectrum around the average source structure. Both geometric modeling and image-domain feature extraction techniques determine the ring diameter to be 51.8 ± 2.3 μas (68% credible intervals), with the ring thickness constrained to have an FWHM between ∼30% and 50% of the ring diameter. To bring the diameter measurements to a common physical scale, we calibrate them using synthetic data generated from GRMHD simulations. This calibration constrains the angular size of the gravitational radius to be 4.8_-0.7^+1.4 μas, which we combine with an independent distance measurement from maser parallaxes to determine the mass of Sgr A* to be 4.0_-0.6^+10^6 M⊙."
WEN LI,Quantitative assessment of Earth’s radiation belt modeling,"The “Quantitative Assessment of Radiation Belt Modeling” focus group was in place at Geospace Environment Modeling from 2014 to 2018. The overarching goals of this focus group were to bring together the current state‐of‐the‐art models for the acceleration, transport, and loss processes in Earth's radiation belts; develop event‐specific and global inputs of wave, plasma, and magnetic field to drive these models; and combine all these components to achieve a quantitative assessment of radiation belt modeling by validating against contemporary radiation belt measurements. This article briefly reviews the current understanding of radiation belt dynamics and related modeling efforts, summarizes the activities and accomplishments of the focus group, and discusses future directions."
WEN LI,"First Sagittarius A* Event Horizon Telescope results. II. EHT and multiwavelength observations, data processing, and calibration","We present Event Horizon Telescope (EHT) 1.3 mm measurements of the radio source located at the position of the supermassive black hole Sagittarius A* (Sgr A*), collected during the 2017 April 5–11 campaign. The observations were carried out with eight facilities at six locations across the globe. Novel calibration methods are employed to account for Sgr A*'s flux variability. The majority of the 1.3 mm emission arises from horizon scales, where intrinsic structural source variability is detected on timescales of minutes to hours. The effects of interstellar scattering on the image and its variability are found to be subdominant to intrinsic source structure. The calibrated visibility amplitudes, particularly the locations of the visibility minima, are broadly consistent with a blurred ring with a diameter of ∼50 μas, as determined in later works in this series. Contemporaneous multiwavelength monitoring of Sgr A* was performed at 22, 43, and 86 GHz and at near-infrared and X-ray wavelengths. Several X-ray flares from Sgr A* are detected by Chandra, one at low significance jointly with Swift on 2017 April 7 and the other at higher significance jointly with NuSTAR on 2017 April 11. The brighter April 11 flare is not observed simultaneously by the EHT but is followed by a significant increase in millimeter flux variability immediately after the X-ray outburst, indicating a likely connection in the emission physics near the event horizon. We compare Sgr A*’s broadband flux during the EHT campaign to its historical spectral energy distribution and find that both the quiescent emission and flare emission are consistent with its long-term behavior."
WEN LI,Broadband multi-wavelength properties of M87 during the 2017 Event Horizon Telescope campaign,"In 2017, the Event Horizon Telescope (EHT) Collaboration succeeded in capturing the first direct image of the center of the M87 galaxy. The asymmetric ring morphology and size are consistent with theoretical expectations for a weakly accreting supermassive black hole of mass ∼6.5 × 109 M ⊙. The EHTC also partnered with several international facilities in space and on the ground, to arrange an extensive, quasi-simultaneous multi-wavelength campaign. This Letter presents the results and analysis of this campaign, as well as the multi-wavelength data as a legacy data repository. We captured M87 in a historically low state, and the core flux dominates over HST-1 at high energies, making it possible to combine core flux constraints with the more spatially precise very long baseline interferometry data. We present the most complete simultaneous multi-wavelength spectrum of the active nucleus to date, and discuss the complexity and caveats of combining data from different spatial scales into one broadband spectrum. We apply two heuristic, isotropic leptonic single-zone models to provide insight into the basic source properties, but conclude that a structured jet is necessary to explain M87’s spectrum. We can exclude that the simultaneous γ-ray emission is produced via inverse Compton emission in the same region producing the EHT mm-band emission, and further conclude that the γ-rays can only be produced in the inner jets (inward of HST-1) if there are strongly particle-dominated regions. Direct synchrotron emission from accelerated protons and secondaries cannot yet be excluded."
WEN LI,Event Horizon Telescope imaging of the archetypal blazar 3C 279 at an extreme 20 microarcsecond resolution,"3C 279 is an archetypal blazar with a prominent radio jet that show broadband flux density variability across the entire electromagnetic spectrum. We use an ultra-high angular resolution technique – global Very Long Baseline Interferometry (VLBI) at 1.3 mm (230 GHz) – to resolve the innermost jet of 3C 279 in order to study its fine-scale morphology close to the jet base where highly variable γ-ray emission is thought to originate, according to various models. The source was observed during four days in April 2017 with the Event Horizon Telescope at 230 GHz, including the phased Atacama Large Millimeter/submillimeter Array (ALMA), at an angular resolution of ∼20 μas (at a redshift of z = 0.536 this corresponds to ∼0.13 pc  ∼ 1700 Schwarzschild radii with a black hole mass M<jats:sub>BH</jats:sub> = 8 × 10^8 M_⊙). Imaging and model-fitting techniques were applied to the data to parameterize the fine-scale source structure and its variation. We find a multicomponent inner jet morphology with the northernmost component elongated perpendicular to the direction of the jet, as imaged at longer wavelengths. The elongated nuclear structure is consistent on all four observing days and across different imaging methods and model-fitting techniques, and therefore appears robust. Owing to its compactness and brightness, we associate the northern nuclear structure as the VLBI “core”. This morphology can be interpreted as either a broad resolved jet base or a spatially bent jet. We also find significant day-to-day variations in the closure phases, which appear most pronounced on the triangles with the longest baselines. Our analysis shows that this variation is related to a systematic change of the source structure. Two inner jet components move non-radially at apparent speeds of ∼15 c and ∼20 c (∼1.3 and ∼1.7 μas day^−1, respectively), which more strongly supports the scenario of traveling shocks or instabilities in a bent, possibly rotating jet. The observed apparent speeds are also coincident with the 3C 279 large-scale jet kinematics observed at longer (cm) wavelengths, suggesting no significant jet acceleration between the 1.3 mm core and the outer jet. The intrinsic brightness temperature of the jet components are ≲10^10 K, a magnitude or more lower than typical values seen at ≥7 mm wavelengths. The low brightness temperature and morphological complexity suggest that the core region of 3C 279 becomes optically thin at short (mm) wavelengths."
WEN LI,Quantification of diffuse auroral electron precipitation driven by whistler mode waves at Jupiter,"While previous studies suggested whistler mode waves as a potential driver of Jupiter's diffuse aurora, their quantitative contribution to generate diffuse aurora remains unclear. We perform an in-depth analysis of an intriguing diffuse auroral electron precipitation event using coordinated observations of precipitating electrons and whistler mode waves from the Juno satellite. A physics-based technique is used to quantify energetic electron precipitation driven by whistler mode waves. We find that the modeled electron precipitation features are consistent with the electron measurements from several keV to several hundred keV over M-shells of 8–18, while additional mechanisms are needed to explain the observed electron precipitation at lower energies (<several keV). Our result provides new quantitative evidence that whistler mode waves are potentially a primary driver of precipitating electrons from several keV to several hundred keV through pitch angle scattering over M ∼ 8–18 and thus generate Jupiter's diffuse aurora."
WEN LI,First M87 Event Horizon Telescope results. II. Array and instrumentation,"The Event Horizon Telescope (EHT) is a very long baseline interferometry (VLBI) array that comprises millimeter- and submillimeter-wavelength telescopes separated by distances comparable to the diameter of the Earth. At a nominal operating wavelength of ~1.3 mm, EHT angular resolution (λ/D) is ~25 μas, which is sufficient to resolve nearby supermassive black hole candidates on spatial and temporal scales that correspond to their event horizons. With this capability, the EHT scientific goals are to probe general relativistic effects in the strong-field regime and to study accretion and relativistic jet formation near the black hole boundary. In this Letter we describe the system design of the EHT, detail the technology and instrumentation that enable observations, and provide measures of its performance. Meeting the EHT science objectives has required several key developments that have facilitated the robust extension of the VLBI technique to EHT observing wavelengths and the production of instrumentation that can be deployed on a heterogeneous array of existing telescopes and facilities. To meet sensitivity requirements, high-bandwidth digital systems were developed that process data at rates of 64 gigabit s−1, exceeding those of currently operating cm-wavelength VLBI arrays by more than an order of magnitude. Associated improvements include the development of phasing systems at array facilities, new receiver installation at several sites, and the deployment of hydrogen maser frequency standards to ensure coherent data capture across the array. These efforts led to the coordination and execution of the first Global EHT observations in 2017 April, and to event-horizon-scale imaging of the supermassive black hole candidate in M87."
WEN LI,First M87 Event Horizon Telescope results. I. The shadow of the supermassive black hole,"When surrounded by a transparent emission region, black holes are expected to reveal a dark shadow caused by gravitational light bending and photon capture at the event horizon. To image and study this phenomenon, we have assembled the Event Horizon Telescope, a global very long baseline interferometry array observing at a wavelength of 1.3 mm. This allows us to reconstruct event-horizon-scale images of the supermassive black hole candidate in the center of the giant elliptical galaxy M87. We have resolved the central compact radio source as an asymmetric bright emission ring with a diameter of 42 ± 3 μas, which is circular and encompasses a central depression in brightness with a flux ratio gsim10:1. The emission ring is recovered using different calibration and imaging schemes, with its diameter and width remaining stable over four different observations carried out in different days. Overall, the observed image is consistent with expectations for the shadow of a Kerr black hole as predicted by general relativity. The asymmetry in brightness in the ring can be explained in terms of relativistic beaming of the emission from a plasma rotating close to the speed of light around a black hole. We compare our images to an extensive library of ray-traced general-relativistic magnetohydrodynamic simulations of black holes and derive a central mass of M = (6.5 ± 0.7) × 10^9 M ⊙. Our radio-wave observations thus provide powerful evidence for the presence of supermassive black holes in centers of galaxies and as the central engines of active galactic nuclei. They also present a new tool to explore gravity in its most extreme limit and on a mass scale that was so far not accessible."
WEN LI,Genomic insights of body plan transitions from bilateral to pentameral symmetry in echinoderms,"Echinoderms are an exceptional group of bilaterians that develop pentameral adult symmetry from a bilaterally symmetric larva. However, the genetic basis in evolution and development of this unique transformation remains to be clarified. Here we report newly sequenced genomes, developmental transcriptomes, and proteomes of diverse echinoderms including the green sea urchin (L. variegatus), a sea cucumber (A. japonicus), and with particular emphasis on a sister group of the earliest-diverged echinoderms, the feather star (A. japonica). We learned that the last common ancestor of echinoderms retained a well-organized Hox cluster reminiscent of the hemichordate, and had gene sets involved in endoskeleton development. Further, unlike in other animal groups, the most conserved developmental stages were not at the body plan establishing phase, and genes normally involved in bilaterality appear to function in pentameric axis development. These results enhance our understanding of the divergence of protostomes and deuterostomes almost 500 Mya."
WEN LI,Unraveling the formation region and frequency of chorus spectral gaps,"Electromagnetic ion cyclotron (EMIC) waves could cause a simultaneous dropout of radiation belt electrons and ring current protons. However, their effects on the dropout of both plasma populations have not been quantified in previous studies. In this paper, we model the simultaneous dropout of MeV electrons and hundreds of keV protons observed by Van Allen Probes within ∼40 min on 27 February 2014. The wave and particle measurements during the period of most intense EMIC waves at 𝐿 ∼ 5.2 are used to calculate the quasilinear diffusion coefficients and simulate the evolution of both energetic electrons and protons. Our model well captures the dropout of electrons with energies >1 MeV and pitch angles <75°, and the concurrent dropout of protons with energies >200 keV and pitch angles >40°. This is the first modeling work quantitatively reproducing the simultaneous dropout of both populations due to EMIC wave scattering."
WEN LI,Derivedness index for estimating degree of phenotypic evolution of embryos: a study of comparative transcriptomic analyses of chordates and echinoderms,"Species retaining ancestral features, such as species called living fossils, are often regarded as less derived than their sister groups, but such discussions are usually based on qualitative enumeration of conserved traits. This approach creates a major barrier, especially when quantifying the degree of phenotypic evolution or degree of derivedness, since it focuses only on commonly shared traits, and newly acquired or lost traits are often overlooked. To provide a potential solution to this problem, especially for inter-species comparison of gene expression profiles, we propose a new method named ""derivedness index"" to quantify the degree of derivedness. In contrast to the conservation-based approach, which deals with expressions of commonly shared genes among species being compared, the derivedness index also considers those that were potentially lost or duplicated during evolution. By applying our method, we found that the gene expression profiles of penta-radial phases in echinoderm tended to be more highly derived than those of the bilateral phase. However, our results suggest that echinoderms may not have experienced much larger modifications to their developmental systems than chordates, at least at the transcriptomic level. In vertebrates, we found that the mid-embryonic and organogenesis stages were generally less derived than the earlier or later stages, indicating that the conserved phylotypic period is also less derived. We also found genes that potentially explain less derivedness, such as Hox genes. Finally, we highlight technical concerns that may influence the measured transcriptomic derivedness, such as read depth and library preparation protocols, for further improvement of our method through future studies. We anticipate that this index will serve as a quantitative guide in the search for constrained developmental phases or processes."
WEN LI,"Targeted micro-fiber arrays for measuring and manipulating localized multi-scale neural dynamics over large, deep brain volumes during behavior","Neural population dynamics relevant for behavior vary over multiple spatial and temporal scales across 3-dimensional volumes. Current optical approaches lack the spatial coverage and resolution necessary to measure and manipulate naturally occurring patterns of large-scale, distributed dynamics within and across deep brain regions such as the striatum. We designed a new micro-fiber array and imaging approach capable of chronically measuring and optogenetically manipulating local dynamics across over 100 targeted locations simultaneously in head-fixed and freely moving mice. We developed a semi-automated micro-CT based strategy to precisely localize positions of each optical fiber. This highly-customizable approach enables investigation of multi-scale spatial and temporal patterns of cell-type and neurotransmitter specific signals over arbitrary 3-D volumes at a spatial resolution and coverage previously inaccessible. We applied this method to resolve rapid dopamine release dynamics across the striatum volume which revealed distinct, modality specific spatiotemporal patterns in response to salient sensory stimuli extending over millimeters of tissue. Targeted optogenetics through our fiber arrays enabled flexible control of neural signaling on multiple spatial scales, better matching endogenous signaling patterns, and spatial localization of behavioral function across large circuits."
WEN LI,First Sagittarius A* Event Horizon Telescope results. III. Imaging of the Galactic center supermassive black hole,"We present the first event-horizon-scale images and spatiotemporal analysis of Sgr A* taken with the Event Horizon Telescope in 2017 April at a wavelength of 1.3 mm. Imaging of Sgr A* has been conducted through surveys over a wide range of imaging assumptions using the classical CLEAN algorithm, regularized maximum likelihood methods, and a Bayesian posterior sampling method. Different prescriptions have been used to account for scattering effects by the interstellar medium toward the Galactic center. Mitigation of the rapid intraday variability that characterizes Sgr A* has been carried out through the addition of a “variability noise budget” in the observed visibilities, facilitating the reconstruction of static full-track images. Our static reconstructions of Sgr A* can be clustered into four representative morphologies that correspond to ring images with three different azimuthal brightness distributions and a small cluster that contains diverse nonring morphologies. Based on our extensive analysis of the effects of sparse (u, v)-coverage, source variability, and interstellar scattering, as well as studies of simulated visibility data, we conclude that the Event Horizon Telescope Sgr A* data show compelling evidence for an image that is dominated by a bright ring of emission with a ring diameter of ∼50 μas, consistent with the expected “shadow” of a 4 × 106 M⊙ black hole in the Galactic center located at a distance of 8 kpc."
WEN LI,Characterizing and mitigating intraday variability: reconstructing source structure in accreting black holes with mm-VLBI,"The extraordinary physical resolution afforded by the Event Horizon Telescope has opened a window onto the astrophysical phenomena unfolding on horizon scales in two known black holes, M87* and Sgr A*. However, with this leap in resolution has come a new set of practical complications. Sgr A* exhibits intraday variability that violates the assumptions underlying Earth aperture synthesis, limiting traditional image reconstruction methods to short timescales and data sets with very sparse (u, v) coverage. We present a new set of tools to detect and mitigate this variability. We develop a data-driven, model-agnostic procedure to detect and characterize the spatial structure of intraday variability. This method is calibrated against a large set of mock data sets, producing an empirical estimator of the spatial power spectrum of the brightness fluctuations. We present a novel Bayesian noise modeling algorithm that simultaneously reconstructs an average image and statistical measure of the fluctuations about it using a parameterized form for the excess variance in the complex visibilities not otherwise explained by the statistical errors. These methods are validated using a variety of simulated data, including general relativistic magnetohydrodynamic simulations appropriate for Sgr A* and M87*. We find that the reconstructed source structure and variability are robust to changes in the underlying image model. We apply these methods to the 2017 EHT observations of M87*, finding evidence for variability across the EHT observing campaign. The variability mitigation strategies presented are widely applicable to very long baseline interferometry observations of variable sources generally, for which they provide a data-informed averaging procedure and natural characterization of inter-epoch image consistency."
WEN LI,Nonlinear interactions between radiation belt electrons and chorus waves: dependence on wave amplitude modulation,"We use test particle simulations to model the interaction between radiation belt electrons and whistler mode chorus waves by focusing on wave amplitude modulations. We quantify the pitch angle and energy changes due to phase trapping and phase bunching (including both advection and scattering) for electrons with various initial energies and pitch angles. Three nonlinear regimes are identified in a broad range of pitch angle-energy space systematically, each indicating different nonlinear effects. Our simulation results show that wave amplitude modulations can extend the nonlinear regimes, while significantly reducing electron acceleration by phase trapping. By including amplitude modulations, the “advective” changes in pitch angle and energy caused by phase bunching are reduced, while the “diffusive” scattering due to phase bunching is enhanced. Our study demonstrates the importance of wave amplitude modulations in nonlinear effects and suggests that they need to be properly incorporated into future theoretical and numerical studies."
WEN LI,Dependence of nonlinear effects on whistler-mode chorus wave bandwidth and amplitude: a perspective from diffusion coefficients,"The electron resonant interaction with whistler-mode waves is characterized by transport in pitch angle–energy space. We calculate electron diffusion and advection coefficients (a simplified characterization of transport) for a large range of electron pitch angle and energy using test particle simulations. Nonlinear effects are analyzed by comparing the diffusion coefficients using test particle simulations and quasilinear theory, and by evaluating the advection rates. Dependence of nonlinear effects on the wave amplitude and bandwidth of whistler-mode waves is evaluated by running test particle simulations with a broad range of wave amplitude and bandwidth. The maximum amplitudes where the quasilinear approach is valid are found to increase with increasing bandwidth, from 50 pT for narrowband waves to 300 pT for broadband waves at L-shell of 6. Moreover, interactions between intense whistler-mode waves and small pitch angle electrons lead to large positive advection, which limits the applicability of diffusion-based models. This study demonstrates the parameter range of the applicability of quasilinear theory and diffusion model for different wave amplitudes and frequency bandwidths of whistler-mode waves, which is critical for evaluating the effects of whistler-mode waves on energetic electrons in the Earth’s magnetosphere."
WEN LI,Dependence of nonlinear effects on whistler-mode wave bandwidth and amplitude: a perspective from diffusion coefficients,"The electron resonant interaction with whistler-mode waves is characterized by transport in pitch angle–energy space. We calculate electron diffusion and advection coefficients (a simplified characterization of transport) for a large range of electron pitch angle and energy using test particle simulations. Nonlinear effects are analyzed by comparing the diffusion coefficients using test particle simulations and quasilinear theory, and by evaluating the advection rates. Dependence of nonlinear effects on the wave amplitude and bandwidth of whistler-mode waves is evaluated by running test particle simulations with a broad range of wave amplitude and bandwidth. The maximum amplitudes where the quasilinear approach is valid are found to increase with increasing bandwidth, from 50 pT for narrowband waves to 300 pT for broadband waves at L-shell of 6. Moreover, interactions between intense whistler-mode waves and small pitch angle electrons lead to large positive advection, which limits the applicability of diffusion-based models. This study demonstrates the parameter range of the applicability of quasilinear theory and diffusion model for different wave amplitudes and frequency bandwidths of whistler-mode waves, which is critical for evaluating the effects of whistler-mode waves on energetic electrons in the Earth’s magnetosphere."
WEN LI,Quantitative assessment of radiation belt modeling,"The “Quantitative Assessment of Radiation Belt Modeling” focus group was in place at Geospace Environment Modeling from 2014 to 2018. The overarching goals of this focus group were to bring together the current state‐of‐the‐art models for the acceleration, transport, and loss processes in Earth's radiation belts; develop event‐specific and global inputs of wave, plasma, and magnetic field to drive these models; and combine all these components to achieve a quantitative assessment of radiation belt modeling by validating against contemporary radiation belt measurements. This article briefly reviews the current understanding of radiation belt dynamics and related modeling efforts, summarizes the activities and accomplishments of the focus group, and discusses future directions."
WEN LI,Analytical results for phase bunching in the pendulum model of wave-particle interactions,"[Radiation belt electrons are strongly affected by resonant interactions with cyclotron-resonant waves. In the case of a particle passing through resonance with a single, coherent wave, a Hamiltonian formulation is advantageous. With certain approximations, the Hamiltonian has the same form as that for a plane pendulum, leading to estimates of the change at resonance of the first adiabatic invariant I, energy, and pitch angle. In the case of large wave amplitude (relative to the spatial variation of the background magnetic field), the resonant change in I and its conjugate phase angle ξ are not diffusive but determined by nonlinear dynamics. A general analytical treatment of slow separatrix crossing has long been available and can be used to give the changes in I associated with “phase bunching,” including the detailed dependence on ξ, in the nonlinear regime. Here we review this treatment, evaluate it numerically, and relate it to previous analytical results for nonlinear wave-particle interactions. “Positive phase bunching” can occur for some particles even in the pendulum Hamiltonian approximation, though the fraction of such particles may be exponentially small.]"
WEN LI,Equations of motion near cyclotron resonance,"This work compares several versions of the equations of motion for a test particle encountering cyclotron resonance with a single, field-aligned whistler mode wave. The gyro-averaged Lorentz equation produces both widespread phase trapping (PT) and “positive phase bunching” of low pitch angle electrons by large amplitude waves. Approximations allow a Hamiltonian description to be reduced to a single pair of conjugate variables, which can account for PT as well as phase bunching at moderate pitch angle, and has recently been used to investigate this unexpected bahavior at low pitch angle. Here, numerical simulations using the Lorentz equation and several versions of Hamiltonian-based equations of motion are compared. Similar behavior at low pitch angle is found in each case."
WEN LI,The ELFIN mission,"The Electron Loss and Fields Investigation with a Spatio-Temporal Ambiguity-Resolving option (ELFIN-STAR, or heretoforth simply: ELFIN) mission comprises two identical 3-Unit (3U) CubeSats on a polar (∼93∘ inclination), nearly circular, low-Earth (∼450 km altitude) orbit. Launched on September 15, 2018, ELFIN is expected to have a >2.5 year lifetime. Its primary science objective is to resolve the mechanism of storm-time relativistic electron precipitation, for which electromagnetic ion cyclotron (EMIC) waves are a prime candidate. From its ionospheric vantage point, ELFIN uses its unique pitch-angle-resolving capability to determine whether measured relativistic electron pitch-angle and energy spectra within the loss cone bear the characteristic signatures of scattering by EMIC waves or whether such scattering may be due to other processes. Pairing identical ELFIN satellites with slowly-variable along-track separation allows disambiguation of spatial and temporal evolution of the precipitation over minutes-to-tens-of-minutes timescales, faster than the orbit period of a single low-altitude satellite (Torbit ∼ 90 min). Each satellite carries an energetic particle detector for electrons (EPDE) that measures 50 keV to 5 MeV electrons with Δ E/E < 40% and a fluxgate magnetometer (FGM) on a ∼72 cm boom that measures magnetic field waves (e.g., EMIC waves) in the range from DC to 5 Hz Nyquist (nominally) with <0.3 nT/sqrt(Hz) noise at 1 Hz. The spinning satellites (Tspin ∼ 3 s) are equipped with magnetorquers (air coils) that permit spin-up or -down and reorientation maneuvers. Using those, the spin axis is placed normal to the orbit plane (nominally), allowing full pitch-angle resolution twice per spin. An energetic particle detector for ions (EPDI) measures 250 keV - 5 MeV ions, addressing secondary science. Funded initially by CalSpace and the University Nanosat Program, ELFIN was selected for flight with joint support from NSF and NASA between 2014 and 2018 and launched by the ELaNa XVIII program on a Delta II rocket (with IceSatII as the primary). Mission operations are currently funded by NASA. Working under experienced UCLA mentors, with advice from The Aerospace Corporation and NASA personnel, more than 250 undergraduates have matured the ELFIN implementation strategy; developed the instruments, satellite, and ground systems and operate the two satellites. ELFIN's already high potential for cutting-edge science return is compounded by concurrent equatorial Heliophysics missions (THEMIS, Arase, Van Allen Probes, MMS) and ground stations. ELFIN's integrated data analysis approach, rapid dissemination strategies via the SPace Environment Data Analysis System (SPEDAS), and data coordination with the Heliophysics/Geospace System Observatory (H/GSO) optimize science yield, enabling the widest community benefits. Several storm-time events have already been captured and are presented herein to demonstrate ELFIN's data analysis methods and potential. These form the basis of on-going studies to resolve the primary mission science objective. Broad energy precipitation events, precipitation bands, and microbursts, clearly seen both at dawn and dusk, extend from tens of keV to >1 MeV. This broad energy range of precipitation indicates that multiple waves are providing scattering concurrently. Many observed events show significant backscattered fluxes, which in the past were hard to resolve by equatorial spacecraft or non-pitch-angle-resolving ionospheric missions. These observations suggest that the ionosphere plays a significant role in modifying magnetospheric electron fluxes and wave-particle interactions. Routine data captures starting in February 2020 and lasting for at least another year, approximately the remainder of the mission lifetime, are expected to provide a very rich dataset to address questions even beyond the primary mission science objective."
WEN LI,The polarized image of a synchrotron-emitting ring of gas orbiting a black hole,"Synchrotron radiation from hot gas near a black hole results in a polarized image. The image polarization is determined by effects including the orientation of the magnetic field in the emitting region, relativistic motion of the gas, strong gravitational lensing by the black hole, and parallel transport in the curved spacetime. We explore these effects using a simple model of an axisymmetric, equatorial accretion disk around a Schwarzschild black hole. By using an approximate expression for the null geodesics derived by Beloborodov and conservation of the Walker–Penrose constant, we provide analytic estimates for the image polarization. We test this model using currently favored general relativistic magnetohydrodynamic simulations of M87*, using ring parameters given by the simulations. For a subset of these with modest Faraday effects, we show that the ring model broadly reproduces the polarimetric image morphology. Our model also predicts the polarization evolution for compact flaring regions, such as those observed from Sgr A* with GRAVITY. With suitably chosen parameters, our simple model can reproduce the EVPA pattern and relative polarized intensity in Event Horizon Telescope images of M87*. Under the physically motivated assumption that the magnetic field trails the fluid velocity, this comparison is consistent with the clockwise rotation inferred from total intensity images."
WEN LI,First Sagittarius A* Event Horizon Telescope results. I. The shadow of the supermassive black hole in the center of the Milky Way,"We present the first Event Horizon Telescope (EHT) observations of Sagittarius A* (Sgr A*), the Galactic center source associated with a supermassive black hole. These observations were conducted in 2017 using a global interferometric array of eight telescopes operating at a wavelength of λ = 1.3 mm. The EHT data resolve a compact emission region with intrahour variability. A variety of imaging and modeling analyses all support an image that is dominated by a bright, thick ring with a diameter of 51.8 ± 2.3 μas (68% credible interval). The ring has modest azimuthal brightness asymmetry and a comparatively dim interior. Using a large suite of numerical simulations, we demonstrate that the EHT images of Sgr A* are consistent with the expected appearance of a Kerr black hole with mass ∼4 × 106 M ⊙, which is inferred to exist at this location based on previous infrared observations of individual stellar orbits, as well as maser proper-motion studies. Our model comparisons disfavor scenarios where the black hole is viewed at high inclination (i &gt; 50°), as well as nonspinning black holes and those with retrograde accretion disks. Our results provide direct evidence for the presence of a supermassive black hole at the center of the Milky Way, and for the first time we connect the predictions from dynamical measurements of stellar orbits on scales of 103–105 gravitational radii to event-horizon-scale images and variability. Furthermore, a comparison with the EHT results for the supermassive black hole M87* shows consistency with the predictions of general relativity spanning over three orders of magnitude in central mass."
WEN LI,"An event of extreme relativistic and ultra-relativistic electron enhancements following the arrival of consecutive corotating interaction regions: coordinated observations by Van Allen Probes, Arase, THEMIS and Galileo satellites","[During July to October of 2019, a sequence of isolated Corotating Interaction Regions (CIRs) impacted the magnetosphere, for four consecutive solar rotations, without any interposed Interplanetary Coronal Mass Ejections. Even though the series of CIRs resulted in relatively weak geomagnetic storms, the net effect of the outer radiation belt during each disturbance was different, depending on the electron energy. During the August-September CIR group, significant multi-MeV electron enhancements occurred, up to ultra-relativistic energies of 9.9 MeV in the heart of the outer Van Allen radiation belt. These characteristics deemed this time period a fine case for studying the different electron acceleration mechanisms. In order to do this, we exploited coordinated data from the Van Allen Probes, the Time History of Events and Macroscale Interactions during Substorms Mission (THEMIS), Arase and Galileo satellites, covering seed, relativistic and ultra-relativistic electron populations, investigating their Phase Space Density (PSD) profile dependence on the values of the second adiabatic invariant K, ranging from near-equatorial to off equatorial mirroring populations. Our results indicate that different acceleration mechanisms took place for different electron energies. The PSD profiles were dependent not only on the μ value, but also on the K value, with higher K values corresponding to more pronounced local acceleration by chorus waves. The 9.9 MeV electrons were enhanced prior to the 7.7 MeV, indicating that different mechanisms took effect on different populations. Finally, all ultra-relativistic enhancements took place below geosynchronous orbit, emphasizing the need for more Medium Earth Orbit (MEO) missions.]"
WEN LI,Interplay of source/seed electrons and wave-particle interactions in producing relativistic electron PSD enhancements in the outer Van Allen belt,"We perform a superposed epoch analysis on two groups of selected geospace disturbance events, emerging from single and isolated interplanetary drivers, and resulting in either the enhancement or the depletion of the average relativistic electron Phase Space Density (PSD). We investigate the occurrence of behavioural/temporal patterns of solar wind and geomagnetic parameters, chorus and ULF Pc5 wave activity, and the source/seed electron PSD in the outer Van Allen radiation belt. Our results indicate that the source electron population of μ = 10 MeV/G exhibits a similar behaviour during both event groups, while the μ = 1 MeV/G population can be considered as negligible for the whole process of wave excitation and electron energisation. Moreover, events that result in relativistic electron enhancement are characterised by statistically stronger and prolonged storm, substorm and wave activity, combined with an abundance of seed electrons of μ = 100 MeV/G, mostly at L* = 4–5, the nominal heart of the outer radiation belt."
YASUKO KANNO,Peripheral or marginal participation?,"For academically bound international students, university-based Intensive English Programs (IEPs) frequently function as an avenue to American undergraduate or graduate degree programs.  This qualitative study examined how one university-based IEP was preparing its academically bound international students and facilitating their transitions to matriculated study.  Lave and Wenger’s (1991) theory of Situated Learning was utilized to explore international students’ participation in the IEP as a community of practice and the IEP’s own marginality within the university structure.  We found that university-based IEPs can play a critical role in helping international students gain the competence and knowledge necessary to begin legitimate peripheral participation in degree programs.  However, the extent to which IEP students were able to participate in the larger university community was limited by the IEP’s own marginality in the university community and the fact that the IEP is ultimately not a discipline-specific community of practice."
YASUKO KANNO,"ESL programs at U.S. community colleges: a multistate analysis of placement tests, course offerings, and course content","When U.S. English learners (ELs) attend college, they are more likely to enroll in 2‐year community colleges than in 4‐year colleges. Prior research points to the tension between English as a second language (ESL) programs providing support to ELs and lengthy ESL programs acting as barriers to ELs seeking access to mainstream college coursework. Nevertheless, community college ELs and ESL programs remain understudied. The researchers investigated community college ESL placement, course sequence length, and types of ESL courses offered across the United States by examining the 2017–2018 catalogs of community colleges in nine states. Two hundred seventy‐two community college catalogs were analyzed. Findings include that 81% of colleges reported offering some ESL‐specific coursework and that ESL course sequences varied on average from 2.3 to 4.7 semesters in length across states. For most states studied, ESL courses were solely structured around skills‐based instruction. Furthermore, although general English placement information was accessible and often standardized within states, ESL placement information was rarely available and sometimes out of date. Based on these findings, the authors recommend that community college ESL programs implement valid placement procedures, award college credit for ESL coursework, and streamline student access to discipline‐specific academic and vocational content."
YASUKO KANNO,New editors’ introduction,
YASUKO KANNO,Teaching Hispanic restaurant workers: Translanguaging as culturally sustaining pedagogy,"In this article, we make a case for incorporating translanguaging pedagogy into the framework of Culturally Sustaining Pedagogy (CSP). Drawing on data from a one-year ethnographic study of an adult ESL program, we show how teachers believed in and attempted to create spaces for translanguaging and CSP, but in practice fell short. We conclude that translanguaging is most powerful when understood as a component of CSP but call for more research in this area."
YASUKO KANNO,High-performing English learners’ limited access to four-year college,"BACKGROUND: Currently, chances for English learners (ELs) to reach higher education in the U.S. are slim. Almost half of ELs do not attend postsecondary education (PSE), and access to four-year college is particularly limited. But we do not exactly know why. PURPOSE: To examine what inhibits ELs’ four-college access in the U.S., Bourdieu’s notion of habitus and a related concept of institutional habitus were used as the theoretical framework. RESEARCH DESIGN: A longitudinal, ethnographic investigation. The study tracked the college-choice experiences of two high-performing ELs who nonetheless elected to attend a local community college without applying to a single four-year institution. Data consist of interviews with the students and key staff members, classroom observations, and relevant documents. DATA ANALYSIS: The data on each EL were first qualitatively analyzed to create an overall picture of her college trajectory (within-case analysis); the cases were then compared with one another to identify common barriers to their college access (cross-case analysis). Data segments related to the school’s institutional habitus and the students’ individual habitus were extracted and coded, and patterns of the interplay between the two were identified. RESULTS: Three factors inhibiting ELs’ four-year college access were identified: (a) limited access to advanced-level college-preparatory courses; (b) underdeveloped college knowledge to effectively navigate college planning and application, and (c) linguistic insecurity about their English proficiency. The school’s institutional habitus highlighted ELs’ linguistic deficits and inclined educators to view highperforming ELs as community-college-bound. The students themselves internalized the deficit orientation and came to view community college as the only possible college choice for them. CONCLUSIONS: A fundamental reexamination of the deficit orientation to ELs’ linguistic and academic capabilities is necessary. ELs need to be placed in advanced college-preparatory courses commensurate with their abilities and provided with regular, frequent, and accessible college guidance."
YASUKO KANNO,Non-college-bound English learners as the underserved third: How students graduate from high school without being college- or career-ready,"Not all high school students go to college. Yet, because there is currently such a dominant emphasis on “college for all,” preparing non-college-bound students for career-readiness has received short shrift. This issue is particularly important for English learners (ELs) because close to half of high school ELs do not advance to postsecondary education. Through a longitudinal ethnography of two underperforming, non-college-bound ELs, I examine how and why a relatively well-resourced school allowed these students to graduate without college- and career-readiness. I argue that although there were substantial structural inequalities that led to the under-education of the two ELs, educators at the school were largely unaware of such barriers and attributed the ELs’ underachievement to the students’ own deficits. I counter this institutional deficit orientation with alternative stories of student assets that illuminate the substantial strengths and talents that the focal ELs possessed, which, if recognized and integrated into their education, could have led to career-readiness."
YASUKO KANNO,English learner as an intersectional identity,
MICHAEL ESTERMAN,Sustained attention training reduces spatial bias in Parkinson’s disease: a pilot case series,"Individuals with Parkinson’s disease (PD) commonly demonstrate lateralized spatial biases, which affect daily functioning. Those with PD with initial motor symptoms on the left body side (LPD) have reduced leftward attention, whereas PD with initial motor symptoms on the right side (RPD) may display reduced rightward attention. We investigated whether a sustained attention training program could help reduce these spatial biases. Four non-demented individuals with PD (2 LPD, 2 RPD) performed a visual search task before and after 1 month of computer training. Before training, all participants showed a significant spatial bias and after training, all participants’ spatial bias was eliminated."
TAMMY VIGIL,Facebook users’ engagement and perceived life satisfaction,"This study extends existing research on Facebook’s impact on users’ life satisfaction. The results from two surveys of college students demonstrate a tension between Facebook use and users’ perceived contentment with their lives. Existing literature indicates students use Facebook to enhance self-esteem, yet the results from this study connect increased Facebook use to lower self-reported levels of happiness. In particular, respondents’ interactions with photos and videos increase users’ dissatisfaction. This phenomenon may be due to the impact photos have on the ways users engage in social comparisons with Facebook “friends” and the self-construals they create based on these comparisons."
ALEVTINA GUSEVA,"Scandals, morality wars, and the field of reproductive surrogacy in Ukraine",
ALEVTINA GUSEVA,"Autonomy as empowerment, or how gendered power manifests itself in contemporary Russian families","What constitutes power in the household, and how much power do contemporary Russian women have vis-à-vis their husbands? Research on intrahousehold gendered power has typically focused on three contexts: employment and relative earnings, the division of household labor, and patterns of money management in the family. Here we focus on intrahousehold power as it pertains to access to household money, asking whether wives share equal control and decision-making power over family money with their husbands."
WEINING LU,Noninvasive Assessment of Antenatal Hydronephrosis in Mice Reveals a Critical Role for Robo2 in Maintaining Anti-Reflux Mechanism,"Antenatal hydronephrosis and vesicoureteral reflux (VUR) are common renal tract birth defects. We recently showed that disruption of the Robo2 gene is associated with VUR in humans and antenatal hydronephrosis in knockout mice. However, the natural history, causal relationship and developmental origins of these clinical conditions remain largely unclear. Although the hydronephrosis phenotype in Robo2 knockout mice has been attributed to the coexistence of ureteral reflux and obstruction in the same mice, this hypothesis has not been tested experimentally. Here we used noninvasive high- resolution micro-ultrasonography and pathological analysis to follow the progression of antenatal hydronephrosis in individual Robo2-deficient mice from embryo to adulthood. We found that hydronephrosis progressed continuously after birth with no spontaneous resolution. With the use of a microbubble ultrasound contrast agent and ultrasound-guided percutaneous aspiration, we demonstrated that antenatal hydronephrosis in Robo2-deficient mice is caused by high-grade VUR resulting from a dilated and incompetent ureterovesical junction rather than ureteral obstruction. We further documented Robo2 expression around the developing ureterovesical junction and identified early dilatation of ureteral orifice structures as a potential fetal origin of antenatal hydronephrosis and VUR. Our results thus demonstrate that Robo2 is crucial for the formation of a normal ureteral orifice and for the maintenance of an effective anti-reflux mechanism. This study also establishes a reproducible genetic mouse model of progressive antenatal hydronephrosis and primary high- grade VUR."
WEINING LU,Inhibitory Effects of Robo2 on Nephrin: A Crosstalk between Positive and Negative Signals Regulating Podocyte Structure,"Robo2 is the cell surface receptor for the repulsive guidance cue Slit and is involved in axon guidance and neuronal migration. Nephrin is a podocyte slit- diaphragm protein that functions in the kidney glomerular filtration barrier. Here, we report that Robo2 is expressed at the basal surface of mouse podocytes and colocalizes with nephrin. Biochemical studies indicate that Robo2 forms a complex with nephrin in the kidney through adaptor protein Nck. In contrast to the role of nephrin that promotes actin polymerization, Slit2-Robo2 signaling inhibits nephrin-induced actin polymerization. In addition, the amount of F-actin associated with nephrin is increased in Robo2 knockout mice that develop an altered podocyte foot process structure. Genetic interaction study further reveals that loss of Robo2 alleviates the abnormal podocyte structural pheno- type in nephrin null mice. These results suggest that Robo2 signaling acts as a negative regulator on neph- rin to influence podocyte foot process architecture."
WEINING LU,NFIA Haploinsufficiency Is Associated with a CNS Malformation Syndrome and Urinary Tract Defects,"Complex central nervous system (CNS) malformations frequently coexist with other developmental abnormalities, but whether the associated defects share a common genetic basis is often unclear. We describe five individuals who share phenotypically related CNS malformations and in some cases urinary tract defects, and also haploinsufficiency for the NFIA transcription factor gene due to chromosomal translocation or deletion. Two individuals have balanced translocations that disrupt NFIA. A third individual and two half-siblings in an unrelated family have interstitial microdeletions that include NFIA. All five individuals exhibit similar CNS malformations consisting of a thin, hypoplastic, or absent corpus callosum, and hydrocephalus or ventriculomegaly. The majority of these individuals also exhibit Chiari type I malformation, tethered spinal cord, and urinary tract defects that include vesicoureteral reflux. Other genes are also broken or deleted in all five individuals, and may contribute to the phenotype. However, the only common genetic defect is NFIA haploinsufficiency. In addition, previous analyses of Nfia−/− knockout mice indicate that Nfia deficiency also results in hydrocephalus and agenesis of the corpus callosum. Further investigation of the mouse Nfia+/− and Nfia−/− phenotypes now reveals that, at reduced penetrance, Nfia is also required in a dosage-sensitive manner for ureteral and renal development. Nfia is expressed in the developing ureter and metanephric mesenchyme, and Nfia+/− and Nfia−/− mice exhibit abnormalities of the ureteropelvic and ureterovesical junctions, as well as bifid and megaureter. Collectively, the mouse Nfia mutant phenotype and the common features among these five human cases indicate that NFIA haploinsufficiency contributes to a novel human CNS malformation syndrome that can also include ureteral and renal defects. Author Summary Central nervous system (CNS) and urinary tract abnormalities are common human malformations, but their variability and genetic complexity make it difficult to identify the responsible genes. Analysis of human chromosomal abnormalities associated with such disorders offers one approach to this problem. In five individuals described herein, a novel human syndrome that involves both CNS and urinary tract defects is associated with chromosomal disruption or deletion of NFIA, encoding a member of the Nuclear Factor I (NFI) family of transcription factors. This syndrome includes brain abnormalities (abnormal corpus callosum, hydrocephalus, ventriculomegaly, and Chiari type I malformation), spinal abnormalities (tethered spinal cord), and urinary tract abnormalities (vesicoureteral reflux). Nfia disruption in mice was already known to cause hydrocephalus and abnormal corpus callosum, and is now shown to exhibit renal defects and disturbed ureteral development. Other genes besides NFIA are also disrupted or deleted and may contribute to the observed phenotype. However, loss of one copy of NFIA is the only genetic defect common to all five patients. The authors thus provide evidence that genetic loss of NFIA contributes to a distinct CNS malformation syndrome with urinary tract defects of variable penetrance."
SCOTT ROBERTSON,"Abstract, classic, and explicit turnpikes","Portfolio turnpikes state that, as the investment horizon increases, optimal portfolios for generic utilities converge to those of isoelastic utilities. This paper proves three kinds of turn- pikes. In a general semimartingale setting, the abstract turnpike states that optimal final payoffs and portfolios converge under their myopic probabilities. In diffusion models with several assets and a single state variable, the classic turnpike demonstrates that optimal portfolios converge un- der the physical probability; meanwhile the explicit turnpike identifies the limit of finite-horizon optimal portfolios as a long-run myopic portfolio defined in terms of the solution of an ergodic HJB equation."
SCOTT ROBERTSON,Predicting attitudinal and behavioral responses to COVID-19 pandemic using machine learning,"At the beginning of 2020, COVID-19 became a global problem. Despite all the efforts to emphasize the relevance of preventive measures, not everyone adhered to them. Thus, learning more about the characteristics determining attitudinal and behavioral responses to the pandemic is crucial to improving future interventions. In this study, we applied machine learning on the multinational data collected by the International Collaboration on the Social and Moral Psychology of COVID-19 (N = 51,404) to test the predictive efficacy of constructs from social, moral, cognitive, and personality psychology, as well as socio-demographic factors, in the attitudinal and behavioral responses to the pandemic. The results point to several valuable insights. Internalized moral identity provided the most consistent predictive contribution-individuals perceiving moral traits as central to their self-concept reported higher adherence to preventive measures. Similar results were found for morality as cooperation, symbolized moral identity, self-control, open-mindedness, and collective narcissism, while the inverse relationship was evident for the endorsement of conspiracy theories. However, we also found a non-neglible variability in the explained variance and predictive contributions with respect to macro-level factors such as the pandemic stage or cultural region. Overall, the results underscore the importance of morality-related and contextual factors in understanding adherence to public health recommendations during the pandemic."
SCOTT ROBERTSON,Small molecule inhibitors of Late SV40 Factor (LSF) abrogate hepatocellular carcinoma (HCC): evaluation using an endogenous HCC model,"Hepatocellular carcinoma (HCC) is a lethal malignancy with high mortality and poor prognosis. Oncogenic transcription factor Late SV40 Factor (LSF) plays an important role in promoting HCC. A small molecule inhibitor of LSF, Factor Quinolinone Inhibitor 1 (FQI1), significantly inhibited human HCC xenografts in nude mice without harming normal cells. Here we evaluated the efficacy of FQI1 and another inhibitor, FQI2, in inhibiting endogenous hepatocarcinogenesis. HCC was induced in a transgenic mouse with hepatocyte-specific overexpression of c-myc (Alb/c-myc) by injecting N-nitrosodiethylamine (DEN) followed by FQI1 or FQI2 treatment after tumor development. LSF inhibitors markedly decreased tumor burden in Alb/c-myc mice with a corresponding decrease in proliferation and angiogenesis. Interestingly, in vitro treatment of human HCC cells with LSF inhibitors resulted in mitotic arrest with an accompanying increase in CyclinB1. Inhibition of CyclinB1 induction by Cycloheximide or CDK1 activity by Roscovitine significantly prevented FQI-induced mitotic arrest. A significant induction of apoptosis was also observed upon treatment with FQI. These effects of LSF inhibition, mitotic arrest and induction of apoptosis by FQI1s provide multiple avenues by which these inhibitors eliminate HCC cells. LSF inhibitors might be highly potent and effective therapeutics for HCC either alone or in combination with currently existing therapies."
JENNIFER ROSS,"Caribbean Corals in Crisis: Record Thermal Stress, Bleaching, and Mortality in 2005","BACKGROUND. The rising temperature of the world's oceans has become a major threat to coral reefs globally as the severity and frequency of mass coral bleaching and mortality events increase. In 2005, high ocean temperatures in the tropical Atlantic and Caribbean resulted in the most severe bleaching event ever recorded in the basin. METHODOLOGY/PRINCIPAL FINDINGS. Satellite-based tools provided warnings for coral reef managers and scientists, guiding both the timing and location of researchers' field observations as anomalously warm conditions developed and spread across the greater Caribbean region from June to October 2005. Field surveys of bleaching and mortality exceeded prior efforts in detail and extent, and provided a new standard for documenting the effects of bleaching and for testing nowcast and forecast products. Collaborators from 22 countries undertook the most comprehensive documentation of basin-scale bleaching to date and found that over 80% of corals bleached and over 40% died at many sites. The most severe bleaching coincided with waters nearest a western Atlantic warm pool that was centered off the northern end of the Lesser Antilles. CONCLUSIONS/SIGNIFICANCE. Thermal stress during the 2005 event exceeded any observed from the Caribbean in the prior 20 years, and regionally-averaged temperatures were the warmest in over 150 years. Comparison of satellite data against field surveys demonstrated a significant predictive relationship between accumulated heat stress (measured using NOAA Coral Reef Watch's Degree Heating Weeks) and bleaching intensity. This severe, widespread bleaching and mortality will undoubtedly have long-term consequences for reef ecosystems and suggests a troubled future for tropical marine ecosystems under a warming climate."
JENNIFER ROSS,Reproductive inequality in humans and other mammals,"To address claims of human exceptionalism, we determine where humans fit within the greater mammalian distribution of reproductive inequality. We show that humans exhibit lower reproductive skew (i.e., inequality in the number of surviving offspring) among males and smaller sex differences in reproductive skew than most other mammals, while nevertheless falling within the mammalian range. Additionally, female reproductive skew is higher in polygynous human populations than in polygynous nonhumans mammals on average. This patterning of skew can be attributed in part to the prevalence of monogamy in humans compared to the predominance of polygyny in nonhuman mammals, to the limited degree of polygyny in the human societies that practice it, and to the importance of unequally held rival resources to women's fitness. The muted reproductive inequality observed in humans appears to be linked to several unusual characteristics of our species-including high levels of cooperation among males, high dependence on unequally held rival resources, complementarities between maternal and paternal investment, as well as social and legal institutions that enforce monogamous norms."
HIROAKI KAIDO,Constraint qualifications in partial identification,"The literature on stochastic programming typically regularizes problems using so-called Constraint Qualifications. The literature on estimation and inference under partial identification frequently restricts the geometry of identified sets with diverse high-level assumptions. These superficially appear to be different approaches to closely related problems. We extensively analyze their relation. Among other things, we show that for partial identification through pure moment inequalities, numerous regularization assumptions from the literature essentially coincide with the Mangasarian-Fromowitz Constraint Qualification. This clarifies the relation between well-known contributions, including within econometrics, and elucidates stringency, as well as ease of verification, of some high-level assumptions in seminal papers."
HIROAKI KAIDO,Moment inequalities in the context of simulated and predicted variables,"This paper explores the effects of simulated moments on the performance of inference methods based on moment inequalities. Commonly used confidence sets for parameters are level sets of criterion functions whose boundary points may depend on sample moments in an irregular manner. Due to this feature, simulation errors can affect the performance of inference in non-standard ways. In particular, a (first-order) bias due to the simulation errors may remain in the estimated boundary of the confidence set. We demonstrate, through Monte Carlo experiments, that simulation errors can significantly reduce the coverage probabilities of confidence sets in small samples. The size distortion is particularly severe when the number of inequality restrictions is large. These results highlight the danger of ignoring the sampling variations due to the simulation errors in moment inequality models. Similar issues arise when using predicted variables in moment inequalities models. We propose a method for properly correcting for these variations based on regularizing the intersection of moments in parameter space, and we show that our proposed method performs well theoretically and in practice."
LESLIE DIETIKER,Understanding linear measure,This article provides strategies for enhancing tasks to offer students better opportunities to develop conceptual understanding of length measurement. Teachers are offered strategies that help move instruction beyond procedures.
LESLIE DIETIKER,Mathematical story: a metaphor for mathematics curriculum,"This paper proposes a theoretical framework for interpreting mathematical content found in mathematics curriculum in order to offer teachers and other mathematics educators comprehensive conceptual tools with which to make curricular decisions. More specifically, it describes a metaphor of mathematics curriculum as story and defines and illustrates the mathematical story elements of mathematical characters, action, setting, and plot. Drawn from literary theory, this framework supports the interpretation of mathematics curriculum as art, able to stimulate the imagination and curiosity of students and teachers alike. In doing so, it is argued, this framework offers teachers and other curriculum designers a conceptual tool that can be used to improve the mathematics curriculum offered to students in terms of both logic and aesthetic."
LESLIE DIETIKER,Shaping mathematics into compelling stories: A curriculum design heuristic,"This article describes a mathematics curriculum design heuristic that was developed and used in the design of CPM Educational Program textbooks. It introduces a metaphor of mathematics curriculum as a narrative story, which allows for the design of mathematical experiences that emotionally moves students and teachers and compels them to engage. Specifically, it explains how curiosity and surprise can be intentionally designed within a mathematical sequence of curricular elements, such as tasks. Background that spurred the development of the mathematical story framework is offered and examples from designing lessons for Algebra and middle school are provided."
LESLIE DIETIKER,Mathematics texts as narrative: Rethinking curriculum,
LESLIE DIETIKER,"Woo! Aesthetic variations of the ""same"" lesson","Efforts to enhance the aesthetic impact of mathematics lessons must account for the role of teachers in shaping the unfolding mathematical content of their enacted lessons. In this paper, we draw from Dietiker (2015) to describe differences in the mathematical stories of the enacted lessons of two veteran teachers teaching the same lesson. We identify connections between these differences and the variations in student experiences as illustrated by visible student reactions."
LESLIE DIETIKER,Opportunities created by misdirection in mathematics education,"This study provides evidence that enacted lessons based on written curriculum do not need to follow a direct curricular path from beginning to end. Deviations in this path, which we refer to as misdirection, can create opportunities for enhanced student interest in mathematical questions. We present three examples of misdirection from two enacted lessons and describe how they intensified student investment in the mathematics by creating contradictions that inspired students to ask their own mathematical questions. These examples can serve as models to teachers and curriculum writers who seek ways to motivate students to pursue mathematical understanding."
LESLIE DIETIKER,Mathematics lessons as stories: A reason to do the math,
LESLIE DIETIKER,Generating student interest with mathematical stories,"Imagine you are planning an algebra lesson involving the roots of quadratic equations, and you have decided to base your lesson on the three tasks listed in figure 1. Assuming that your students have some experience with factoring quadratics, solving equations, and graphing, but no experience with completing the square, calculating a vertex, or quadratic formula, consider how you might sequence these tasks. How might the potential mathematical goals change based on the sequence? Are there any benefits to student interest or engagement by ordering the tasks in one sequence over another? Note: The reader is encouraged to solve these tasks as algebra students and consider these questions before proceeding. You may be surprised at what you find. The tasks have been provided in a form that allows a reader to cut them apart and experiment with different sequences."
LESLIE DIETIKER,Inside the envelope: Describing the influence of curriculum materials on enacted lessons,
LESLIE DIETIKER,The role of sequence in the experience of mathematical beauty,"In this article, I analyze the aesthetic dimensions of a sequence of mathematical events found in an unusual first grade lesson in order to demonstrate how sequencing may affect an individual’s experience of mathematical beauty. By approaching aesthetic as a sense or felt quality of an experience in context (Sinclair, 2001, 2011), this analysis explains how sequence can affect the way mathematical objects or actions are experienced by an individual. Thus, rather than questioning whether or in what ways a set of mathematical objects are beautiful or not, this paper addresses under what conditions is the mathematics in play beautiful. It is argued that with a better understanding of the temporal dimension of mathematical beauty, educational experiences with mathematics can be designed to captivate attention and nurture interest and positive disposition by students toward mathematics."
LESLIE DIETIKER,The plot thickens: The aesthetic dimensions of a captivating mathematics lesson,"We present an analysis of a sixth-grade mathematics lesson in which an aesthetically-rich moment of mathematical surprise, inspired by a decontextualized integer addition problem, spurred students to ask mathematical questions and actively sustain inquiry into the lesson’s central ideas. In order to understand how the unfolding mathematical content enabled this moment, we interpret the lesson as a mathematical story. Using this narrative framework, we describe the aesthetic dimensions of the story including its plot, density, coherence, and rhythm, and connect them to the unfolding mathematical content. This analysis demonstrates how these aesthetic elements of a lesson can be recognized and how they help explain the students’ productive engagement. This framework offers a potential tool for researchers and practitioners who seek to understand, design, and enact captivating mathematical experiences."
LESLIE DIETIKER,Design (In)Tensions in mathematics curriculum,"Designers of curriculum materials have intentions, which are goals and visions for what will happen in the classroom and the way that mathematics will be experienced by students and a teacher. These perspectives inform design decisions that aim to enable teachers to enact this vision and achieve these goals in expected contexts. Yet teachers and students have their own goals and visions, or different contextual conditions, that may be different from or even at odds with those of the curriculum designers. These potential differences result in design tensions, which reflect the conflicting demands on the curriculum materials. In this article, we call attention to multiple dimensions of design tensions that are central to the broader goals of curriculum reform."
LESLIE DIETIKER,What do teachers attend to in curriculum materials?,"In this paper, we describe an emerging methodology using eye tracking to explore teachers’ curricular attending as they interact with curriculum materials to design a lesson in order to learn what teachers pay attention to and how this attention shifts during planning. We propose affordances of this new method, remark on some of its limitations, and propose future directions."
LESLIE DIETIKER,The changing expectations for the reading of geometric diagrams,"Students studying geometry at the secondary level are expected to read diagrams in different ways than those in elementary school. In this paper, we present an analysis of the changes in diagrammatic expectations by comparing the geometric diagrams found in Grade 1 U.S. textbooks with those in U.S. high school geometry textbooks. This work included developing and using a coding scheme that recognizes dimensions of reading a diagram geometrically, including the type of object represented, use of deduction, use of mental redrawing, interpretation of markings, and the necessity of the diagram. The way in which elementary and secondary students are expected to interpret diagrams was shown to change along several of these dimensions, posing potential learning barriers for students. We end our paper with a discussion of what our results mean for the learning of geometry."
LESLIE DIETIKER,Collective noticing of teacher lesson design,
LESLIE DIETIKER,Impact of lesson design on teacher and student mathematical questions,"How does the design of lessons impact the types of questions teachers and students ask during enacted high school mathematics lessons? In this study, we present data suggesting that lessons designed with the mathematical story framework in order to elicit a specific aesthetic response (“MCLEs”) have a positive influence on the types of teacher and student questions asked during the lesson. Our findings suggest that when teachers plan and enact lessons with the mathematical story framework, teachers and students are more likely to ask questions that explore mathematical relationships and focus on meaning-making. In addition, teachers are less likely to ask short recall or procedural questions in MCLEs. These findings point to the role of lesson design in the quality of questions asked by teachers and students."
LESLIE DIETIKER,What makes a mathematics lesson interesting to students?,"How can we design mathematical lessons that spark student interest? To answer this, we analyzed teacher-designed and enacted lessons that students described as interesting for how the content unfolded. When compared to those the same students describe as uninteresting, multiple distinguishing characteristics are evident, such as the presence of misdirection, mathematical questions that remain unanswered for extended time, and a greater number of questions that are unanswered at each point of the lesson. Low-interest lessons did not contain many special narrative features and mostly had questions that were answered immediately. Our findings offer guidance for the design of lessons that can shift student mathematical dispositions."
LESLIE DIETIKER,Characterizing coherence within enacted mathematics lessons,"Curricular coherence has been emphasized by leaders in mathematics education as it enhances deeper understanding by enabling students to see connections between mathematical ideas. Although there are different forms of curricular coherence, the coherence of lesson has received considerably less attention. Little is known about what constitutes coherent lessons or how to measure the degree of coherence. Using the data from a larger study in which lessons are intentionally designed for coherence, we propose a tool for examining lesson coherence and describe characteristics of the lessons with different levels of coherence."
LESLIE DIETIKER,Engaging learners with plot twists,
LESLIE DIETIKER,How textbooks can promote inquiry: using a narrative framework to investigate the design of mathematical content in a lesson,
LESLIE DIETIKER,When is an exploration exploratory?  A comparative analysis of geometry lessons,"This paper presents a comparative analysis of two textbook lessons on the same topic from U.S. textbooks to learn how differently - designed “exploratory” lessons may structure content to enable or constrain student inquiry. One lesson, representative of a “reform - based” textbook, contains investigations of conditions of triangle congruence. The second is a “technology lab” on triangle congruence fro m a ""traditional"" textbook, the design of which is atypical for that textbook. Framing a lesson as a mathematical story, this analysis exposes three distinct ways that these lessons are different: (a) the proportion of the lesson in which mathematical questions remain unanswered, (b) the manner in which content unfolds to address each question, and (c) the way in which open mathematical questions overlap to increase the dynamically - changing number of questions that are pursued. This contrast of the two lessons illuminates how a lesson structure can prevent an ""exploration"" from being exploratory."
LESLIE DIETIKER,Exposing the mathematical differences between enactments of the same written lesson,"In this paper we respond to Huntley and Heck’s 2014 call for new conceptual frameworks that recognize mathematical differences between enactments of the same written lessons that stick “closely” to the textbook. We use a mathematical story framework to describe differences in the mathematical development of three enactments of the same algebra 1 lesson by three different experienced teachers. We find and document differences in how the lessons raise questions, sustain inquiry (or not), and progress toward resolution of the questions. These differences influence the overall mathematical and temporal structure of the enactments, which, in turn, affect the student experience and potentially affect student opportunities to learn."
LESLIE DIETIKER,Narrative characteristics of captivating secondary mathematics lessons,"Why do some mathematics lessons captivate high school students and others not? This study explores this question by comparing how the content unfolds in the lessons that students rated highest with respect to their aesthetic affordances (e.g., using terms like “intriguing,” “surprising”) with those the same students rated lowest with respect to their aesthetic affordances (e.g., “just ok,” “dull”). Using a framework that interprets the unfolding content across a lesson as a mathematical story, we examine how some lessons can provoke curiosity or enable surprise. We identify eight characteristics that distinguish captivating lessons and show how some, such as the average number of questions under consideration at any point in the lesson, are strongly related to student aesthetic experiences. In addition, the lessons that students described as more interesting included more instances of misdirection, such as when students’ false assumptions provide opportunities for surprising results. These findings point to the characteristics of future lesson designs that could enable more students to experience curiosity and wonder in secondary mathematics classrooms."
LESLIE DIETIKER,THAT’S CRAZY: An exploration of student exclamations in high school mathematics lessons,"In this study, we explore the relationships between the types of student exclamations in an enacted lesson (e.g., “Wow!”) and the varying dramatic tensions created by the unfolding content. By analyzing student exclamations in six specially-designed high school mathematics lessons, we explore how the dynamic tension between revelations of mathematical ideas at the moment and what is yet to be known connects with the aesthetic pull to react by the student. As students work through novel problems with limited information, their joys and frustrations are expressed in the form of exclamations."
LESLIE DIETIKER,Relevance as perceived by high school students in decontextualized mathematics lessons,
LESLIE DIETIKER,The integration of mathematical and social justice content in secondary lessons for social justice,
LESLIE DIETIKER,How the teacher and students impact the unfolding of mathematical ideas across a lesson,
LESLIE DIETIKER,The aesthetic effects of a new lesson design approach: mathematical stories,"Research suggests that high school students often have negative experiences with mathematics. To address this challenge, this paper shares findings of a design-based research project in which researchers and teachers developed and used a narrative approach to lesson planning in order to design lesson experiences that provide opportunities for high school students to become captivated with mathematical content (“CMLs”). The goal of this approach is to provide students positive aesthetic opportunities, such as inspiring student curiosity, while maintaining cognitive demand and coherence. Overall, students reported more positive, varied aesthetic experiences (e.g., suspense, surprise) in CMLs than in other lessons with the same teacher and students. These findings provide evidence that designing lessons as mathematical stories shows promise and can offer students more positive aesthetic experiences in mathematics."
LESLIE DIETIKER,“Oh! That’s Interesting!”: Captivating students who hate mathematics with mathematical ideas,"Research suggests that high school students often have negative experiences with mathematics. To address this challenge, this paper shares findings of a design-based research project in which researchers and teachers developed and used a narrative approach to lesson planning in order to design lesson experiences that provide opportunities for high school students to become captivated with mathematical content (“CMLs”). The goal of this approach is to provide students positive aesthetic opportunities, such as inspiring student curiosity, while maintaining cognitive demand and coherence. Overall, students reported more positive, varied aesthetic experiences (e.g., suspense, surprise) in CMLs than in other lessons with the same teacher and students. These findings provide evidence that designing lessons as mathematical stories shows promise and can offer students more positive aesthetic experiences in mathematics."
LESLIE DIETIKER,Aesthetic and affective dimensions of mathematics learning. Working group,"Students’ aesthetic and affective responses are interrelated and both central to mathematics learning. This working group will continue the conversation begun in 2022 to explore the connection between the affective and aesthetic dimensions of mathematics education, and how connecting these dimensions can help to understand how students experience mathematics. The goals of this working group are to evaluate the state of the field, build shared terms, and identify research questions for further inquiry."
LESLIE DIETIKER,Opportunities in social justice mathematics curriculum: analyzing high school algebra lessons,"This paper describes the opportunities for students in social justice mathematics (“SJM”) curricula designed for high school algebra students. We looked for opportunities for students to make sense of intersectional identities, take political action, and experience rich and expansive mathematical activities. Across 16 lessons, a majority have a strong emphasis on middle school, early-sequence linear functions, and statistics content. Additionally, the social action available to students within the classroom setting tends to be more on understanding contexts and less on using mathematics as a catalyst for identity attunement and community change. With these results, we make recommendations for future development of SJM materials that offer a wide spectrum of opportunities, designed in collaboration with local communities."
LESLIE DIETIKER,Curricular noticing: A comprehensive framework to describe teachers’ interactions with curriculum materials,"Building on the work of Professional Noticing of Children’s Mathematical Thinking, we introduce the Curricular Noticing Framework to describe how teachers recognize opportunities within curriculum materials, understand their affordances and limitations, and use strategies to act on them. This framework builds on Remillard’s (2005) notion of participation with curriculum materials, connects with and broadens existing research on the relationship between teachers and written curriculum, and highlights new are as for research. We argue that once mathematics educators better understand the strategic curricular practices that support ambitious teaching, which we refer to as professional curricular noticing, then this knowledge can lead to recommendations for how to support the curricular work of teachers, particularly novice teachers."
DANIEL COLE,Subharmonic resonance and critical eccentricity for the classical hydrogen atomic system,"Subharmonic resonance behaviors are investigated for the classical hy- drogen atom, with classical radiation damping and circularly polarized light acting on the classical electron. This study is intended for both potential experimental applications as well as for deeper theoretical pur- poses. Long resonant states are predicted for realistic Rydberg atoms and highly excited hydrogen states. Several previously undiscovered physical e¤ects are predicted. First, the semimajor axis remains relatively con- stant when in subharmonic resonance; second, the eccentricity steadily increases until a maximum, critical value is reached, at which point or- bital decay sets in. If the initial orbit is circular, this critical eccentricity value is shown to always be the same for each subharmonic condition, regardless of the initial orbital radius. An analytic derivation for this re- sult is presented. The illustrated dynamics are of interest for the classical theory of stochastic electrodynamics (SED) regarding whether SED can fundamentally describe more of quantum phenomena, particularly atomic excited state behavior and related emission and absorption spectra. Also of interest are how classical resonances can be imposed on a near con- tinuum of quantum states. Finally, there may be future technological applications, such as reading and writing information into Rydberg atoms in the form of subharmonic resonances."
DANIEL COLE,"Bostonia: v. 10, no. 1-10",
DANIEL COLE,Probability calculations within stochastic electrodynamics,"Several stochastic situations in stochastic electrodynamics (SED) are analytically calculated from first principles. These situations include probability density functions, as well as correlation functions at multiple points of time and space, for the zero-point (ZP) electromagnetic fields, as well as for ZP plus Planckian (ZPP) electromagnetic fields. More lengthy analytical calculations are indicated, using similar methods, for the simple harmonic electric dipole oscillator bathed in ZP as well as ZPP electromagnetic fields. The method presented here makes an interesting contrast to Feynman’s path integral approach in quantum electrodynamics (QED). The present SED approach directly entails probabilities, while the QED approach involves summing weighted paths for the wave function."
DANIEL COLE,Energy considerations of classical electromagnetic zero-point radiation and a specific probability calculation in stochastic electrodynamics,"The zero-point (ZP) radiation field in stochastic electrodynamics (SED) is considered to be formally infinite, or perhaps bounded by mechanisms yet to be revealed someday. A similar situation holds in quantum electrodynamics (QED), although there the ZP field is considered to be “virtual”. The first part of this article addresses the concern by some about the related disturbing concept of “extracting energy” from this formally, enormous source of energy. The second part of this article introduces a new method for calculating probabilities of fields in SED, which can be extended to linear oscillators in SED."
DANIEL COLE,The power of forecasts to advance ecological theory,"Ecological forecasting provides a powerful set of methods for predicting short‐ and long‐term change in living systems. Forecasts are now widely produced, enabling proactive management for many applied ecological problems. However, despite numerous calls for an increased emphasis on prediction in ecology, the potential for forecasting to accelerate ecological theory development remains underrealized. Here, we provide a conceptual framework describing how ecological forecasts can energize and advance ecological theory. We emphasize the many opportunities for future progress in this area through increased forecast development, comparison and synthesis. Our framework describes how a forecasting approach can shed new light on existing ecological theories while also allowing researchers to address novel questions. Through rigorous and repeated testing of hypotheses, forecasting can help to refine theories and understand their generality across systems. Meanwhile, synthesizing across forecasts allows for the development of novel theory about the relative predictability of ecological variables across forecast horizons and scales. We envision a future where forecasting is integrated as part of the toolset used in fundamental ecology. By outlining the relevance of forecasting methods to ecological theory, we aim to decrease barriers to entry and broaden the community of researchers using forecasting for fundamental ecological insight."
DIANA M. HIGGINS,NFIA Haploinsufficiency Is Associated with a CNS Malformation Syndrome and Urinary Tract Defects,"Complex central nervous system (CNS) malformations frequently coexist with other developmental abnormalities, but whether the associated defects share a common genetic basis is often unclear. We describe five individuals who share phenotypically related CNS malformations and in some cases urinary tract defects, and also haploinsufficiency for the NFIA transcription factor gene due to chromosomal translocation or deletion. Two individuals have balanced translocations that disrupt NFIA. A third individual and two half-siblings in an unrelated family have interstitial microdeletions that include NFIA. All five individuals exhibit similar CNS malformations consisting of a thin, hypoplastic, or absent corpus callosum, and hydrocephalus or ventriculomegaly. The majority of these individuals also exhibit Chiari type I malformation, tethered spinal cord, and urinary tract defects that include vesicoureteral reflux. Other genes are also broken or deleted in all five individuals, and may contribute to the phenotype. However, the only common genetic defect is NFIA haploinsufficiency. In addition, previous analyses of Nfia−/− knockout mice indicate that Nfia deficiency also results in hydrocephalus and agenesis of the corpus callosum. Further investigation of the mouse Nfia+/− and Nfia−/− phenotypes now reveals that, at reduced penetrance, Nfia is also required in a dosage-sensitive manner for ureteral and renal development. Nfia is expressed in the developing ureter and metanephric mesenchyme, and Nfia+/− and Nfia−/− mice exhibit abnormalities of the ureteropelvic and ureterovesical junctions, as well as bifid and megaureter. Collectively, the mouse Nfia mutant phenotype and the common features among these five human cases indicate that NFIA haploinsufficiency contributes to a novel human CNS malformation syndrome that can also include ureteral and renal defects. Author Summary Central nervous system (CNS) and urinary tract abnormalities are common human malformations, but their variability and genetic complexity make it difficult to identify the responsible genes. Analysis of human chromosomal abnormalities associated with such disorders offers one approach to this problem. In five individuals described herein, a novel human syndrome that involves both CNS and urinary tract defects is associated with chromosomal disruption or deletion of NFIA, encoding a member of the Nuclear Factor I (NFI) family of transcription factors. This syndrome includes brain abnormalities (abnormal corpus callosum, hydrocephalus, ventriculomegaly, and Chiari type I malformation), spinal abnormalities (tethered spinal cord), and urinary tract abnormalities (vesicoureteral reflux). Nfia disruption in mice was already known to cause hydrocephalus and abnormal corpus callosum, and is now shown to exhibit renal defects and disturbed ureteral development. Other genes besides NFIA are also disrupted or deleted and may contribute to the observed phenotype. However, loss of one copy of NFIA is the only genetic defect common to all five patients. The authors thus provide evidence that genetic loss of NFIA contributes to a distinct CNS malformation syndrome with urinary tract defects of variable penetrance."
IAN R RIFKIN,DNA-like Class R Inhibitory Oligonucleotides (INH-ODNs) Preferentially Block Autoantigen-Induced B-Cell and Dendritic Cell Activation in Vitro and Autoantibody Production in Lupus-Prone MRL-Faslpr/lpr Mice in Vivo,"INTRODUCTION. B cells have many different roles in systemic lupus erythematosus (SLE), ranging from autoantigen recognition and processing to effector functions (for example, autoantibody and cytokine secretion). Recent studies have shown that intracellular nucleic acid-sensing receptors, Toll-like receptor (TLR) 7 and TLR9, play an important role in the pathogenesis of SLE. Dual engagement of rheumatoid factor-specific AM14 B cells through the B-cell receptor (BCR) and TLR7/9 results in marked proliferation of autoimmune B cells. Thus, strategies to preferentially block innate activation through TLRs in autoimmune B cells may be preferred over non-selective B-cell depletion. METHODS. We have developed a new generation of DNA-like compounds named class R inhibitory oligonucleotides (INH-ODNs). We tested their effectiveness in autoimmune B cells and interferon-alpha-producing dendritic cells in vitro and in lupus-prone MRL-Faslpr/lpr mice in vivo. RESULTS. Class R INH-ODNs have 10- to 30-fold higher inhibitory potency when autoreactive B cells are synergistically activated through the BCR and associated TLR7 or 9 than when stimulation occurs via non-BCR-engaged TLR7/9. Inhibition of TLR9 requires the presence of both CCT and GGG triplets in an INH-ODN, whereas the inhibition of the TLR7 pathway appears to be sequence-independent but dependent on the phosphorothioate backbone. This difference was also observed in the MRL-Faslpr/lpr mice in vivo, where the prototypic class R INH-ODN was more effective in curtailing abnormal autoantibody secretion and prolonging survival. CONCLUSIONS. The increased potency of class R INH-ODNs for autoreactive B cells and dendritic cells may be beneficial for lupus patients by providing pathway-specific inhibition yet allowing them to generate protective immune response when needed."
BOBAK NAZER,Information-distilling quantizers,"Let X and Y be dependent random variables. This paper considers the problem of designing a scalar quantizer for Y to maximize the mutual information between the quantizer's output and X, and develops fundamental properties and bounds for this form of quantization, which is connected to the log-loss distortion criterion. The main focus is the regime of low I(X;Y), where it is shown that, if X is binary, a constant fraction of the mutual information can always be preserved using O(log(1/I(X;Y))) quantization levels, and there exist distributions for which this many quantization levels are necessary. Furthermore, for larger finite alphabets 2<|X|<∞, it is established that an η-fraction of the mutual information can be preserved using roughly (log(|X|/I(X;Y)))^(η⋅(|X|−1)) quantization levels."
BOBAK NAZER,Compute-forward for DMCs: simultaneous decoding of multiple combinations,"Algebraic network information theory is an emerging facet of network information theory, studying the achievable rates of random code ensembles that have algebraic structure, such as random linear codes. A distinguishing feature is that linear combinations of codewords can sometimes be decoded more efficiently than codewords themselves. The present work further develops this framework by studying the simultaneous decoding of multiple messages. Specifically,} consider a receiver in a multi-user network that wishes to decode several messages. Simultaneous joint typicality decoding is one of the most powerful techniques for determining the fundamental limits at which reliable decoding is possible. This technique has historically been used in conjunction with random i.i.d. codebooks to establish achievable rate regions for networks. Recently, it has been shown that, in certain scenarios, nested linear codebooks in conjunction with ""single-user""' or sequential decoding can yield better achievable rates. For instance, the compute--forward problem examines the scenario of recovering L <= K linear combinations of transmitted codewords over a K-user multiple-access channel (MAC), and it is well established that linear codebooks can yield higher rates. Here, we develop bounds for simultaneous joint typicality decoding used in conjunction with nested linear codebooks, and apply them to obtain a larger achievable region for compute--forward over a K-user discrete memoryless MAC. The key technical challenge is that competing codeword tuples that are linearly dependent on the true codeword tuple introduce statistical dependencies, which requires careful partitioning of the associated error events."
BOBAK NAZER,A unified discretization approach to compute-forward: from discrete to continuous inputs,"Compute–forward is a coding technique that enables receiver(s) in a network to directly decode one or more linear combinations of the transmitted codewords. Initial efforts focused on Gaussian channels and derived achievable rate regions via nested lattice codes and single-user (lattice) decoding as well as sequential (lattice) decoding. Recently, these results have been generalized to discrete memoryless channels via nested linear codes and joint typicality coding, culminating in a simultaneous-decoding rate region for recovering one or more linear combinations from K users. Using a discretization approach, this paper translates this result into a simultaneous-decoding rate region for a wide class of continuous memoryless channels, including the important special case of Gaussian channels. Additionally, this paper derives a single, unified expression for both discrete and continuous rate regions via an algebraic generalization of Renyi’s information dimension."
BOBAK NAZER,Integer-forcing architectures for uplink cloud radio access networks,"Consider an uplink cloud radio access network where users are observed simultaneously by several base stations, each with a rate-limited link to a central processor, which wishes to decode all transmitted messages. Recent efforts have demonstrated the advantages of compression-based strategies that send quantized channel observations to the central processor, rather than attempt local decoding. We study the setting where channel state information is not available at the transmitters, but known fully or partially at the base stations. We propose an end-to-end integer forcing framework for compression-based uplink cloud radio access, and show that it operates within a constant gap from the optimal outage probability if channel state information is fully available at the base stations.We demonstrate via simulations that our framework is competitive with state-of-the-art Wyner-Ziv-based strategies."
BOBAK NAZER,Limits on testing structural changes in Ising models,"We present novel information-theoretic limits on detecting sparse changes in Ising models, a problem that arises in many applications where network changes can occur due to some external stimuli. We show that the sample complexity for detecting sparse changes, in a minimax sense, is no better than learning the entire model even in settings with local sparsity. This is a surprising fact in light of prior work rooted in sparse recovery methods, which suggest that sample complexity in this context scales only with the number of network changes. To shed light on when change detection is easier than structured learning, we consider testing of edge deletion in forest-structured graphs, and high-temperature ferromagnets as case studies. We show for these that testing of small changes is similarly hard, but testing of \emph{large} changes is well-separated from structure learning. These results imply that testing of graphical models may not be amenable to concepts such as restricted strong convexity leveraged for sparsity pattern recovery, and algorithm development instead should be directed towards detection of large changes."
BOBAK NAZER,Detecting correlated Gaussian databases,
BOBAK NAZER,Distributed lossy computation with structured codes: from discrete to continuous sources,
JONATHAN A BARNES,"Miniature exoplanet radial velocity array I: design, commissioning, and early photometric results","The MINiature Exoplanet Radial Velocity Array (MINERVA) is a US-based observational facility dedicated to the discovery and characterization of exoplanets around a nearby sample of bright stars. MINERVA employs a robotic array of four 0.7 m telescopes outfitted for both high-resolution spec- troscopy and photometry, and is designed for completely autonomous operation. The primary science program is a dedicated radial velocity survey and the secondary science objective is to obtain high precision transit light curves. The modular design of the facility and the flexibility of our hardware allows for both science programs to be pursued simultaneously, while the robotic control software provides a robust and efficient means to carry out nightly observations. In this article, we describe the design of MINERVA including major hardware components, software, and science goals. The telescopes and photometry cameras are characterized at our test facility on the Caltech campus in Pasadena, CA, and their on-sky performance is validated. New observations from our test facility demonstrate sub-mmag photometric precision of one of our radial velocity survey targets, and we present new transit observations and fits of WASP-52b—a known hot-Jupiter with an inflated radius and misaligned orbit. The process of relocating the MINERVA hardware to its final destination at the Fred Lawrence Whipple Observatory in southern Arizona has begun, and science operations are expected to commence within 2015."
JONATHAN A BARNES,First radial velocity results from the MINiature Exoplanet Radial Velocity Array (MINERVA),"The MINiature Exoplanet Radial Velocity Array (MINERVA) is a dedicated observatory of four 0.7 m robotic telescopes fiber-fed to a KiwiSpec spectrograph. The MINERVA mission is to discover super-Earths in the habitable zones of nearby stars. This can be accomplished with MINERVA's unique combination of high precision and high cadence over long time periods. In this work, we detail changes to the MINERVA facility that have occurred since our previous paper. We then describe MINERVA's robotic control software, the process by which we perform 1D spectral extraction, and our forward modeling Doppler pipeline. In the process of improving our forward modeling procedure, we found that our spectrograph's intrinsic instrumental profile is stable for at least nine months. Because of that, we characterized our instrumental profile with a time-independent, cubic spline function based on the profile in the cross dispersion direction, with which we achieved a radial velocity precision similar to using a conventional ""sum-of-Gaussians"" instrumental profile: 1.8 m s−1 over 1.5 months on the RV standard star HD 122064. Therefore, we conclude that the instrumental profile need not be perfectly accurate as long as it is stable. In addition, we observed 51 Peg and our results are consistent with the literature, confirming our spectrograph and Doppler pipeline are producing accurate and precise radial velocities."
ANTHONY JOSEPH ROSELLINI,Initial development and validation of a dimensional classification system for the emotional disorders,"Problems with the current categorical approach to classification used by the Diagnostic and Statistical Manual of Mental Disorders (DSM) have led to proposals that classify the emotional disorders (EDs; anxiety and mood disorders) using a dimensional-categorical system based on shared ED vulnerabilities and phenotypes. Such profile-based approaches have yet to be empirically evaluated, in part because a single multidimensional assessment of shared ED vulnerabilities and phenotypes amenable to profile-based classification has not been developed. The present studies aimed to provide an initial examination of a categorical-dimensional approach to ED classification (Study 1) as well as develop and evaluate a multidimensional self-report assessment of shared ED vulnerabilities and phenotypes (the Multidimensional Emotional Disorder Inventory [MEDI], Study 2). The samples consisted of 1,218 (Study 1) and 227 (Study 2) participants who presented for assessment and treatment at an outpatient ED treatment center. All participants were assessed using a semi-structured ED interview and a set of ED self-report questionnaires. The MEDI was completed only by the participants in Study 2. Study 1 used mixture modeling to identify six unobserved groups (classes) of individuals sharing similar profiles across seven dimensional ED vulnerability and phenotype indicators. The external validity of the profiles was supported when related ED covariates were added to the solution. The incremental validity of the profiles was supported using hierarchical regression models; the profiles accounted for unique variance in ED outcomes beyond DSM diagnoses. In Study 2, exploratory structural equation modeling (ESEM) and confirmatory factor analysis were used to evaluate the factor structure of the MEDI. ESEM supported an eight-factor solution of a 47-item version of the MEDI. Differential magnitude of correlation analyses supported the convergent/discriminant validity of seven of the eight MEDI scales. A five-class (profile) solution, consistent with Study 1, was found when mixture modeling was applied to the MEDI scales. Collectively, the present studies provide compelling evidence in support of the development and utility of a hybrid dimensional-categorical profile approach to emotional disorder classification using multidimensional self-report assessment methods such as the MEDI."
RONALD K RICHARDSON,The long-baseline neutrino experiment: exploring fundamental symmetries of the universe,"The preponderance of matter over antimatter in the early Universe, the dynamics of the supernova bursts that produced the heavy elements necessary for life and whether protons eventually decay --- these mysteries at the forefront of particle physics and astrophysics are key to understanding the early evolution of our Universe, its current state and its eventual fate. The Long-Baseline Neutrino Experiment (LBNE) represents an extensively developed plan for a world-class experiment dedicated to addressing these questions. LBNE is conceived around three central components: (1) a new, high-intensity neutrino source generated from a megawatt-class proton accelerator at Fermi National Accelerator Laboratory, (2) a near neutrino detector just downstream of the source, and (3) a massive liquid argon time-projection chamber deployed as a far detector deep underground at the Sanford Underground Research Facility. This facility, located at the site of the former Homestake Mine in Lead, South Dakota, is approximately 1,300 km from the neutrino source at Fermilab -- a distance (baseline) that delivers optimal sensitivity to neutrino charge-parity symmetry violation and mass ordering effects. This ambitious yet cost-effective design incorporates scalability and flexibility and can accommodate a variety of upgrades and contributions. With its exceptional combination of experimental configuration, technical capabilities, and potential for transformative discoveries, LBNE promises to be a vital facility for the field of particle physics worldwide, providing physicists from around the globe with opportunities to collaborate in a twenty to thirty year program of exciting science. In this document we provide a comprehensive overview of LBNE's scientific objectives, its place in the landscape of neutrino physics worldwide, the technologies it will incorporate and the capabilities it will possess."
YOON SUN YANG,"Panel discussion with Yoon Sun Yang (Discussant): Nanae Tamura, Robert Tuck and Reiko Abe Auestad",
VALENTINA PERISSI,Inhibition of Ubc13-mediated ubiquitination by GPS2 regulates multiple stages of B cell development,"Non-proteolytic ubiquitin signaling mediated by Lys63 ubiquitin chains plays a critical role in multiple pathways that are key to the development and activation of immune cells. Our previous work indicates that GPS2 (G-protein Pathway Suppressor 2) is a multifunctional protein regulating TNF signaling and lipid metabolism in the adipose tissue through modulation of Lys63 ubiquitination events. However, the full extent of GPS2-mediated regulation of ubiquitination and the underlying molecular mechanisms are unknown. Here, we report that GPS2 is required for restricting the activation of TLR and BCR signaling pathways and the AKT/FOXO1 pathway in immune cells based on direct inhibition of Ubc13 enzymatic activity. Relevance of this regulatory strategy is confirmed in vivo by B cell-targeted deletion of GPS2, resulting in developmental defects at multiple stages of B cell differentiation. Together, these findings reveal that GPS2 genomic and non-genomic functions are critical for the development and cellular homeostasis of B cells."
WAYNE SNYDER,Proceedings of Sixth International Workshop on Unification,
GUANGLAN ZHANG,Rare variants and HLA haplotypes associated in patients with neuromyelitis optica spectrum disorders,"Neuromyelitis optica spectrum disorders (NMOSD) are rare, debilitating autoimmune diseases of the central nervous system. Many NMOSD patients have antibodies to Aquaporin-4 (AQP4). Prior studies show associations of NMOSD with individual Human Leukocyte Antigen (HLA) alleles and with mutations in the complement pathway and potassium channels. HLA allele associations with NMOSD are inconsistent between populations, suggesting complex relationships between the identified alleles and risk of disease. We used a retrospective case-control approach to identify contributing genetic variants in patients who met the diagnostic criteria for NMOSD and their unaffected family members. Potentially deleterious variants identified in NMOSD patients were compared to members of their families who do not have the disease and to existing databases of human genetic variation. HLA sequences from patients from Belgrade, Serbia, were compared to the frequency of HLA haplotypes in the general population in Belgrade. We analyzed exome sequencing on 40 NMOSD patients and identified rare inherited variants in the complement pathway and potassium channel genes. Haplotype analysis further detected two haplotypes, HLA-A*01, B*08, DRB1*03 and HLA-A*01, B*08, C*07, DRB1*03, DQB1*02, which were more prevalent in NMOSD patients than in unaffected individuals. In silico modeling indicates that HLA molecules within these haplotypes are predicted to bind AQP4 at several sites, potentially contributing to the development of autoimmunity. Our results point to possible autoimmune and neurodegenerative mechanisms that cause NMOSD, and can be used to investigate potential NMOSD drug targets."
GUANGLAN ZHANG,Data analytics based positioning of health informatics programs,"The Master of Science in Computer Information Systems (CIS) with concentration in Health Informatics (HI) at Metropolitan College (MET), Boston University (BU), is a 40-credit degree program that are delivered in three formats: face-to-face, online, and blended. The MET CIS-HI program is unique because of the population of students it serves, namely those interested in gaining skills in HI technology field, to serve as data analysts and knowledge-based technology drivers in the thriving health care industry. This set of skills is essential for addressing the challenges of Big Data and knowledge-based health care support of the modern health care. The MET CIS-HI program was accredited by the Commission on Accreditation for Health Informatics and Information Management Education (CAHIIM) in 2017."
GUANGLAN ZHANG,CK2 inhibitor CX-4945 destabilizes NOTCH1 and synergizes with JQ1 against human T-acute lymphoblastic leukemic cells.,"T-cell acute lymphoblastic leukemia (T-ALL) is an aggressive cancer of developing thymocytes, and remains fatal in 20% of pediatric and 50% of adult patients.1,2 Frequent application of multi-agent cytotoxic drugs leads to disease relapse and high toxicities, underscoring the need for targeted therapies. The suppression of aberrant NOTCH1 signaling in T-ALL cells by gamma secretase inhibitors (GSIs) has been met with much enthusiasm; however, the gastrointestinal toxicities and drug resistance of GSIs restrain their clinical applications.3 The proto-oncogene MYC is a transcriptional target of NOTCH1 and a dominant driver of T-ALL pathogenesis.3 Targeting MYC-mediated transcriptional programs through BET bromodomain inhibitor JQ1 exhibits anti-leukemic efficacy in vitro and in vivo.4 However, global repression of transcription is predicted to cause toxicities. Identification of drug(s) synergizing with JQ1 to kill T-ALL cells may enhance the efficacy while reducing toxicities. Protein kinase CK2 is a tetrameric serine-threonine kinase composed of two catalytic (α or α′) and regulatory (β) subunits that can phosphorylate NOTCH1.5 CK2 inhibition by CX-4945, a potent and specific inhibitor in clinical trials for treating breast cancer and multiple myeloma, significantly reduces growth and survival of human T-ALL cells,6 and down-regulates NOTCH1 in lung cancer cells.7 However, it remains unclear whether the cytotoxic effect of CX-4945 on T-ALL cells is associated with repression of NOTCH1 signaling. Here we show that CK2 inhibition by CX-4945 destabilizes NOTCH1 and synergizes with JQ1 to induce apoptosis in human T-ALL cells, implicating an alternative strategy to target NOTCH1 signaling in refractory/relapsed T-ALL."
GUANGLAN ZHANG,Examining mental illness trends in the United States from 2006 to 2019,We investigate the characteristics of medical expenditures associated with mental illness hospitalizations using the Truven Health MarketScan Database. We focus on the inpatient admissions due to mental illness of adults aged 1S to 64 between 2006 to 2019. We aim to answer the following questions: (1) Did the financial crisis of 2008 impact mental health in the U.S.?(2) What are the other macro-level (socioeconomic and regulartory) and micro-level (individualpatient related) factors that affect the cost of inpatient care due to mental illness; (3) Did mental illness affect men and women differently? (4) How were different regions within the U.S. affected by mental illness?
GUANGLAN ZHANG,TANTIGEN 2.0: a knowledge base of tumor T cell antigens and epitopes,"We previously developed TANTIGEN, a comprehensive online database cataloging more than 1,000 T cell epitopes and HLA ligands from 292 tumor antigens. In TANTIGEN 2.0, we significantly expanded coverage in both immune response targets (T cell epitopes and HLA ligands) and tumor antigens. It catalogs 4,296 antigen variants from 403 unique tumor antigens and more than 1,500 T cell epitopes and HLA ligands. We also included neoantigens, a class of tumor antigens generated through mutations resulting in new amino acid sequences in tumor antigens. TANTIGEN 2.0 contains validated TCR sequences specific for cognate T cell epitopes and tumor antigen gene/mRNA/protein expression information in major human cancers extracted by Human Pathology Atlas. TANTIGEN 2.0 is a rich data resource for tumor antigens and their associated epitopes and neoepitopes. It hosts a set of tailored data analytics tools tightly integrated with the data to form meaningful analysis workflows. It is freely available at http://projects.met-hilab.org/tadb."
GUANGLAN ZHANG,Advances in computational immunology,
GUANGLAN ZHANG,UFD1 contributes to MYC-mediated leukemia aggressiveness through suppression of the proapoptotic unfolded protein response,"Despite the pivotal role of MYC in tumorigenesis, the mechanisms by which it promotes cancer aggressiveness remain incompletely understood. Here, we show that MYC transcriptionally upregulates the ubiquitin fusion degradation 1 (UFD1) gene in T-cell acute lymphoblastic leukemia (T-ALL). Allelic loss of ufd1 in zebrafish induces tumor cell apoptosis and impairs MYC-driven T-ALL progression but does not affect general health. As the E2 component of an endoplasmic reticulum (ER)-associated degradation (ERAD) complex, UFD1 facilitates the elimination of misfolded/unfolded proteins from the ER. We found that UFD1 inactivation in human T-ALL cells impairs ERAD, exacerbates ER stress, and induces apoptosis. Moreover, we show that UFD1 inactivation promotes the proapoptotic unfolded protein response (UPR) mediated by protein kinase RNA-like ER kinase (PERK). This effect is demonstrated by an upregulation of PERK and its downstream effector C/EBP homologous protein (CHOP), as well as a downregulation of BCL2 and BCLxL. Indeed, CHOP inactivation or BCL2 overexpression is sufficient to rescue tumor cell apoptosis induced by UFD1 knockdown. Together, our studies identify UFD1 as a critical regulator of the ER stress response and a novel contributor to MYC-mediated leukemia aggressiveness, with implications for targeted therapy in T-ALL and likely other MYC-driven cancers."
JOHN H CONNOR,"The role of religion in the longer-range future, April 6, 7, and 8, 2006","The conference brought together some 40 experts from various disciplines to ponder upon the “great dilemma” of how science, religion, and the human future interact. In particular, different panels looked at trends in what is happening to religion around the world, questions about how religion is impacting the current political and economic order, and how the social dynamics unleashed by science and by religion can be reconciled."
JOHN H CONNOR,"Miniature exoplanet radial velocity array I: design, commissioning, and early photometric results","The MINiature Exoplanet Radial Velocity Array (MINERVA) is a US-based observational facility dedicated to the discovery and characterization of exoplanets around a nearby sample of bright stars. MINERVA employs a robotic array of four 0.7 m telescopes outfitted for both high-resolution spec- troscopy and photometry, and is designed for completely autonomous operation. The primary science program is a dedicated radial velocity survey and the secondary science objective is to obtain high precision transit light curves. The modular design of the facility and the flexibility of our hardware allows for both science programs to be pursued simultaneously, while the robotic control software provides a robust and efficient means to carry out nightly observations. In this article, we describe the design of MINERVA including major hardware components, software, and science goals. The telescopes and photometry cameras are characterized at our test facility on the Caltech campus in Pasadena, CA, and their on-sky performance is validated. New observations from our test facility demonstrate sub-mmag photometric precision of one of our radial velocity survey targets, and we present new transit observations and fits of WASP-52b—a known hot-Jupiter with an inflated radius and misaligned orbit. The process of relocating the MINERVA hardware to its final destination at the Fred Lawrence Whipple Observatory in southern Arizona has begun, and science operations are expected to commence within 2015."
JOHN H CONNOR,A high-throughput single-particle imaging platform for antibody characterization and a novel competition assay for therapeutic antibodies,"Monoclonal antibodies (mAbs) play an important role in diagnostics and therapy of infectious diseases. Here we utilize a single-particle interferometric reflectance imaging sensor (SP-IRIS) for screening 30 mAbs against Ebola, Sudan, and Lassa viruses (EBOV, SUDV, and LASV) to find out the ideal capture antibodies for whole virus detection using recombinant vesicular stomatitis virus (rVSV) models expressing surface glycoproteins (GPs) of EBOV, SUDV, and LASV. We also make use of the binding properties on SP-IRIS to develop a model for mapping the antibody epitopes on the GP structure. mAbs that bind to mucin-like domain or glycan cap of the EBOV surface GP show the highest signal on SP-IRIS, followed by mAbs that target the GP1-GP2 interface at the base domain. These antibodies were shown to be highly efficacious against EBOV infection in non-human primates in previous studies. For LASV detection, 8.9F antibody showed the best performance on SP-IRIS. This antibody binds to a unique region on the surface GP compared to other 15 mAbs tested. In addition, we demonstrate a novel antibody competition assay using SP-IRIS and rVSV-EBOV models to reveal the competition between mAbs in three successful therapeutic mAb cocktails against EBOV infection. We provide an explanation as to why ZMapp cocktail has higher efficacy compared to the other two cocktails by showing that three mAbs in this cocktail (13C6, 2G4, 4G7) do not compete with each other for binding to EBOV GP. In fact, the binding of 13C6 enhances the binding of 2G4 and 4G7 antibodies. Our results establish SP-IRIS as a versatile tool that can provide high-throughput screening of mAbs, multiplexed and sensitive detection of viruses, and evaluation of therapeutic antibody cocktails."
JOHN H CONNOR,Comparison of BinaxNOW and SARS-CoV-2 qRT-PCR detection of the omicron variant from matched anterior nares swabs,"The COVID-19 pandemic has increased use of rapid diagnostic tests (RDTs). In winter 2021 to 2022, the Omicron variant surge made it apparent that although RDTs are less sensitive than quantitative reverse transcription-PCR (qRT-PCR), the accessibility, ease of use, and rapid readouts made them a sought after and often sold-out item at local suppliers. Here, we sought to qualify the Abbott BinaxNOW RDT for use in our university testing program as a method to rule in positive or rule out negative individuals quickly at our priority qRT-PCR testing site. To perform this qualification study, we collected additional swabs from individuals attending this site. All swabs were tested using BinaxNOW. Initially as part of a feasibility study, test period 1 (n = 110) samples were stored cold before testing. In test period 2 (n = 209), samples were tested immediately. Combined, 102/319 samples tested severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) positive via qRT-PCR. All sequenced samples were Omicron (n = 92). We calculated 53.9% sensitivity, 100% specificity, a 100% positive predictive value, and an 82.2% negative predictive value for BinaxNOW (n = 319). Sensitivity would be improved (75.3%) by changing the qRT-PCR positivity threshold from a threshold cycle (CT) value of 40 to a CT value of 30. The receiver operating characteristic (ROC) curve shows that for qRT-PCR-positive CT values of between 24 and 40, the BinaxNOW test is of limited value diagnostically. Results suggest BinaxNOW could be used in our setting to confirm SARS-CoV-2 infection in individuals with substantial viral load, but a significant fraction of infected individuals would be missed if we used RDTs exclusively to rule out infection. IMPORTANCE Our results suggest BinaxNOW can rule in SARS-CoV-2 infection but would miss infections if RDTs were exclusively used."
JOHN H CONNOR,Wolbachia wStri blocks Zika virus growth at two independent stages of viral replication,"Mosquito-transmitted viruses are spread globally and present a great risk to human health. Among the many approaches investigated to limit the diseases caused by these viruses are attempts to make mosquitos resistant to virus infection. Coinfection of mosquitos with the bacterium Wolbachia pipientis from supergroup A is a recent strategy employed to reduce the capacity for major vectors in the Aedes mosquito genus to transmit viruses, including dengue virus (DENV), Chikungunya virus (CHIKV), and Zika virus (ZIKV). Recently, a supergroup B Wolbachia wStri, isolated from Laodelphax striatellus, was shown to inhibit multiple lineages of ZIKV in Aedes albopictus cells. Here, we show that wStri blocks the growth of positive-sense RNA viruses DENV, CHIKV, ZIKV, and yellow fever virus by greater than 99.9%. wStri presence did not affect the growth of the negative-sense RNA viruses LaCrosse virus or vesicular stomatitis virus. Investigation of the stages of the ZIKV life cycle inhibited by wStri identified two distinct blocks in viral replication. We found a reduction of ZIKV entry into wStri-infected cells. This was partially rescued by the addition of a cholesterol-lipid supplement. Independent of entry, transfected viral genome was unable to replicate in Wolbachia-infected cells. RNA transfection and metabolic labeling studies suggested that this replication defect is at the level of RNA translation, where we saw a 66% reduction in mosquito protein synthesis in wStri-infected cells. This study’s findings increase the potential for application of wStri to block additional arboviruses and also identify specific blocks in viral infection caused by Wolbachia coinfection."
JOHN H CONNOR,"High-throughput, high-resolution interferometric light microscopy of biological nanoparticles","Label-free, visible light microscopy is an indispensable tool for studying biological nanoparticles (BNPs). However, conventional imaging techniques have two major challenges: (i) weak contrast due to low-refractive-index difference with the surrounding medium and exceptionally small size and (ii) limited spatial resolution. Advances in interferometric microscopy have overcome the weak contrast limitation and enabled direct detection of BNPs, yet lateral resolution remains as a challenge in studying BNP morphology. Here, we introduce a wide-field interferometric microscopy technique augmented by computational imaging to demonstrate a 2-fold lateral resolution improvement over a large field-of-view (>100 × 100 μm2), enabling simultaneous imaging of more than 104 BNPs at a resolution of ∼150 nm without any labels or sample preparation. We present a rigorous vectorial-optics-based forward model establishing the relationship between the intensity images captured under partially coherent asymmetric illumination and the complex permittivity distribution of nanoparticles. We demonstrate high-throughput morphological visualization of a diverse population of Ebola virus-like particles and a structurally distinct Ebola vaccine candidate. Our approach offers a low-cost and robust label-free imaging platform for high-throughput and high-resolution characterization of a broad size range of BNPs."
JOHN H CONNOR,Enhanced light microscopy visualization of virus particles from Zika virus to filamentous ebolaviruses,"Light microscopy is a powerful tool in the detection and analysis of parasites, fungi, and prokaryotes, but has been challenging to use for the detection of individual virus particles. Unlabeled virus particles are too small to be visualized using standard visible light microscopy. Characterization of virus particles is typically performed using higher resolution approaches such as electron microscopy or atomic force microscopy. These approaches require purification of virions away from their normal millieu, requiring significant levels of expertise, and can only enumerate small numbers of particles per field of view. Here, we utilize a visible light imaging approach called Single Particle Interferometric Reflectance Imaging Sensor (SP-IRIS) that allows automated counting and sizing of thousands of individual virions. Virions are captured directly from complex solutions onto a silicon chip and then detected using a reflectance interference imaging modality. We show that the use of different imaging wavelengths allows the visualization of a multitude of virus particles. Using Violet/UV illumination, the SP-IRIS technique is able to detect individual flavivirus particles (~40 nm), while green light illumination is capable of identifying and discriminating between vesicular stomatitis virus and vaccinia virus (~360 nm). Strikingly, the technology allows the clear identification of filamentous infectious ebolavirus particles and virus-like particles. The ability to differentiate and quantify unlabeled virus particles extends the usefulness of traditional light microscopy and can be embodied in a straightforward benchtop approach allowing widespread applications ranging from rapid detection in biological fluids to analysis of virus-like particles for vaccine development and production."
JOHN H CONNOR,Robust visualization and discrimination of nanoparticles by interferometric imaging,"Single-molecule and single-nanoparticle biosensors are a growing frontier in diagnostics. Digital biosensors are those which enumerate all specifically immobilized biomolecules or biological nanoparticles, and thereby achieve limits of detection usually beyond the reach of ensemble measurements. Here we review modern optical techniques for single nanoparticle detection and describe the single-particle interferometric reflectance imaging sensor (SP-IRIS). We present challenges associated with reliably detecting faint nanoparticles with SP-IRIS, and describe image acquisition processes and software modifications to address them. Specifically, we describe a image acquisition processing method for the discrimination and accurate counting of nanoparticles that greatly reduces both the number of false positives and false negatives. These engineering improvements are critical steps in the translation of SP-IRIS towards applications in medical diagnostics."
JOHN H CONNOR,Eosinophil and T Cell Markers Predict Functional Decline in COPD Patients,"BACKGROUND. The major marker utilized to monitor COPD patients is forced expiratory volume in one second (FEV1). However, asingle measurement of FEV1 cannot reliably predict subsequent decline. Recent studies indicate that T lymphocytes and eosinophils are important determinants of disease stability in COPD. We therefore measured cytokine levels in the lung lavage fluid and plasma of COPD patients in order to determine if the levels of T cell or eosinophil related cytokines were predictive of the future course of the disease. METHODS. Baseline lung lavage and plasma samples were collected from COPD subjects with moderately severe airway obstruction and emphysematous changes on chest CT. The study participants were former smokers who had not had a disease exacerbation within the past six months or used steroids within the past two months. Those subjects who demonstrated stable disease over the following six months (ΔFEV1 % predicted = 4.7 ± 7.2; N = 34) were retrospectively compared with study participants who experienced a rapid decline in lung function (ΔFEV1 % predicted = -16.0 ± 6.0; N = 16) during the same time period and with normal controls (N = 11). Plasma and lung lavage cytokines were measured from clinical samples using the Luminex multiplex kit which enabled the simultaneous measurement of several T cell and eosinophil related cytokines. RESULTS AND DISCUSSION. Stable COPD participants had significantly higher plasma IL-2 levels compared to participants with rapidly progressive COPD (p = 0.04). In contrast, plasma eotaxin-1 levels were significantly lower in stable COPD subjects compared to normal controls (p < 0.03). In addition, lung lavage eotaxin-1 levels were significantly higher in rapidly progressive COPD participants compared to both normal controls (p < 0.02) and stable COPD participants (p < 0.05). CONCLUSION. These findings indicate that IL-2 and eotaxin-1 levels may be important markers of disease stability in advanced emphysema patients. Prospective studies will need to confirm whether measuring IL-2 or eotaxin-1 can identify patients at risk for rapid disease progression."
JOHN H CONNOR,Single virus fingerprinting by widefield interferometric defocus-enhanced mid-infrared photothermal microscopy,"Clinical identification and fundamental study of viruses rely on the detection of viral proteins or viral nucleic acids. Yet, amplification-based and antigen-based methods are not able to provide precise compositional information of individual virions due to small particle size and low-abundance chemical contents (e.g., ~ 5000 proteins in a vesicular stomatitis virus). Here, we report a widefield interferometric defocus-enhanced mid-infrared photothermal (WIDE-MIP) microscope for high-throughput fingerprinting of single viruses. With the identification of feature absorption peaks, WIDE-MIP reveals the contents of viral proteins and nucleic acids in single DNA vaccinia viruses and RNA vesicular stomatitis viruses. Different nucleic acid signatures of thymine and uracil residue vibrations are obtained to differentiate DNA and RNA viruses. WIDE-MIP imaging further reveals an enriched β sheet components in DNA varicella-zoster virus proteins. Together, these advances open a new avenue for compositional analysis of viral vectors and elucidating protein function in an assembled virion."
JOHN H CONNOR,"Economic development, human development, and the pursuit of happiness, April 1, 2, and 3, 2004","The conference asks the questions, how can we make sure that the benefits of economic growth flow into health, education, welfare, and other aspects of human development; and what is the relationship between human development and economic development? Speakers and participants discuss the role that culture, legal and political institutions, the UN Developmental Goals, the level of decision-making, and ethics, play in development."
JOHN H CONNOR,First radial velocity results from the MINiature Exoplanet Radial Velocity Array (MINERVA),"The MINiature Exoplanet Radial Velocity Array (MINERVA) is a dedicated observatory of four 0.7 m robotic telescopes fiber-fed to a KiwiSpec spectrograph. The MINERVA mission is to discover super-Earths in the habitable zones of nearby stars. This can be accomplished with MINERVA's unique combination of high precision and high cadence over long time periods. In this work, we detail changes to the MINERVA facility that have occurred since our previous paper. We then describe MINERVA's robotic control software, the process by which we perform 1D spectral extraction, and our forward modeling Doppler pipeline. In the process of improving our forward modeling procedure, we found that our spectrograph's intrinsic instrumental profile is stable for at least nine months. Because of that, we characterized our instrumental profile with a time-independent, cubic spline function based on the profile in the cross dispersion direction, with which we achieved a radial velocity precision similar to using a conventional ""sum-of-Gaussians"" instrumental profile: 1.8 m s−1 over 1.5 months on the RV standard star HD 122064. Therefore, we conclude that the instrumental profile need not be perfectly accurate as long as it is stable. In addition, we observed 51 Peg and our results are consistent with the literature, confirming our spectrograph and Doppler pipeline are producing accurate and precise radial velocities."
JOHN H CONNOR,"Minerva-Australis. I. design, commissioning, and first photometric results","The Minerva-Australis telescope array is a facility dedicated to the follow-up, confirmation, characterization, and mass measurement of planets orbiting bright stars discovered by the Transiting Exoplanet Survey Satellite (TESS)—a category in which it is almost unique in the Southern Hemisphere. It is located at the University of Southern Queensland's Mount Kent Observatory near Toowoomba, Australia. Its flexible design enables multiple 0.7 m robotic telescopes to be used both in combination, and independently, for high-resolution spectroscopy and precision photometry of TESS transit planet candidates. Minerva-Australis also enables complementary studies of exoplanet spin–orbit alignments via Doppler observations of the Rossiter–McLaughlin effect, radial velocity searches for nontransiting planets, planet searches using transit timing variations, and ephemeris refinement for TESS planets. In this first paper, we describe the design, photometric instrumentation, software, and science goals of Minerva-Australis, and note key differences from its Northern Hemisphere counterpart, the Minerva array. We use recent transit observations of four planets, WASP-2b, WASP-44b, WASP-45b, and HD 189733b, to demonstrate the photometric capabilities of Minerva-Australis."
JOHN H CONNOR,"Looking ahead: forecasting and planning for the longer-range future, April 1, 2, and 3, 2005","The conference allowed for many highly esteemed scholars and professionals from a broad range of fields to come together to discuss strategies designed for the 21st century and beyond. The speakers and discussants covered a broad range of subjects including: long-term policy analysis, forecasting for business and investment, the National Intelligence Council Global Trends 2020 report, Europe’s transition from the Marshal plan to the EU, forecasting global transitions, foreign policy planning, and forecasting for defense."
VIPUL C CHITALIA,Deep-learning-driven quantification of interstitial fibrosis in digitized kidney biopsies,"Interstitial fibrosis and tubular atrophy (IFTA) on a renal biopsy are strong indicators of disease chronicity and prognosis. Techniques that are typically used for IFTA grading remain manual, leading to variability among pathologists. Accurate IFTA estimation using computational techniques can reduce this variability and provide quantitative assessment. Using trichrome-stained whole-slide images (WSIs) processed from human renal biopsies, we developed a deep-learning framework that captured finer pathologic structures at high resolution and overall context at the WSI level to predict IFTA grade. WSIs (n = 67) were obtained from The Ohio State University Wexner Medical Center. Five nephropathologists independently reviewed them and provided fibrosis scores that were converted to IFTA grades: ≤10% (none or minimal), 11% to 25% (mild), 26% to 50% (moderate), and >50% (severe). The model was developed by associating the WSIs with the IFTA grade determined by majority voting (reference estimate). Model performance was evaluated on WSIs (n = 28) obtained from the Kidney Precision Medicine Project. There was good agreement on the IFTA grading between the pathologists and the reference estimate (κ = 0.622 ± 0.071). The accuracy of the deep-learning model was 71.8% ± 5.3% on The Ohio State University Wexner Medical Center and 65.0% ± 4.2% on Kidney Precision Medicine Project data sets. Our approach to analyzing microscopic- and WSI-level changes in renal biopsies attempts to mimic the pathologist and provides a regional and contextual estimation of IFTA. Such methods can assist clinicopathologic diagnosis."
VIPUL C CHITALIA,"Towards minimally-invasive, quantitative assessment of chronic kidney disease using optical spectroscopy","The universal pathologic features implicated in the progression of chronic kidney disease (CKD) are interstitial fibrosis and tubular atrophy (IFTA). Current methods of estimating IFTA are slow, labor-intensive and fraught with variability and sampling error, and are not quantitative. As such, there is pressing clinical need for a less-invasive and faster method that can quantitatively assess the degree of IFTA. We propose a minimally-invasive optical method to assess the macro-architecture of kidney tissue, as an objective, quantitative assessment of IFTA, as an indicator of the degree of kidney disease. The method of elastic-scattering spectroscopy (ESS) measures backscattered light over the spectral range 320-900 nm and is highly sensitive to micromorphological changes in tissues. Using two discrete mouse models of CKD, we observed spectral trends of increased scattering intensity in the near-UV to short-visible region (350-450 nm), relative to longer wavelengths, for fibrotic kidneys compared to normal kidney, with a quasi-linear correlation between the ESS changes and the histopathology-determined degree of IFTA. These results suggest the potential of ESS as an objective, quantitative and faster assessment of IFTA for the management of CKD patients and in the allocation of organs for kidney transplantation."
MICHAEL BIRENBAUM QUINTERO,"Alicia Camacho Garcés interview: December 28, 2013",
MICHAEL BIRENBAUM QUINTERO,"Alicia Camacho Garcés interview: December 24, 2013",
MICHAEL BIRENBAUM QUINTERO,"Alicia Camacho Garcés interview: May 20, 2014",
MICHAEL BIRENBAUM QUINTERO,"Alicia Camacho Garcés interview: May 18, 2014",
MICHAEL BIRENBAUM QUINTERO,"Alicia Camacho Garcés interview: May 17, 2014",
MICHAEL BIRENBAUM QUINTERO,"Alicia Camacho Garcés interview: May 19, 2014",
MICHAEL BIRENBAUM QUINTERO,"Alicia Camacho Garcés interview: January 4, 2014",
MICHAEL BIRENBAUM QUINTERO,"Alicia Camacho Garcés interview: December 29, 2013",
MICHAEL BIRENBAUM QUINTERO,"Alicia Camacho Garcés interview: January 5, 2014",
MICHAEL BIRENBAUM QUINTERO,Alicia Camacho Garcés interview transcript,
HEATHER SCHOENFELD,Patchwork protection: the politics of prisoners’ rights accountability in the United States,"In recent years US prisons have failed to meet legally required minimum standards of care and protection of incarcerated people. Explanations for the failure to protect prisoners in the United States focus on the effects of the Prison Litigation Reform Act (PLRA) and lack of adequate external oversight. However, very little scholarship empirically examines how different systems of accountability for prisoners’ rights work (or do not work) together. In this article, we introduce an accountability framework that helps us examine the prisoners’ rights “accountability environment” in the United States. We then compare two post-PLRA case studies of failure to protect incarcerated women from sexual assault in two different states. We find that the prisoners’ rights accountability environment is a patchwork of legal, bureaucratic, professional, and political systems. The patchwork accountability environment consists of a web of hierarchical and interdependent relationships that constrain or enable accountability. We argue that ultimately the effectiveness of prisoners’ rights accountability environments depends on whether protecting prisoners’ rights aligns with the priorities of dominant political officials. Our argument has implications for efforts to improve prison conditions and incarcerated people’s well-being."
MICHAEL SMITH,A systematic search of Zwicky Transient Facility data for ultracompact binary LISA-detectable gravitational-wave sources,"Using photometry collected with the Zwicky Transient Facility, we are conducting an ongoing survey for binary systems with short orbital periods (P_b < 1 hr) with the goal of identifying new gravitational-wave sources detectable by the upcoming Laser Interferometer Space Antenna (LISA). We present a sample of 15 binary systems discovered thus far, with orbital periods ranging from 6.91 to 56.35 minutes. Of the 15 systems, seven are eclipsing systems that do not show signs of significant mass transfer. Additionally, we have discovered two AM Canum Venaticorum systems and six systems exhibiting primarily ellipsoidal variations in their lightcurves. We present follow-up spectroscopy and high-speed photometry confirming the nature of these systems, estimates of their LISA signal-to-noise ratios, and a discussion of their physical characteristics."
MICHAEL SMITH,Shared and distinct transcriptomic cell types across neocortical areas,"The neocortex contains a multitude of cell types that are segregated into layers and functionally distinct areas. To investigate the diversity of cell types across the mouse neocortex, here we analysed 23,822 cells from two areas at distant poles of the mouse neocortex: the primary visual cortex and the anterior lateral motor cortex. We define 133 transcriptomic cell types by deep, single-cell RNA sequencing. Nearly all types of GABA (γ-aminobutyric acid)-containing neurons are shared across both areas, whereas most types of glutamatergic neurons were found in one of the two areas. By combining single-cell RNA sequencing and retrograde labelling, we match transcriptomic types of glutamatergic neurons to their long-range projection specificity. Our study establishes a combined transcriptomic and projectional taxonomy of cortical cell types from functionally distinct areas of the adult mouse cortex."
MICHAEL SMITH,"The role of religion in the longer-range future, April 6, 7, and 8, 2006","The conference brought together some 40 experts from various disciplines to ponder upon the “great dilemma” of how science, religion, and the human future interact. In particular, different panels looked at trends in what is happening to religion around the world, questions about how religion is impacting the current political and economic order, and how the social dynamics unleashed by science and by religion can be reconciled."
MICHAEL SMITH,Biomimetic total synthesis of (+/-)-griffipavixanthone via a cationic cycloaddition-cyclization cascade,"We report the concise, biomimetic total synthesis of the dimeric, Diels-Alder natural product griffipavixanthone from a readily accessible prenylated xanthone monomer. The key step utilizes a novel intermolecular [4+2] cycloaddition-cyclization cascade between a vinyl p-quinone methide and an in situ generated isomeric diene promoted by either Lewis or Brønsted acids. Experimental and computational studies of the reaction pathway suggest that a stepwise, cationic Diels-Alder cycloaddition is operative."
MICHAEL SMITH,The first ultracompact Roche lobe–filling hot subdwarf binary,"We report the discovery of the first short-period binary in which a hot subdwarf star (sdOB) filled its Roche lobe and started mass transfer to its companion. The object was discovered as part of a dedicated high-cadence survey of the Galactic plane named the Zwicky Transient Facility and exhibits a period of P = 39.3401(1) minutes, making it the most compact hot subdwarf binary currently known. Spectroscopic observations are consistent with an intermediate He-sdOB star with an effective temperature of T_eff = 42,400 ± 300 K and a surface gravity of log(g) = 5.77 ± 0.05. A high signal-to-noise ratio GTC+HiPERCAM light curve is dominated by the ellipsoidal deformation of the sdOB star and an eclipse of the sdOB by an accretion disk. We infer a low-mass hot subdwarf donor with a mass MsdOB = 0.337 ± 0.015 M_⊙ and a white dwarf accretor with a mass MWD = 0.545 ± 0.020 M_⊙. Theoretical binary modeling indicates the hot subdwarf formed during a common envelope phase when a 2.5–2.8 M_⊙ star lost its envelope when crossing the Hertzsprung gap. To match its current P_orb, T_eff, log(g), and masses, we estimate a post–common envelope period of P_orb ≈ 150 minutes and find that the sdOB star is currently undergoing hydrogen shell burning. We estimate that the hot subdwarf will become a white dwarf with a thick helium layer of ≈0.1 M_⊙, merge with its carbon/oxygen white dwarf companion after ≈17 Myr, and presumably explode as a thermonuclear supernova or form an R CrB star."
MICHAEL SMITH,Long‐term observations and physical processes in the Moon's extended sodium tail,"The lunar surface is constantly bombarded by the solar wind, photons, and meteoroids, which can liberate Na atoms from the regolith. These atoms are subsequently accelerated by solar photon pressure to form a long comet-like tail opposite the sun. Near new moon, these atoms encounter the Earth's gravity and are “focused” into a beam of enhanced density. This beam appears as the ∼3° diameter Sodium Moon Spot (SMS). Data from the all sky imager at the El Leoncito Observatory have been analyzed for changes in the SMS shape and brightness. New geometry-based relationships have been found that affect the SMS brightness. The SMS is brighter when the Moon is north of the ecliptic at new moon; the SMS is brighter when new moon occurs near perigee; and the SMS peaks in brightness ∼5 h after new moon. After removing these effects, the data were analyzed for long term and seasonal patterns that could be attributed to changes in source mechanisms. No correlation was found between the SMS brightness and the 11-year solar-cycle, the proton or the He++ flow pressure, the density, the speed or the plasma temperature of the solar wind, but an annual pattern was found. A ∼0.83 correlation (Pearson's “r”) was found between the SMS brightness and a 4-year average of sporadic meteor rates at Earth, suggesting a cause-and-effect. The new insights gained from this long-term study put new constraints on the variability of the potential sources of the Na atoms escaping from the Moon."
MICHAEL SMITH,Dielectric elastomer actuator for the measurement of cell traction forces with sub-cellular resolution,
MICHAEL SMITH,The dynamics of the hydroxymethylome and methylome during the progression of Alzheimer's disease,"Alzheimer's disease (AD) is a neurodegenerative condition affecting millions of individuals worldwide and is a major source of mortality in elderly populations. While it is well established that there is a strong genetic basis for the disease, the epigenetic mechanism underlying the disease is largely unknown. The main purpose of this thesis is to understand the alteration of epigenetic modifications associated with the disease and its progression. In particular, we examine how alterations in the cytosine methylation and cytosine hydroxymethylation, two epigenetic modifications that are critically important for the development and function of the brain, are associated with advancing stages of Alzheimer's disease. Eight progressive AD brain samples were examined for changes in DNA methylation and hydroxymethylation by both dot blot analysis and a new oxidative bisulfite (OXBS) deep sequencing technology. The initial results of dot blot analysis reveal a statistically significant decrease in 5hmC associated with intermediate stage AD among the samples. This data suggests that the alterations in epigenetic modifications is likely associated with the pathophysiology of Alzheimer's disease, not only shedding new light on our understanding of the epigenetics of the disease, but also providing the basis for our future investigation on the exact cause and effect relationships of these epigenetic changes and their respective stages in Alzheimer's."
MICHAEL SMITH,Dependence of tensional homeostasis on cell type and on cell-cell interactions,"INTRODUCTION The ability to maintain a homeostatic level of cell tension is essential for many physiological processes. Our group has recently reported that multicellularity is required for tensional homeostasis in endothelial cells. However, other studies have shown that isolated fibroblasts also maintain constant tension over short time scales without the need of cell–cell contacts. Therefore, in this study, our aim was to determine how different cell types regulate tension as isolated cells or in small clustered groupings and to investigate the role of cell–cell adhesion molecules, such as E-cadherin, in this system. METHODS Micropattern traction force microscopy was used to determine how bovine aortic endothelial cells, bovine vascular smooth muscle cells, mouse embryonic fibroblasts, and human gastric adenocarcinoma cells, with or without cell–cell interactions due to E-cadherin, maintain tensional homeostasis over time. Tension temporal fluctuations in single cells and cell clusters were evaluated. RESULTS We found that only endothelial cells require clustering for tensional homeostasis. The same was not verified in fibroblasts or vascular smooth muscle cells. Of relevance, in adenocarcinoma cells, we verified that tensional homeostasis was dependent on the competence of the adhesion molecule E-cadherin at both the single cells and multicellular levels. CONCLUSION These findings indicate that cell–cell contacts may be critical for tensional homeostasis and, potentially, for barrier function of the endothelium. Furthermore, the cell–cell adhesion molecule E-cadherin is an important regulator of tensional homeostasis, even in the absence of cadherin engagement with neighboring cells, which demonstrates its relevance not only as a structural molecule but also as a signaling moiety."
MICHAEL SMITH,Evidence-based implementation practices applied to the intensive treatment of eating disorders: Summary of research and illustration of principles using a case example,"Implementation of evidence‐based practices (EBPs) in intensive treatment settings poses a major challenge in the field of psychology. This is particularly true for eating disorder (ED) treatment, where multidisciplinary care is provided to a severe and complex patient population; almost no data exist concerning best practices in these settings. We summarize the research on EBP implementation science organized by existing frameworks and illustrate how these practices may be applied using a case example. We describe the recent successful implementation of EBPs in a community‐based intensive ED treatment network, which recently adapted and implemented transdiagnostic, empirically supported treatment for emotional disorders across its system of residential and day‐hospital programs. The research summary, implementation frameworks, and case example may inform future efforts to implement evidence‐based practice in intensive treatment settings."
MICHAEL SMITH,Single-platelet nanomechanics measured by high-throughput cytometry,
MICHAEL SMITH,"IMPACT: The Journal of the Center for Interdisciplinary Teaching and Learning. Volume 12, Issue 1, Summer 2023","The essays in this issue explore how to enhance teaching and student learning in the classroom. Our first contributor argues that providing students the opportunity to write questions about course material is a fruitful way to address students’ reticence about asking questions during class and also may result in students performing better on testable material. Moreover, instructors benefit from having students’ questions because the written questions can also be used by the instructor to know better what students are and are not understanding about course material and alerts instructors to where they can further explain or clarify course material. Finally, our first contributor also suggests that students in interdisciplinary classrooms might especially benefit from writing their questions, while instructors of interdisciplinary courses may find the flexibility with using technology to address the written questions in “real time” via the use of technology especially beneficial. In our second contribution, the author argues that pre-service teachers’ educational curriculum should address the academic literature that links poor musical-rhythmic tendencies with reading struggles for reading learners. The author also argues that the rhythm-reading connection is applicable to interdisciplinary educators because it asks those educators to reflect on possible connections between the body and the acquisition of skills that are usually considered purely intellectual. Our Impact book reviewers cover a varied set of interesting and important topics in this issue. One reviewer informs readers about a handbook on community psychology that prioritizes applied and interdisciplinary work; another reviewer details an author’s synthesis of what contemporary archaeology has now come to understand about Maya civilization’s resilient and complex society through time and within their varied mosaic of managed environments; a different reviewer delves into an author’s exploration of how digital media platforms generate novel opportunities for sufferers of trauma to make sense of their experience, and our final reviewer details an author’s accounting of the history, origins, and evolution of the Camp Fire Girls, one of America’s longest-serving girls’ youth movements, its impact on girls’ lives, and how the organization adapted to and resisted dominant ideologies about girls, culture, and race across time."
MICHAEL SMITH,"Bostonia: v. 61, no. 1-2, 4",
MICHAEL SMITH,White paper: an integrated perspective on the causes of hypometric metabolic scaling in animals,"Larger animals studied during ontogeny, across populations, or across species, usually have lower mass-specific metabolic rates than smaller animals (hypometric scaling). This pattern is usually observed regardless of physiological state (e.g., basal, resting, field, and maximally active). The scaling of metabolism is usually highly correlated with the scaling of many life-history traits, behaviors, physiological variables, and cellular/molecular properties, making determination of the causation of this pattern challenging. For across-species comparisons of resting and locomoting animals (but less so for across populations or during ontogeny), the mechanisms at the physiological and cellular level are becoming clear. Lower mass-specific metabolic rates of larger species at rest are due to (a) lower contents of expensive tissues (brains, liver, and kidneys), and (b) slower ion leak across membranes at least partially due to membrane composition, with lower ion pump ATPase activities. Lower mass-specific costs of larger species during locomotion are due to lower costs for lower-frequency muscle activity, with slower myosin and Ca++ ATPase activities, and likely more elastic energy storage. The evolutionary explanation(s) for hypometric scaling remain(s) highly controversial. One subset of evolutionary hypotheses relies on constraints on larger animals due to changes in geometry with size; for example, lower surface-to-volume ratios of exchange surfaces may constrain nutrient or heat exchange, or lower cross-sectional areas of muscles and tendons relative to body mass ratios would make larger animals more fragile without compensation. Another subset of hypotheses suggests that hypometric scaling arises from biotic interactions and correlated selection, with larger animals experiencing less selection for mass-specific growth or neurolocomotor performance. An additional third type of explanation comes from population genetics. Larger animals with their lower effective population sizes and subsequent less effective selection relative to drift may have more deleterious mutations, reducing maximal performance and metabolic rates. Resolving the evolutionary explanation for the hypometric scaling of metabolism and associated variables is a major challenge for organismal and evolutionary biology. To aid progress, we identify some variation in terminology use that has impeded cross-field conversations on scaling. We also suggest that promising directions for the field to move forward include (1) studies examining the linkages between ontogenetic, population-level, and cross-species allometries; (2) studies linking scaling to ecological or phylogenetic context; (3) studies that consider multiple, possibly interacting hypotheses; and (4) obtaining better field data for metabolic rates and the life history correlates of metabolic rate such as lifespan, growth rate, and reproduction."
MICHAEL SMITH,A new class of large-amplitude radial-mode hot subdwarf pulsators,"Using high-cadence observations from the Zwicky Transient Facility at low Galactic latitudes, we have discovered a new class of pulsating, hot compact stars. We have found four candidates, exhibiting blue colors (g − r ≤ −0.1 mag), pulsation amplitudes of >5%, and pulsation periods of 200–475 s. Fourier transforms of the light curves show only one dominant frequency. Phase-resolved spectroscopy for three objects reveals significant radial velocity, T eff, and log(g) variations over the pulsation cycle, which are consistent with large-amplitude radial oscillations. The mean T eff and log(g) for these stars are consistent with hot subdwarf B (sdB) effective temperatures and surface gravities. We calculate evolutionary tracks using MESA and adiabatic pulsations using GYRE for low-mass, helium-core pre-white dwarfs (pre-WDs) and low-mass helium-burning stars. Comparison of low-order radial oscillation mode periods with the observed pulsation periods show better agreement with the pre-WD models. Therefore, we suggest that these new pulsators and blue large-amplitude pulsators (BLAPs) could be members of the same class of pulsators, composed of young ≈0.25–0.35 M ⊙ helium-core pre-WDs."
MICHAEL SMITH,Asymmetric synthesis of griffipavixanthone employing a chiral phosphoric acid-catalyzed cycloaddition,"Asymmetric synthesis of the biologically active xanthone dimer griffipavixanthone is reported along with its absolute stereochemistry determination. Synthesis of the natural product is accomplished via dimerization of a p-quinone methide using a chiral phosphoric acid catalyst to afford a protected precursor in excellent diastereo- and enantioselectivity. Mechanistic studies, including an unbiased computational investigation of chiral ion-pairs using parallel tempering, were performed in order to probe the mode of asymmetric induction."
MICHAEL SMITH,Syntheses of griffipavixanthone and related dimeric xanthones using para-quinone methides,"Xanthone natural products are a diverse class of structurally interesting and biologically active molecules most commonly isolated from plants. The tricyclic framework of a xanthone can be found in a number of complex natural products. Previous efforts have mostly focused on the synthesis of polycyclic xanthone natural products, thereby leaving dimeric xanthones an unexplored realm. Herein, we report an efficient methodology to construct the dimeric natural product griffipavixanthone and related congeners. We first explored the racemic synthesis of griffipavixanthone (GPX). The key step utilizes a novel, intermolecular [4+2] cycloaddition–cyclization cascade between a vinyl p-quinone methide (p-QM) and an in situ generated 1,3-diene promoted by either Lewis or Brønsted acids. Experimental and computational studies reveal that the reaction pathway operates via a stepwise, cationic Diels–Alder cycloaddition. With an interest in harnessing the inherent cationic nature of the cascade reaction, we became interested in achieving an asymmetric synthesis of GPX. Synthesis of the natural product was accomplished via dimerization of a p-quinone methide using a specific chiral phosphoric acid (CPA) catalyst to afford a protected precursor in excellent diastereo- and enantioselectivity. Mechanistic studies, including an unbiased computational investigation of chiral ion-pairs using parallel tempering (PT) methods, were performed in order to probe the mode of asymmetric induction. This methodology enabled the absolute stereochemistry determination and prompted biological investigations to probe its efficacy as an anticancer agent. Finally, we report a divergent reaction of the xanthone p-QM monomers to form a novel limonene-type bis-xanthone architecture. A Hammett study designed to probe the mechanism revealed that the electronics of the xanthone carbonyl dictate regioselectivity; the overall process allows for initial bond construction tunability and ultimately new chemotypes."
MICHAEL SMITH,Leveraging genomics to understand threats in a migratory waterbird,"Understanding how risk factors affect populations across their annual cycle is a major challenge for conserving migratory birds. For example, disease outbreaks may happen on the breeding grounds, the wintering grounds, or during migration and are expected to accelerate under climate change. The ability to identify the geographic origins of impacted individuals, especially outside of breeding areas, might make it possible to predict demographic trends and inform conservation decision-making. However, such an effort is made more challenging by the degraded state of carcasses and resulting low quality of DNA available. Here, we describe a rapid and low-cost approach for identifying the origins of birds sampled across their annual cycle that is robust even when DNA quality is poor. We illustrate the approach in the common loon (Gavia immer), an iconic migratory aquatic bird that is under increasing threat on both its breeding and wintering areas. Using 300 samples collected from across the breeding range, we develop a panel of 158 single-nucleotide polymorphisms (SNP) loci with divergent allele frequencies across six genetic subpopulations. We use this SNP panel to identify the breeding grounds for 142 live nonbreeding individuals and carcasses. For example, genetic assignment of loons sampled during botulism outbreaks in parts of the Great Lakes provides evidence for the significant role the lakes play as migratory stopover areas for loons that breed across wide swaths of Canada, and highlights the vulnerability of a large segment of the breeding population to botulism outbreaks that are occurring in the Great Lakes with increasing frequency. Our results illustrate that the use of SNP panels to identify breeding origins of carcasses collected during the nonbreeding season can improve our understanding of the population-specific impacts of mortality from disease and anthropogenic stressors, ultimately allowing more effective management."
MICHAEL SMITH,Between fragments of touch and skin,"Composed for the JACK Quartet during their Spring residency at BU during the week of Febuary 19-23, 2018. Recorded at the BU Concert Hall on Febuary 21, 2018. Composed between September 2016 - February 2018. duration: approx. 30 min. “ ccidentall , r’s finger touches Ch e’s, their feet, under the table, happen to against each other. W might be eng by the mean of these accidents; e might concentrate ph on these slight zones of contact and d l t in this fragm nt of inert finger or f , fet i tically, without concern for the re- sponse (like od——as t etym y of the word t lls us——the Fe does not reply). But in fact erthe is not pe e, he is in lov : h creates meaning, al ays and ev ry here, out of nothing, a it is meaning wh th ll im: is in crucible of meaning. Every contact, f r t lover, raises qu st on of n answer: the skin s asked to reply. “ Quand mon doigt par mégarde… ” (A squeeze of the hand——enormous documentation——a tiny gesture within the palm, a knee which doesn’t move away, an arm extended, as if quite naturally, along the back of a sofa and against which the other’s head gradu- ally comes to rest——this is the paradisiac realm of subtle and clandestine signs: a kind of festival not of the senses but of meaning.) ” Roland Barthes, A Lover’s Discourse: Fragments"
MICHAEL SMITH,NRXN3 Is a Novel Locus for Waist Circumference: A Genome-Wide Association Study from the CHARGE Consortium,"Central abdominal fat is a strong risk factor for diabetes and cardiovascular disease. To identify common variants influencing central abdominal fat, we conducted a two-stage genome-wide association analysis for waist circumference (WC). In total, three loci reached genome-wide significance. In stage 1, 31,373 individuals of Caucasian descent from eight cohort studies confirmed the role of FTO and MC4R and identified one novel locus associated with WC in the neurexin 3 gene [NRXN3 (rs10146997, p = 6.4×10−7)]. The association with NRXN3 was confirmed in stage 2 by combining stage 1 results with those from 38,641 participants in the GIANT consortium (p = 0.009 in GIANT only, p = 5.3×10−8 for combined analysis, n = 70,014). Mean WC increase per copy of the G allele was 0.0498 z-score units (0.65 cm). This SNP was also associated with body mass index (BMI) [p = 7.4×10−6, 0.024 z-score units (0.10 kg/m2) per copy of the G allele] and the risk of obesity (odds ratio 1.13, 95% CI 1.07–1.19; p = 3.2×10−5 per copy of the G allele). The NRXN3 gene has been previously implicated in addiction and reward behavior, lending further evidence that common forms of obesity may be a central nervous system-mediated disorder. Our findings establish that common variants in NRXN3 are associated with WC, BMI, and obesity. Author Summary Obesity is a major health concern worldwide. In the past two years, genome-wide association studies of DNA markers known as SNPs (single nucleotide polymorphisms) have identified two novel genetic factors that may help scientists better understand why some people may be more susceptible to obesity. Similarly, this paper describes results from a large scale genome-wide association analysis for obesity susceptibility genes that includes 31,373 individuals from 8 separate studies. We uncovered a new gene influencing waist circumference, the neurexin 3 gene (NRXN3), which has been previously implicated in studies of addiction and reward behavior. These findings lend further evidence that our genes may influence our desire and consumption of food and, in turn, our susceptibility to obesity."
MICHAEL SMITH,Investigating the neural correlates of voice versus speech-sound directed information in pre-school children.,"Studies in sleeping newborns and infants propose that the superior temporal sulcus is involved in speech processing soon after birth. Speech processing also implicitly requires the analysis of the human voice, which conveys both linguistic and extra-linguistic information. However, due to technical and practical challenges when neuroimaging young children, evidence of neural correlates of speech and/or voice processing in toddlers and young children remains scarce. In the current study, we used functional magnetic resonance imaging (fMRI) in 20 typically developing preschool children (average age  = 5.8 y; range 5.2-6.8 y) to investigate brain activation during judgments about vocal identity versus the initial speech sound of spoken object words. FMRI results reveal common brain regions responsible for voice-specific and speech-sound specific processing of spoken object words including bilateral primary and secondary language areas of the brain. Contrasting voice-specific with speech-sound specific processing predominantly activates the anterior part of the right-hemispheric superior temporal sulcus. Furthermore, the right STS is functionally correlated with left-hemispheric temporal and right-hemispheric prefrontal regions. This finding underlines the importance of the right superior temporal sulcus as a temporal voice area and indicates that this brain region is specialized, and functions similarly to adults by the age of five. We thus extend previous knowledge of voice-specific regions and their functional connections to the young brain which may further our understanding of the neuronal mechanism of speech-specific processing in children with developmental disorders, such as autism or specific language impairments."
MICHAEL SMITH,Mechanical forces regulate the interactions of fibronectin and collagen I in extracellular matrix,"Despite the crucial role of extracellular matrix (ECM) in directing cell fate in healthy and diseased tissues--particularly in development, wound healing, tissue regeneration and cancer--the mechanisms that direct the assembly and regulate hierarchical architectures of ECM are poorly understood. Collagen I matrix assembly in vivo requires active fibronectin (Fn) fibrillogenesis by cells. Here we exploit Fn-FRET probes as mechanical strain sensors and demonstrate that collagen I fibres preferentially co-localize with more-relaxed Fn fibrils in the ECM of fibroblasts in cell culture. Fibre stretch-assay studies reveal that collagen I's Fn-binding domain is responsible for the mechano-regulated interaction. Furthermore, we show that Fn-collagen interactions are reciprocal: relaxed Fn fibrils act as multivalent templates for collagen assembly, but once assembled, collagen fibres shield Fn fibres from being stretched by cellular traction forces. Thus, in addition to the well-recognized, force-regulated, cell-matrix interactions, forces also tune the interactions between different structural ECM components."
MICHAEL SMITH,"One future or many? November 14, 15, and 16, 2002","The conference brought together some 30 experts from various disciplines to discuss whether the trajectories of the future will be ‘global’ or ‘regional’ in nature. Different panels looks at the future trajectories for Europe, the Western Hemisphere, Central Asia and the Former Soviet Union, and on Asia and in each case the discussion looked at the relative importance of the regional and of global dynamics on teh forces shaping the future of these regions."
MICHAEL SMITH,Priorities for synthesis research in ecology and environmental science,
MICHAEL SMITH,Monetizing virtuous employees,"This study addresses contracting with an employee (labeled a saint) whose distaste for profit-seeking effort can be mitigated by engaging in another effort directed toward the realization of broader societal goals (i.e., sustainability). The saint is also optimistic about the efficacy of this effort. I establish conditions under which the principal maximizes expected profits by hiring a saint instead of a traditional agent. This can occur even if sustainability initiatives, not including the effect on compensation, generate negative cash flows. I extend the model to include a sustainability report used in a second period for recontracting purposes, and find that the principal can prefer an uninformative report because it may allow her to continue to extract the saint's private benefits from sustainability actions."
MICHAEL SMITH,Heat and learning,
MICHAEL SMITH,"O Brother, where start thou? Sibling spillovers on college and major choice in four countries","Family and social networks are widely believed to influence important life decisions, but causal identification of those effects is notoriously challenging. Using data from Chile, Croatia, Sweden, and the United States, we study within-family spillovers in college and major choice across a variety of national contexts. Exploiting college-specific admissions thresholds that directly affect older but not younger siblings’ college options, we show that in all four countries a meaningful portion of younger siblings follow their older sibling to the same college or college-major combination. Older siblings are followed regardless of whether their target and counterfactual options have large, small, or even negative differences in quality. Spillover effects disappear, however, if the older sibling drops out of college, suggesting that older siblings’ college experiences matter. That siblings influence important human capital investment decisions across such varied contexts suggests that our findings are not an artifact of particular institutional detail but a more generalizable description of human behavior. Causal links between the postsecondary paths of close peers may partly explain persistent college enrollment inequalities between social groups, and this suggests that interventions to improve college access may have multiplier effects."
MICHAEL SMITH,A chemical screen identifies structurally diverse metal chelators with activity against the fungal pathogen Candida albicans,"Candida albicans, one of the most prevalent human fungal pathogens, causes diverse diseases extending from superficial infections to deadly systemic mycoses. Currently, only three major classes of antifungal drugs are available to treat systemic infections: azoles, polyenes, and echinocandins. Alarmingly, the efficacy of these antifungals against C. albicans is hindered both by basal tolerance toward the drugs and the development of resistance mechanisms such as alterations of the drug's target, modulation of stress responses, and overexpression of efflux pumps. Thus, the need to identify novel antifungal strategies is dire. To address this challenge, we screened 3,049 structurally-diverse compounds from the Boston University Center for Molecular Discovery (BU-CMD) chemical library against a C. albicans clinical isolate and identified 17 molecules that inhibited C. albicans growth by >80% relative to controls. Among the most potent compounds were CMLD013360, CMLD012661, and CMLD012693, molecules representing two distinct chemical scaffolds, including 3-hydroxyquinolinones and a xanthone natural product. Based on structural insights, CMLD013360, CMLD012661, and CMLD012693 were hypothesized to exert antifungal activity through metal chelation. Follow-up investigations revealed all three compounds exerted antifungal activity against non-albicans Candida, including Candida auris and Candida glabrata, with the xanthone natural product CMLD013360 also displaying activity against the pathogenic mould Aspergillus fumigatus. Media supplementation with metallonutrients, namely ferric or ferrous iron, rescued C. albicans growth, confirming these compounds act as metal chelators. Thus, this work identifies and characterizes two chemical scaffolds that chelate iron to inhibit the growth of the clinically relevant fungal pathogen C. albicansIMPORTANCEThe worldwide incidence of invasive fungal infections is increasing at an alarming rate. Systemic candidiasis caused by the opportunistic pathogen Candida albicans is the most common cause of life-threatening fungal infection. However, due to the limited number of antifungal drug classes available and the rise of antifungal resistance, an urgent need exists for the identification of novel treatments. By screening a compound collection from the Boston University Center for Molecular Discovery (BU-CMD), we identified three compounds representing two distinct chemical scaffolds that displayed activity against C. albicans. Follow-up analyses confirmed these molecules were also active against other pathogenic fungal species including Candida auris and Aspergillus fumigatus. Finally, we determined that these compounds inhibit the growth of C. albicans in culture through iron chelation. Overall, this observation describes two novel chemical scaffolds with antifungal activity against diverse fungal pathogens."
MICHAEL SMITH,Event Horizon Telescope imaging of the archetypal blazar 3C 279 at an extreme 20 microarcsecond resolution,"3C 279 is an archetypal blazar with a prominent radio jet that show broadband flux density variability across the entire electromagnetic spectrum. We use an ultra-high angular resolution technique – global Very Long Baseline Interferometry (VLBI) at 1.3 mm (230 GHz) – to resolve the innermost jet of 3C 279 in order to study its fine-scale morphology close to the jet base where highly variable γ-ray emission is thought to originate, according to various models. The source was observed during four days in April 2017 with the Event Horizon Telescope at 230 GHz, including the phased Atacama Large Millimeter/submillimeter Array (ALMA), at an angular resolution of ∼20 μas (at a redshift of z = 0.536 this corresponds to ∼0.13 pc  ∼ 1700 Schwarzschild radii with a black hole mass M<jats:sub>BH</jats:sub> = 8 × 10^8 M_⊙). Imaging and model-fitting techniques were applied to the data to parameterize the fine-scale source structure and its variation. We find a multicomponent inner jet morphology with the northernmost component elongated perpendicular to the direction of the jet, as imaged at longer wavelengths. The elongated nuclear structure is consistent on all four observing days and across different imaging methods and model-fitting techniques, and therefore appears robust. Owing to its compactness and brightness, we associate the northern nuclear structure as the VLBI “core”. This morphology can be interpreted as either a broad resolved jet base or a spatially bent jet. We also find significant day-to-day variations in the closure phases, which appear most pronounced on the triangles with the longest baselines. Our analysis shows that this variation is related to a systematic change of the source structure. Two inner jet components move non-radially at apparent speeds of ∼15 c and ∼20 c (∼1.3 and ∼1.7 μas day^−1, respectively), which more strongly supports the scenario of traveling shocks or instabilities in a bent, possibly rotating jet. The observed apparent speeds are also coincident with the 3C 279 large-scale jet kinematics observed at longer (cm) wavelengths, suggesting no significant jet acceleration between the 1.3 mm core and the outer jet. The intrinsic brightness temperature of the jet components are ≲10^10 K, a magnitude or more lower than typical values seen at ≥7 mm wavelengths. The low brightness temperature and morphological complexity suggest that the core region of 3C 279 becomes optically thin at short (mm) wavelengths."
MICHAEL SMITH,First M87 Event Horizon Telescope results. II. Array and instrumentation,"The Event Horizon Telescope (EHT) is a very long baseline interferometry (VLBI) array that comprises millimeter- and submillimeter-wavelength telescopes separated by distances comparable to the diameter of the Earth. At a nominal operating wavelength of ~1.3 mm, EHT angular resolution (λ/D) is ~25 μas, which is sufficient to resolve nearby supermassive black hole candidates on spatial and temporal scales that correspond to their event horizons. With this capability, the EHT scientific goals are to probe general relativistic effects in the strong-field regime and to study accretion and relativistic jet formation near the black hole boundary. In this Letter we describe the system design of the EHT, detail the technology and instrumentation that enable observations, and provide measures of its performance. Meeting the EHT science objectives has required several key developments that have facilitated the robust extension of the VLBI technique to EHT observing wavelengths and the production of instrumentation that can be deployed on a heterogeneous array of existing telescopes and facilities. To meet sensitivity requirements, high-bandwidth digital systems were developed that process data at rates of 64 gigabit s−1, exceeding those of currently operating cm-wavelength VLBI arrays by more than an order of magnitude. Associated improvements include the development of phasing systems at array facilities, new receiver installation at several sites, and the deployment of hydrogen maser frequency standards to ensure coherent data capture across the array. These efforts led to the coordination and execution of the first Global EHT observations in 2017 April, and to event-horizon-scale imaging of the supermassive black hole candidate in M87."
MICHAEL SMITH,First M87 Event Horizon Telescope results. I. The shadow of the supermassive black hole,"When surrounded by a transparent emission region, black holes are expected to reveal a dark shadow caused by gravitational light bending and photon capture at the event horizon. To image and study this phenomenon, we have assembled the Event Horizon Telescope, a global very long baseline interferometry array observing at a wavelength of 1.3 mm. This allows us to reconstruct event-horizon-scale images of the supermassive black hole candidate in the center of the giant elliptical galaxy M87. We have resolved the central compact radio source as an asymmetric bright emission ring with a diameter of 42 ± 3 μas, which is circular and encompasses a central depression in brightness with a flux ratio gsim10:1. The emission ring is recovered using different calibration and imaging schemes, with its diameter and width remaining stable over four different observations carried out in different days. Overall, the observed image is consistent with expectations for the shadow of a Kerr black hole as predicted by general relativity. The asymmetry in brightness in the ring can be explained in terms of relativistic beaming of the emission from a plasma rotating close to the speed of light around a black hole. We compare our images to an extensive library of ray-traced general-relativistic magnetohydrodynamic simulations of black holes and derive a central mass of M = (6.5 ± 0.7) × 10^9 M ⊙. Our radio-wave observations thus provide powerful evidence for the presence of supermassive black holes in centers of galaxies and as the central engines of active galactic nuclei. They also present a new tool to explore gravity in its most extreme limit and on a mass scale that was so far not accessible."
MICHAEL SMITH,Using molecular mechanics to predict bulk material properties of fibronectin fibers,"The structural proteins of the extracellular matrix (ECM) form fibers with finely tuned mechanical properties matched to the time scales of cell traction forces. Several proteins such as fibronectin (Fn) and fibrin undergo molecular conformational changes that extend the proteins and are believed to be a major contributor to the extensibility of bulk fibers. The dynamics of these conformational changes have been thoroughly explored since the advent of single molecule force spectroscopy and molecular dynamics simulations but remarkably, these data have not been rigorously applied to the understanding of the time dependent mechanics of bulk ECM fibers. Using measurements of protein density within fibers, we have examined the influence of dynamic molecular conformational changes and the intermolecular arrangement of Fn within fibers on the bulk mechanical properties of Fn fibers. Fibers were simulated as molecular strands with architectures that promote either equal or disparate molecular loading under conditions of constant extension rate. Measurements of protein concentration within micron scale fibers using deep ultraviolet transmission microscopy allowed the simulations to be scaled appropriately for comparison to in vitro measurements of fiber mechanics as well as providing estimates of fiber porosity and water content, suggesting Fn fibers are approximately 75% solute. Comparing the properties predicted by single molecule measurements to in vitro measurements of Fn fibers showed that domain unfolding is sufficient to predict the high extensibility and nonlinear stiffness of Fn fibers with surprising accuracy, with disparately loaded fibers providing the best fit to experiment. This work shows the promise of this microstructural modeling approach for understanding Fn fiber properties, which is generally applicable to other ECM fibers, and could be further expanded to tissue scale by incorporating these simulated fibers into three dimensional network models."
MICHAEL SMITH,Psychometric properties of the mock interview rating scale for schizophrenia and other serious mental illnesses,"BACKGROUND: Over the past 10 years, job interview training has emerged as an area of study among adults with schizophrenia and other serious mental illnesses who face significant challenges when navigating job interviews. The field of mental health services research has limited access to assessments of job interview skills with rigorously evaluated psychometric properties. OBJECTIVE: We sought to evaluate the initial psychometric properties of a measure assessing job interview skills via role-play performance. METHODS: As part of a randomized controlled trial, 90 adults with schizophrenia or other serious mental illnesses completed a job interview role-play assessment with eight items (and scored using anchors) called the mock interview rating scale (MIRS). A classical test theory analysis was conducted including confirmatory factor analyses, Rasch model analysis and calibration, and differential item functioning; along with inter-rater, internal consistency, and test-retest reliabilities. Pearson correlations were used to evaluate construct, convergent, divergent, criterion, and predictive validity by correlating the MIRS with demographic, clinical, cognitive, work history measures, and employment outcomes. RESULTS: Our analyses resulted in the removal of a single item (sounding honest) and yielded a unidimensional total score measurement with support for its inter-rater reliability, internal consistency, and test-retest reliability. There was initial support for the construct, convergent, criterion, and predictive validities of the MIRS, as it correlated with measures of social competence, neurocognition, valuing job interview training, and employment outcomes. Meanwhile, the lack of correlations with race, physical health, and substance abuse lent support for divergent validity. CONCLUSION: This study presents initial evidence that the seven-item version of the MIRS has acceptable psychometric properties supporting its use to assess job interview skills reliably and validly among adults with schizophrenia and other serious mental illnesses. CLINICAL TRIAL REGISTRATION: NCT03049813."
MICHAEL SMITH,"Silk-fibronectin protein alloy fibres support cell adhesion and viability as a high strength, matrix fibre analogue","Silk is a natural polymer with broad utility in biomedical applications because it exhibits general biocompatibility and high tensile material properties. While mechanical integrity is important for most biomaterial applications, proper function and integration also requires biomaterial incorporation into complex surrounding tissues for many physiologically relevant processes such as wound healing. In this study, we spin silk fibroin into a protein alloy fibre with whole fibronectin using wet spinning approaches in order to synergize their respective strength and cell interaction capabilities. Results demonstrate that silk fibroin alone is a poor adhesive surface for fibroblasts, endothelial cells, and vascular smooth muscle cells in the absence of serum. However, significantly improved cell attachment is observed to silk-fibronectin alloy fibres without serum present while not compromising the fibres' mechanical integrity. Additionally, cell viability is improved up to six fold on alloy fibres when serum is present while migration and spreading generally increase as well. These findings demonstrate the utility of composite protein alloys as inexpensive and effective means to create durable, biologically active biomaterials."
MICHAEL SMITH,A reporting format for leaf-level gas exchange data and metadata,"Leaf-level gas exchange data support the mechanistic understanding of plant fluxes of carbon and water. These fluxes inform our understanding of ecosystem function, are an important constraint on parameterization of terrestrial biosphere models, are necessary to understand the response of plants to global environmental change, and are integral to efforts to improve crop production. Collection of these data using gas analyzers can be both technically challenging and time consuming, and individual studies generally focus on a small range of species, restricted time periods, or limited geographic regions. The high value of these data is exemplified by the many publications that reuse and synthesize gas exchange data, however the lack of metadata and data reporting conventions make full and efficient use of these data difficult. Here we propose a reporting format for leaf-level gas exchange data and metadata to provide guidance to data contributors on how to store data in repositories to maximize their discoverability, facilitate their efficient reuse, and add value to individual datasets. For data users, the reporting format will better allow data repositories to optimize data search and extraction, and more readily integrate similar data into harmonized synthesis products. The reporting format specifies data table variable naming and unit conventions, as well as metadata characterizing experimental conditions and protocols. For common data types that were the focus of this initial version of the reporting format, i.e., survey measurements, dark respiration, carbon dioxide and light response curves, and parameters derived from those measurements, we took a further step of defining required additional data and metadata that would maximize the potential reuse of those data types. To aid data contributors and the development of data ingest tools by data repositories we provided a translation table comparing the outputs of common gas exchange instruments. Extensive consultation with data collectors, data users, instrument manufacturers, and data scientists was undertaken in order to ensure that the reporting format met community needs. The reporting format presented here is intended to form a foundation for future development that will incorporate additional data types and variables as gas exchange systems and measurement approaches advance in the future. The reporting format is published in the U.S. Department of Energy's ESS-DIVE data repository, with documentation and future development efforts being maintained in a version control system."
MICHAEL SMITH,Reproductive inequality in humans and other mammals,"To address claims of human exceptionalism, we determine where humans fit within the greater mammalian distribution of reproductive inequality. We show that humans exhibit lower reproductive skew (i.e., inequality in the number of surviving offspring) among males and smaller sex differences in reproductive skew than most other mammals, while nevertheless falling within the mammalian range. Additionally, female reproductive skew is higher in polygynous human populations than in polygynous nonhumans mammals on average. This patterning of skew can be attributed in part to the prevalence of monogamy in humans compared to the predominance of polygyny in nonhuman mammals, to the limited degree of polygyny in the human societies that practice it, and to the importance of unequally held rival resources to women's fitness. The muted reproductive inequality observed in humans appears to be linked to several unusual characteristics of our species-including high levels of cooperation among males, high dependence on unequally held rival resources, complementarities between maternal and paternal investment, as well as social and legal institutions that enforce monogamous norms."
MICHAEL SMITH,The long-baseline neutrino experiment: exploring fundamental symmetries of the universe,"The preponderance of matter over antimatter in the early Universe, the dynamics of the supernova bursts that produced the heavy elements necessary for life and whether protons eventually decay --- these mysteries at the forefront of particle physics and astrophysics are key to understanding the early evolution of our Universe, its current state and its eventual fate. The Long-Baseline Neutrino Experiment (LBNE) represents an extensively developed plan for a world-class experiment dedicated to addressing these questions. LBNE is conceived around three central components: (1) a new, high-intensity neutrino source generated from a megawatt-class proton accelerator at Fermi National Accelerator Laboratory, (2) a near neutrino detector just downstream of the source, and (3) a massive liquid argon time-projection chamber deployed as a far detector deep underground at the Sanford Underground Research Facility. This facility, located at the site of the former Homestake Mine in Lead, South Dakota, is approximately 1,300 km from the neutrino source at Fermilab -- a distance (baseline) that delivers optimal sensitivity to neutrino charge-parity symmetry violation and mass ordering effects. This ambitious yet cost-effective design incorporates scalability and flexibility and can accommodate a variety of upgrades and contributions. With its exceptional combination of experimental configuration, technical capabilities, and potential for transformative discoveries, LBNE promises to be a vital facility for the field of particle physics worldwide, providing physicists from around the globe with opportunities to collaborate in a twenty to thirty year program of exciting science. In this document we provide a comprehensive overview of LBNE's scientific objectives, its place in the landscape of neutrino physics worldwide, the technologies it will incorporate and the capabilities it will possess."
ANNA CERVANTES-ARSLANIAN,Illicit drug use and cerebral microbleeds in stroke and transient ischemic attack patients,"Background: Cerebral microbleeds (CMB) signal cerebral small vessel disease and are associated with ischemic stroke (IS) incidence, recurrence, and complications. While illicit drug use (IDU) is associated with cerebral small vessel disease, the association between CMB and IDU is understudied. We sought to delineate differences in vascular risk factors between IDU and CMB and determine the effect of this relationship on outcomes in IS/transient ischemic attack (TIA) patients. Methods: We included 2001 consecutive IS and TIA patients (years 2009-2018) with a readable T2*gradient-echo MRI sequence. CMB rating followed standardized guidelines and CMB were grouped topographically into lobar, deep or infratentorial. IDU data (history and/or urine toxicology) was available for 1746 patients. The adverse composite outcome included pneumonia, urinary tract infection, deep venous thrombosis or death during hospitalization. Good functional outcome was defined as modified Rankin scale score < 3 and ambulatory on discharge. Univariate analysis was used to assess vascular risk factors and multivariable logistic regression was used to characterize the IDU/CMB relationship on outcomes. Results: We observed IDU in 13.8 % (n=241), and CMB in 32.9% (n=575, 53.8% lobar, 27.3% deep and 18.8% infratentorial). Patients with IDU and at least one CMB were older (53.6±10.5 vs. 56.9±11.5, p=0.04), had a lower BMI (28.1±5.9 vs. 26.6±4.4, p=0.04), and were more likely to have had a previous IS/TIA (25.1% vs. 41.9%, p=0.01). IDU trended higher for those with severe CMB (10+) compared with those without CMB and 1-9 CMB (25% [n=9] vs 14.3% [n=1171] and 12.1% [n=65] respectively; p=0.07) without individual drug deviations from this pattern. Adverse and good functional outcomes were observed in 177 and 905 total patients, respectively. No significant interaction was observed between IDU and CMB with either adverse or functional composite outcomes. Conclusion: IDU prevalence was high in our urban study population, and showed a borderline association with increasing CMB burden. Patients with CMB and IDU history were older and more likely to have had a previous IS/TIA. Further studies are required to clarify the clinical consequences related to the relationship between IDU and CMB."
SUSAN REBECCA MARTIN,"The ISCIP Analyst, Volume XI, Issue 1",
VASILEIOS ZIKOPOULOS,"Sleep spindles in primates: modelling the effects of distinct laminar thalamocortical connectivity in core, matrix, and reticular thalamic circuits","Sleep spindles are associated with the beginning of deep sleep and memory consolidation and are disrupted in schizophrenia and autism. In primates, distinct core and matrix thalamocortical (TC) circuits regulate sleep-spindle activity, through communications that are filtered by the inhibitory thalamic reticular nucleus (TRN) however, little is known about typical TC network interactions and the mechanisms that are disrupted in brain disorders. We developed a primate-specific, circuit-based TC computational model with distinct core and matrix loops that can simulate sleep spindles. We implemented novel multilevel cortical and thalamic mixing, and included local thalamic inhibitory interneurons, and direct layer 5 projections of variable density to TRN and thalamus to investigate the functional consequences of different ratios of core and matrix node connectivity contribution to spindle dynamics. Our simulations showed that spindle power in primates can be modulated based on the level of cortical feedback, thalamic inhibition, and engagement of model core vs. matrix, with the latter having a greater role in spindle dynamics. The study of the distinct spatial and temporal dynamics of core-, matrix-, and mix-generated sleep spindles establishes a framework to study disruption of TC circuit balance underlying deficits in sleep and attentional gating seen in autism and schizophrenia."
VASILEIOS ZIKOPOULOS,Relay of affective stimuli from amygdala to thalamus parallels sensory pathways,"The amygdala, the emotional sensor of the brain, is strongly connected with the posterior orbitofrontal cortex (pOFC), forming a pathway activated by reward learning. In addition, the amygdala innervates neurons in the mediodorsal thalamic nucleus (MD) that project to pOFC, forming a second, indirect route for the amygdala to in􀃓uence the pOFC sector of the prefrontal cortex. The indirect pathway that connects the amygdala and pOFC through the thalamus may be similar to sensory pathways connecting peripheral receptors with sensory cortices through sensory relay thalamic nuclei. The indirect pathway is morphologically distinct from the direct pathway; amygdalar pathway terminals in MD are larger than those in the pOFC, and likely derive from separate neuronal populations in the amygdala (Timbie and Barbas, Society for Neuroscience, 2013; J Neurosci, 2015). The synaptic interactions and potential specializations of amygdalar terminals in MD have not yet been described in comparison to other thalamic afferents. We addressed this issue by labeling amygdalar axons in MD in rhesus monkeys and compared them with retinal axons terminating in the lateral geniculate nucleus (LGN). We studied axon terminations in MD and LGN using serial section electron microscopy and analyzed pre- and post-synaptic elements by morphology. All amygdalar terminals in MD and retinal ganglion terminals in LGN contained multiple mitochondria, and were classed as round, large (RL) boutons. Amygdalar and retinal RL boutons contained excitatory type vesicles and formed several asymmetric (excitatory) synapses with dendrites of thalamocortical relay neurons and dendrites of inhibitory interneurons. In a significant proportion of these multi-synaptic arrangements, the inhibitory dendrites contained vesicles and formed symmetric synapses with the dendrite of the thalamocortical neuron. These novel findings reveal that amygdalar terminals in MD form synaptic triads, reminiscent of those found in sensory thalamic relay nuclei, like LGN. Our findings suggest that amygdalar inputs to MD can drive signals to cortex, ensuring efficient transmission of salient emotional information, akin to sensory thalamic relays."
VASILEIOS ZIKOPOULOS,Balance of excitation and inhibition in orbitofrontal cortex and potential for disruption in autism,"The human orbitofrontal cortex (OFC) is involved in assessing the emotional significance of events and stimuli, emotion based learning, allocation of attentional resources, and social cognition. Little is known about the structure, connectivity and excitatory/inhibitory circuit interactions underlying these diverse functions in human OFC. To fill this gap we used high resolution microscopy, followed by quantitative tracing analysis, to characterize the morphology and distribution of myelinated axons across cortical layers in human OFC at the single axon level, as a proxy of excitatory pathways. In the same regions, we also examined the laminar distribution of neurochemically- and functionally-distinct inhibitory neurons that express calcium-binding proteins parvalbumin (PV), calbindin (CB), and calretinin (CR). Associations of myelinated axons with distinct inhibitory neurons changed across layers and provided a proxy for the study of the excitatory/inhibitory ratio in OFC. We found that density of myelinated axons increased consistently towards layer VI, while average axon diameter did not change significantly. Inhibitory CR-positive neurons were mostly found in layer II, the layer with the lowest density of myelinated axons. CB-positive inhibitory neurons were most dense in layer II and upper layer III. PV-positive inhibitory neurons were mostly found in the middle/deep layers, especially lower layer III, among a dense plexus of myelinated axons, some of which also expressed PV, presumably coming from the thalamus. The balance between excitation and inhibition in OFC is at the core of OFC function. The OFC gets an overview of the sensory environment through feedforward cortical inputs and assesses the emotional significance of events, based on robust feedback input from the amygdala, in processes that are disrupted in autism spectrum disorder (ASD). We previously showed that in individuals with ASD, excitatory OFC pathways exhibit overall thinning of the myelin sheath of axons, which likely affects conduction velocity and neurotransmission. This suggests laminar-specific changes in the ratio of excitation/inhibition in OFC of individuals with ASD, and may provide the anatomic basis for disrupted transmission of signals for emotions."
VASILEIOS ZIKOPOULOS,Atypical excitatory-inhibitory balance in feedforward and feedback circuits in autism,"Interactions between excitatory and inhibitory elements in neural circuits are crucially altered in autism and contribute to its central symptoms. Functionally and neurochemically distinct classes of inhibitory neurons, which express the calcium-binding proteins calbindin (CB), calretinin (CR), and parvalbumin (PV), are distributed differentially between different cortical areas and cortical layers. These neurons modify the influence of the excitatory pathways, carried by myelinated axons, that project to those layers. Excitatory connections that terminate in the middle or deep cortical layers behave similarly to the feedforward pathways that are defined in sensory areas, and provide driving input to the cortex. Pathways that terminate in superficial layers behave as feedback pathways and modulate the activity of the cortex. In order to study excitatory-inhibitory balance in the human cortex we studied the distribution of the three classes of inhibitory neurons and the density of myelinated axons in post-mortem tissue from medial, cingulate, and lateral prefrontal cortices of typically developing individuals and individuals with autism. We separately studied superficial and middle/deep cortical layers in order to distinguish changes that in􀃓uence feedback and feedforward pathways. Adults with autism had a significant reduction in the density of CR-expressing inhibitory neurons in both superficial and middle/deep cortical layers in lateral prefrontal cortices. There was a similar trend in medial prefrontal cortices in adults with autism. CR-expressing inhibitory neurons in superficial cortical layers serve a disinhibitory role while those in deep layers may provide modulatory inhibition. We found no significant change in the density of PV-expressing or CBexpressing interneurons in adults with autism in these regions. In individuals with autism there was also a steeper rate of increase in the density of small myelinated axons, which are representative of short-range pathways, across layers during development. These parallel structural changes likely produce opposite functional effects: enhanced short-range feedback pathways terminate in an environment with increased inhibition, while enhanced shortrange feedforward pathways terminate in an environment with reduced inhibition. Together, these changes in laminar structure may significantly affect information processing in the prefrontal cortex in autism."
VASILEIOS ZIKOPOULOS,A neural model of modified excitation/inhibition and feedback levels in schizophrenia,"The strength of certain visual illusions is weakened in individuals with schizophrenia. Such phenomena have been interpreted as the impaired integration of inhibitory and excitatory neural responses, and impaired top-down feedback mechanisms. To investigate whether and how these factors influence the perceived illusions in individuals with schizophrenia, we propose a two-layer network that can model visual receptive fields (RFs), their inhibitory and excitatory subfields, and the top-down feedback. Our neural model suggests that illusion perception changes in individuals with schizophrenia can be influenced by altered top-down mechanisms and the organization of the on-center off-surround receptive fields. Alteration of the RF inhibitory surround and/or the excitatory center can replicate the difference of illusion precepts between individuals with schizophrenia and normal controls. The results show that the simulated top-down feedback modulation enlarges the difference of the model illusion representations, replicating the difference between the two groups. We propose that the heterogeneity of visual and in general sensory processing in schizophrenia can be largely explained by the degree of top-down feedback reduction, emphasizing the critical role of top-down feedback in illusion perception, and to a lesser extent on the imbalance of excitation/inhibition. Our neural model provides a mechanistic explanation for the modulated visual percepts in schizophrenia with findings that can explain a broad range of visual perceptual observations in previous studies. The two-layer motif of the current model provides a general framework that can be tailored to investigate subcortico-cortical (such as thalamocortical) and cortico-cortical networks, bridging neurobiological changes in schizophrenia and perceptual processing."
SIMONE V GILL,Walking to the beat of their own drum: how children and adults meet timing constraints,"Walking requires adapting to meet task constraints. Between 5- and 7-years old, children's walking approximates adult walking without constraints. To examine how children and adults adapt to meet timing constraints, 57 5- to 7-year olds and 20 adults walked to slow and fast audio metronome paces. Both children and adults modified their walking. However, at the slow pace, children had more trouble matching the metronome compared to adults. The youngest children's walking patterns deviated most from the slow metronome pace, and practice improved their performance. Five-year olds were the only group that did not display carryover effects to the metronome paces. Findings are discussed in relation to what contributes to the development of adaptation in children."
SIMONE V GILL,Effects of additional anterior body mass on gait,"BACKGROUND: Gradual increases in mass such as during pregnancy are associated with changes in gait at natural velocities. The purpose of this study was to examine how added mass at natural and imposed slow walking velocities would affect gait parameters. METHODS: Eighteen adult females walked at two velocities (natural and 25 % slower than their natural pace) under four mass conditions (initial harness only (1 kg), 4.535 kg added anteriorly, 9.07 kg added anteriorly, and final harness only (1 kg)). We collected gait kinematics (100 Hz) using a motion capture system. RESULTS: Added anterior mass decreased cycle time and stride length. Stride width decreased once the mass was removed (p < .01). Added mass resulted in smaller peak hip extension angles (p < .01). The imposed slow walking velocity increased cycle time, double limb support time and decreased stride length, peak hip extension angles, and peak plantarflexion angles (p < .01). With added anterior mass and an imposed slow walking velocity, participants decreased cycle time when mass was added and increased cycle time once the mass was removed (p < .01). CONCLUSIONS: Gait adaptations may be commensurate with the magnitude of additional mass when walking at imposed slow versus natural velocities. This study presents a method for understanding how increased mass and imposed speed might affect gait independent of other effects related to pregnancy. Examining how added body mass and speed influence gait is one step in better understanding how women adapt to walking under different conditions."
SIMONE V GILL,The relationship between foot arch measurements and walking parameters in children,"BACKGROUND: Walking mechanics are influenced by body morphology. Foot arch height is one aspect of body morphology central to walking. However, generalizations about the relationship between arch height and walking are limited due to previous methodologies used for measuring the arch and the populations that have been studied. To gain the knowledge needed to support healthy gait in children and adults, we need to understand this relationship in unimpaired, typically developing children and adults using dynamic measures. The purpose of the current study was to examine the relationship between arch height and gait in a sample of healthy children and adults using dynamic measures. METHODS: Data were collected from 638 participants (n = 254 children and n = 384 adults) at the Museum of Science, Boston (MOS) and from 18 4- to 8-year-olds at the Motor Development and Motor Control Laboratories. Digital footprints were used to calculate two arch indices: the Chippaux-Smirak (CSI) and the Keimig Indices (KI). The height of the navicular bone was measured. Gait parameters were captured with a mechanized gait carpet at the MOS and three-dimensional motion analyses and in-ground force plates in the Motor Development and Motor Control Laboratories. RESULTS: Linear regression analyses on data from the MOS confirmed that as age increases, step length increases. With a linear mixed effect regression model, we found that individuals who took longer steps had higher arches as measured by the KI. However, this relationship was no longer significant when only adults were included in the model. A model restricted to children found that amongst this sample, those with higher CSI and higher KI values take longer relative step lengths. Data from the Motor Development and Motor Control Laboratories showed that both CSI and KI added to the prediction; children with lower anterior ground reaction forces had higher CSI and higher KI values. Arch height indices were correlated with navicular height. CONCLUSIONS: These results suggest that more than one measure of the arch may be needed elucidate the relationship between arch height and gait."
SIMONE V GILL,Effort-based decision-making and gross motor performance: are they linked?,"The purpose of this study was to investigate the relationship between effort-based decision making and gross motor performance. Effort-based decision making was measured using a modified version of the Effort Expenditure for Rewards Task (EEfRT), in which participants pressed a button on a keyboard to fill a bar on a screen for monetary reward. Participants received monetary rewards that were commensurate with the level of effort that they were willing to expend. Gross motor performance was measured with a walking task, in which participants matched their steps to the beat of an audio metronome; they walked to metronome beats that were slower and also faster than their normal walking pace. We hypothesized that increased effort during the effort-based decision making task would be paired with an increase in steps taken per minute during the gross motor task. However, the results of this study indicated a lack of a statistically significant relationship between the effort-based decision making task and the gross motor task. Planning rather than decision-making may have been the cognitive construct that governed our gross motor task. These findings can be beneficial when thinking about potential interventions for populations who experience deficits in motor performance and cognition as well as for understanding the relationship between both cognitive and motor performance in healthy adults."
SIMONE V GILL,Neuroimaging techniques as descriptive and diagnostic tools for infants at risk for autism spectrum disorder: a systematic review,"Autism Spectrum Disorder (ASD) has traditionally been evaluated and diagnosed via behavioral assessments. However, increasing research suggests that neuroimaging as early as infancy can reliably identify structural and functional differences between autistic and non-autistic brains. The current review provides a systematic overview of imaging approaches used to identify differences between infants at familial risk and without risk and predictive biomarkers. Two primary themes emerged after reviewing the literature: (1) neuroimaging methods can be used to describe structural and functional differences between infants at risk and infants not at risk for ASD (descriptive), and (2) neuroimaging approaches can be used to predict ASD diagnosis among high-risk infants and developmental outcomes beyond infancy (predicting later diagnosis). Combined, the articles highlighted that several neuroimaging studies have identified a variety of neuroanatomical and neurological differences between infants at high and low risk for ASD, and among those who later receive an ASD diagnosis. Incorporating neuroimaging into ASD evaluations alongside traditional behavioral assessments can provide individuals with earlier diagnosis and earlier access to supportive resources."
HORACIO M FRYDMAN,Wolbachia wStri blocks Zika virus growth at two independent stages of viral replication,"Mosquito-transmitted viruses are spread globally and present a great risk to human health. Among the many approaches investigated to limit the diseases caused by these viruses are attempts to make mosquitos resistant to virus infection. Coinfection of mosquitos with the bacterium Wolbachia pipientis from supergroup A is a recent strategy employed to reduce the capacity for major vectors in the Aedes mosquito genus to transmit viruses, including dengue virus (DENV), Chikungunya virus (CHIKV), and Zika virus (ZIKV). Recently, a supergroup B Wolbachia wStri, isolated from Laodelphax striatellus, was shown to inhibit multiple lineages of ZIKV in Aedes albopictus cells. Here, we show that wStri blocks the growth of positive-sense RNA viruses DENV, CHIKV, ZIKV, and yellow fever virus by greater than 99.9%. wStri presence did not affect the growth of the negative-sense RNA viruses LaCrosse virus or vesicular stomatitis virus. Investigation of the stages of the ZIKV life cycle inhibited by wStri identified two distinct blocks in viral replication. We found a reduction of ZIKV entry into wStri-infected cells. This was partially rescued by the addition of a cholesterol-lipid supplement. Independent of entry, transfected viral genome was unable to replicate in Wolbachia-infected cells. RNA transfection and metabolic labeling studies suggested that this replication defect is at the level of RNA translation, where we saw a 66% reduction in mosquito protein synthesis in wStri-infected cells. This study’s findings increase the potential for application of wStri to block additional arboviruses and also identify specific blocks in viral infection caused by Wolbachia coinfection."
HORACIO M FRYDMAN,Author correction: large enriched fragment targeted sequencing (LEFT-SEQ) applied to capture of Wolbachia genomes,An amendment to this paper has been published and can be accessed via a link at the top of the paper.
HORACIO M FRYDMAN,Large enriched fragment targeted sequencing (LEFT-SEQ) applied to capture of Wolbachia genomes,"Symbiosis is a major force of evolutionary change, influencing virtually all aspects of biology, from population ecology and evolution to genomics and molecular/biochemical mechanisms of development and reproduction. A remarkable example is Wolbachia endobacteria, present in some parasitic nematodes and many arthropod species. Acquisition of genomic data from diverse Wolbachia clades will aid in the elucidation of the different symbiotic mechanisms(s). However, challenges of de novo assembly of Wolbachia genomes include the presence in the sample of host DNA: nematode/vertebrate or insect. We designed biotinylated probes to capture large fragments of Wolbachia DNA for sequencing using PacBio technology (LEFT-SEQ: Large Enriched Fragment Targeted Sequencing). LEFT-SEQ was used to capture and sequence four Wolbachia genomes: the filarial nematode Brugia malayi, wBm, (21-fold enrichment), Drosophila mauritiana flies (2 isolates), wMau (11-fold enrichment), and Aedes albopictus mosquitoes, wAlbB (200-fold enrichment). LEFT-SEQ resulted in complete genomes for wBm and for wMau. For wBm, 18 single-nucleotide polymorphisms (SNPs), relative to the wBm reference, were identified and confirmed by PCR. A limit of LEFT-SEQ is illustrated by the wAlbB genome, characterized by a very high level of insertion sequences elements (ISs) and DNA repeats, for which only a 20-contig draft assembly was achieved."
HORACIO M FRYDMAN,Construction and modeling of a coculture microplate for real-time measurement of microbial interactions,"The dynamic structures of microbial communities emerge from the complex network of interactions between their constituent microorganisms. Quantitative measurements of these interactions are important for understanding and engineering ecosystem structure. Here, we present the development and application of the BioMe plate, a redesigned microplate device in which pairs of wells are separated by porous membranes. BioMe facilitates the measurement of dynamic microbial interactions and integrates easily with standard laboratory equipment. We first applied BioMe to recapitulate recently characterized, natural symbiotic interactions between bacteria isolated from the Drosophila melanogaster gut microbiome. Specifically, the BioMe plate allowed us to observe the benefit provided by two Lactobacillus strains to an Acetobacter strain. We next explored the use of BioMe to gain quantitative insight into the engineered obligate syntrophic interaction between a pair of Escherichia coli amino acid auxotrophs. We integrated experimental observations with a mechanistic computational model to quantify key parameters associated with this syntrophic interaction, including metabolite secretion and diffusion rates. This model also allowed us to explain the slow growth observed for auxotrophs growing in adjacent wells by demonstrating that, under the relevant range of parameters, local exchange between auxotrophs is essential for efficient growth. The BioMe plate provides a scalable and flexible approach for the study of dynamic microbial interactions. IMPORTANCE Microbial communities participate in many essential processes from biogeochemical cycles to the maintenance of human health. The structure and functions of these communities are dynamic properties that depend on poorly understood interactions among different species. Unraveling these interactions is therefore a crucial step toward understanding natural microbiota and engineering artificial ones. Microbial interactions have been difficult to measure directly, largely due to limitations of existing methods to disentangle the contribution of different organisms in mixed cocultures. To overcome these limitations, we developed the BioMe plate, a custom microplate-based device that enables direct measurement of microbial interactions, by detecting the abundance of segregated populations of microbes that can exchange small molecules through a membrane. We demonstrated the possible application of the BioMe plate for studying both natural and artificial consortia. BioMe is a scalable and accessible platform that can be used to broadly characterize microbial interactions mediated by diffusible molecules."
LEE E GOLDSTEIN,Clinicopathological evaluation of chronic traumatic encephalopathy in players of American football,"IMPORTANCE: Players of American football may be at increased risk of long-term neurological conditions, particularly chronic traumatic encephalopathy (CTE). OBJECTIVE: To determine the neuropathological and clinical features of deceased football players with CTE. DESIGN, SETTING, AND PARTICIPANTS: Case series of 202 football players whose brains were donated for research. Neuropathological evaluations and retrospective telephone clinical assessments (including head trauma history) with informants were performed blinded. Online questionnaires ascertained athletic and military history. EXPOSURES: Participation in American football at any level of play. MAIN OUTCOMES AND MEASURES: Neuropathological diagnoses of neurodegenerative diseases, including CTE, based on defined diagnostic criteria; CTE neuropathological severity (stages I to IV or dichotomized into mild [stages I and II] and severe [stages III and IV]); informant-reported athletic history and, for players who died in 2014 or later, clinical presentation, including behavior, mood, and cognitive symptoms and dementia. RESULTS: Among 202 deceased former football players (median age at death, 66 years [interquartile range, 47-76 years]), CTE was neuropathologically diagnosed in 177 players (87%; median age at death, 67 years [interquartile range, 52-77 years]; mean years of football participation, 15.1 [SD, 5.2]), including 0 of 2 pre–high school, 3 of 14 high school (21%), 48 of 53 college (91%), 9 of 14 semiprofessional (64%), 7 of 8 Canadian Football League (88%), and 110 of 111 National Football League (99%) players. Neuropathological severity of CTE was distributed across the highest level of play, with all 3 former high school players having mild pathology and the majority of former college (27 [56%]), semiprofessional (5 [56%]), and professional (101 [86%]) players having severe pathology. Among 27 participants with mild CTE pathology, 26 (96%) had behavioral or mood symptoms or both, 23 (85%) had cognitive symptoms, and 9 (33%) had signs of dementia. Among 84 participants with severe CTE pathology, 75 (89%) had behavioral or mood symptoms or both, 80 (95%) had cognitive symptoms, and 71 (85%) had signs of dementia. CONCLUSIONS AND RELEVANCE: In a convenience sample of deceased football players who donated their brains for research, a high proportion had neuropathological evidence of CTE, suggesting that CTE may be related to prior participation in football."
LEE E GOLDSTEIN,"A 680,000-person megastudy of nudges to encourage vaccination in pharmacies","Encouraging vaccination is a pressing policy problem. To assess whether text-based reminders can encourage pharmacy vaccination and what kinds of messages work best, we conducted a megastudy. We randomly assigned 689,693 Walmart pharmacy patients to receive one of 22 different text reminders using a variety of different behavioral science principles to nudge flu vaccination or to a business-as-usual control condition that received no messages. We found that the reminder texts that we tested increased pharmacy vaccination rates by an average of 2.0 percentage points, or 6.8%, over a 3-mo follow-up period. The most-effective messages reminded patients that a flu shot was waiting for them and delivered reminders on multiple days. The top-performing intervention included two texts delivered 3 d apart and communicated to patients that a vaccine was “waiting for you.” Neither experts nor lay people anticipated that this would be the best-performing treatment, underscoring the value of simultaneously testing many different nudges in a highly powered megastudy."
LEE E GOLDSTEIN,The Alzheimer's Disease-Associated Amyloid β-Protein Is an Antimicrobial Peptide,"BACKGROUND. The amyloid β-protein (Aβ) is believed to be the key mediator of Alzheimer's disease (AD) pathology. Aβ is most often characterized as an incidental catabolic byproduct that lacks a normal physiological role. However, Aβ has been shown to be a specific ligand for a number of different receptors and other molecules, transported by complex trafficking pathways, modulated in response to a variety of environmental stressors, and able to induce pro-inflammatory activities. METHODOLOGY/PRINCIPAL FINDINGS. Here, we provide data supporting an in vivo function for Aβ as an antimicrobial peptide (AMP). Experiments used established in vitro assays to compare antimicrobial activities of Aβ and LL-37, an archetypical human AMP. Findings reveal that Aβ exerts antimicrobial activity against eight common and clinically relevant microorganisms with a potency equivalent to, and in some cases greater than, LL-37. Furthermore, we show that AD whole brain homogenates have significantly higher antimicrobial activity than aged matched non-AD samples and that AMP action correlates with tissue Aβ levels. Consistent with Aβ-mediated activity, the increased antimicrobial action was ablated by immunodepletion of AD brain homogenates with anti-Aβ antibodies. CONCLUSIONS/SIGNIFICANCE. Our findings suggest Aβ is a hitherto unrecognized AMP that may normally function in the innate immune system. This finding stands in stark contrast to current models of Aβ-mediated pathology and has important implications for ongoing and future AD treatment strategies."
LEE E GOLDSTEIN,"Concussion, microvascular injury, and early tauopathy in young athletes after impact head injury and an impact concussion mouse model","The mechanisms underpinning concussion, traumatic brain injury, and chronic traumatic encephalopathy, and the relationships between these disorders, are poorly understood. We examined post-mortem brains from teenage athletes in the acute-subacute period after mild closed-head impact injury and found astrocytosis, myelinated axonopathy, microvascular injury, perivascular neuroinflammation, and phosphorylated tau protein pathology. To investigate causal mechanisms, we developed a mouse model of lateral closed-head impact injury that uses momentum transfer to induce traumatic head acceleration. Unanaesthetized mice subjected to unilateral impact exhibited abrupt onset, transient course, and rapid resolution of a concussion-like syndrome characterized by altered arousal, contralateral hemiparesis, truncal ataxia, locomotor and balance impairments, and neurobehavioural deficits. Experimental impact injury was associated with axonopathy, blood–brain barrier disruption, astrocytosis, microgliosis (with activation of triggering receptor expressed on myeloid cells, TREM2), monocyte infiltration, and phosphorylated tauopathy in cerebral cortex ipsilateral and subjacent to impact. Phosphorylated tauopathy was detected in ipsilateral axons by 24 h, bilateral axons and soma by 2 weeks, and distant cortex bilaterally at 5.5 months post-injury. Impact pathologies co-localized with serum albumin extravasation in the brain that was diagnostically detectable in living mice by dynamic contrast-enhanced MRI. These pathologies were also accompanied by early, persistent, and bilateral impairment in axonal conduction velocity in the hippocampus and defective long-term potentiation of synaptic neurotransmission in the medial prefrontal cortex, brain regions distant from acute brain injury. Surprisingly, acute neurobehavioural deficits at the time of injury did not correlate with blood–brain barrier disruption, microgliosis, neuroinflammation, phosphorylated tauopathy, or electrophysiological dysfunction. Furthermore, concussion-like deficits were observed after impact injury, but not after blast exposure under experimental conditions matched for head kinematics. Computational modelling showed that impact injury generated focal point loading on the head and seven-fold greater peak shear stress in the brain compared to blast exposure. Moreover, intracerebral shear stress peaked before onset of gross head motion. By comparison, blast induced distributed force loading on the head and diffuse, lower magnitude shear stress in the brain. We conclude that force loading mechanics at the time of injury shape acute neurobehavioural responses, structural brain damage, and neuropathological sequelae triggered by neurotrauma. These results indicate that closed-head impact injuries, independent of concussive signs, can induce traumatic brain injury as well as early pathologies and functional sequelae associated with chronic traumatic encephalopathy. These results also shed light on the origins of concussion and relationship to traumatic brain injury and its aftermath."
GARY BENSON,Discovering Frequent Poly-Regions in DNA Sequences,"The problem of discovering frequent arrangements of regions of high occurrence of one or more items of a given alphabet in a sequence is studied, and two efficient approaches are proposed to solve it. The first approach is entropy-based and uses an existing recursive segmentation technique to split the input sequence into a set of homogeneous segments. The key idea of the second approach is to use a set of sliding windows over the sequence. Each sliding window keeps a set of statistics of a sequence segment that mainly includes the number of occurrences of each item in that segment. Combining these statistics efficiently yields the complete set of regions of high occurrence of the items of the given alphabet. After identifying these regions, the sequence is converted to a sequence of labeled intervals (each one corresponding to a region). An efficient algorithm for mining frequent arrangements of temporal intervals on a single sequence is applied on the converted sequence to discover frequently occurring arrangements of these regions. The proposed algorithms are tested on various DNA sequences producing results with significant biological meaning."
GARY BENSON,Generalized Methods for Discovering Frequent Poly-Regions in DNA,"The problem of discovering frequent poly-regions (i.e. regions of high occurrence of a set of items or patterns of a given alphabet) in a sequence is studied, and three efficient approaches are proposed to solve it. The first one is entropy-based and applies a recursive segmentation technique that produces a set of candidate segments which may potentially lead to a poly-region. The key idea of the second approach is the use of a set of sliding windows over the sequence. Each sliding window covers a sequence segment and keeps a set of statistics that mainly include the number of occurrences of each item or pattern in that segment. Combining these statistics efficiently yields the complete set of poly-regions in the given sequence. The third approach applies a technique based on the majority vote, achieving linear running time with a minimal number of false negatives. After identifying the poly-regions, the sequence is converted to a sequence of labeled intervals (each one corresponding to a poly-region). An efficient algorithm for mining frequent arrangements of intervals is applied to the converted sequence to discover frequently occurring arrangements of poly-regions in different parts of DNA, including coding regions. The proposed algorithms are tested on various DNA sequences producing results of significant biological meaning."
GARY BENSON,The Distribution of Inverted Repeat Sequences in the Saccharomyces Cerevisiae Genome,"Although a variety of possible functions have been proposed for inverted repeat sequences (IRs), it is not known which of them might occur in vivo. We investigate this question by assessing the distributions and properties of IRs in the Saccharomyces cerevisiae (SC) genome. Using the IRFinder algorithm we detect 100,514 IRs having copy length greater than 6 bp and spacer length less than 77 bp. To assess statistical significance we also determine the IR distributions in two types of randomization of the S. cerevisiae genome. We find that the S. cerevisiae genome is significantly enriched in IRs relative to random. The S. cerevisiae IRs are significantly longer and contain fewer imperfections than those from the randomized genomes, suggesting that processes to lengthen and/or correct errors in IRs may be operative in vivo. The S. cerevisiae IRs are highly clustered in intergenic regions, while their occurrence in coding sequences is consistent with random. Clustering is stronger in the 3′ flanks of genes than in their 5′ flanks. However, the S. cerevisiae genome is not enriched in those IRs that would extrude cruciforms, suggesting that this is not a common event. Various explanations for these results are considered. ELECTRONIC SUPPLEMENTARY MATERIAL. The online version of this article (doi:10.1007/s00294-010-0302-6) contains supplementary material, which is available to authorized users."
GARY BENSON,3'-UTR SIRF: A database for identifying clusters of short interspersed repeats in 3' untranslated regions,"BACKGROUND:Short (~5 nucleotides) interspersed repeats regulate several aspects of post-transcriptional gene expression. Previously we developed an algorithm (REPFIND) that assigns P-values to all repeated motifs in a given nucleic acid sequence and reliably identifies clusters of short CAC-containing motifs required for mRNA localization in Xenopus oocytes.DESCRIPTION:In order to facilitate the identification of genes possessing clusters of repeats that regulate post-transcriptional aspects of gene expression in mammalian genes, we used REPFIND to create a database of all repeated motifs in the 3' untranslated regions (UTR) of genes from the Mammalian Gene Collection (MGC). The MGC database includes seven vertebrate species: human, cow, rat, mouse and three non-mammalian vertebrate species. A web-based application was developed to search this database of repeated motifs to generate species-specific lists of genes containing specific classes of repeats in their 3'-UTRs. This computational tool is called 3'-UTR SIRF (Short Interspersed Repeat Finder), and it reveals that hundreds of human genes contain an abundance of short CAC-rich and CAG-rich repeats in their 3'-UTRs that are similar to those found in mRNAs localized to the neurites of neurons. We tested four candidate mRNAs for localization in rat hippocampal neurons by in situ hybridization. Our results show that two candidate CAC-rich (Syntaxin 1B and Tubulin beta4) and two candidate CAG-rich (Sec61alpha and Syntaxin 1A) mRNAs are localized to distal neurites, whereas two control mRNAs lacking repeated motifs in their 3'-UTR remain primarily in the cell body.CONCLUSION:Computational data generated with 3'-UTR SIRF indicate that hundreds of mammalian genes have an abundance of short CA-containing motifs that may direct mRNA localization in neurons. In situ hybridization shows that four candidate mRNAs are localized to distal neurites of cultured hippocampal neurons. These data suggest that short CA-containing motifs may be part of a widely utilized genetic code that regulates mRNA localization in vertebrate cells. The use of 3'-UTR SIRF to search for new classes of motifs that regulate other aspects of gene expression should yield important information in future studies addressing cis-regulatory information located in 3'-UTRs."
GARY BENSON,Evolutionary history of mammalian transposons determined by genome-wide defragmentation,"The constant bombardment of mammalian genomes by transposable elements (TEs) has resulted in TEs comprising at least 45% of the human genome. Because of their great age and abundance, TEs are important in comparative phylogenomics. However, estimates of TE age were previously based on divergence from derived consensus sequences or phylogenetic analysis, which can be unreliable, especially for older more diverged elements. Therefore, a novel genome-wide analysis of TE organization and fragmentation was performed to estimate TE age independently of sequence composition and divergence or the assumption of a constant molecular clock. Analysis of TEs in the human genome revealed ∼600,000 examples where TEs have transposed into and fragmented other TEs, covering >40% of all TEs or ∼542 Mbp of genomic sequence. The relative age of these TEs over evolutionary time is implicit in their organization, because newer TEs have necessarily transposed into older TEs that were already present. A matrix of the number of times that each TE has transposed into every other TE was constructed, and a novel objective function was developed that derived the chronological order and relative ages of human TEs spanning >100 million years. This method has been used to infer the relative ages across all four major TE classes, including the oldest, most diverged elements. Analysis of DNA transposons over the history of the human genome has revealed the early activity of some MER2 transposons, and the relatively recent activity of MER1 transposons during primate lineages. The TEs from six additional mammalian genomes were defragmented and analyzed. Pairwise comparison of the independent chronological orders of TEs in these mammalian genomes revealed species phylogeny, the fact that transposons shared between genomes are older than species-specific transposons, and a subset of TEs that were potentially active during periods of speciation. Author Summary. Transposable elements (TEs) are interspersed repetitive DNA families that are capable of copying themselves from place to place; they have literally infested our genome over evolutionary time, and now comprise as much as 45% of our total DNA. Because of their great age and abundance, TEs are important in evolutionary genomics. However, estimates of their age based on DNA sequence composition have been unreliable, especially for older more diverged elements. Therefore, a novel method to estimate the age of TEs was developed based on the fact that as TEs spread throughout the genome, they inserted into and fragmented older TEs that were already present. Therefore, the age of TEs can be revealed by how often they have been fragmented over evolutionary time. We performed a genome-wide defragmention of TEs, and developed a novel objective function to derive the chronological order of TEs spanning <100 million years. This method has been used to infer the relative ages of TEs from seven sequenced mammalian genomes across all four major TE classes, including the oldest, most diverged elements. This age estimate is independent of TE sequence composition or divergence and does not rely on the assumption of a constant molecular clock. This study provides a novel analysis of the evolutionary history of some of the most abundant and ancient repetitive DNA elements in mammalian genomes, which is important for understanding the dynamic forces that shape our genomes during evolution."
GARY BENSON,Nucleic Acids Research Annual Web Server Issue in 2009,
GARY BENSON,Editorial,
GARY BENSON,3'-UTR SIRF: A Database for Identifying Clusters of Whort Interspersed Repeats in 3' Untranslated Regions,"BACKGROUND. Short (~5 nucleotides) interspersed repeats regulate several aspects of post-transcriptional gene expression. Previously we developed an algorithm (REPFIND) that assigns P-values to all repeated motifs in a given nucleic acid sequence and reliably identifies clusters of short CAC-containing motifs required for mRNA localization in Xenopus oocytes. DESCRIPTION. In order to facilitate the identification of genes possessing clusters of repeats that regulate post-transcriptional aspects of gene expression in mammalian genes, we used REPFIND to create a database of all repeated motifs in the 3' untranslated regions (UTR) of genes from the Mammalian Gene Collection (MGC). The MGC database includes seven vertebrate species: human, cow, rat, mouse and three non-mammalian vertebrate species. A web-based application was developed to search this database of repeated motifs to generate species-specific lists of genes containing specific classes of repeats in their 3'-UTRs. This computational tool is called 3'-UTR SIRF (Short Interspersed Repeat Finder), and it reveals that hundreds of human genes contain an abundance of short CAC-rich and CAG-rich repeats in their 3'-UTRs that are similar to those found in mRNAs localized to the neurites of neurons. We tested four candidate mRNAs for localization in rat hippocampal neurons by in situ hybridization. Our results show that two candidate CAC-rich (Syntaxin 1B and Tubulin β4) and two candidate CAG-rich (Sec61α and Syntaxin 1A) mRNAs are localized to distal neurites, whereas two control mRNAs lacking repeated motifs in their 3'-UTR remain primarily in the cell body. CONCLUSION. Computational data generated with 3'-UTR SIRF indicate that hundreds of mammalian genes have an abundance of short CA-containing motifs that may direct mRNA localization in neurons. In situ hybridization shows that four candidate mRNAs are localized to distal neurites of cultured hippocampal neurons. These data suggest that short CA-containing motifs may be part of a widely utilized genetic code that regulates mRNA localization in vertebrate cells. The use of 3'-UTR SIRF to search for new classes of motifs that regulate other aspects of gene expression should yield important information in future studies addressing cis-regulatory information located in 3'-UTRs."
GARY BENSON,TRDB—The Tandem Repeats Database,"Tandem repeats in DNA have been under intensive study for many years, first, as a consequence of their usefulness as genomic markers and DNA fingerprints and more recently as their role in human disease and regulatory processes has become apparent. The Tandem Repeats Database (TRDB) is a public repository of information on tandem repeats in genomic DNA. It contains a variety of tools for repeat analysis, including the Tandem Repeats Finder program, query and filtering capabilities, repeat clustering, polymorphism prediction, PCR primer selection, data visualization and data download in a variety of formats. In addition, TRDB serves as a centralized research workbench. It provides user storage space and permits collaborators to privately share their data and analysis. TRDB is available at https://tandem. bu.edu/cgi-bin/trdb/trdb.exe."
GARY BENSON,"Whole genome sequences of a male and female supercentenarian, ages greater than 114 years","Supercentenarians (age 110+ years old) generally delay or escape age-related diseases and disability well beyond the age of 100 and this exceptional survival is likely to be influenced by a genetic predisposition that includes both common and rare genetic variants. In this report, we describe the complete genomic sequences of male and female supercentenarians, both age >114 years old. We show that: (1) the sequence variant spectrum of these two individuals' DNA sequences is largely comparable to existing non-supercentenarian genomes; (2) the two individuals do not appear to carry most of the well-established human longevity enabling variants already reported in the literature; (3) they have a comparable number of known disease-associated variants relative to most human genomes sequenced to-date; (4) approximately 1% of the variants these individuals possess are novel and may point to new genes involved in exceptional longevity; and (5) both individuals are enriched for coding variants near longevity-associated variants that we discovered through a large genome-wide association study. These analyses suggest that there are both common and rare longevity-associated variants that may counter the effects of disease-predisposing variants and extend lifespan. The continued analysis of the genomes of these and other rare individuals who have survived to extremely old ages should provide insight into the processes that contribute to the maintenance of health during extreme aging."
ELLIOT SALTZMAN,Music Maker – A Camera-based Music Making Tool for Physical Rehabilitation,"The therapeutic effects of playing music are being recognized increasingly in the field of rehabilitation medicine. People with physical disabilities, however, often do not have the motor dexterity needed to play an instrument. We developed a camera-based human-computer interface called ""Music Maker"" to provide such people with a means to make music by performing therapeutic exercises. Music Maker uses computer vision techniques to convert the movements of a patient's body part, for example, a finger, hand, or foot, into musical and visual feedback using the open software platform EyesWeb. It can be adjusted to a patient's particular therapeutic needs and provides quantitative tools for monitoring the recovery process and assessing therapeutic outcomes. We tested the potential of Music Maker as a rehabilitation tool with six subjects who responded to or created music in various movement exercises. In these proof-of-concept experiments, Music Maker has performed reliably and shown its promise as a therapeutic device."
ELLIOT SALTZMAN,Veering in hemi-Parkinson’s disease: primacy of visual over motor contributions,"Veering while walking is often reported in individuals with Parkinson’s disease (PD), with potential mechanisms being vision-based (asymmetrical perception of the visual environment) or motoric (asymmetry in stride length between relatively affected and non-affected body side). We examined these competing hypotheses by assessing veering in 13 normal control participants (NC) and 20 non-demented individuals with PD: 9 with left-side onset of motor symptoms (LPD) and 11 with right-side onset (RPD). Participants walked in a corridor under three conditions: eyes-open, egocentric reference point (ECRP; walk toward a subjectively perceived center of a target at the end of the corridor), and vision-occluded. The visual hypothesis predicted that LPD participants would veer rightward, in line with their rightward visual-field bias, whereas those with RPD would veer leftward. The motor hypothesis predicted the opposite pattern of results, with veering toward the side with shorter stride length. Results supported the visual hypothesis. Under visual guidance, RPD participants significantly differed from NC, veering leftward despite a shorter right- than left-stride length, whereas LPD veered rightward (not significantly different from NC), despite shorter left- than right-stride length. LPD participants showed significantly reduced rightward veering and stride asymmetry when they walked in the presence of a visual landmark (ECRP) than in the eyes-open condition without a target. There were no group differences in veering in the vision-occluded condition. The findings suggest that interventions to correct walking abnormalities such as veering in PD should incorporate vision-based strategies rather than solely addressing motor asymmetries, and should be tailored to the distinctive navigational profiles of LPD and RPD."
ELLIOT SALTZMAN,Effects of Parkinson’s disease on optic flow perception for heading direction during navigation,"Visuoperceptual disorders have been identified in individuals with Parkinson’s disease (PD) and may affect the perception of optic flow for heading direction during navigation. Studies in healthy subjects have confirmed that heading direction can be determined by equalizing the optic flow speed (OS) between visual fields. The present study investigated the effects of PD on the use of optic flow for heading direction, walking parameters, and interlimb coordination during navigation, examining the contributions of OS and spatial frequency (dot density). Twelve individuals with PD without dementia, 18 age-matched normal control adults (NC), and 23 young control adults (YC) walked through a virtual hallway at about 0.8 m/s. The hallway was created by random dots on side walls. Three levels of OS (0.8, 1.2, and 1.8 m/s) and dot density (1, 2, and 3 dots/m2) were presented on one wall while on the other wall, OS and dot density were fixed at 0.8 m/s and 3 dots/m2, respectively. Three-dimensional kinematic data were collected, and lateral drift, walking speed, stride frequency and length, and frequency, and phase relations between arms and legs were calculated. A significant linear effect was observed on lateral drift to the wall with lower OS for YC and NC, but not for PD. Compared to YC and NC, PD veered more to the left under OS and dot density conditions. The results suggest that healthy adults perceive optic flow for heading direction. Heading direction in PD may be more affected by the asymmetry of dopamine levels between the hemispheres and by motor lateralization as indexed by handedness."
ALEXIS PERI,"Review of: Hass, Jeffrey K. Wartime suffering and survival: the human condition under siege in the blockade of Leningrad 1941-1944",
ALEXIS PERI,Spreading intimacy and influence: women’s correspondence across the Iron Curtain,
ALEXIS PERI,"Operation friendship: Soviet and British women discuss war, work, and womanhood","During World War II, the British and Soviet governments permitted more personal contact between their citizens in hope that they would develop feelings of goodwill and become more supportive of their Alliance. This article examines the wartime correspondence exchanged between women of Britain and the Soviet Union as well as between two organizations, which facilitated their interactions. Participants from both countries used personal and gendered language to frame the Alliance and their contributions to it. Despite their ideological and political differences, the participants found common ground by focusing on their shared experiences as mothers, wives, and workers as well as by stressing a model of womanhood, which contained both radical and traditional elements. They combined essentializing concepts of femininity, which emphasized women’s maternalism and vulnerability, with arguments for women’s empowerment, based on their ability to change state policies and overcome gender inequities. The two committees that facilitated the exchanges wielded this feminine ideal to bolster the Alliance as well as to advance their own institutional agendas. Ultimately, these conversations shed light on: popular participation in the Anglo‐Soviet alliance, the power of emotion to forge political ties, and how womanhood was conceptualized and put in service of military and political goals."
ALEXIS PERI,Book review: Ben Macintyre. The Spy and the Traitor: The Greatest Espionage Story of the Cold War,
ALEXIS PERI,More than allies: Soviet and British women and the campaign for wartime friendship,
ALEXIS PERI,"Lessons of the Leningrad blockade: schoolchildren’s diaries as sites of learning, 1941-1943","This essay examines the importance of education and the idiom of learning in diaries of the Leningrad Blockade. Using the diaries of schoolchildren, as well as of some teachers, this essay argues that learning and studying continued to play a central role in the lives young blokadniki even though the conditions of the Blockade greatly disrupted classroom lessons. Nevertheless, determined to maintain their studies and fulfill the Soviet regime’s didactic mission, some Leningrad schoolchildren used their diaries to design and carry out their own independent programs of study. In the process of undertaking these self-directed studies, the diarists critically engaged with Soviet textbooks and theories of pedagogy as well as with the particular circumstances created by the siege to draw some unique insights and unorthodox conclusions about familiar subjects like mathematics, history, composition, and political education."
ALEXIS PERI,Soviet diaries of the Great Patriotic War,
ALEXIS PERI,Fifty years of friendship,
ALEXIS PERI,"H-Diplo article review of Olga Kucherenko, “A Fleeting Friendship: Anglo-Soviet Penpalship in the Second World War”",
ALEXIS PERI,Review of: Pomnit’ po-nashemu: sotsrealisticheskii istorizm i blokada Leningrada,
ALEXIS PERI,Women’s work and the politics of the daily routine,
JOSE RAFAEL ROMERO,Illicit drug use and cerebral microbleeds in stroke and transient ischemic attack patients,"Background: Cerebral microbleeds (CMB) signal cerebral small vessel disease and are associated with ischemic stroke (IS) incidence, recurrence, and complications. While illicit drug use (IDU) is associated with cerebral small vessel disease, the association between CMB and IDU is understudied. We sought to delineate differences in vascular risk factors between IDU and CMB and determine the effect of this relationship on outcomes in IS/transient ischemic attack (TIA) patients. Methods: We included 2001 consecutive IS and TIA patients (years 2009-2018) with a readable T2*gradient-echo MRI sequence. CMB rating followed standardized guidelines and CMB were grouped topographically into lobar, deep or infratentorial. IDU data (history and/or urine toxicology) was available for 1746 patients. The adverse composite outcome included pneumonia, urinary tract infection, deep venous thrombosis or death during hospitalization. Good functional outcome was defined as modified Rankin scale score < 3 and ambulatory on discharge. Univariate analysis was used to assess vascular risk factors and multivariable logistic regression was used to characterize the IDU/CMB relationship on outcomes. Results: We observed IDU in 13.8 % (n=241), and CMB in 32.9% (n=575, 53.8% lobar, 27.3% deep and 18.8% infratentorial). Patients with IDU and at least one CMB were older (53.6±10.5 vs. 56.9±11.5, p=0.04), had a lower BMI (28.1±5.9 vs. 26.6±4.4, p=0.04), and were more likely to have had a previous IS/TIA (25.1% vs. 41.9%, p=0.01). IDU trended higher for those with severe CMB (10+) compared with those without CMB and 1-9 CMB (25% [n=9] vs 14.3% [n=1171] and 12.1% [n=65] respectively; p=0.07) without individual drug deviations from this pattern. Adverse and good functional outcomes were observed in 177 and 905 total patients, respectively. No significant interaction was observed between IDU and CMB with either adverse or functional composite outcomes. Conclusion: IDU prevalence was high in our urban study population, and showed a borderline association with increasing CMB burden. Patients with CMB and IDU history were older and more likely to have had a previous IS/TIA. Further studies are required to clarify the clinical consequences related to the relationship between IDU and CMB."
MARCO GABOARDI,Relational cost analysis in a functional-imperative setting,"Relational cost analysis aims at formally establishing bounds on the difference in the evaluation costs of two programs. As a particular case, one can also use relational cost analysis to establish bounds on the difference in the evaluation cost of the same program on two different inputs. One way to perform relational cost analysis is to use a relational type-and-effect system that supports reasoning about relations between two executions of two programs. Building on this basic idea, we present a type-and-effect system, called ARel, for reasoning about the relative cost (the difference in the evaluation cost) of array-manipulating, higher order functional-imperative programs. The key ingredient of our approach is a new lightweight type refinement discipline that we use to track relations (differences) between two mutable arrays. This discipline combined with Hoare-style triples built into the types allows us to express and establish precise relative costs of several interesting programs that imperatively update their data. We have implemented ARel using ideas from bidirectional type checking."
MARCO GABOARDI,Estimating smooth GLM in non-interactive local differential privacy model with public unlabeled data,"In this paper, we study the problem of estimating smooth Generalized Linear Models (GLM) in the Non-interactive Local Differential Privacy (NLDP) model. Different from its classical setting, our model allows the server to access some additional public but unlabeled data. Firstly, motived by Stein’s lemma, we show that if each data record is i.i.d. sampled from zero-mean Gaussian distribution, we show that there exists an (𝜖, 𝛿)-NLDP algorithm for GLM. The sample complexity of the public and private data, for the algorithm to achieve an 𝛼 estimation error (in 𝓁_2-norm) with high probability, is O(p𝛼^-2) and O(p^3𝛼^-2𝜖^-2), respectively. This is a significant improvement over the previously known exponential or quasi-polynomial in 𝛼^-1, or exponential in p sample complexity of GLM with no public data. Then, by a variant of Stein’s lemma, we show that there is an (𝜖, 𝛿)-NLDP algorithm for GLM (under some mild assumptions), if each data record is i.i.d sampled from some sub-Gaussian distribution with bounded 𝓁_1-norm. Then the sample complexity of the public and private data, for the algorithm to achieve an estimation error (in 𝓁∞-norm) with high probability, is O(p^2𝛼^-2) and O(p^2𝛼^-2𝜖^-2), respectively, if is not too small (i.e., 𝛼 ≥ Ω (1/√p )), where p is the dimensionality of the data. We also extend our idea to the non-linear regression problem and show a similar phenomenon for it. Finally, we demonstrate the effectiveness of our algorithms through experiments on both synthetic and real world datasets. To our best knowledge, this is the first paper showing the existence of efficient and effective algorithms for GLM and non-linear regression in the NLDP model with public unlabeled data."
MARCO GABOARDI,Coupled relational symbolic execution for differential privacy,"Differential privacy is a de facto standard in data privacy with applications in the private and public sectors. Most of the techniques that achieve differential privacy are based on a judicious use of randomness. However, reasoning about randomized programs is difficult and error prone. For this reason, several techniques have been recently proposed to support designer in proving programs differentially private or in finding violations to it. In this work we propose a technique based on symbolic execution for reasoning about differential privacy. Symbolic execution is a classic technique used for testing, counterexample generation and to prove absence of bugs. Here we use symbolic execution to support these tasks specifically for differential privacy. To achieve this goal, we design a relational symbolic execution technique which supports reasoning about probabilistic coupling, a formal notion that has been shown useful to structure proofs of differential privacy. We show how our technique can be used to both verify and find violations to differential privacy."
MARCO GABOARDI,Covariance-aware private mean estimation without private covariance estimation,
MARCO GABOARDI,Hypothesis testing interpretations and Renyi differential privacy,"Differential privacy is a de facto standard in data privacy, with applications in the public and private sectors. A way to explain differential privacy, which is particularly appealing to statistician and social scientists, is by means of its statistical hypothesis testing interpretation. Informally, one cannot effectively test whether a specific individual has contributed her data by observing the output of a private mechanism—any test cannot have both high significance and high power. In this paper, we identify some conditions under which a privacy definition given in terms of a statistical divergence satisfies a similar interpretation. These conditions are useful to analyze the distinguishability power of divergences and we use them to study the hypothesis testing interpretation of some relaxations of differential privacy based on Rényi divergence. This analysis also results in an improved conversion rule between these definitions and differential privacy."
MARCO GABOARDI,Relational symbolic execution,"Symbolic execution is a classical program analysis technique used to show that programs satisfy or violate given specifications. In this work we generalize symbolic execution to support program analysis for relational specifications in the form of relational properties - these are properties about two runs of two programs on related inputs, or about two executions of a single program on related inputs. Relational properties are useful to formalize notions in security and privacy, and to reason about program optimizations. We design a relational symbolic execution engine, named RelSym which supports interactive refutation, as well as proving of relational properties for programs written in a language with arrays and for-like loops."
MARCO GABOARDI,Controlling privacy loss in sampling schemes: an analysis of stratified and cluster sampling,"Sampling schemes are fundamental tools in statistics, survey design, and algorithm design. A fundamental result in differential privacy is that a differentially private mechanism run on a simple random sample of a population provides stronger privacy guarantees than the same algorithm run on the entire population. However, in practice, sampling designs are often more complex than the simple, data-independent sampling schemes that are addressed in prior work. In this work, we extend the study of privacy amplification results to more complex, data-dependent sampling schemes. We find that not only do these sampling schemes often fail to amplify privacy, they can actually result in privacy degradation. We analyze the privacy implications of the pervasive cluster sampling and stratified sampling paradigms, as well as provide some insight into the study of more general sampling designs"
MARCO GABOARDI,Multiclass versus binary differentially private PAC learning,We show a generic reduction from multiclass differentially private PAC learning to binary private PAC learning. We apply this transformation to a recently proposed binary private PAC learner to obtain a private multiclass learner with sample complexity that has a polynomial dependence on the multiclass Littlestone dimension and a poly-logarithmic dependence on the number of classes. This yields a doubly exponential improvement in the dependence on both parameters over learners from previous work. Our proof extends the notion of 𝚿-dimension defined in work of Ben-David et al. [5] to the online setting and explores its general properties.
MARCO GABOARDI,Empirical risk minimization in the non-interactive local model of differential privacy,"In this paper, we study the Empirical Risk Minimization (ERM) problem in the non-interactive Local Differential Privacy (LDP) model. Previous research on this problem (Smith et al., 2017) indicates that the sample complexity, to achieve error 𝛼, needs to be exponentially depending on the dimensionality p for general loss functions. In this paper, we make two attempts to resolve this issue by investigating conditions on the loss functions that allow us to remove such a limit. In our first attempt, we show that if the loss function is (∞, T)-smooth, by using the Bernstein polynomial approximation we can avoid the exponential dependency in the term of 𝛼. We then propose player-efficient algorithms with 1-bit communication complexity and O(1) computation cost for each player. The error bound of these algorithms is asymptotically the same as the original one. With some additional assumptions, we also give an algorithm which is more efficient for the server. In our second attempt, we show that for any 1-Lipschitz generalized linear convex loss function, there is an (𝝐, 𝛿)-LDP algorithm whose sample complexity for achieving error 𝛼 is only linear in the dimensionality p. Our results use a polynomial of inner product approximation technique. Finally, motivated by the idea of using polynomial approximation and based on different types of polynomial approximations, we propose (efficient) non-interactive locally differentially private algorithms for learning the set of k-way marginal queries and the set of smooth queries."
MARCO GABOARDI,The complexity of verifying loop-free programs as differentially private,"We study the problem of verifying differential privacy for loop-free programs with probabilistic choice. Programs in this class can be seen as randomized Boolean circuits, which we will use as a formal model to answer two different questions: first, deciding whether a program satisfies a prescribed level of privacy; second, approximating the privacy parameters a program realizes. We show that the problem of deciding whether a program satisfies ε-differential privacy is coNP^#P-complete. In fact, this is the case when either the input domain or the output range of the program is large. Further, we show that deciding whether a program is (ε,δ)-differentially private is coNP^#P-hard, and in coNP^#P for small output domains, but always in coNP^{#P^#P}. Finally, we show that the problem of approximating the level of differential privacy is both NP-hard and coNP-hard. These results complement previous results by Murtagh and Vadhan [Jack Murtagh and Salil P. Vadhan, 2016] showing that deciding the optimal composition of differentially private components is #P-complete, and that approximating the optimal composition of differentially private components is in P."
MARCO GABOARDI,Graded Hoare logic and its categorical semantics,"Deductive verification techniques based on program logics (i.e., the family of Floyd-Hoare logics) are a powerful approach for program reasoning. Recently, there has been a trend of increasing the expressive power of such logics by augmenting their rules with additional information to reason about program side-effects. For example, general program logics have been augmented with cost analyses, logics for probabilistic computations have been augmented with estimate measures, and logics for differential privacy with indistinguishability bounds. In this work, we unify these various approaches via the paradigm of grading, adapted from the world of functional calculi and semantics. We propose Graded Hoare Logic (GHL), a parameterisable framework for augmenting program logics with a preordered monoidal analysis. We develop a semantic framework for modelling GHL such that grading, logical assertions (pre- and post-conditions) and the underlying effectful semantics of an imperative language can be integrated together. Central to our framework is the notion of a graded category which we extend here, introducing graded Freyd categories which provide a semantics that can interpret many examples of augmented program logics from the literature. We leverage coherent fibrations to model the base assertion language, and thus the overall setting is also fibrational."
MARCO GABOARDI,On facility location problem in the local differential privacy model,"In this paper we study the uncapacitated facility location problem in the model of differential privacy (DP) with uniform facility cost. Specifically, we first show that, under the hierarchically well-separated tree (HST) metrics and the super-set output setting that was introduced in [8], there is an  ∊-DP algorithm that achieves an O (¹/∊) expected multiplicative) approximation ratio; this implies an O( ^log n/_∊) approximation ratio for the general metric case, where n is the size of the input metric. These bounds improve the best-known results given by [8]. In particular, our approximation ratio for HST-metrics is independent of n, and the ratio for general metrics is independent of the aspect ratio of the input metric. On the negative side, we show that the approximation ratio of any  ∊-DP algorithm is lower bounded by Ω (1/√∊), even for instances on HST metrics with uniform facility cost, under the super-set output setting. The lower bound shows that the dependence of the approximation ratio for HST metrics on ∊ can not be removed or greatly improved. Our novel methods and techniques for both the upper and lower bound may find additional applications."
MARCO GABOARDI,"Stability is stable: connections between replicability, privacy, and adaptive generalization",
MARCO GABOARDI,"8th International conference on formal structures for computation and deduction, FSCD 2023",
MARCO GABOARDI,Generalized linear models in non-interactive local differential privacy with public data,
MARCO GABOARDI,Bunched fuzz: sensitivity for vector metrics,
MARCO GABOARDI,Continual release of differentially private synthetic data,
IAN DAVISON,Neural mechanisms of social learning in the female mouse,"Social interactions are often powerful drivers of learning. In female mice, mating creates a long-lasting sensory memory for the pheromones of the stud male that alters neuroendocrine responses to his chemosignals for many weeks. The cellular and synaptic correlates of pheromonal learning, however, remain unclear. We examined local circuit changes in the accessory olfactory bulb (AOB) using targeted ex vivo recordings of mating-activated neurons tagged with a fluorescent reporter. Imprinting led to striking plasticity in the intrinsic membrane excitability of projection neurons (mitral cells, MCs) that dramatically curtailed their responsiveness, suggesting a novel cellular substrate for pheromonal learning. Plasticity was selectively expressed in the MC ensembles activated by the stud male, consistent with formation of memories for specific individuals. Finally, MC excitability gained atypical activity-dependence whose slow dynamics strongly attenuated firing on timescales of several minutes. This unusual form of AOB plasticity may act to filter sustained or repetitive sensory signals."
IAN DAVISON,Neuronal imaging with ultrahigh dynamic range multiphoton microscopy,"Multiphoton microscopes are hampered by limited dynamic range, preventing weak sample features from being detected in the presence of strong features, or preventing the capture of unpredictable bursts in sample strength. We present a digital electronic add-on technique that vastly improves the dynamic range of a multiphoton microscope while limiting potential photodamage. The add-on provides real-time negative feedback to regulate the laser power delivered to the sample, and a log representation of the sample strength to accommodate ultrahigh dynamic range without loss of information. No microscope hardware modifications are required, making the technique readily compatible with commercial instruments. Benefits are shown in both structural and in-vivo functional mouse brain imaging applications."
IAN DAVISON,The Bruce effect: representational stability and memory formation in the accessory olfactory bulb of the female mouse,"In the Bruce effect, a mated female mouse becomes resistant to the pregnancy-blocking effect of the stud. Various lines of evidence suggest that this form of behavioral imprinting results from reduced sensitivity of the female's accessory olfactory bulb (AOB) to the stud's chemosignals. However, the AOB's combinatorial code implies that diminishing responses to one individual will distort representations of other stimuli. Here, we record extracellular responses of AOB neurons in mated and unmated female mice while presenting urine stimuli from the stud and from other sources. We find that, while initial sensory responses in the AOB (within a timescale required to guide social interactions) remain stable, responses to extended stimulation (as required for eliciting the pregnancy block) display selective attenuation of stud-responsive neurons. Such temporal disassociation could allow attenuation of slow-acting endocrine processes in a stimulus-specific manner without compromising ongoing representations that guide behavior."
IAN DAVISON,Synchronous infra-slow oscillations organize ensembles of accessory olfactory bulb projection neurons into distinct microcircuits,"The accessory olfactory system controls social and sexual behavior. In the mouse accessory olfactory bulb, the first central stage of information processing along the accessory olfactory pathway, projection neurons (mitral cells) display infra-slow oscillatory discharge with remarkable periodicity. The physiological mechanisms that underlie this default output state, however, remain controversial. Moreover, whether such rhythmic infra-slow activity patterns exist in awake behaving mice and whether such activity reflects the functional organization of the accessory olfactory bulb circuitry remain unclear. Here, we hypothesize that mitral cell ensembles form synchronized microcircuits that subdivide the accessory olfactory bulb into segregated functional clusters. We use a miniature microscope to image the Ca2+ dynamics within the apical dendritic compartments of large mitral cell ensembles in vivo We show that infra-slow periodic patterns of concerted neural activity, indeed, reflect the idle state of accessory olfactory bulb output in awake male and female mice. Ca2+ activity profiles are distinct and glomerulus-specific. Confocal time-lapse imaging in acute slices reveals that groups of mitral cells assemble into microcircuits that exhibit correlated Ca2+ signals. Moreover, electrophysiological profiling of synaptic connectivity indicates functional coupling between mitral cells. Our results suggest that both intrinsically rhythmogenic neurons and neurons entrained by fast synaptic drive are key elements in organizing the accessory olfactory bulb into functional microcircuits, each characterized by a distinct default pattern of infra-slow rhythmicity.SIGNIFICANCE STATEMENT Information processing in the accessory olfactory bulb (AOB) plays a central role in conspecific chemosensory communication. Surprisingly, many basic physiological principles that underlie neuronal signaling in the AOB remain elusive. Here, we show that AOB projection neurons (mitral cells) form parallel synchronized ensembles both in vitro and in vivo Infra-slow synchronous oscillatory activity within AOB microcircuits thus adds a new dimension to chemosensory coding along the accessory olfactory pathway."
IAN DAVISON,Rapid changes in synaptic strength after mild traumatic brain injury,"Traumatic brain injury (TBI) affects millions of Americans annually, but effective treatments remain inadequate due to our poor understanding of how injury impacts neural function. Data are particularly limited for mild, closed-skull TBI, which forms the majority of human cases, and for acute injury phases, when trauma effects and compensatory responses appear highly dynamic. Here we use a mouse model of mild TBI to characterize injury-induced synaptic dysfunction, and examine its progression over the hours to days after trauma. Mild injury consistently caused both locomotor deficits and localized neuroinflammation in piriform and entorhinal cortices, along with reduced olfactory discrimination ability. Using whole-cell recordings to characterize synaptic input onto piriform pyramidal neurons, we found moderate effects on excitatory or inhibitory synaptic function at 48 h after TBI and robust increase in excitatory inputs in slices prepared 1 h after injury. Excitatory increases predominated over inhibitory effects, suggesting that loss of excitatory-inhibitory balance is a common feature of both mild and severe TBI. Our data indicate that mild injury drives rapidly evolving alterations in neural function in the hours following injury, highlighting the need to better characterize the interplay between the primary trauma responses and compensatory effects during this early time period."
IAN DAVISON,Single-shot 3D widefield fluorescence imaging with a computational miniature mesoscope,"Fluorescence imaging is indispensable to biology and neuroscience. The need for largescale imaging in freely behaving animals has further driven the development in miniaturized microscopes (miniscopes). However, conventional microscopes / miniscopes are inherently constrained by their limited space-bandwidth-product, shallow depth-of-field, and inability to resolve 3D distributed emitters. Here, we present a Computational Miniature Mesoscope (CM2) that overcomes these bottlenecks and enables single-shot 3D imaging across an 8 × 7-mm2 field-of-view and 2.5-mm depth-of-field, achieving 7-μm lateral resolution and better than 200-μm axial resolution. Notably, the CM2 has a compact lightweight design that integrates a microlens array for imaging and an LED array for excitation in a single platform. Its expanded imaging capability is enabled by computational imaging that augments the optics by algorithms. We experimentally validate the mesoscopic 3D imaging capability on volumetrically distributed fluorescent beads and fibers. We further quantify the effects of bulk scattering and background fluorescence on phantom experiments."
IAN DAVISON,"Targeted micro-fiber arrays for measuring and manipulating localized multi-scale neural dynamics over large, deep brain volumes during behavior","Neural population dynamics relevant for behavior vary over multiple spatial and temporal scales across 3-dimensional volumes. Current optical approaches lack the spatial coverage and resolution necessary to measure and manipulate naturally occurring patterns of large-scale, distributed dynamics within and across deep brain regions such as the striatum. We designed a new micro-fiber array and imaging approach capable of chronically measuring and optogenetically manipulating local dynamics across over 100 targeted locations simultaneously in head-fixed and freely moving mice. We developed a semi-automated micro-CT based strategy to precisely localize positions of each optical fiber. This highly-customizable approach enables investigation of multi-scale spatial and temporal patterns of cell-type and neurotransmitter specific signals over arbitrary 3-D volumes at a spatial resolution and coverage previously inaccessible. We applied this method to resolve rapid dopamine release dynamics across the striatum volume which revealed distinct, modality specific spatiotemporal patterns in response to salient sensory stimuli extending over millimeters of tissue. Targeted optogenetics through our fiber arrays enabled flexible control of neural signaling on multiple spatial scales, better matching endogenous signaling patterns, and spatial localization of behavioral function across large circuits."
IAN DAVISON,Simultaneous multiplane imaging with reverberation multiphoton microscopy,"Multiphoton microscopy (MPM) has gained enormous popularity over the years for its capacity to provide high resolution images from deep within scattering samples1. However, MPM is generally based on single-point laser-focus scanning, which is intrinsically slow. While imaging speeds as fast as video rate have become routine for 2D planar imaging, such speeds have so far been unattainable for 3D volumetric imaging without severely compromising microscope performance. We demonstrate here 3D volumetric (multiplane) imaging at the same speed as 2D planar (single plane) imaging, with minimal compromise in performance. Specifically, multiple planes are acquired by near-instantaneous axial scanning while maintaining 3D micron-scale resolution. Our technique, called reverberation MPM, is well adapted for large-scale imaging in scattering media with low repetition-rate lasers, and can be implemented with conventional MPM as a simple add-on."
IAN DAVISON,Dorsolateral septum somatostatin interneurons gate mobility to calibrate context-specific behavioral fear responses,"Adaptive fear responses to external threats rely upon efficient relay of computations underlying contextual encoding to subcortical circuits. Brain-wide analysis of highly coactivated ensembles following contextual fear discrimination identified the dorsolateral septum (DLS) as a relay of the dentate gyrus-CA3 circuit. Retrograde monosynaptic tracing and electrophysiological whole-cell recordings demonstrated that DLS somatostatin-expressing interneurons (SST-INs) receive direct CA3 inputs. Longitudinal in vivo calcium imaging of DLS SST-INs in awake, behaving mice identified a stable population of footshock-responsive SST-INs during contextual conditioning whose activity tracked and predicted non-freezing epochs during subsequent recall in the training context but not in a similar, neutral context or open field. Optogenetic attenuation or stimulation of DLS SST-INs bidirectionally modulated conditioned fear responses and recruited proximal and distal subcortical targets. Together, these observations suggest a role for a potentially hard-wired DLS SST-IN subpopulation as arbiters of mobility that calibrate context-appropriate behavioral fear responses."
IAN DAVISON,Olfactory receptor accessory proteins play crucial roles in receptor function and gene choice,"Each of the olfactory sensory neurons (OSNs) chooses to express a single G protein-coupled olfactory receptor (OR) from a pool of hundreds. Here, we show the receptor transporting protein (RTP) family members play a dual role in both normal OR trafficking and determining OR gene choice probabilities. Rtp1 and Rtp2 double knockout mice (RTP1,2DKO) show OR trafficking defects and decreased OSN activation. Surprisingly, we discovered a small subset of the ORs are expressed in larger numbers of OSNs despite the presence of fewer total OSNs in RTP1,2DKO. Unlike typical ORs, some overrepresented ORs show robust cell surface expression in heterologous cells without the co-expression of RTPs. We present a model in which developing OSNs exhibit unstable OR expression until they choose to express an OR that exits the ER or undergo cell death. Our study sheds light on the new link between OR protein trafficking and OR transcriptional regulation."
JESSICA R LEVI,First Sagittarius A* Event Horizon Telescope results. V. Testing astrophysical models of the galactic center black hole,"In this paper we provide a first physical interpretation for the Event Horizon Telescope's (EHT) 2017 observations of Sgr A*. Our main approach is to compare resolved EHT data at 230 GHz and unresolved non-EHT observations from radio to X-ray wavelengths to predictions from a library of models based on time-dependent general relativistic magnetohydrodynamics simulations, including aligned, tilted, and stellar-wind-fed simulations; radiative transfer is performed assuming both thermal and nonthermal electron distribution functions. We test the models against 11 constraints drawn from EHT 230 GHz data and observations at 86 GHz, 2.2 μm, and in the X-ray. All models fail at least one constraint. Light-curve variability provides a particularly severe constraint, failing nearly all strongly magnetized (magnetically arrested disk (MAD)) models and a large fraction of weakly magnetized models. A number of models fail only the variability constraints. We identify a promising cluster of these models, which are MAD and have inclination i ≤ 30°. They have accretion rate (5.2–9.5) × 10−9 M ⊙ yr−1, bolometric luminosity (6.8–9.2) × 1035 erg s−1, and outflow power (1.3–4.8) × 1038 erg s−1. We also find that all models with i ≥ 70° fail at least two constraints, as do all models with equal ion and electron temperature; exploratory, nonthermal model sets tend to have higher 2.2 μm flux density; and the population of cold electrons is limited by X-ray constraints due to the risk of bremsstrahlung overproduction. Finally, we discuss physical and numerical limitations of the models, highlighting the possible importance of kinetic effects and duration of the simulations."
JESSICA R LEVI,First M87 Event Horizon Telescope results. VII. Polarization of the ring,"In 2017 April, the Event Horizon Telescope (EHT) observed the near-horizon region around the supermassive black hole at the core of the M87 galaxy. These 1.3 mm wavelength observations revealed a compact asymmetric ring-like source morphology. This structure originates from synchrotron emission produced by relativistic plasma located in the immediate vicinity of the black hole. Here we present the corresponding linear-polarimetric EHT images of the center of M87. We find that only a part of the ring is significantly polarized. The resolved fractional linear polarization has a maximum located in the southwest part of the ring, where it rises to the level of ∼15%. The polarization position angles are arranged in a nearly azimuthal pattern. We perform quantitative measurements of relevant polarimetric properties of the compact emission and find evidence for the temporal evolution of the polarized source structure over one week of EHT observations. The details of the polarimetric data reduction and calibration methodology are provided. We carry out the data analysis using multiple independent imaging and modeling techniques, each of which is validated against a suite of synthetic data sets. The gross polarimetric structure and its apparent evolution with time are insensitive to the method used to reconstruct the image. These polarimetric images carry information about the structure of the magnetic fields responsible for the synchrotron emission. Their physical interpretation is discussed in an accompanying publication."
JESSICA R LEVI,First M87 Event Horizon Telescope results. VIII. Magnetic field structure near The Event Horizon,"Event Horizon Telescope (EHT) observations at 230 GHz have now imaged polarized emission around the supermassive black hole in M87 on event-horizon scales. This polarized synchrotron radiation probes the structure of magnetic fields and the plasma properties near the black hole. Here we compare the resolved polarization structure observed by the EHT, along with simultaneous unresolved observations with the Atacama Large Millimeter/submillimeter Array, to expectations from theoretical models. The low fractional linear polarization in the resolved image suggests that the polarization is scrambled on scales smaller than the EHT beam, which we attribute to Faraday rotation internal to the emission region. We estimate the average density n_e ∼ 10^4–7 cm^−3, magnetic field strength B ∼ 1–30 G, and electron temperature T_e ∼ (1–12) × 10^10 K of the radiating plasma in a simple one-zone emission model. We show that the net azimuthal linear polarization pattern may result from organized, poloidal magnetic fields in the emission region. In a quantitative comparison with a large library of simulated polarimetric images from general relativistic magnetohydrodynamic (GRMHD) simulations, we identify a subset of physical models that can explain critical features of the polarimetric EHT observations while producing a relativistic jet of sufficient power. The consistent GRMHD models are all of magnetically arrested accretion disks, where near-horizon magnetic fields are dynamically important. We use the models to infer a mass accretion rate onto the black hole in M87 of (3–20) × 10^−4 M ⊙ yr^−1."
JESSICA R LEVI,Resolving the inner parsec of the blazar J1924–2914 with the event horizon telescope,"The blazar J1924–2914 is a primary Event Horizon Telescope (EHT) calibrator for the Galactic center’s black hole Sagittarius A*. Here we present the first total and linearly polarized intensity images of this source obtained with the unprecedented 20 μas resolution of the EHT. J1924–2914 is a very compact flat-spectrum radio source with strong optical variability and polarization. In April 2017 the source was observed quasi-simultaneously with the EHT (April 5–11), the Global Millimeter VLBI Array (April 3), and the Very Long Baseline Array (April 28), giving a novel view of the source at four observing frequencies, 230, 86, 8.7, and 2.3 GHz. These observations probe jet properties from the subparsec to 100 pc scales. We combine the multifrequency images of J1924–2914 to study the source morphology. We find that the jet exhibits a characteristic bending, with a gradual clockwise rotation of the jet projected position angle of about 90° between 2.3 and 230 GHz. Linearly polarized intensity images of J1924–2914 with the extremely fine resolution of the EHT provide evidence for ordered toroidal magnetic fields in the blazar compact core."
JESSICA R LEVI,A universal power-law prescription for variability from synthetic images of black hole accretion flows,"We present a framework for characterizing the spatiotemporal power spectrum of the variability expected from the horizon-scale emission structure around supermassive black holes, and we apply this framework to a library of general relativistic magnetohydrodynamic (GRMHD) simulations and associated general relativistic ray-traced images relevant for Event Horizon Telescope (EHT) observations of Sgr A*. We find that the variability power spectrum is generically a red-noise process in both the temporal and spatial dimensions, with the peak in power occurring on the longest timescales and largest spatial scales. When both the time-averaged source structure and the spatially integrated light-curve variability are removed, the residual power spectrum exhibits a universal broken power-law behavior. On small spatial frequencies, the residual power spectrum rises as the square of the spatial frequency and is proportional to the variance in the centroid of emission. Beyond some peak in variability power, the residual power spectrum falls as that of the time-averaged source structure, which is similar across simulations; this behavior can be naturally explained if the variability arises from a multiplicative random field that has a steeper high-frequency power-law index than that of the time-averaged source structure. We briefly explore the ability of power spectral variability studies to constrain physical parameters relevant for the GRMHD simulations, which can be scaled to provide predictions for black holes in a range of systems in the optically thin regime. We present specific expectations for the behavior of the M87* and Sgr A* accretion flows as observed by the EHT."
JESSICA R LEVI,Millimeter light curves of Sagittarius A* observed during the 2017 Event Horizon Telescope campaign,"The Event Horizon Telescope (EHT) observed the compact radio source, Sagittarius A* (Sgr A*), in the Galactic Center on 2017 April 5–11 in the 1.3 mm wavelength band. At the same time, interferometric array data from the Atacama Large Millimeter/submillimeter Array and the Submillimeter Array were collected, providing Sgr A* light curves simultaneous with the EHT observations. These data sets, complementing the EHT very long baseline interferometry, are characterized by a cadence and signal-to-noise ratio previously unattainable for Sgr A* at millimeter wavelengths, and they allow for the investigation of source variability on timescales as short as a minute. While most of the light curves correspond to a low variability state of Sgr A*, the April 11 observations follow an X-ray flare and exhibit strongly enhanced variability. All of the light curves are consistent with a red-noise process, with a power spectral density (PSD) slope measured to be between −2 and −3 on timescales between 1 minute and several hours. Our results indicate a steepening of the PSD slope for timescales shorter than 0.3 hr. The spectral energy distribution is flat at 220 GHz, and there are no time lags between the 213 and 229 GHz frequency bands, suggesting low optical depth for the event horizon scale source. We characterize Sgr A*’s variability, highlighting the different behavior observed just after the X-ray flare, and use Gaussian process modeling to extract a decorrelation timescale and a PSD slope. We also investigate the systematic calibration uncertainties by analyzing data from independent data reduction pipelines."
JESSICA R LEVI,Selective dynamical imaging of interferometric data,"Recent developments in very long baseline interferometry (VLBI) have made it possible for the Event Horizon Telescope (EHT) to resolve the innermost accretion flows of the largest supermassive black holes on the sky. The sparse nature of the EHT’s (u, v)-coverage presents a challenge when attempting to resolve highly time-variable sources. We demonstrate that the changing (u, v)-coverage of the EHT can contain regions of time over the course of a single observation that facilitate dynamical imaging. These optimal time regions typically have projected baseline distributions that are approximately angularly isotropic and radially homogeneous. We derive a metric of coverage quality based on baseline isotropy and density that is capable of ranking array configurations by their ability to produce accurate dynamical reconstructions. We compare this metric to existing metrics in the literature and investigate their utility by performing dynamical reconstructions on synthetic data from simulated EHT observations of sources with simple orbital variability. We then use these results to make recommendations for imaging the 2017 EHT Sgr A* data set."
JESSICA R LEVI,First Sagittarius A* Event Horizon Telescope results. VI. Testing the black hole metric,"Astrophysical black holes are expected to be described by the Kerr metric. This is the only stationary, vacuum, axisymmetric metric, without electromagnetic charge, that satisfies Einstein’s equations and does not have pathologies outside of the event horizon. We present new constraints on potential deviations from the Kerr prediction based on 2017 EHT observations of Sagittarius A* (Sgr A*). We calibrate the relationship between the geometrically defined black hole shadow and the observed size of the ring-like images using a library that includes both Kerr and non-Kerr simulations. We use the exquisite prior constraints on the mass-to-distance ratio for Sgr A* to show that the observed image size is within ∼10% of the Kerr predictions. We use these bounds to constrain metrics that are parametrically different from Kerr, as well as the charges of several known spacetimes. To consider alternatives to the presence of an event horizon, we explore the possibility that Sgr A* is a compact object with a surface that either absorbs and thermally reemits incident radiation or partially reflects it. Using the observed image size and the broadband spectrum of Sgr A*, we conclude that a thermal surface can be ruled out and a fully reflective one is unlikely. We compare our results to the broader landscape of gravitational tests. Together with the bounds found for stellar-mass black holes and the M87 black hole, our observations provide further support that the external spacetimes of all black holes are described by the Kerr metric, independent of their mass."
JESSICA R LEVI,Polarimetric properties of Event Horizon Telescope targets from ALMA,"We present the results from a full polarization study carried out with the Atacama Large Millimeter/submillimeter Array (ALMA) during the first Very Long Baseline Interferometry (VLBI) campaign, which was conducted in 2017 April in the λ3 mm and λ1.3 mm bands, in concert with the Global mm-VLBI Array (GMVA) and the Event Horizon Telescope (EHT), respectively. We determine the polarization and Faraday properties of all VLBI targets, including Sgr A*, M87, and a dozen radio-loud active galactic nuclei (AGNs), in the two bands at several epochs in a time window of 10 days. We detect high linear polarization fractions (2%–15%) and large rotation measures (RM &gt; 103.3–105.5 rad m−2), confirming the trends of previous AGN studies at millimeter wavelengths. We find that blazars are more strongly polarized than other AGNs in the sample, while exhibiting (on average) order-of-magnitude lower RM values, consistent with the AGN viewing angle unification scheme. For Sgr A* we report a mean RM of (−4.2 ± 0.3) × 105 rad m−2 at 1.3 mm, consistent with measurements over the past decade and, for the first time, an RM of (–2.1 ± 0.1) × 105 rad m−2 at 3 mm, suggesting that about half of the Faraday rotation at 1.3 mm may occur between the 3 mm photosphere and the 1.3 mm source. We also report the first unambiguous measurement of RM toward the M87 nucleus at millimeter wavelengths, which undergoes significant changes in magnitude and sign reversals on a one year timescale, spanning the range from −1.2 to 0.3 × 105 rad m−2 at 3 mm and −4.1 to 1.5 × 105 rad m−2 at 1.3 mm. Given this time variability, we argue that, unlike the case of Sgr A*, the RM in M87 does not provide an accurate estimate of the mass accretion rate onto the black hole. We put forward a two-component model, comprised of a variable compact region and a static extended region, that can simultaneously explain the polarimetric properties observed by both the EHT (on horizon scales) and ALMA (which observes the combined emission from both components). These measurements provide critical constraints for the calibration, analysis, and interpretation of simultaneously obtained VLBI data with the EHT and GMVA."
JESSICA R LEVI,"First Sagittarius A* Event Horizon Telescope results. IV. Variability, morphology, and black hole mass","In this paper we quantify the temporal variability and image morphology of the horizon-scale emission from Sgr A*, as observed by the EHT in 2017 April at a wavelength of 1.3 mm. We find that the Sgr A* data exhibit variability that exceeds what can be explained by the uncertainties in the data or by the effects of interstellar scattering. The magnitude of this variability can be a substantial fraction of the correlated flux density, reaching ∼100% on some baselines. Through an exploration of simple geometric source models, we demonstrate that ring-like morphologies provide better fits to the Sgr A* data than do other morphologies with comparable complexity. We develop two strategies for fitting static geometric ring models to the time-variable Sgr A* data; one strategy fits models to short segments of data over which the source is static and averages these independent fits, while the other fits models to the full data set using a parametric model for the structural variability power spectrum around the average source structure. Both geometric modeling and image-domain feature extraction techniques determine the ring diameter to be 51.8 ± 2.3 μas (68% credible intervals), with the ring thickness constrained to have an FWHM between ∼30% and 50% of the ring diameter. To bring the diameter measurements to a common physical scale, we calibrate them using synthetic data generated from GRMHD simulations. This calibration constrains the angular size of the gravitational radius to be 4.8_-0.7^+1.4 μas, which we combine with an independent distance measurement from maser parallaxes to determine the mass of Sgr A* to be 4.0_-0.6^+10^6 M⊙."
JESSICA R LEVI,"Cosmology intertwined: a review of the particle physics, astrophysics, and cosmology associated with the cosmological tensions and anomalies",
JESSICA R LEVI,"First Sagittarius A* Event Horizon Telescope results. II. EHT and multiwavelength observations, data processing, and calibration","We present Event Horizon Telescope (EHT) 1.3 mm measurements of the radio source located at the position of the supermassive black hole Sagittarius A* (Sgr A*), collected during the 2017 April 5–11 campaign. The observations were carried out with eight facilities at six locations across the globe. Novel calibration methods are employed to account for Sgr A*'s flux variability. The majority of the 1.3 mm emission arises from horizon scales, where intrinsic structural source variability is detected on timescales of minutes to hours. The effects of interstellar scattering on the image and its variability are found to be subdominant to intrinsic source structure. The calibrated visibility amplitudes, particularly the locations of the visibility minima, are broadly consistent with a blurred ring with a diameter of ∼50 μas, as determined in later works in this series. Contemporaneous multiwavelength monitoring of Sgr A* was performed at 22, 43, and 86 GHz and at near-infrared and X-ray wavelengths. Several X-ray flares from Sgr A* are detected by Chandra, one at low significance jointly with Swift on 2017 April 7 and the other at higher significance jointly with NuSTAR on 2017 April 11. The brighter April 11 flare is not observed simultaneously by the EHT but is followed by a significant increase in millimeter flux variability immediately after the X-ray outburst, indicating a likely connection in the emission physics near the event horizon. We compare Sgr A*’s broadband flux during the EHT campaign to its historical spectral energy distribution and find that both the quiescent emission and flare emission are consistent with its long-term behavior."
JESSICA R LEVI,Broadband multi-wavelength properties of M87 during the 2017 Event Horizon Telescope campaign,"In 2017, the Event Horizon Telescope (EHT) Collaboration succeeded in capturing the first direct image of the center of the M87 galaxy. The asymmetric ring morphology and size are consistent with theoretical expectations for a weakly accreting supermassive black hole of mass ∼6.5 × 109 M ⊙. The EHTC also partnered with several international facilities in space and on the ground, to arrange an extensive, quasi-simultaneous multi-wavelength campaign. This Letter presents the results and analysis of this campaign, as well as the multi-wavelength data as a legacy data repository. We captured M87 in a historically low state, and the core flux dominates over HST-1 at high energies, making it possible to combine core flux constraints with the more spatially precise very long baseline interferometry data. We present the most complete simultaneous multi-wavelength spectrum of the active nucleus to date, and discuss the complexity and caveats of combining data from different spatial scales into one broadband spectrum. We apply two heuristic, isotropic leptonic single-zone models to provide insight into the basic source properties, but conclude that a structured jet is necessary to explain M87’s spectrum. We can exclude that the simultaneous γ-ray emission is produced via inverse Compton emission in the same region producing the EHT mm-band emission, and further conclude that the γ-rays can only be produced in the inner jets (inward of HST-1) if there are strongly particle-dominated regions. Direct synchrotron emission from accelerated protons and secondaries cannot yet be excluded."
JESSICA R LEVI,First Sagittarius A* Event Horizon Telescope results. III. Imaging of the Galactic center supermassive black hole,"We present the first event-horizon-scale images and spatiotemporal analysis of Sgr A* taken with the Event Horizon Telescope in 2017 April at a wavelength of 1.3 mm. Imaging of Sgr A* has been conducted through surveys over a wide range of imaging assumptions using the classical CLEAN algorithm, regularized maximum likelihood methods, and a Bayesian posterior sampling method. Different prescriptions have been used to account for scattering effects by the interstellar medium toward the Galactic center. Mitigation of the rapid intraday variability that characterizes Sgr A* has been carried out through the addition of a “variability noise budget” in the observed visibilities, facilitating the reconstruction of static full-track images. Our static reconstructions of Sgr A* can be clustered into four representative morphologies that correspond to ring images with three different azimuthal brightness distributions and a small cluster that contains diverse nonring morphologies. Based on our extensive analysis of the effects of sparse (u, v)-coverage, source variability, and interstellar scattering, as well as studies of simulated visibility data, we conclude that the Event Horizon Telescope Sgr A* data show compelling evidence for an image that is dominated by a bright ring of emission with a ring diameter of ∼50 μas, consistent with the expected “shadow” of a 4 × 106 M⊙ black hole in the Galactic center located at a distance of 8 kpc."
JESSICA R LEVI,Characterizing and mitigating intraday variability: reconstructing source structure in accreting black holes with mm-VLBI,"The extraordinary physical resolution afforded by the Event Horizon Telescope has opened a window onto the astrophysical phenomena unfolding on horizon scales in two known black holes, M87* and Sgr A*. However, with this leap in resolution has come a new set of practical complications. Sgr A* exhibits intraday variability that violates the assumptions underlying Earth aperture synthesis, limiting traditional image reconstruction methods to short timescales and data sets with very sparse (u, v) coverage. We present a new set of tools to detect and mitigate this variability. We develop a data-driven, model-agnostic procedure to detect and characterize the spatial structure of intraday variability. This method is calibrated against a large set of mock data sets, producing an empirical estimator of the spatial power spectrum of the brightness fluctuations. We present a novel Bayesian noise modeling algorithm that simultaneously reconstructs an average image and statistical measure of the fluctuations about it using a parameterized form for the excess variance in the complex visibilities not otherwise explained by the statistical errors. These methods are validated using a variety of simulated data, including general relativistic magnetohydrodynamic simulations appropriate for Sgr A* and M87*. We find that the reconstructed source structure and variability are robust to changes in the underlying image model. We apply these methods to the 2017 EHT observations of M87*, finding evidence for variability across the EHT observing campaign. The variability mitigation strategies presented are widely applicable to very long baseline interferometry observations of variable sources generally, for which they provide a data-informed averaging procedure and natural characterization of inter-epoch image consistency."
JESSICA R LEVI,The polarized image of a synchrotron-emitting ring of gas orbiting a black hole,"Synchrotron radiation from hot gas near a black hole results in a polarized image. The image polarization is determined by effects including the orientation of the magnetic field in the emitting region, relativistic motion of the gas, strong gravitational lensing by the black hole, and parallel transport in the curved spacetime. We explore these effects using a simple model of an axisymmetric, equatorial accretion disk around a Schwarzschild black hole. By using an approximate expression for the null geodesics derived by Beloborodov and conservation of the Walker–Penrose constant, we provide analytic estimates for the image polarization. We test this model using currently favored general relativistic magnetohydrodynamic simulations of M87*, using ring parameters given by the simulations. For a subset of these with modest Faraday effects, we show that the ring model broadly reproduces the polarimetric image morphology. Our model also predicts the polarization evolution for compact flaring regions, such as those observed from Sgr A* with GRAVITY. With suitably chosen parameters, our simple model can reproduce the EVPA pattern and relative polarized intensity in Event Horizon Telescope images of M87*. Under the physically motivated assumption that the magnetic field trails the fluid velocity, this comparison is consistent with the clockwise rotation inferred from total intensity images."
JESSICA R LEVI,First Sagittarius A* Event Horizon Telescope results. I. The shadow of the supermassive black hole in the center of the Milky Way,"We present the first Event Horizon Telescope (EHT) observations of Sagittarius A* (Sgr A*), the Galactic center source associated with a supermassive black hole. These observations were conducted in 2017 using a global interferometric array of eight telescopes operating at a wavelength of λ = 1.3 mm. The EHT data resolve a compact emission region with intrahour variability. A variety of imaging and modeling analyses all support an image that is dominated by a bright, thick ring with a diameter of 51.8 ± 2.3 μas (68% credible interval). The ring has modest azimuthal brightness asymmetry and a comparatively dim interior. Using a large suite of numerical simulations, we demonstrate that the EHT images of Sgr A* are consistent with the expected appearance of a Kerr black hole with mass ∼4 × 106 M ⊙, which is inferred to exist at this location based on previous infrared observations of individual stellar orbits, as well as maser proper-motion studies. Our model comparisons disfavor scenarios where the black hole is viewed at high inclination (i &gt; 50°), as well as nonspinning black holes and those with retrograde accretion disks. Our results provide direct evidence for the presence of a supermassive black hole at the center of the Milky Way, and for the first time we connect the predictions from dynamical measurements of stellar orbits on scales of 103–105 gravitational radii to event-horizon-scale images and variability. Furthermore, a comparison with the EHT results for the supermassive black hole M87* shows consistency with the predictions of general relativity spanning over three orders of magnitude in central mass."
JESSICA R LEVI,The variability of the black hole image in M87 at the dynamical timescale,"The black hole images obtained with the Event Horizon Telescope (EHT) are expected to be variable at the dynamical timescale near their horizons. For the black hole at the center of the M87 galaxy, this timescale (5–61 days) is comparable to the 6 day extent of the 2017 EHT observations. Closure phases along baseline triangles are robust interferometric observables that are sensitive to the expected structural changes of the images but are free of station-based atmospheric and instrumental errors. We explored the day-to-day variability in closure-phase measurements on all six linearly independent nontrivial baseline triangles that can be formed from the 2017 observations. We showed that three triangles exhibit very low day-to-day variability, with a dispersion of ∼3°–5°. The only triangles that exhibit substantially higher variability (∼90°–180°) are the ones with baselines that cross the visibility amplitude minima on the u–v plane, as expected from theoretical modeling. We used two sets of general relativistic magnetohydrodynamic simulations to explore the dependence of the predicted variability on various black hole and accretion-flow parameters. We found that changing the magnetic field configuration, electron temperature model, or black hole spin has a marginal effect on the model consistency with the observed level of variability. On the other hand, the most discriminating image characteristic of models is the fractional width of the bright ring of emission. Models that best reproduce the observed small level of variability are characterized by thin ring-like images with structures dominated by gravitational lensing effects and thus least affected by turbulence in the accreting plasmas."
JESSICA R LEVI,Constraints on black-hole charges with the 2017 EHT observations of M87*,
MICHAEL L SMITH,A systematic search of Zwicky Transient Facility data for ultracompact binary LISA-detectable gravitational-wave sources,"Using photometry collected with the Zwicky Transient Facility, we are conducting an ongoing survey for binary systems with short orbital periods (P_b < 1 hr) with the goal of identifying new gravitational-wave sources detectable by the upcoming Laser Interferometer Space Antenna (LISA). We present a sample of 15 binary systems discovered thus far, with orbital periods ranging from 6.91 to 56.35 minutes. Of the 15 systems, seven are eclipsing systems that do not show signs of significant mass transfer. Additionally, we have discovered two AM Canum Venaticorum systems and six systems exhibiting primarily ellipsoidal variations in their lightcurves. We present follow-up spectroscopy and high-speed photometry confirming the nature of these systems, estimates of their LISA signal-to-noise ratios, and a discussion of their physical characteristics."
MICHAEL L SMITH,Shared and distinct transcriptomic cell types across neocortical areas,"The neocortex contains a multitude of cell types that are segregated into layers and functionally distinct areas. To investigate the diversity of cell types across the mouse neocortex, here we analysed 23,822 cells from two areas at distant poles of the mouse neocortex: the primary visual cortex and the anterior lateral motor cortex. We define 133 transcriptomic cell types by deep, single-cell RNA sequencing. Nearly all types of GABA (γ-aminobutyric acid)-containing neurons are shared across both areas, whereas most types of glutamatergic neurons were found in one of the two areas. By combining single-cell RNA sequencing and retrograde labelling, we match transcriptomic types of glutamatergic neurons to their long-range projection specificity. Our study establishes a combined transcriptomic and projectional taxonomy of cortical cell types from functionally distinct areas of the adult mouse cortex."
MICHAEL L SMITH,"The role of religion in the longer-range future, April 6, 7, and 8, 2006","The conference brought together some 40 experts from various disciplines to ponder upon the “great dilemma” of how science, religion, and the human future interact. In particular, different panels looked at trends in what is happening to religion around the world, questions about how religion is impacting the current political and economic order, and how the social dynamics unleashed by science and by religion can be reconciled."
MICHAEL L SMITH,The first ultracompact Roche lobe–filling hot subdwarf binary,"We report the discovery of the first short-period binary in which a hot subdwarf star (sdOB) filled its Roche lobe and started mass transfer to its companion. The object was discovered as part of a dedicated high-cadence survey of the Galactic plane named the Zwicky Transient Facility and exhibits a period of P = 39.3401(1) minutes, making it the most compact hot subdwarf binary currently known. Spectroscopic observations are consistent with an intermediate He-sdOB star with an effective temperature of T_eff = 42,400 ± 300 K and a surface gravity of log(g) = 5.77 ± 0.05. A high signal-to-noise ratio GTC+HiPERCAM light curve is dominated by the ellipsoidal deformation of the sdOB star and an eclipse of the sdOB by an accretion disk. We infer a low-mass hot subdwarf donor with a mass MsdOB = 0.337 ± 0.015 M_⊙ and a white dwarf accretor with a mass MWD = 0.545 ± 0.020 M_⊙. Theoretical binary modeling indicates the hot subdwarf formed during a common envelope phase when a 2.5–2.8 M_⊙ star lost its envelope when crossing the Hertzsprung gap. To match its current P_orb, T_eff, log(g), and masses, we estimate a post–common envelope period of P_orb ≈ 150 minutes and find that the sdOB star is currently undergoing hydrogen shell burning. We estimate that the hot subdwarf will become a white dwarf with a thick helium layer of ≈0.1 M_⊙, merge with its carbon/oxygen white dwarf companion after ≈17 Myr, and presumably explode as a thermonuclear supernova or form an R CrB star."
MICHAEL L SMITH,Dependence of tensional homeostasis on cell type and on cell-cell interactions,"INTRODUCTION The ability to maintain a homeostatic level of cell tension is essential for many physiological processes. Our group has recently reported that multicellularity is required for tensional homeostasis in endothelial cells. However, other studies have shown that isolated fibroblasts also maintain constant tension over short time scales without the need of cell–cell contacts. Therefore, in this study, our aim was to determine how different cell types regulate tension as isolated cells or in small clustered groupings and to investigate the role of cell–cell adhesion molecules, such as E-cadherin, in this system. METHODS Micropattern traction force microscopy was used to determine how bovine aortic endothelial cells, bovine vascular smooth muscle cells, mouse embryonic fibroblasts, and human gastric adenocarcinoma cells, with or without cell–cell interactions due to E-cadherin, maintain tensional homeostasis over time. Tension temporal fluctuations in single cells and cell clusters were evaluated. RESULTS We found that only endothelial cells require clustering for tensional homeostasis. The same was not verified in fibroblasts or vascular smooth muscle cells. Of relevance, in adenocarcinoma cells, we verified that tensional homeostasis was dependent on the competence of the adhesion molecule E-cadherin at both the single cells and multicellular levels. CONCLUSION These findings indicate that cell–cell contacts may be critical for tensional homeostasis and, potentially, for barrier function of the endothelium. Furthermore, the cell–cell adhesion molecule E-cadherin is an important regulator of tensional homeostasis, even in the absence of cadherin engagement with neighboring cells, which demonstrates its relevance not only as a structural molecule but also as a signaling moiety."
MICHAEL L SMITH,Single-platelet nanomechanics measured by high-throughput cytometry,
MICHAEL L SMITH,"IMPACT: The Journal of the Center for Interdisciplinary Teaching and Learning. Volume 12, Issue 1, Summer 2023","The essays in this issue explore how to enhance teaching and student learning in the classroom. Our first contributor argues that providing students the opportunity to write questions about course material is a fruitful way to address students’ reticence about asking questions during class and also may result in students performing better on testable material. Moreover, instructors benefit from having students’ questions because the written questions can also be used by the instructor to know better what students are and are not understanding about course material and alerts instructors to where they can further explain or clarify course material. Finally, our first contributor also suggests that students in interdisciplinary classrooms might especially benefit from writing their questions, while instructors of interdisciplinary courses may find the flexibility with using technology to address the written questions in “real time” via the use of technology especially beneficial. In our second contribution, the author argues that pre-service teachers’ educational curriculum should address the academic literature that links poor musical-rhythmic tendencies with reading struggles for reading learners. The author also argues that the rhythm-reading connection is applicable to interdisciplinary educators because it asks those educators to reflect on possible connections between the body and the acquisition of skills that are usually considered purely intellectual. Our Impact book reviewers cover a varied set of interesting and important topics in this issue. One reviewer informs readers about a handbook on community psychology that prioritizes applied and interdisciplinary work; another reviewer details an author’s synthesis of what contemporary archaeology has now come to understand about Maya civilization’s resilient and complex society through time and within their varied mosaic of managed environments; a different reviewer delves into an author’s exploration of how digital media platforms generate novel opportunities for sufferers of trauma to make sense of their experience, and our final reviewer details an author’s accounting of the history, origins, and evolution of the Camp Fire Girls, one of America’s longest-serving girls’ youth movements, its impact on girls’ lives, and how the organization adapted to and resisted dominant ideologies about girls, culture, and race across time."
MICHAEL L SMITH,A new class of large-amplitude radial-mode hot subdwarf pulsators,"Using high-cadence observations from the Zwicky Transient Facility at low Galactic latitudes, we have discovered a new class of pulsating, hot compact stars. We have found four candidates, exhibiting blue colors (g − r ≤ −0.1 mag), pulsation amplitudes of >5%, and pulsation periods of 200–475 s. Fourier transforms of the light curves show only one dominant frequency. Phase-resolved spectroscopy for three objects reveals significant radial velocity, T eff, and log(g) variations over the pulsation cycle, which are consistent with large-amplitude radial oscillations. The mean T eff and log(g) for these stars are consistent with hot subdwarf B (sdB) effective temperatures and surface gravities. We calculate evolutionary tracks using MESA and adiabatic pulsations using GYRE for low-mass, helium-core pre-white dwarfs (pre-WDs) and low-mass helium-burning stars. Comparison of low-order radial oscillation mode periods with the observed pulsation periods show better agreement with the pre-WD models. Therefore, we suggest that these new pulsators and blue large-amplitude pulsators (BLAPs) could be members of the same class of pulsators, composed of young ≈0.25–0.35 M ⊙ helium-core pre-WDs."
MICHAEL L SMITH,NRXN3 Is a Novel Locus for Waist Circumference: A Genome-Wide Association Study from the CHARGE Consortium,"Central abdominal fat is a strong risk factor for diabetes and cardiovascular disease. To identify common variants influencing central abdominal fat, we conducted a two-stage genome-wide association analysis for waist circumference (WC). In total, three loci reached genome-wide significance. In stage 1, 31,373 individuals of Caucasian descent from eight cohort studies confirmed the role of FTO and MC4R and identified one novel locus associated with WC in the neurexin 3 gene [NRXN3 (rs10146997, p = 6.4×10−7)]. The association with NRXN3 was confirmed in stage 2 by combining stage 1 results with those from 38,641 participants in the GIANT consortium (p = 0.009 in GIANT only, p = 5.3×10−8 for combined analysis, n = 70,014). Mean WC increase per copy of the G allele was 0.0498 z-score units (0.65 cm). This SNP was also associated with body mass index (BMI) [p = 7.4×10−6, 0.024 z-score units (0.10 kg/m2) per copy of the G allele] and the risk of obesity (odds ratio 1.13, 95% CI 1.07–1.19; p = 3.2×10−5 per copy of the G allele). The NRXN3 gene has been previously implicated in addiction and reward behavior, lending further evidence that common forms of obesity may be a central nervous system-mediated disorder. Our findings establish that common variants in NRXN3 are associated with WC, BMI, and obesity. Author Summary Obesity is a major health concern worldwide. In the past two years, genome-wide association studies of DNA markers known as SNPs (single nucleotide polymorphisms) have identified two novel genetic factors that may help scientists better understand why some people may be more susceptible to obesity. Similarly, this paper describes results from a large scale genome-wide association analysis for obesity susceptibility genes that includes 31,373 individuals from 8 separate studies. We uncovered a new gene influencing waist circumference, the neurexin 3 gene (NRXN3), which has been previously implicated in studies of addiction and reward behavior. These findings lend further evidence that our genes may influence our desire and consumption of food and, in turn, our susceptibility to obesity."
MICHAEL L SMITH,Mechanical forces regulate the interactions of fibronectin and collagen I in extracellular matrix,"Despite the crucial role of extracellular matrix (ECM) in directing cell fate in healthy and diseased tissues--particularly in development, wound healing, tissue regeneration and cancer--the mechanisms that direct the assembly and regulate hierarchical architectures of ECM are poorly understood. Collagen I matrix assembly in vivo requires active fibronectin (Fn) fibrillogenesis by cells. Here we exploit Fn-FRET probes as mechanical strain sensors and demonstrate that collagen I fibres preferentially co-localize with more-relaxed Fn fibrils in the ECM of fibroblasts in cell culture. Fibre stretch-assay studies reveal that collagen I's Fn-binding domain is responsible for the mechano-regulated interaction. Furthermore, we show that Fn-collagen interactions are reciprocal: relaxed Fn fibrils act as multivalent templates for collagen assembly, but once assembled, collagen fibres shield Fn fibres from being stretched by cellular traction forces. Thus, in addition to the well-recognized, force-regulated, cell-matrix interactions, forces also tune the interactions between different structural ECM components."
MICHAEL L SMITH,Priorities for synthesis research in ecology and environmental science,
MICHAEL L SMITH,Event Horizon Telescope imaging of the archetypal blazar 3C 279 at an extreme 20 microarcsecond resolution,"3C 279 is an archetypal blazar with a prominent radio jet that show broadband flux density variability across the entire electromagnetic spectrum. We use an ultra-high angular resolution technique – global Very Long Baseline Interferometry (VLBI) at 1.3 mm (230 GHz) – to resolve the innermost jet of 3C 279 in order to study its fine-scale morphology close to the jet base where highly variable γ-ray emission is thought to originate, according to various models. The source was observed during four days in April 2017 with the Event Horizon Telescope at 230 GHz, including the phased Atacama Large Millimeter/submillimeter Array (ALMA), at an angular resolution of ∼20 μas (at a redshift of z = 0.536 this corresponds to ∼0.13 pc  ∼ 1700 Schwarzschild radii with a black hole mass M<jats:sub>BH</jats:sub> = 8 × 10^8 M_⊙). Imaging and model-fitting techniques were applied to the data to parameterize the fine-scale source structure and its variation. We find a multicomponent inner jet morphology with the northernmost component elongated perpendicular to the direction of the jet, as imaged at longer wavelengths. The elongated nuclear structure is consistent on all four observing days and across different imaging methods and model-fitting techniques, and therefore appears robust. Owing to its compactness and brightness, we associate the northern nuclear structure as the VLBI “core”. This morphology can be interpreted as either a broad resolved jet base or a spatially bent jet. We also find significant day-to-day variations in the closure phases, which appear most pronounced on the triangles with the longest baselines. Our analysis shows that this variation is related to a systematic change of the source structure. Two inner jet components move non-radially at apparent speeds of ∼15 c and ∼20 c (∼1.3 and ∼1.7 μas day^−1, respectively), which more strongly supports the scenario of traveling shocks or instabilities in a bent, possibly rotating jet. The observed apparent speeds are also coincident with the 3C 279 large-scale jet kinematics observed at longer (cm) wavelengths, suggesting no significant jet acceleration between the 1.3 mm core and the outer jet. The intrinsic brightness temperature of the jet components are ≲10^10 K, a magnitude or more lower than typical values seen at ≥7 mm wavelengths. The low brightness temperature and morphological complexity suggest that the core region of 3C 279 becomes optically thin at short (mm) wavelengths."
MICHAEL L SMITH,First M87 Event Horizon Telescope results. II. Array and instrumentation,"The Event Horizon Telescope (EHT) is a very long baseline interferometry (VLBI) array that comprises millimeter- and submillimeter-wavelength telescopes separated by distances comparable to the diameter of the Earth. At a nominal operating wavelength of ~1.3 mm, EHT angular resolution (λ/D) is ~25 μas, which is sufficient to resolve nearby supermassive black hole candidates on spatial and temporal scales that correspond to their event horizons. With this capability, the EHT scientific goals are to probe general relativistic effects in the strong-field regime and to study accretion and relativistic jet formation near the black hole boundary. In this Letter we describe the system design of the EHT, detail the technology and instrumentation that enable observations, and provide measures of its performance. Meeting the EHT science objectives has required several key developments that have facilitated the robust extension of the VLBI technique to EHT observing wavelengths and the production of instrumentation that can be deployed on a heterogeneous array of existing telescopes and facilities. To meet sensitivity requirements, high-bandwidth digital systems were developed that process data at rates of 64 gigabit s−1, exceeding those of currently operating cm-wavelength VLBI arrays by more than an order of magnitude. Associated improvements include the development of phasing systems at array facilities, new receiver installation at several sites, and the deployment of hydrogen maser frequency standards to ensure coherent data capture across the array. These efforts led to the coordination and execution of the first Global EHT observations in 2017 April, and to event-horizon-scale imaging of the supermassive black hole candidate in M87."
MICHAEL L SMITH,First M87 Event Horizon Telescope results. I. The shadow of the supermassive black hole,"When surrounded by a transparent emission region, black holes are expected to reveal a dark shadow caused by gravitational light bending and photon capture at the event horizon. To image and study this phenomenon, we have assembled the Event Horizon Telescope, a global very long baseline interferometry array observing at a wavelength of 1.3 mm. This allows us to reconstruct event-horizon-scale images of the supermassive black hole candidate in the center of the giant elliptical galaxy M87. We have resolved the central compact radio source as an asymmetric bright emission ring with a diameter of 42 ± 3 μas, which is circular and encompasses a central depression in brightness with a flux ratio gsim10:1. The emission ring is recovered using different calibration and imaging schemes, with its diameter and width remaining stable over four different observations carried out in different days. Overall, the observed image is consistent with expectations for the shadow of a Kerr black hole as predicted by general relativity. The asymmetry in brightness in the ring can be explained in terms of relativistic beaming of the emission from a plasma rotating close to the speed of light around a black hole. We compare our images to an extensive library of ray-traced general-relativistic magnetohydrodynamic simulations of black holes and derive a central mass of M = (6.5 ± 0.7) × 10^9 M ⊙. Our radio-wave observations thus provide powerful evidence for the presence of supermassive black holes in centers of galaxies and as the central engines of active galactic nuclei. They also present a new tool to explore gravity in its most extreme limit and on a mass scale that was so far not accessible."
MICHAEL L SMITH,Using molecular mechanics to predict bulk material properties of fibronectin fibers,"The structural proteins of the extracellular matrix (ECM) form fibers with finely tuned mechanical properties matched to the time scales of cell traction forces. Several proteins such as fibronectin (Fn) and fibrin undergo molecular conformational changes that extend the proteins and are believed to be a major contributor to the extensibility of bulk fibers. The dynamics of these conformational changes have been thoroughly explored since the advent of single molecule force spectroscopy and molecular dynamics simulations but remarkably, these data have not been rigorously applied to the understanding of the time dependent mechanics of bulk ECM fibers. Using measurements of protein density within fibers, we have examined the influence of dynamic molecular conformational changes and the intermolecular arrangement of Fn within fibers on the bulk mechanical properties of Fn fibers. Fibers were simulated as molecular strands with architectures that promote either equal or disparate molecular loading under conditions of constant extension rate. Measurements of protein concentration within micron scale fibers using deep ultraviolet transmission microscopy allowed the simulations to be scaled appropriately for comparison to in vitro measurements of fiber mechanics as well as providing estimates of fiber porosity and water content, suggesting Fn fibers are approximately 75% solute. Comparing the properties predicted by single molecule measurements to in vitro measurements of Fn fibers showed that domain unfolding is sufficient to predict the high extensibility and nonlinear stiffness of Fn fibers with surprising accuracy, with disparately loaded fibers providing the best fit to experiment. This work shows the promise of this microstructural modeling approach for understanding Fn fiber properties, which is generally applicable to other ECM fibers, and could be further expanded to tissue scale by incorporating these simulated fibers into three dimensional network models."
MICHAEL L SMITH,"Silk-fibronectin protein alloy fibres support cell adhesion and viability as a high strength, matrix fibre analogue","Silk is a natural polymer with broad utility in biomedical applications because it exhibits general biocompatibility and high tensile material properties. While mechanical integrity is important for most biomaterial applications, proper function and integration also requires biomaterial incorporation into complex surrounding tissues for many physiologically relevant processes such as wound healing. In this study, we spin silk fibroin into a protein alloy fibre with whole fibronectin using wet spinning approaches in order to synergize their respective strength and cell interaction capabilities. Results demonstrate that silk fibroin alone is a poor adhesive surface for fibroblasts, endothelial cells, and vascular smooth muscle cells in the absence of serum. However, significantly improved cell attachment is observed to silk-fibronectin alloy fibres without serum present while not compromising the fibres' mechanical integrity. Additionally, cell viability is improved up to six fold on alloy fibres when serum is present while migration and spreading generally increase as well. These findings demonstrate the utility of composite protein alloys as inexpensive and effective means to create durable, biologically active biomaterials."
MICHAEL L SMITH,A reporting format for leaf-level gas exchange data and metadata,"Leaf-level gas exchange data support the mechanistic understanding of plant fluxes of carbon and water. These fluxes inform our understanding of ecosystem function, are an important constraint on parameterization of terrestrial biosphere models, are necessary to understand the response of plants to global environmental change, and are integral to efforts to improve crop production. Collection of these data using gas analyzers can be both technically challenging and time consuming, and individual studies generally focus on a small range of species, restricted time periods, or limited geographic regions. The high value of these data is exemplified by the many publications that reuse and synthesize gas exchange data, however the lack of metadata and data reporting conventions make full and efficient use of these data difficult. Here we propose a reporting format for leaf-level gas exchange data and metadata to provide guidance to data contributors on how to store data in repositories to maximize their discoverability, facilitate their efficient reuse, and add value to individual datasets. For data users, the reporting format will better allow data repositories to optimize data search and extraction, and more readily integrate similar data into harmonized synthesis products. The reporting format specifies data table variable naming and unit conventions, as well as metadata characterizing experimental conditions and protocols. For common data types that were the focus of this initial version of the reporting format, i.e., survey measurements, dark respiration, carbon dioxide and light response curves, and parameters derived from those measurements, we took a further step of defining required additional data and metadata that would maximize the potential reuse of those data types. To aid data contributors and the development of data ingest tools by data repositories we provided a translation table comparing the outputs of common gas exchange instruments. Extensive consultation with data collectors, data users, instrument manufacturers, and data scientists was undertaken in order to ensure that the reporting format met community needs. The reporting format presented here is intended to form a foundation for future development that will incorporate additional data types and variables as gas exchange systems and measurement approaches advance in the future. The reporting format is published in the U.S. Department of Energy's ESS-DIVE data repository, with documentation and future development efforts being maintained in a version control system."
MICHAEL L SMITH,Reproductive inequality in humans and other mammals,"To address claims of human exceptionalism, we determine where humans fit within the greater mammalian distribution of reproductive inequality. We show that humans exhibit lower reproductive skew (i.e., inequality in the number of surviving offspring) among males and smaller sex differences in reproductive skew than most other mammals, while nevertheless falling within the mammalian range. Additionally, female reproductive skew is higher in polygynous human populations than in polygynous nonhumans mammals on average. This patterning of skew can be attributed in part to the prevalence of monogamy in humans compared to the predominance of polygyny in nonhuman mammals, to the limited degree of polygyny in the human societies that practice it, and to the importance of unequally held rival resources to women's fitness. The muted reproductive inequality observed in humans appears to be linked to several unusual characteristics of our species-including high levels of cooperation among males, high dependence on unequally held rival resources, complementarities between maternal and paternal investment, as well as social and legal institutions that enforce monogamous norms."
MICHAEL L SMITH,The long-baseline neutrino experiment: exploring fundamental symmetries of the universe,"The preponderance of matter over antimatter in the early Universe, the dynamics of the supernova bursts that produced the heavy elements necessary for life and whether protons eventually decay --- these mysteries at the forefront of particle physics and astrophysics are key to understanding the early evolution of our Universe, its current state and its eventual fate. The Long-Baseline Neutrino Experiment (LBNE) represents an extensively developed plan for a world-class experiment dedicated to addressing these questions. LBNE is conceived around three central components: (1) a new, high-intensity neutrino source generated from a megawatt-class proton accelerator at Fermi National Accelerator Laboratory, (2) a near neutrino detector just downstream of the source, and (3) a massive liquid argon time-projection chamber deployed as a far detector deep underground at the Sanford Underground Research Facility. This facility, located at the site of the former Homestake Mine in Lead, South Dakota, is approximately 1,300 km from the neutrino source at Fermilab -- a distance (baseline) that delivers optimal sensitivity to neutrino charge-parity symmetry violation and mass ordering effects. This ambitious yet cost-effective design incorporates scalability and flexibility and can accommodate a variety of upgrades and contributions. With its exceptional combination of experimental configuration, technical capabilities, and potential for transformative discoveries, LBNE promises to be a vital facility for the field of particle physics worldwide, providing physicists from around the globe with opportunities to collaborate in a twenty to thirty year program of exciting science. In this document we provide a comprehensive overview of LBNE's scientific objectives, its place in the landscape of neutrino physics worldwide, the technologies it will incorporate and the capabilities it will possess."
JEAN M FRANCIS,"BMQ : Boston medical quarterly: v. 6, no. 1-4",
JEAN M FRANCIS,"Towards minimally-invasive, quantitative assessment of chronic kidney disease using optical spectroscopy","The universal pathologic features implicated in the progression of chronic kidney disease (CKD) are interstitial fibrosis and tubular atrophy (IFTA). Current methods of estimating IFTA are slow, labor-intensive and fraught with variability and sampling error, and are not quantitative. As such, there is pressing clinical need for a less-invasive and faster method that can quantitatively assess the degree of IFTA. We propose a minimally-invasive optical method to assess the macro-architecture of kidney tissue, as an objective, quantitative assessment of IFTA, as an indicator of the degree of kidney disease. The method of elastic-scattering spectroscopy (ESS) measures backscattered light over the spectral range 320-900 nm and is highly sensitive to micromorphological changes in tissues. Using two discrete mouse models of CKD, we observed spectral trends of increased scattering intensity in the near-UV to short-visible region (350-450 nm), relative to longer wavelengths, for fibrotic kidneys compared to normal kidney, with a quasi-linear correlation between the ESS changes and the histopathology-determined degree of IFTA. These results suggest the potential of ESS as an objective, quantitative and faster assessment of IFTA for the management of CKD patients and in the allocation of organs for kidney transplantation."
KEVIN CHANG,Intoxication and pitch control in tonal and non-tonal language speakers,"Alcohol intoxication is known to affect pitch variability in non-tonal languages. In this study, intoxication's effects on pitch were examined in tonal and non-tonal language speakers, in both their native language (L1; German, Korean, Mandarin) and nonnative language (L2; English). Intoxication significantly increased pitch variability in the German group (in L1 and L2), but not in the Korean or Mandarin groups (in L1 or L2), although there were individual differences. These results support the view that pitch control is related to the functional load of pitch and is an aspect of speech production that can be advantageously transferred across languages, overriding the expected effects of alcohol."
KEVIN CHANG,COMBREX: A Project to Accelerate the Functional Annotation of Prokaryotic Genomes,COMBREX (http://combrex.bu.edu) is a project to increase the speed of the functional annotation of new bacterial and archaeal genomes. It consists of a database of functional predictions produced by computational biologists and a mechanism for experimental biochemists to bid for the validation of those predictions. Small grants are available to support successful bids.
KEVIN CHANG,Event Horizon Telescope imaging of the archetypal blazar 3C 279 at an extreme 20 microarcsecond resolution,"3C 279 is an archetypal blazar with a prominent radio jet that show broadband flux density variability across the entire electromagnetic spectrum. We use an ultra-high angular resolution technique – global Very Long Baseline Interferometry (VLBI) at 1.3 mm (230 GHz) – to resolve the innermost jet of 3C 279 in order to study its fine-scale morphology close to the jet base where highly variable γ-ray emission is thought to originate, according to various models. The source was observed during four days in April 2017 with the Event Horizon Telescope at 230 GHz, including the phased Atacama Large Millimeter/submillimeter Array (ALMA), at an angular resolution of ∼20 μas (at a redshift of z = 0.536 this corresponds to ∼0.13 pc  ∼ 1700 Schwarzschild radii with a black hole mass M<jats:sub>BH</jats:sub> = 8 × 10^8 M_⊙). Imaging and model-fitting techniques were applied to the data to parameterize the fine-scale source structure and its variation. We find a multicomponent inner jet morphology with the northernmost component elongated perpendicular to the direction of the jet, as imaged at longer wavelengths. The elongated nuclear structure is consistent on all four observing days and across different imaging methods and model-fitting techniques, and therefore appears robust. Owing to its compactness and brightness, we associate the northern nuclear structure as the VLBI “core”. This morphology can be interpreted as either a broad resolved jet base or a spatially bent jet. We also find significant day-to-day variations in the closure phases, which appear most pronounced on the triangles with the longest baselines. Our analysis shows that this variation is related to a systematic change of the source structure. Two inner jet components move non-radially at apparent speeds of ∼15 c and ∼20 c (∼1.3 and ∼1.7 μas day^−1, respectively), which more strongly supports the scenario of traveling shocks or instabilities in a bent, possibly rotating jet. The observed apparent speeds are also coincident with the 3C 279 large-scale jet kinematics observed at longer (cm) wavelengths, suggesting no significant jet acceleration between the 1.3 mm core and the outer jet. The intrinsic brightness temperature of the jet components are ≲10^10 K, a magnitude or more lower than typical values seen at ≥7 mm wavelengths. The low brightness temperature and morphological complexity suggest that the core region of 3C 279 becomes optically thin at short (mm) wavelengths."
KEVIN CHANG,First M87 Event Horizon Telescope results. II. Array and instrumentation,"The Event Horizon Telescope (EHT) is a very long baseline interferometry (VLBI) array that comprises millimeter- and submillimeter-wavelength telescopes separated by distances comparable to the diameter of the Earth. At a nominal operating wavelength of ~1.3 mm, EHT angular resolution (λ/D) is ~25 μas, which is sufficient to resolve nearby supermassive black hole candidates on spatial and temporal scales that correspond to their event horizons. With this capability, the EHT scientific goals are to probe general relativistic effects in the strong-field regime and to study accretion and relativistic jet formation near the black hole boundary. In this Letter we describe the system design of the EHT, detail the technology and instrumentation that enable observations, and provide measures of its performance. Meeting the EHT science objectives has required several key developments that have facilitated the robust extension of the VLBI technique to EHT observing wavelengths and the production of instrumentation that can be deployed on a heterogeneous array of existing telescopes and facilities. To meet sensitivity requirements, high-bandwidth digital systems were developed that process data at rates of 64 gigabit s−1, exceeding those of currently operating cm-wavelength VLBI arrays by more than an order of magnitude. Associated improvements include the development of phasing systems at array facilities, new receiver installation at several sites, and the deployment of hydrogen maser frequency standards to ensure coherent data capture across the array. These efforts led to the coordination and execution of the first Global EHT observations in 2017 April, and to event-horizon-scale imaging of the supermassive black hole candidate in M87."
KEVIN CHANG,First M87 Event Horizon Telescope results. I. The shadow of the supermassive black hole,"When surrounded by a transparent emission region, black holes are expected to reveal a dark shadow caused by gravitational light bending and photon capture at the event horizon. To image and study this phenomenon, we have assembled the Event Horizon Telescope, a global very long baseline interferometry array observing at a wavelength of 1.3 mm. This allows us to reconstruct event-horizon-scale images of the supermassive black hole candidate in the center of the giant elliptical galaxy M87. We have resolved the central compact radio source as an asymmetric bright emission ring with a diameter of 42 ± 3 μas, which is circular and encompasses a central depression in brightness with a flux ratio gsim10:1. The emission ring is recovered using different calibration and imaging schemes, with its diameter and width remaining stable over four different observations carried out in different days. Overall, the observed image is consistent with expectations for the shadow of a Kerr black hole as predicted by general relativity. The asymmetry in brightness in the ring can be explained in terms of relativistic beaming of the emission from a plasma rotating close to the speed of light around a black hole. We compare our images to an extensive library of ray-traced general-relativistic magnetohydrodynamic simulations of black holes and derive a central mass of M = (6.5 ± 0.7) × 10^9 M ⊙. Our radio-wave observations thus provide powerful evidence for the presence of supermassive black holes in centers of galaxies and as the central engines of active galactic nuclei. They also present a new tool to explore gravity in its most extreme limit and on a mass scale that was so far not accessible."
KEVIN CHANG,First Sagittarius A* Event Horizon Telescope results. I. The shadow of the supermassive black hole in the center of the Milky Way,"We present the first Event Horizon Telescope (EHT) observations of Sagittarius A* (Sgr A*), the Galactic center source associated with a supermassive black hole. These observations were conducted in 2017 using a global interferometric array of eight telescopes operating at a wavelength of λ = 1.3 mm. The EHT data resolve a compact emission region with intrahour variability. A variety of imaging and modeling analyses all support an image that is dominated by a bright, thick ring with a diameter of 51.8 ± 2.3 μas (68% credible interval). The ring has modest azimuthal brightness asymmetry and a comparatively dim interior. Using a large suite of numerical simulations, we demonstrate that the EHT images of Sgr A* are consistent with the expected appearance of a Kerr black hole with mass ∼4 × 106 M ⊙, which is inferred to exist at this location based on previous infrared observations of individual stellar orbits, as well as maser proper-motion studies. Our model comparisons disfavor scenarios where the black hole is viewed at high inclination (i &gt; 50°), as well as nonspinning black holes and those with retrograde accretion disks. Our results provide direct evidence for the presence of a supermassive black hole at the center of the Milky Way, and for the first time we connect the predictions from dynamical measurements of stellar orbits on scales of 103–105 gravitational radii to event-horizon-scale images and variability. Furthermore, a comparison with the EHT results for the supermassive black hole M87* shows consistency with the predictions of general relativity spanning over three orders of magnitude in central mass."
KEVIN CHANG,COMBREX: a project to accelerate the functional annotation of prokaryotic genomes,COMBREX (http://combrex.bu.edu) is a project to increase the speed of the functional annotation of new bacterial and archaeal genomes. It consists of a database of functional predictions produced by computational biologists and a mechanism for experimental biochemists to bid for the validation of those predictions. Small grants are available to support successful bids.
DAVID P NUNES,"Cosmology intertwined: a review of the particle physics, astrophysics, and cosmology associated with the cosmological tensions and anomalies",
DAVID P NUNES,Scintillation light detection in the 6-m drift-length ProtoDUNE Dual Phase liquid argon TPC,"DUNE is a dual-site experiment for long-baseline neutrino oscillation studies, neutrino astrophysics and nucleon decay searches. ProtoDUNE Dual Phase (DP) is a 6  ×  6  ×  6 m 3 liquid argon time-projection-chamber (LArTPC) that recorded cosmic-muon data at the CERN Neutrino Platform in 2019-2020 as a prototype of the DUNE Far Detector. Charged particles propagating through the LArTPC produce ionization and scintillation light. The scintillation light signal in these detectors can provide the trigger for non-beam events. In addition, it adds precise timing capabilities and improves the calorimetry measurements. In ProtoDUNE-DP, scintillation and electroluminescence light produced by cosmic muons in the LArTPC is collected by photomultiplier tubes placed up to 7 m away from the ionizing track. In this paper, the ProtoDUNE-DP photon detection system performance is evaluated with a particular focus on the different wavelength shifters, such as PEN and TPB, and the use of Xe-doped LAr, considering its future use in giant LArTPCs. The scintillation light production and propagation processes are analyzed and a comparison of simulation to data is performed, improving understanding of the liquid argon properties."
DAVID P NUNES,Prospects for beyond the standard model physics searches at the deep underground neutrino experiment: DUNE collaboration,"The Deep Underground Neutrino Experiment (DUNE) will be a powerful tool for a variety of physics topics. The high-intensity proton beams provide a large neutrino flux, sampled by a near detector system consisting of a combination of capable precision detectors, and by the massive far detector system located deep underground. This configuration sets up DUNE as a machine for discovery, as it enables opportunities not only to perform precision neutrino measurements that may uncover deviations from the present three-flavor mixing paradigm, but also to discover new particles and unveil new interactions and symmetries beyond those predicted in the Standard Model (SM). Of the many potential beyond the Standard Model (BSM) topics DUNE will probe, this paper presents a selection of studies quantifying DUNE's sensitivities to sterile neutrino mixing, heavy neutral leptons, non-standard interactions, CPT symmetry violation, Lorentz invariance violation, neutrino trident production, dark matter from both beam induced and cosmogenic sources, baryon number violation, and other new physics topics that complement those at high-energy colliders and significantly extend the present reach."
DAVID P NUNES,Identification and reconstruction of low-energy electrons in the ProtoDUNE-SP detector,
SIU CHEONG LAU,"Gross fibration, SYZ mirror symmetry, and open Gromov-Witten invariants for toric Calabi-Yau orbifolds","Given a toric Calabi-Yau orbifold X, we define and study a non-toric Lagrangian torus fibration on X, which we call the Gross fibration. We apply the SYZ recipe to a suitable modification of the Gross fibration of X to construct an instanton-corrected mirror of X. To further study the instanton corrections, we explicitly evaluate all relevant open Gromov- Witten invariants of X via an open/closed equality and mirror theorem for toric orbifolds. We apply our calculations to study relations between open Gromov-Witten invariants and periods of the mirror, and to prove a result on how open Gromov-Witten invariants change under toric crepant resolutions."
SIU CHEONG LAU,Localized mirror functor constructed from a Lagrangian torus,"Fixing a weakly unobstructed Lagrangian torus in a symplectic manifold 𝘟, we define a holomorphic function 𝘞 known as the Floer potential. We construct a canonical 𝑨∞ -functor from the Fukaya category of 𝘟 to the category of matrix factorizations of 𝘞. It provides a unified way to construct matrix factorizations from Lagrangian Floer theory. The technique is applied to toric Fano manifolds to transform Lagrangian branes to matrix factorizations and prove homological mirror symmetry. Using the method, we also obtain an explicit expression of the matrix factorization mirror to the real locus of the complex projective space."
SIU CHEONG LAU,Lagrangian Floer potential of orbifold spheres,"For each sphere with three orbifold points, we construct an algorithm to compute the open Gromov–Witten potential, which serves as the quantum-corrected Landau–Ginzburg mirror and is an infinite series in general. This gives the first class of general-type geometries whose full potentials can be computed. As a consequence we obtain an enumerative meaning of mirror maps for elliptic curve quotients. Furthermore, we prove that the open Gromov–Witten potential is convergent, even in the general-type cases, and has an isolated singularity at the origin, which is an important ingredient of proving homological mirror symmetry."
SIU CHEONG LAU,Mirror of Atiyah flop in symplectic geometry and stability conditions,We study the mirror operation of the Atiyah flop in symplectic geometry. We formulate the operation for a symplectic manifold with a Lagrangian fibration. Furthermore we construct geometric stability conditions on the derived Fukaya category of the deformed conifold and study the action of the mirror Atiyah flop on these stability conditions.
SIU CHEONG LAU,Generalized SYZ mirror transformation,"Strominger-Yau-Zaslow proposed that mirror symmetry can be understood by torus duality. In this article we explain how it fits into a bigger framework, where tori are replaced by general Lagrangian immersions. The generalized construction is applicable to a wider class of geometries. We also give a brief introduction to our ongoing work on gluing local mirrors into global geometries."
SIU CHEONG LAU,Quantum corrections and wall-crossing via Lagrangian intersections,"This article introduces the past and ongoing works on quantum corrections in SYZ from the author’s perspective. It emphasizes on a method of gluing local pieces of mirrors using isomorphisms between immersed Lagrangians, which is an ongoing joint work with Cho and Hong. It gives a canonical construction of mirrors and generalizes the SYZ setting."
SIU CHEONG LAU,Geometric transitions and SYZ mirror symmetry,"We prove that generalized conifolds and orbifolded conifolds are mirror symmetric under the SYZ program with quantum corrections. Our work mathematically confirms the gauge-theoretic assertion of Aganagic–Karch–Lüst–Miemiec, and also provides a supportive evidence to Morrison’s conjecture that geometric transitions are reversed under mirror symmetry."
SIU CHEONG LAU,"Open Gromov–Witten invariants, mirror maps, and Seidel representations for toric manifolds","Let X be a compact toric Kähler manifold with −KX nef. Let L⊂X be a regular fiber of the moment map of the Hamiltonian torus action on X. Fukaya, Oh, Ohta, and Ono defined open Gromov–Witten (GW) invariants of X as virtual counts of holomorphic disks with Lagrangian boundary condition L. We prove a formula that equates such open GW invariants with closed GW invariants of certain X-bundles over ℙ1 used by Seidel and McDuff earlier to construct Seidel representations for X. We apply this formula and degeneration techniques to explicitly calculate all these open GW invariants. This yields a formula for the disk potential of X, an enumerative meaning of mirror maps, and a description of the inverse of the ring isomorphism of Fukaya, Oh, Ohta, and Ono."
SIU CHEONG LAU,Open Gromov–Witten invariants and mirror maps for semi-Fano toric manifolds,"We prove that for a compact toric manifold whose anticanonical divisor is numerically effective, the Lagrangian Floer superpotential defined by Fukaya–Oh–Ohto–Ono [15] is equal to the superpotential written down by using the toric mirror map under a convergence assumption. This gives a method to compute open Gromov–Witten invariants using mirror symmetry."
SIU CHEONG LAU,SYZ mirror symmetry for hypertoric varieties,We construct a Lagrangian torus fibration on a smooth hypertoric variety and a corresponding SYZ mirror variety using T-duality and generating functions of open Gromov–Witten invariants. The variety is singular in general. We construct a resolution of the variety using the wall and chamber structure on the base of the SYZ fibration.
SIU CHEONG LAU,SYZ mirror symmetry for del Pezzo surfaces and affine structures,
SIU CHEONG LAU,Kaehler geometry of quiver varieties and machine learning,"We develop an algebro-geometric formulation for neural networks in machine learning using the moduli space of framed quiver representations. We find natural Hermitian metrics on the universal bundles over the moduli which are compatible with the GIT quotient construction by the general linear group, and show that their Ricci curvatures give a Kahler metric on the moduli. Moreover, we use toric moment maps to construct activation functions, and prove the universal approximation theorem for the multi-variable activation function constructed from the complex projective space."
SIU CHEONG LAU,Moduli of Lagrangian immersions with formal deformations,"We introduce a joint project with Cheol-Hyun Cho on the construction of quantum-corrected moduli of Lagrangian immersions. The construction has important applications to mirror symmetry for pair-of-pants decompositions, SYZ and wall-crossing. The key ingredient is Floer-theoretical gluing between local moduli spaces of Lagrangians with different topologies."
CHRISTOPHER B BROWN,"Canvass: a crowd-sourced, natural-product screening library for exploring biological space",
CHRISTOPHER B BROWN,Thoracolumbar Injury Classification and Severity Score: A New Paradigm for the Treatment of Thoracolumbar Spine Trauma,"BACKGROUND Contemporary understanding of the biomechanics, natural history, and methods of treating thoracolumbar spine injuries continues to evolve. Current classification schemes of these injuries, however, can be either too simplified or overly complex for clinical use. METHODS The Spine Trauma Group was given a survey to identify similarities in treatment algorithms for common thoracolumbar injuries, as well as to identify characteristics of injury that played a key role in the decision-making process. RESULTS Based on the survey, the Spine Trauma Group has developed a classification system and an injury severity score (thoracolumbar injury classification and severity score, or TLICS), which may facilitate communication between physicians and serve as a guideline for treating these injuries. The classification system is based on the morphology of the injury, integrity of the posterior ligamentous complex, and neurological status of the patient. Points are assigned for each category, and the final total points suggest a possible treatment option. CONCLUSIONS The usefulness of this new system will have to be proven in future studies investigating inter- and intraobserver reliability, as well as long-term outcome studies for operative and nonoperative treatment methods."
CHRISTOPHER B BROWN,Priorities for synthesis research in ecology and environmental science,
CHRISTOPHER B BROWN,Evaluation of association of HNF1B variants with diverse cancers: collaborative analysis of data from 19 genome-wide association studies,"BACKGROUND. Genome-wide association studies have found type 2 diabetes-associated variants in the HNF1B gene to exhibit reciprocal associations with prostate cancer risk. We aimed to identify whether these variants may have an effect on cancer risk in general versus a specific effect on prostate cancer only. METHODOLOGY/PRINCIPAL FINDINGS. In a collaborative analysis, we collected data from GWAS of cancer phenotypes for the frequently reported variants of HNF1B, rs4430796 and rs7501939, which are in linkage disequilibrium (r2=0.76, HapMap CEU). Overall, the analysis included 16 datasets on rs4430796 with 19,640 cancer cases and 21,929 controls; and 21 datasets on rs7501939 with 26,923 cases and 49,085 controls. Malignancies other than prostate cancer included colorectal, breast, lung and pancreatic cancers, and melanoma. Meta-analysis showed large between-dataset heterogeneity that was driven by different effects in prostate cancer and other cancers. The per-T2D-risk-allele odds ratios (95% confidence intervals) for rs4430796 were 0.79 (0.76, 0.83)] per G allele for prostate cancer (p<10-15 for both); and 1.03 (0.99, 1.07) for all other cancers. Similarly for rs7501939 the per-T2D-risk-allele odds ratios (95% confidence intervals) were 0.80 (0.77, 0.83) per T allele for prostate cancer (p<10-15 for both); and 1.00 (0.97, 1.04) for all other cancers. No malignancy other than prostate cancer had a nominally statistically significant association. CONCLUSIONS/SIGNIFICANCE. The examined HNF1B variants have a highly specific effect on prostate cancer risk with no apparent association with any of the other studied cancer types."
CHRISTOPHER B BROWN,"Bostonia: 2003-2004, no. 1-4",
CHRISTOPHER B BROWN,The long-baseline neutrino experiment: exploring fundamental symmetries of the universe,"The preponderance of matter over antimatter in the early Universe, the dynamics of the supernova bursts that produced the heavy elements necessary for life and whether protons eventually decay --- these mysteries at the forefront of particle physics and astrophysics are key to understanding the early evolution of our Universe, its current state and its eventual fate. The Long-Baseline Neutrino Experiment (LBNE) represents an extensively developed plan for a world-class experiment dedicated to addressing these questions. LBNE is conceived around three central components: (1) a new, high-intensity neutrino source generated from a megawatt-class proton accelerator at Fermi National Accelerator Laboratory, (2) a near neutrino detector just downstream of the source, and (3) a massive liquid argon time-projection chamber deployed as a far detector deep underground at the Sanford Underground Research Facility. This facility, located at the site of the former Homestake Mine in Lead, South Dakota, is approximately 1,300 km from the neutrino source at Fermilab -- a distance (baseline) that delivers optimal sensitivity to neutrino charge-parity symmetry violation and mass ordering effects. This ambitious yet cost-effective design incorporates scalability and flexibility and can accommodate a variety of upgrades and contributions. With its exceptional combination of experimental configuration, technical capabilities, and potential for transformative discoveries, LBNE promises to be a vital facility for the field of particle physics worldwide, providing physicists from around the globe with opportunities to collaborate in a twenty to thirty year program of exciting science. In this document we provide a comprehensive overview of LBNE's scientific objectives, its place in the landscape of neutrino physics worldwide, the technologies it will incorporate and the capabilities it will possess."
MILLARD BAUBLITZ,Cosmic visions: bridging science and art,"Since the dawn of recorded history, stargazing has shaped—and been shaped by—our understanding of the universe and the place of humans within it. Though we tend to conceptualize art and science as separate spheres, the observation of the heavens has always been interwoven with culture, and artists and astronomers continue to draw inspiration from one another even today. The authors of this paper, over the past few years, have developed and team-taught an interdisciplinary course titled Cosmic Visions: The Science of Astronomy and the Arts. Our course traces the shared, often symbiotic, history of these two ways of knowing, combining scientific instruction with examination of art in a range of genres and traditions, including visual art, music, and theater. Each week students engage in discussions, listen to lectures, and consider readings related to both the science of astronomy and the role of celestial objects in literature and the arts. A midterm and a final exam test students’ mastery of the science, while short essays on works of art and literature challenge them to think about how our changing understanding of heavenly bodies intersects with changing beliefs about humanity. The course culminates in an art project in which students express their own vision of the cosmos and our place within it. What happens when students employ humanistic modes of analysis in company with scientific ones? How does artistic expression change students’ apprehension of scientific concepts? This short essay offers preliminary answers to these deep pedagogical questions."
MILLARD BAUBLITZ,"IMPACT: The Journal of the Center for Interdisciplinary Teaching and Learning. Volume 10, Issue 2, Summer 2021","The theme of this issue is interdisciplinary approaches to, or including, the sciences. STEM disciplines like chemistry, biology, physics, computer science, and math are often taught as separate and distinct from the humanities. The concept of STEAM (STEM + Arts) has attempted to make STEM subjects more interdisciplinary, allowing students to interact with the material from different perspectives. The essays in this issue explore unique ways to design and implement interdisciplinary curricula that combine sciences and humanities/arts."
SAIDA GRUNDY,Allyship in the time of aggrievement: the case of Black Feminism and the New Black masculinities,"In 2019, Vox reporter Jane Coaston announced that intersectionality—or the idea of mutually reinforcing systems of oppression—might be most hated word in American conservatism. Even self-identified liberals have made their contempt for feminist theory and intersectionality known in their attacks on “grievance studies”. Black male aggrievement, and antagonism between black feminism and New Black Masculinities (NBM), has been nurtured by a neoliberal academy that delegitimizes critical scholarship and takes delight in conflict between progressive movements. While NBM is new in name, it relies on an old formula: a progressive anti-racist agenda anchored in an anti-feminist, conservative gender politics—Black male aggrievement. The legal roots of “aggrievement” help emphasize how NBM advocates make a claim to injury at hands of black feminism and black women scholars. Neoliberal ideologies built on divisiveness, competition over scarce resources, and a post-race and post-feminist worldview have fed gender conservative, cis-normative and zero-sum politics of Black male aggrievement. NBM, therefore, has been seduced by neoliberal project."
SAIDA GRUNDY,Gendering social justice capitalism: politics and paradox in the practice of black male success initiatives,
SAIDA GRUNDY,"Lifting the veil on campus sexual assault: Morehouse college, hegemonic masculinity, and revealing racialized rape culture through the Du Boisian lens","As national rates of sexual assault continue to fall, sexual assault rates for colleges and universities have remained stagnate. Subsequent focusses on campus sexual assault have continued to press a simple question: what about sexual assault on college campuses is so different that rates are not declining with the nation? A longstanding approach in the literature has turned to the contexts in which college men “do” rape culture. How men are racialized is a critically missing context in our understandings of campus gender violence. Race is one of the most pronounced ways that college men see themselves and their interactions, and yet it is grossly overlooked in extant literature. Researchers have missed an opportunity to apply race theories to college men, and thus unveil how college men’s rape cultures operate as racialized rape cultures. By interviewing 32 graduates of Morehouse College, the nation’s only historically Black college for men and a campus rife with high-profile sexual misconduct, this study finds that race is a modality through which men make meanings of masculinity, sex, women competition, and the repercussions of sexual assault in ways that perpetuate assaults on their campus. Through a Du Boisian lens of double consciousness, (in which racialized men think about themselves through the lens of the White gaze) this paper finds that rape culture is not only how these men do gender, but it is a formative means by which they do race and are racialized throughout their college experience."
XIAOLING ZHANG,Bulk brain tissue cell-type deconvolution with bias correction for single-nuclei RNA sequencing data using DeTREM,"BACKGROUND: Quantifying cell-type abundance in bulk tissue RNA-sequencing enables researchers to better understand complex systems. Newer deconvolution methodologies, such as MuSiC, use cell-type signatures derived from single-cell RNA-sequencing (scRNA-seq) data to make these calculations. Single-nuclei RNA-sequencing (snRNA-seq) reference data can be used instead of scRNA-seq data for tissues such as human brain where single-cell data are difficult to obtain, but accuracy suffers due to sequencing differences between the technologies. RESULTS: We propose a modification to MuSiC entitled 'DeTREM' which compensates for sequencing differences between the cell-type signature and bulk RNA-seq datasets in order to better predict cell-type fractions. We show DeTREM to be more accurate than MuSiC in simulated and real human brain bulk RNA-sequencing datasets with various cell-type abundance estimates. We also compare DeTREM to SCDC and CIBERSORTx, two recent deconvolution methods that use scRNA-seq cell-type signatures. We find that they perform well in simulated data but produce less accurate results than DeTREM when used to deconvolute human brain data. CONCLUSION: DeTREM improves the deconvolution accuracy of MuSiC and outperforms other deconvolution methods when applied to snRNA-seq data. DeTREM enables accurate cell-type deconvolution in situations where scRNA-seq data are not available. This modification improves characterization cell-type specific effects in brain tissue and identification of cell-type abundance differences under various conditions."
JUAN FUXMAN BASS,Global landscape of mouse and human cytokine transcriptional regulation,"Cytokines are cell-to-cell signaling proteins that play a central role in immune development, pathogen responses, and diseases. Cytokines are highly regulated at the transcriptional level by combinations of transcription factors (TFs) that recruit cofactors and the transcriptional machinery. Here, we mined through three decades of studies to generate a comprehensive database, CytReg, reporting 843 and 647 interactions between TFs and cytokine genes, in human and mouse respectively. By integrating CytReg with other functional datasets, we determined general principles governing the transcriptional regulation of cytokine genes. In particular, we show a correlation between TF connectivity and immune phenotype and disease, we discuss the balance between tissue-specific and pathogen-activated TFs regulating each cytokine gene, and cooperativity and plasticity in cytokine regulation. We also illustrate the use of our database as a blueprint to predict TF–disease associations and identify potential TF–cytokine regulatory axes in autoimmune diseases. Finally, we discuss research biases in cytokine regulation studies, and use CytReg to predict novel interactions based on co-expression and motif analyses which we further validated experimentally. Overall, this resource provides a framework for the rational design of future cytokine gene regulation studies."
JUAN FUXMAN BASS,Identification of single nucleotide non-coding driver mutations in cancer,"Recent whole-genome sequencing studies have identified millions of somatic variants present in tumor samples. Most of these variants reside in non-coding regions of the genome potentially affecting transcriptional and post-transcriptional gene regulation. Although a few hallmark examples of driver mutations in non-coding regions have been reported, the functional role of the vast majority of somatic non-coding variants remains to be determined. This is because the few driver variants in each sample must be distinguished from the thousands of passenger variants and because the logic of regulatory element function has not yet been fully elucidated. Thus, variants prioritized based on mutational burden and location within regulatory elements need to be validated experimentally. This is generally achieved by combining assays that measure physical binding, such as chromatin immunoprecipitation, with those that determine regulatory activity, such as luciferase reporter assays. Here, we present an overview of in silico approaches used to prioritize somatic non-coding variants and the experimental methods used for functional validation and characterization."
JUAN FUXMAN BASS,Transcription factor binding to Caenorhabditis elegans first introns reveals lack of redundancy with gene promoters,"Gene expression is controlled through the binding of transcription factors (TFs) to regulatory genomic regions. First introns are longer than other introns in multiple eukaryotic species and are under selective constraint. Here we explore the importance of first introns in TF binding in the nematode Caenorhabditis elegans by combining computational predictions and experimentally derived TF-DNA interaction data. We found that first introns of C. elegans genes, particularly those for families enriched in long first introns, are more conserved in length, have more conserved predicted TF interactions and are bound by more TFs than other introns. We detected a significant positive correlation between first intron size and the number of TF interactions obtained from chromatin immunoprecipitation assays or determined by yeast one-hybrid assays. TFs that bind first introns are largely different from those binding promoters, suggesting that the different interactions are complementary rather than redundant. By combining first intron and promoter interactions, we found that genes that share a large fraction of TF interactions are more likely to be co-expressed than when only TF interactions with promoters are considered. Altogether, our data suggest that C. elegans gene regulation may be additive through the combined effects of multiple regulatory regions."
JUAN FUXMAN BASS,Mapping and analysis of Caenorhabditis elegans transcription factor sequence specificities,"Caenorhabditis elegans is a powerful model for studying gene regulation, as it has a compact genome and a wealth of genomic tools. However, identification of regulatory elements has been limited, as DNA-binding motifs are known for only 71 of the estimated 763 sequencespecific transcription factors (TFs). To address this problem, we performed protein binding microarray experiments on representatives of canonical TF families in C. elegans, obtaining motifs for 129 TFs. Additionally, we predict motifs for many TFs that have DNA-binding domains similar to those already characterized, increasing coverage of binding specificities to 292 C. elegans TFs (∼40%). These data highlight the diversification of binding motifs for the nuclear hormone receptor and C2H2 zinc finger families and reveal unexpected diversity of motifs for T-box and DM families. Motif enrichment in promoters of functionally related genes is consistent with known biology and also identifies putative regulatory roles for unstudied TFs."
JUAN FUXMAN BASS,Epitope-Evaluator: an interactive web application to study predicted T-cell epitopes,"Multiple immunoinformatic tools have been developed to predict T-cell epitopes from protein amino acid sequences for different major histocompatibility complex (MHC) alleles. These prediction tools output hundreds of potential peptide candidates which require further processing; however, these tools are either not graphical or not friendly for non-programming users. We present Epitope-Evaluator, a web tool developed in the Shiny/R framework to interactively analyze predicted T-cell epitopes. Epitope-Evaluator contains six tools providing the distribution of epitopes across a selected set of MHC alleles, the promiscuity and conservation of epitopes, and their density and location within antigens. Epitope-Evaluator requires as input the fasta file of protein sequences and the output prediction file coming out from any predictor. By choosing different cutoffs and parameters, users can produce several interactive plots and tables that can be downloaded as JPG and text files, respectively. Using Epitope-Evaluator, we found the HLA-B*40, HLA-B*27:05 and HLA-B*07:02 recognized fewer epitopes from the SARS-CoV-2 proteome than other MHC Class I alleles. We also identified shared epitopes between Delta, Omicron, and Wuhan Spike variants as well as variant-specific epitopes. In summary, Epitope-Evaluator removes the programming barrier and provides intuitive tools, allowing a straightforward interpretation and graphical representations that facilitate the selection of candidate epitopes for experimental evaluation. The web server Epitope-Evaluator is available at https://fuxmanlab.shinyapps.io/Epitope-Evaluator."
JUAN FUXMAN BASS,A gene‐centered C. elegans protein–DNA interaction network provides a framework for functional predictions,"Transcription factors (TFs) play a central role in controlling spatiotemporal gene expression and the response to environmental cues. A comprehensive understanding of gene regulation requires integrating physical protein–DNA interactions (PDIs) with TF regulatory activity, expression patterns, and phenotypic data. Although great progress has been made in mapping PDIs using chromatin immunoprecipitation, these studies have only characterized ~10% of TFs in any metazoan species. The nematode C. elegans has been widely used to study gene regulation due to its compact genome with short regulatory sequences. Here, we delineated the largest gene‐centered metazoan PDI network to date by examining interactions between 90% of C. elegans TFs and 15% of gene promoters. We used this network as a backbone to predict TF binding sites for 77 TFs, two‐thirds of which are novel, as well as integrate gene expression, protein–protein interaction, and phenotypic data to predict regulatory and biological functions for multiple genes and TFs."
JUAN FUXMAN BASS,Enhanced yeast one-hybrid screens to identify transcription factor binding to human DNA sequences,"Identifying the sets of transcription factors (TFs) that regulate each human gene is a daunting task that requires integrating numerous experimental and computational approaches. One such method is the yeast one-hybrid (Y1H) assay, in which interactions between TFs and DNA regions are tested in the milieu of the yeast nucleus using reporter genes. Y1H assays involve two components: a 'DNA-bait' (e.g., promoters, enhancers, silencers, etc.) and a 'TF-prey,' which can be screened for reporter gene activation. Most published protocols for performing Y1H screens are based on transforming TF-prey libraries or arrays into DNA-bait yeast strains. Here, we describe a pipeline, called enhanced Y1H (eY1H) assays, where TF-DNA interactions are interrogated by mating DNA-bait strains with an arrayed collection of TF-prey strains using a high density array (HDA) robotic platform that allows screening in a 1,536 colony format. This allows for a dramatic increase in throughput (60 DNA-bait sequences against >1,000 TFs takes two weeks per researcher) and reproducibility. We illustrate the different types of expected results by testing human promoter sequences against an array of 1,086 human TFs, as well as examples of issues that can arise during screens and how to troubleshoot them."
JUAN FUXMAN BASS,"Uncovering human transcription factor interactions associated with genetic variants, novel DNA motifs, and repetitive elements using enhanced yeast one-hybrid assays","Identifying transcription factor (TF) binding to noncoding variants, uncharacterized DNA motifs, and repetitive genomic elements has been difficult due to technical and computational challenges. Indeed, current experimental methods such as chromatin immunoprecipitation are capable of only testing one TF at a time and motif prediction algorithms often lead to false positive and false negative predictions. Here, we address these limitations by developing two approaches based on enhanced yeast one-hybrid assays. The first approach allows to interrogate the binding of >1,000 human TFs to single nucleotide variant alleles, short insertions and deletions (indels), and novel DNA motifs; while the second approach allows for the identification of TFs that bind to repetitive DNA elements. Using the former approach, we identified gain of TF interactions to a GG→AA mutation in the TERT promoter and an 18 bp indel in the TAL1 super-enhancer, both of which are associated with cancer, and identified the TFs that bind to three uncharacterized DNA motifs identified by the ENCODE Project in footprinting assays. Using the latter approach, we detected the binding of 75 TFs to the highly repetitive Alu elements. We anticipate that these approaches will expand our capabilities to study genetic variation and under-characterized genomic regions."
JUAN FUXMAN BASS,Paired yeast one-hybrid assays to detect DNA-binding cooperativity and antagonism across transcription factors,"Cooperativity and antagonism between transcription factors (TFs) can drastically modify their binding to regulatory DNA elements. While mapping these relationships between TFs is important for understanding their context-specific functions, existing approaches either rely on DNA binding motif predictions, interrogate one TF at a time, or study individual TFs in parallel. Here, we introduce paired yeast one-hybrid (pY1H) assays to detect cooperativity and antagonism across hundreds of TF-pairs at DNA regions of interest. We provide evidence that a wide variety of TFs are subject to modulation by other TFs in a DNA region-specific manner. We also demonstrate that TF-TF relationships are often affected by alternative isoform usage and identify cooperativity and antagonism between human TFs and viral proteins from human papillomaviruses, Epstein-Barr virus, and other viruses. Altogether, pY1H assays provide a broadly applicable framework to study how different functional relationships affect protein occupancy at regulatory DNA regions."
JUAN FUXMAN BASS,Widespread perturbation of ETS factor binding sites in cancer,"Although >90% of somatic mutations reside in non-coding regions, few have been reported as cancer drivers. To predict driver non-coding variants (NCVs), we present a transcription factor (TF)-aware burden test based on a model of coherent TF function in promoters. We apply this test to NCVs from the Pan-Cancer Analysis of Whole Genomes cohort and predict 2555 driver NCVs in the promoters of 813 genes across 20 cancer types. These genes are enriched in cancer-related gene ontologies, essential genes, and genes associated with cancer prognosis. We find that 765 candidate driver NCVs alter transcriptional activity, 510 lead to differential binding of TF-cofactor regulatory complexes, and that they primarily impact the binding of ETS factors. Finally, we show that different NCVs within a promoter often affect transcriptional activity through shared mechanisms. Our integrated computational and experimental approach shows that cancer NCVs are widespread and that ETS factors are commonly disrupted."
SOFIA PEREZ,The political economy of austerity in Southern Europe,"Europe’s response to the sovereign debt crisis in Southern Europe has been premised on the idea that these states can return to growth through internal devaluation and fiscal consolidation. This article explores the distributive consequences of that strategy in Greece, Portugal, Italy, and Spain. We argue that standard measures of poverty do not capture the deterioration in living standards as fully as anchored poverty. Moreover, we show that inequality trends conceal considerable re-ranking within the income distribution: those who were rich in 2012 had got richer in 2009–12, but those who were rich in 2009 lost ground in 2009–12. We find that in all four countries the new poor include significantly fewer pensioners and more unemployed workers, and are considerably poorer than the old poor had been. We demonstrate that there was significant variation in the magnitude and design of austerity, with Italy imposing a far smaller adjustment than Spain, and Portugal achieving less inequality in spite of robust fiscal consolidation. Nevertheless, even when austerity measures were designed to reduce inequality by compressing incomes downward, their second-order macro-economic effects ultimately increased inequality (except in Portugal). In the last section, we explore the political reasons for this variation."
SOFIA PEREZ,Banking on Privilege: The Politics of Spanish Financial Reform,
SOFIA PEREZ,A Europe of creditor and debtor states: explaining the north/south divide in the Eurozone,"The divide in the Eurozone between a small set of core economies with strong international financial positions (North) and a set of debtor states that show periodic vulnerability in international financial markets (South) remains a core feature of the area. Our understanding of that schism, however, remains incomplete. Comparative political economists have emphasised differences in labour market institutions – in particular wage setting – to explain the split. This article takes issue with that view, suggesting that the case for a wage-driven explanation of creditor and debtor states’ positions in the Eurozone remains weak. Instead, it emphasises the role of capital flows and the uneven impact these had on domestic demand across Eurozone states both before and after 2008. This macro-economically centred explanation – in which financial, rather than labour market, dynamics play the central role – has important implications for our evaluation of Eurozone reforms."
SOFIA PEREZ,Export or perish: can internal devaluation create enough good jobs in southern Europe?,
SOFIA PEREZ,The pandemic and the long shadow of austerity in Southern Europe,
LINDA SPRAGUE MARTINEZ,POV: COVID-19 has unmasked an unprecedented housing crisis—here’s how to fix it,
LINDA SPRAGUE MARTINEZ,Strategies to promote language inclusion at 17 CTSA hubs,"The prioritization of English language in clinical research is a barrier to translational science. We explored promising practices to advance the inclusion of people who speak languages other than English in research conducted within and supported by NIH Clinical Translational Science Award (CTSA) hubs. Key informant interviews were conducted with representatives (n = 24) from CTSA hubs (n = 17). Purposive sampling was used to identify CTSA hubs focused on language inclusion. Hubs electing to participate were interviewed via Zoom. Thematic analysis was performed to analyze interview transcripts. We report on strategies employed by hubs to advance linguistic inclusion and influence institutional change that were identified. Strategies ranged from translations, development of culturally relevant materials and consultations to policies and procedural changes and workforce initiatives. An existing framework was adapted to conceptualize hub strategies. Language justice is paramount to bringing more effective treatments to all people more quickly. Inclusion will require institutional transformation and CTSA hubs are well positioned to catalyze change."
LINDA SPRAGUE MARTINEZ,Community advisory board members’ perspectives on their contributions to a large multistate cluster RCT: a mixed methods study,"BACKGROUND: Community advisory boards (CABs) are an established approach to ensuring research reflects community priorities. This paper examines two CABs that are part of the HEALing Communities Study which aims to reduce overdose mortality. This analysis aimed to understand CAB members’ expectations, experiences, and perspectives on CAB structure, communication, facilitation, and effectiveness during the first year of an almost fully remote CAB implementation. Current literature exploring these perspectives is limited. METHODS: We collected qualitative and survey data simultaneously from members (n = 53) of two sites’ CABs in the first 9 months of CAB development. The survey assessed trust, communication, and relations; we also conducted 32 semi-structured interviews. We analyzed the survey results descriptively. The qualitative data were analyzed using a deductive codebook based on the RE-AIM PRISM framework. Themes were drawn from the combined qualitative data and triangulated with survey results to further enrich the findings. RESULTS: CAB members expressed strong commitment to overall study goals and valued the representation of occupational sectors. The qualitative data described a dissonance between CAB members’ commitment to the mission and unmet expectations for influencing the study within an advisory role. Survey results indicated lower satisfaction with the research teams’ ability to create a mutually beneficial process, clear communication, and sharing of power. CONCLUSION: Building a CAB on a remote platform, within a study utilizing a community engagement strategy, still presents challenges to fully realizing the potential of a CAB. These findings can inform more effective operationalizing of community-engaged research through enhanced CAB engagement."
LINDA SPRAGUE MARTINEZ,Community engagement and financial arrangements: navigating institutional change,"Despite their documented benefits, the widespread adoption of community-engaged and participatory approaches among health researchers remains limited. Institutional practices and policies influence the uptake of community engagement and participatory approaches. We examine the role of financial arrangements between university researchers and community partners, by exploring efforts to bridge the gap between research administration and researchers at two research-intensive institutions. The type of financial arrangement a researcher has with a community partner plays an important role in setting the stage for the structure of the partnership as it relates to shared decision-making and ownership of the research. Continued efforts to clarify and streamline subcontracting processes are needed as is infrastructure to support community partners and researchers as they navigate financial arrangements if progress is to be made."
RENA CONTI,Cost-effectiveness of tyrosine kinase inhibitor treatment strategies for chronic myeloid leukemia in chronic phase after generic entry of imatinib in the United States,"BACKGROUND: We analyzed the cost-effectiveness of treating incident chronic myeloid leukemia in chronic phase (CML-CP) with generic imatinib when it becomes available in United States in 2016. In the year following generic entry, imatinib's price is expected to drop 70% to 90%. We hypothesized that initiating treatment with generic imatinib in these patients and then switching to the other tyrosine-kinase inhibitors (TKIs), dasatinib or nilotinib, because of intolerance or lack of effectiveness (""imatinib-first"") would be cost-effective compared with the current standard of care: ""physicians' choice"" of initiating treatment with any one of the three TKIs. METHODS: We constructed Markov models to compare the five-year cost-effectiveness of imatinib-first vs physician's choice from a US commercial payer perspective, assuming 3% annual discounting ($US 2013). The models' clinical endpoint was five-year overall survival taken from a systematic review of clinical trial results. Per-person spending on incident CML-CP treatment overall care components was estimated using Truven's MarketScan claims data. The main outcome of the models was cost per quality-adjusted life-year (QALY). We interpreted outcomes based on a willingness-to-pay threshold of $100 000/QALY. A panel of European LeukemiaNet experts oversaw the study's conduct. RESULTS: Both strategies met the threshold. Imatinib-first ($277 401, 3.87 QALYs) offered patients a 0.10 decrement in QALYs at a savings of $88 343 over five years to payers compared with physician's choice ($365 744, 3.97 QALYs). The imatinib-first incremental cost-effectiveness ratio was approximately $883 730/QALY. The results were robust to multiple sensitivity analyses. CONCLUSION: When imatinib loses patent protection and its price declines, its use will be the cost-effective initial treatment strategy for CML-CP."
RENA CONTI,Public research funding and pharmaceutical prices: do Americans pay twice for drugs?,"In the debate over prescription drug pricing, some pharmaceutical industry critics claim that U.S. taxpayers pay twice for costly therapies, because publicly supported research is a major contributor to drug discovery and American taxpayers are inadequately rewarded for their research investment due to high drug prices. In fact, the empirical evidence supporting these claims is weak, and the pay twice argument distracts from important efforts to ensure that impactful new drugs continue to be developed and made widely available to patients who need them."
RENA CONTI,Estimating the financial impact of gene therapy in the U.S.,"We empirically assess the potential financial impact of future gene therapies on the US economy. After identifying 109 late-stage gene therapy clinical trials currently underway, we estimate the number of new and existing patients with corresponding diseases to be treated by these gene therapies, developing and applying novel mathematical models to estimate the increase in quality-adjusted life years for each approved gene therapy. We then simulate the launch prices and the expected spending for these therapies over a 15-year time horizon. Under conservative assumptions, the results of our simulation suggest that an expected total of 1.09 million patients will be treated by gene therapy from January 2020 to December 2034. The expected peak annual spending on these therapies is $25.3 billion, and the expected total spending from January 2020 to December 2034 is $306 billion. Assuming a linear pace of future gene therapy development fitted to past experience, our spending estimate increases by only 15.7% under conservative assumptions. As a proxy for the impact of expected spending on different public and private payers, we decompose the estimated annual spending by treated age group. Since experience suggests that insurers with annual budget constraints may restrict access to therapies with expected benefit to the patient, we consider various methods of payment to ensure access to these therapies even among those insured by the most budget-constrained payers."
RENA CONTI,The generic drug user fee amendments: an economic perspective,"Since the vast majority of prescription drugs consumed by Americans are off patent (‘generic’), their regulation and supply is of wide interest. We describe events leading up to the US Congress's 2012 passage of the Generic Drug User Fee Amendments (GDUFA I) as part of the Food and Drug Administration Safety and Innovation Act (FDASIA). Under GDUFA I, generic manufacturers agreed to pay approximately $300 million in fees each year of the five-year program. In exchange, the US Food and Drug Administration (FDA) committed to performance goals. We describe GDUFA I’s FDA commitments, provisions, goals, and annual fee structure and compare it to that entailed in the authorization and implementation of GDUFA II on October 1, 2017. We explain how user fees required under GDUFA I erected barriers to entry and created scale and scope economies for incumbent manufacturers. Congress changed user fees under GDUFA II in part to lessen these incentives. In order to initiate and sustain user fees under GDUFA legislation, FDA requires the submission of self-reported data on generic manufacturers including domestic and foreign facilities. These data are public and our examination of them provides an unprecedented window into the recent organization of generic drug manufacturers supplying the US market. Our results suggest that generic drug manufacturing is increasingly concentrated and foreign. We discuss the implications of this observed market structure for GDUFA II’s implementation among other outcomes."
RENA CONTI,Valuing rare pediatric drugs: an economics perspective,"There is a coming wave of novel genetic therapies aiming to treat rare pediatric disease. A large literature investigates the valuation of new treatments, but the valuation of treatments for rare pediatric illness raises a host of unique issues. In this paper, we review the challenges of applying both the standard economic model and standard approaches to estimating cost-effectiveness using the quality-adjusted life year (QALY) to this case. We argue that there are a large number of special issues that have only been partially addressed by past work and we conclude that more data and the development of new methods are vital as innovators, health technology assessment practitioners and policymakers confront the launch of these new drugs."
RENA CONTI,Generic prescription drug price increases: which products will be affected by proposed anti-gouging legislation,"BACKGROUND In the United States (U.S.), large price increases for selected generic drugs have elicited public outrage. Recent legislative proposals aim to increase price transparency and identify outlier drug “price spikes.” It is unknown how many and what types of products would be highlighted by such efforts. METHODS IQVIA Health Incorporated’s National Sales Perspectives™ provided sales, use and price data for all generic prescription products (unique molecule-manufacturer-formulation combinations) sold in the U.S. We estimated annual prescription price levels and changes between 2013 and 2014. We identify drugs with annual prescription price increases in excess of the medical consumer price index (CPI), and in excess of 15% or 20%, per legislative proposals. We reported annualized inflation-adjusted mean, standard deviation (SD), median, and 95th percentile prescription price increases and percentage of products exceeding the growth in the medical CPI. We fitted logistic regression models to identify characteristics of drugs associated with each category of price increase. RESULTS We analyzed data for 6,182 generic products. The mean inflation-adjusted price increase among all generic products was 38% (SD 1,053%), the median, 2%; the 95th percentile, 135%; and the mean price level, $29.69 (SD $378.44). Approximately half of all products experienced price increases in excess of the growth in the medical CPI; 28% had price increases greater than 15% and 23% had price increases greater than 20%. Drugs exceeding outlier thresholds exhibited lower baseline price levels than the mean price level observed among all generic drugs. The most consistent characteristic predicting whether a product would exceed “price spike” thresholds proposed in legislation is the being supplied by only one manufacturer. CONCLUSIONS “Price spikes” among generic drugs in 2014 were more common than newspaper stories and legislative hearings suggest. While the cross-sectional association between an indicator of being sold by only a single manufacturer and the probability of meeting specific price growth thresholds is suggestive of an economically intuitive causal story, future work should delve more deeply into whether decreases in generic competition explain the dramatic price increases that have captured the public’s attention in recent years."
RENA CONTI,Stockpiling medicines at the onset of the COVID-19 pandemic: an empirical analysis of national prescription drug sales and prices,"Hospitals with Coronavirus disease (COVID-19) demand surges at the onset of the pandemic report medication shortages, a worrisome phenomenon as inadequate medication supplies negatively affect patient outcomes. The popular press implicates a lack of raw ingredients and spikes in purchases but rigorous research is needed to more accurately identify shortage causes. We leverage a quasi-experimental design on IQVIA’s National Sales Perspectives™ data from 2018-2020 with a focus on medicines related to U.S. hospital-based COVID-19 treatment and a set of control medicines not used for COVID-19. We contribute to supply chain theory by empirically demonstrating that stockpiling among U.S. medical providers in the early phase of the pandemic accounts for the shortages. The buyers’ behavior results in concentration of the sales volume of COVID-19 medicines in the first two months of the pandemic. After these first two months, the sales volume of drugs for COVID-19 treatment decreases significantly despite a nationwide increase in COVID-19-related hospitalizations. An implication for manufacturers is that orders due to stockpiling by downstream buyers early on in a pandemic period should be discounted when predicting future demand. We also investigate another potential cause: expected price increases in the future. Counter to concerns that drug manufacturers would engage in price gouging behavior, we find no evidence of price inflation for these drugs. Our results are robust to numerous sensitivity checks and have implications for manufacturers, hospitals, and policymakers that may improve medicine supply resiliency against future threats."
KATHERINE K. FRANKEL,What does it mean to be a reader? Identity and positioning in two high school literacy intervention classes,"Studies of high school literacy intervention classes have measured reading gains through standardized assessments, but few have considered the impact on students’ identities. In this embedded case study, I used theories of identity and positioning to answer two research questions: How did institutional and interpersonal acts of positioning in two literacy intervention classrooms build on, change, or challenge students’ personal histories and identities as readers? How did these acts shape students’ understandings of themselves as readers over time? I collected and analyzed interviews, field notes, and artifacts. Analyses revealed that ongoing positioning in one classroom thickened one student’s identity as a poor reader. Positioning in the second classroom reinforced the other student’s identity as a good student but had little impact on her identity as a reader. These findings highlight the need to better understand how instructional contexts privilege particular ways of reading and understandings of what it means to be a reader."
KATHERINE K. FRANKEL,The intersection of reading and identity in high school literacy intervention classes,"It is common practice to enroll adolescents in classes designed to improve their reading. Previous studies of literacy intervention classes focus on students’ acquisition of reading skills and strategies, but few studies consider how reading identities may contribute to literacy learning. To address this gap, I used theories of positioning and identity to answer the question: How do students’ understandings of literacy and their own reading identities interact with the figured worlds of their literacy intervention classrooms? I analyzed interviews, field notes, and artifacts for two students and teachers in different classrooms, focusing on students’ acts of agency. Analyses revealed that the students’ identities as good readers conflicted with the figured worlds of their classrooms, but they responded differently. One challenged the norms of his classroom in a manner contrary to his teacher’s expectations and was unable to disrupt his positioning as struggling reader. The other acquiesced to the norms of her classroom in ways her teacher recognized as characteristic of a capable reader, ultimately upsetting her struggling reader subject position. The findings reveal that students’ acts of agency and teachers’ interpretations of those acts are informed by students’ perceptions of themselves as readers and teachers’ understandings of literacy and learning in intervention classrooms. The findings also problematize the practice of placing students in classes that position them as deficient. Additional research that attends to sociocultural factors in classrooms is necessary to understand the academic, social, and personal implications of particular approaches to literacy instruction and intervention for individual students."
KATHERINE K. FRANKEL,From “what is reading?” to what is literacy?,"In their 1985 report, Becoming a Nation of Readers, Anderson, Hiebert, Scott, and Wilkinson defined reading and proposed five principles that guide its successful enactment: (1) reading is a constructive process, (2) reading must be fluent, (3) reading must be strategic, (4) reading requires motivation, and (5) reading is a continuously developing skill. In this article we revise the definition from reading to literacy and rethink the principles in response to theoretical and empirical developments in the intervening years with regard to the processes of, and contexts for, reading. Our updated principles include: (1) literacy is a constructive, integrative, and critical process situated in social practices; (2) fluent reading is shaped by language processes and contexts; (3) literacy is strategic and disciplinary; (4) literacy entails motivation and engagement; and (5) literacy is a continuously developing set of practices. We redefine each principle and offer new explanations in light of what we now know."
KATHERINE K. FRANKEL,Struggling readers? Using theory to complicate understandings of what it means to be literate in school,"Theories guide many aspects of literacy research. In this article we describe four theoretical approaches that we have used in qualitative research with students who are perceived to struggle with reading in school, including: New Literacy Studies, Disability Studies in Education, Bioecological Systems Theory, and Cultural Historical Activity Theory. We provide a brief overview of each of the theories and then explain how we have used them to gain insights about students with whom we have worked in the context of our research. Although grounded in distinct perspectives, we argue that each of the theories are lenses through which we were better able to understand the complexities of students’ struggles with reading. We further argue that the theories are united in their ability to broaden the perspectives of researchers and teachers to better account for the social, cultural, and institutional factors that shape literacy teaching and learning in schools. We conclude by questioning the use of the term “struggling reader” and highlighting the implications of our individual theoretical frames and analyses for both research and practice."
KATHERINE K. FRANKEL,Positioning adolescents in literacy teaching and learning,"Secondary literacy instruction often happens to adolescents rather than with them. To disrupt this trend, we collaborated with 12th-grade “literacy mentors” to reimagine literacy teaching and learning with 10th-grade mentees in a public high school classroom. We used positioning theory as an analytic tool to (a) understand how mentors positioned themselves and how we positioned them and (b) examine the literacy practices that enabled and constrained the mentor position. We found that our positioning of mentors as collaborators was taken up in different and sometimes unexpected ways as a result of the multiple positions available to them and institutional-level factors that shaped what literacy practices were and were not negotiable. We argue that future collaborations with youth must account for the rights and duties of all members of a classroom community, including how those rights and duties intersect, merge, or come into conflict within and across practices."
KATHERINE K. FRANKEL,"Why the ""Struggling Reader"" label Is harmful (and what educators can do about it)",The authors featured in this department column share instructional practices that support transformative literacy teaching and disrupt “struggling reader” and “struggling writer” labels.
KATHERINE K. FRANKEL,Collaborating with youths as coteachers in literacy learning,The authors featured in this department column share instructional practices that support transformative literacy teaching and disrupt “struggling reader” and “struggling writer” labels.
KATHERINE K. FRANKEL,Oral reading: practices and purposes in secondary classrooms,"PURPOSE This paper aims to investigate teacher-initiated whole-group oral reading practices in two ninth-grade reading intervention classrooms and how teachers understood the purposes of those practices. DESIGN/METHODOLOGY/APPROACH In this qualitative cross-case analysis, a literacy-as-social-practice perspective is used to collaboratively analyze ethnographic data (fieldnotes, audio recordings, interviews, artifacts) across two classrooms. FINDINGS Oral reading was a routine instructional reading event in both classrooms. However, the literacy practices that characterized oral reading and teachers’ purposes for using oral reading varied depending on teachers’ pedagogical philosophies, instructional goals and contextual constraints. During oral reading, students’ opportunities to engage in independent meaning making with texts were either absent or secondary to other purposes or goals. PRACTICAL IMPLICATIONS Findings emphasize the significance of understanding both how and why oral reading happens in secondary classrooms. Specifically, they point to the importance of collaborating with teachers to (a) examine their own ideas about the power of oral reading and the institutional factors that shape their existing oral reading practices; (b) investigate the intended and actual outcomes of oral reading for their students and (c) develop other instructional approaches to support students to individually and collaboratively make meaning from texts. ORIGINALITY/VALUE This study falls at the intersection of three under-researched areas of study: the nature of everyday instruction in secondary literacy intervention settings, the persistence of oral reading in secondary school and teachers’ purposes for using oral reading in their instruction. Consequently, it contributes new knowledge that can support educators in creating more equitable instructional environments."
KATHERINE K. FRANKEL,A student's perspective on literacy teaching and learning: starting a conversation through six suggestions,The authors featured in this department column share instructional practices that support transformative literacy teaching and disrupt “struggling reader” and “struggling writer” labels.
KATHERINE K. FRANKEL,Appendices — A meta-synthesis of qualitative research on reading intervention classes in secondary schools,
PETER R BLAKE,"Miniature exoplanet radial velocity array I: design, commissioning, and early photometric results","The MINiature Exoplanet Radial Velocity Array (MINERVA) is a US-based observational facility dedicated to the discovery and characterization of exoplanets around a nearby sample of bright stars. MINERVA employs a robotic array of four 0.7 m telescopes outfitted for both high-resolution spec- troscopy and photometry, and is designed for completely autonomous operation. The primary science program is a dedicated radial velocity survey and the secondary science objective is to obtain high precision transit light curves. The modular design of the facility and the flexibility of our hardware allows for both science programs to be pursued simultaneously, while the robotic control software provides a robust and efficient means to carry out nightly observations. In this article, we describe the design of MINERVA including major hardware components, software, and science goals. The telescopes and photometry cameras are characterized at our test facility on the Caltech campus in Pasadena, CA, and their on-sky performance is validated. New observations from our test facility demonstrate sub-mmag photometric precision of one of our radial velocity survey targets, and we present new transit observations and fits of WASP-52b—a known hot-Jupiter with an inflated radius and misaligned orbit. The process of relocating the MINERVA hardware to its final destination at the Fred Lawrence Whipple Observatory in southern Arizona has begun, and science operations are expected to commence within 2015."
PETER R BLAKE,Priorities for synthesis research in ecology and environmental science,
PETER R BLAKE,First radial velocity results from the MINiature Exoplanet Radial Velocity Array (MINERVA),"The MINiature Exoplanet Radial Velocity Array (MINERVA) is a dedicated observatory of four 0.7 m robotic telescopes fiber-fed to a KiwiSpec spectrograph. The MINERVA mission is to discover super-Earths in the habitable zones of nearby stars. This can be accomplished with MINERVA's unique combination of high precision and high cadence over long time periods. In this work, we detail changes to the MINERVA facility that have occurred since our previous paper. We then describe MINERVA's robotic control software, the process by which we perform 1D spectral extraction, and our forward modeling Doppler pipeline. In the process of improving our forward modeling procedure, we found that our spectrograph's intrinsic instrumental profile is stable for at least nine months. Because of that, we characterized our instrumental profile with a time-independent, cubic spline function based on the profile in the cross dispersion direction, with which we achieved a radial velocity precision similar to using a conventional ""sum-of-Gaussians"" instrumental profile: 1.8 m s−1 over 1.5 months on the RV standard star HD 122064. Therefore, we conclude that the instrumental profile need not be perfectly accurate as long as it is stable. In addition, we observed 51 Peg and our results are consistent with the literature, confirming our spectrograph and Doppler pipeline are producing accurate and precise radial velocities."
PETER R BLAKE,"Minerva-Australis. I. design, commissioning, and first photometric results","The Minerva-Australis telescope array is a facility dedicated to the follow-up, confirmation, characterization, and mass measurement of planets orbiting bright stars discovered by the Transiting Exoplanet Survey Satellite (TESS)—a category in which it is almost unique in the Southern Hemisphere. It is located at the University of Southern Queensland's Mount Kent Observatory near Toowoomba, Australia. Its flexible design enables multiple 0.7 m robotic telescopes to be used both in combination, and independently, for high-resolution spectroscopy and precision photometry of TESS transit planet candidates. Minerva-Australis also enables complementary studies of exoplanet spin–orbit alignments via Doppler observations of the Rossiter–McLaughlin effect, radial velocity searches for nontransiting planets, planet searches using transit timing variations, and ephemeris refinement for TESS planets. In this first paper, we describe the design, photometric instrumentation, software, and science goals of Minerva-Australis, and note key differences from its Northern Hemisphere counterpart, the Minerva array. We use recent transit observations of four planets, WASP-2b, WASP-44b, WASP-45b, and HD 189733b, to demonstrate the photometric capabilities of Minerva-Australis."
PETER R BLAKE,The long-baseline neutrino experiment: exploring fundamental symmetries of the universe,"The preponderance of matter over antimatter in the early Universe, the dynamics of the supernova bursts that produced the heavy elements necessary for life and whether protons eventually decay --- these mysteries at the forefront of particle physics and astrophysics are key to understanding the early evolution of our Universe, its current state and its eventual fate. The Long-Baseline Neutrino Experiment (LBNE) represents an extensively developed plan for a world-class experiment dedicated to addressing these questions. LBNE is conceived around three central components: (1) a new, high-intensity neutrino source generated from a megawatt-class proton accelerator at Fermi National Accelerator Laboratory, (2) a near neutrino detector just downstream of the source, and (3) a massive liquid argon time-projection chamber deployed as a far detector deep underground at the Sanford Underground Research Facility. This facility, located at the site of the former Homestake Mine in Lead, South Dakota, is approximately 1,300 km from the neutrino source at Fermilab -- a distance (baseline) that delivers optimal sensitivity to neutrino charge-parity symmetry violation and mass ordering effects. This ambitious yet cost-effective design incorporates scalability and flexibility and can accommodate a variety of upgrades and contributions. With its exceptional combination of experimental configuration, technical capabilities, and potential for transformative discoveries, LBNE promises to be a vital facility for the field of particle physics worldwide, providing physicists from around the globe with opportunities to collaborate in a twenty to thirty year program of exciting science. In this document we provide a comprehensive overview of LBNE's scientific objectives, its place in the landscape of neutrino physics worldwide, the technologies it will incorporate and the capabilities it will possess."
PINGHUA LIU,OvoAMtht from Methyloversatilis thermotolerans ovothiol biosynthesis is a bifunction enzyme: thiol oxygenase and sulfoxide synthase activities,"Mononuclear non-heme iron enzymes are a large class of enzymes catalyzing a wide-range of reactions. In this work, we report that a non-heme iron enzyme in Methyloversatilis thermotolerans, OvoAMtht, has two different activities, as a thiol oxygenase and a sulfoxide synthase. When cysteine is presented as the only substrate, OvoAMtht is a thiol oxygenase. In the presence of both histidine and cysteine as substrates, OvoAMtht catalyzes the oxidative coupling between histidine and cysteine (a sulfoxide synthase). Additionally, we demonstrate that both substrates and the active site iron's secondary coordination shell residues exert exquisite control over the dual activities of OvoAMtht (sulfoxide synthase vs. thiol oxygenase activities). OvoAMtht is an excellent system for future detailed mechanistic investigation on how metal ligands and secondary coordination shell residues fine-tune the iron-center electronic properties to achieve different reactivities."
PINGHUA LIU,Mechanistic elucidation of two catalytically versatile iron(II)- and α-ketoglutarate-dependent enzymes: cases beyond hydroxylation,"Iron(II)- and α-ketoglutarate-dependent (Fe/αKG) enzymes catalyze a large array of reactions. Although hydroxylation reaction catalyzed by these enzymes has been investigated in great details, involving the ferryl (FeIV=O) as a key reactive intermediate. The mechanisms of reactions other than hydroxylation are still largely unknown. By using a combined biochemical, bio-organic, and spectroscopic approach, we have studied the mechanisms of two newly discovered Fe/αKG enzymes, FtmOx1 (endoperoxidase) and AsqJ (desaturase/epoxidase), revealing their strategies in controlling reactivity, namely the effect of redox/polar residues near the iron center, the electronic properties of the substrate, and the intrinsic reactivity of the ferryl intermediate."
PINGHUA LIU,"Mini-review: Ergothioneine and ovothiol biosyntheses, an unprecedented trans-sulfur strategy in natural product biosynthesis","As one of the most abundant elements on earth, sulfur is part of many small molecular metabolites and is key to their biological activities. Over the past few decades, some general strategies have been discovered for the incorporation of sulfur into natural products. In this review, we summarize recent efforts in elucidating the biosynthetic details for two sulfur-containing metabolites, ergothioneine and ovothiol. Their biosyntheses involve an unprecedented trans-sulfur strategy, a combination of a mononuclear non-heme iron enzyme-catalyzed oxidative C-S bond formation reaction and a PLP enzyme-mediated C-S lyase reaction."
PINGHUA LIU,"Use of a tyrosine analogue to modulate the two activities of a nonheme iron enzyme OvoA in ovothiol biosynthesis, cysteine oxidation versus oxidative C-S bond formation","Ovothiol is a histidine thiol derivative. The biosynthesis of ovothiol involves an extremely efficient trans-sulfuration strategy. The nonheme iron enzyme OvoA catalyzed oxidative coupling between cysteine and histidine is one of the key steps. Besides catalyzing the oxidative coupling between cysteine and histidine, OvoA also catalyzes the oxidation of cysteine to cysteine sulfinic acid (cysteine dioxygenase activity). Thus far, very little mechanistic information is available for OvoA-catalysis. In this report, we measured the kinetic isotope effect (KIE) in OvoA-catalysis using the isotopically sensitive branching method. In addition, by replacing an active site tyrosine (Tyr417) with 2-amino-3-(4-hydroxy-3-(methylthio)phenyl)propanoic acid (MtTyr) through the amber suppressor mediated unnatural amino acid incorporation method, the two OvoA activities (oxidative coupling between cysteine and histidine, and cysteine dioxygenase activity) can be modulated. These results suggest that the two OvoA activities branch out from a common intermediate and that the active site tyrosine residue plays some key roles in controlling the partitioning between these two pathways."
PINGHUA LIU,Recent examples of α-ketoglutarate-dependent mononuclear non-haem iron enzymes in natural product biosyntheses,"Covering: up to 2018 α-Ketoglutarate (αKG, also known as 2-oxoglutarate)-dependent mononuclear non-haem iron (αKG-NHFe) enzymes catalyze a wide range of biochemical reactions, including hydroxylation, ring fragmentation, C-C bond cleavage, epimerization, desaturation, endoperoxidation and heterocycle formation. These enzymes utilize iron(ii) as the metallo-cofactor and αKG as the co-substrate. Herein, we summarize several novel αKG-NHFe enzymes involved in natural product biosyntheses discovered in recent years, including halogenation reactions, amino acid modifications and tailoring reactions in the biosynthesis of terpenes, lipids, fatty acids and phosphonates. We also conducted a survey of the currently available structures of αKG-NHFe enzymes, in which αKG binds to the metallo-centre bidentately through either a proximal- or distal-type binding mode. Future structure-function and structure-reactivity relationship investigations will provide crucial information regarding how activities in this large class of enzymes have been fine-tuned in nature."
PINGHUA LIU,Chemical modifications of proteins and their applications in metalloenzyme studies,"Protein chemical modifications are important tools for elucidating chemical and biological functions of proteins. Several strategies have been developed to implement these modifications, including enzymatic tailoring reactions, unnatural amino acid incorporation using the expanded genetic codes, and recognition-driven transformations. These technologies have been applied in metalloenzyme studies, specifically in dissecting their mechanisms, improving their enzymatic activities, and creating artificial enzymes with non-natural activities. Herein, we summarize some of the recent efforts in these areas with an emphasis on a few metalloenzyme case studies."
PINGHUA LIU,Dissecting the mechanism of the nonheme iron endoperoxidase FtmOx1 using substrate analogues,"FtmOx1 is a nonheme iron (NHFe) endoperoxidase, catalyzing three disparate reactions, endoperoxidation, alcohol dehydrogenation, and dealkylation, under in vitro conditions; the diversity complicates its mechanistic studies. In this study, we use two substrate analogues to simplify the FtmOx1-catalyzed reaction to either a dealkylation or an alcohol dehydrogenation reaction for structure-function relationship analysis to address two key FtmOx1 mechanistic questions: (1) Y224 flipping in the proposed COX-like model vs α-ketoglutarate (αKG) rotation proposed in the CarC-like mechanistic model and (2) the involvement of a Y224 radical (COX-like model) or a Y68 radical (CarC-like model) in FtmOx1-catalysis. When 13-oxo-fumitremorgin B (7) is used as the substrate, FtmOx1-catalysis changes from the endoperoxidation to a hydroxylation reaction and leads to dealkylation. In addition, consistent with the dealkylation side-reaction in the COX-like model prediction, the X-ray structure of the FtmOx1•CoII•αKG•7 ternary complex reveals a flip of Y224 to an alternative conformation relative to the FtmOx1•FeII•αKG binary complex. Verruculogen (2) was used as a second substrate analogue to study the alcohol dehydrogenation reaction to examine the involvement of the Y224 radical or Y68 radical in FtmOx1-catalysis, and again, the results from the verruculogen reaction are more consistent with the COX-like model."
PINGHUA LIU,Hybrid plasmonic photoreactors as visible light-mediated bactericides,"Photocatalytic compounds and complexes, such as tris(bipyridine)ruthenium(II), [Ru(bpy)3]2+, have recently attracted attention as light-mediated bactericides that can help to address the need for new antibacterial strategies. We demonstrate in this work that the bactericidal efficacy of [Ru(bpy)3]2+ and the control of its antibacterial function can be significantly enhanced through combination with a plasmonic nanoantenna. We report strong, visible light-controlled bacterial inactivation with a nanocomposite design that incorporates [Ru(bpy)3]2+ as a photocatalyst and a Ag nanoparticle (NP) core as a light-concentrating nanoantenna into a plasmonic hybrid photoreactor. The hybrid photoreactor platform is facilitated by a self-assembled lipid membrane that encapsulates the Ag NP and binds the photocatalyst. The lipid membrane renders the nanocomposite biocompatible in the absence of resonant illumination. Upon illumination, the plasmon-enhanced photoexcitation of the metal-to-ligand charge-transfer band of [Ru(bpy)3]2+ prepares the reactive excited state of the complex that oxidizes the nanocomposite membrane and increases its permeability. The photooxidation induces the release of [Ru(bpy)3]2+, Ag+, and peroxidized lipids into the ambient medium, where they interact synergistically to inactivate bacteria. We measured a 7 order of magnitude decrease in Gram-positive Arthrobacter sp. and a 4 order of magnitude decrease in Gram-negative Escherichia coli colony forming units with the photoreactor bactericides after visible light illumination for 1 h. In both cases, the photoreactor exceeds the bactericidal standard of a log reduction value of 3 and surpasses the antibacterial effect of free Ag NPs or [Ru(bpy)3]2+ by >4 orders of magnitude. We also implement the inactivation of a bacterial thin film in a proof-of-concept study."
PINGHUA LIU,Implications for an imidazol-2-yl carbene intermediate in the rhodanase-catalyzed C-S bond formation reaction of anaerobic ergothioneine biosynthesis,"In the anaerobic ergothioneine biosynthetic pathway, a rhodanese domain containing enzyme (EanB) activates tne hercynine's sp2 ε-C-H Dona ana replaces it with a C-S bond to produce ergothioneine. The key intermediate for this trans-sulfuration reaction is the Cys412 persulfide. Substitution of the EanB-Cys412 persulfide with a Cys412 perselenide does not yield the selenium analog of ergothioneine, selenoneine. However, in deuterated buffer, the perselenide-modified EanB catalyzes the deuterium exchange between hercynine's sp2 ε-C-H bond and D2O. Results from QM/MM calculations suggest that the reaction involves a carbene intermediate and that Tyr353 plays a key role. We hypothesize that modulating the pKa of Tyr353 will affect the deuterium-exchange rate. Indeed, the 3,5-difluoro tyrosine containing EanB catalyzes the deuterium exchange reaction with k ex of ~10-fold greater than the wild-type EanB (EanBWT). With regards to potential mechanisms, these results support the involvement of a carbene intermediate in EanB-catalysis, rendering EanB as one of the few carbene-intermediate involving enzymatic systems."
PINGHUA LIU,Retraction note: endoperoxide formation by an α-ketoglutarate-dependent mononuclear non-haem iron enzyme,
PINGHUA LIU,Single-step replacement of an unreactive C-H bond by a C-S bond using polysulfide as the direct sulfur source in anaerobic ergothioneine biosynthesis,"Ergothioneine, a natural longevity vitamin and antioxidant, is a thiol-histidine derivative. Recently, two types of biosynthetic pathways were reported. In the aerobic ergothioneine biosynthesis, a non-heme iron enzyme incorporates a sulfoxide to an sp2 C-H bond in trimethyl-histidine (hercynine) through oxidation reactions. In contrast, in the anaerobic ergothioneine biosynthetic pathway in a green sulfur bacterium, Chlorobium limicola, a rhodanese domain containing protein (EanB) directly replaces this unreactive hercynine C-H bond with a C-S bond. Herein, we demonstrate that polysulfide (HSSnSR) is the direct sulfur-source in EanB-catalysis. After identifying EanB's substrates, X-ray crystallography of several intermediate states along with mass spectrometry results provide additional mechanistic details for this reaction. Further, quantum mechanics/molecular mechanics (QM/MM) calculations reveal that protonation of Nπ of hercynine by Tyr353 with the assistance of Thr414 is a key activation step for the hercynine sp2 C-H bond in this trans-sulfuration reaction."
PINGHUA LIU,Method of treating diseases,Published patent application
YVETTE C COZIER,Body mass index and sociodemographic predictors of school lunch purchase behavior during a year-long environmental intervention in middle school,"Modifying the school food environment is on the national agenda as one strategy to improve the nutritional quality of children's diets. Because few environmental-level interventions have been rigorously evaluated, the evidence base to inform programs and policies is limited. Of concern is the impact that changes to cafeteria offerings will have on participation in school meal programs. This study evaluates school lunch participation in the setting of a year-long middle school cafeteria intervention by examining the association between body mass index (BMI), sociodemographics, and the purchases of school lunch meals. IMOVE meals were healthier choices that met stringent nutritional criteria and were offered alongside standard lunch meals. Students who were overweight had a significantly higher purchase rate for both types of meals compared to those with a healthy BMI. Non-white race, younger age, being male, and low-income status were also significantly associated with participation in school lunch. Results indicate that nutritionally vulnerable students participate in school lunch and are equally likely to buy healthy alternatives or standard meals. This behavioral observation has important implications for school foodservice programs and policies. These results are timely given recent federal legislation to improve the school food environment to influence students' food choice behaviors."
ZACHARY ROSSETTI,Parent and teacher perspectives on friendships and social interactions of secondary students with intellectual and developmental disabilities,"Friendships between students with and without intellectual and developmental disabilities (IDD) remain infrequent, especially at the secondary level. However, when friendships between students with and without IDD have developed, direct support from parents and teachers has been a critical facilitator. Thus, this qualitative study examined parent (n = 10) and teacher (n = 20) perspectives on friendships and social interactions of middle and high school students with IDD receiving special education services in inclusive settings at least part of the day. The data were collected through semi-structured interviews with each participant and analyzed inductively utilizing a multi stage process of open and then thematic coding. The thematic findings suggest that the challenge of friendship development between students with and without IDD is ongoing, though there may be potential in focusing more explicitly and intentionally on increasing social interaction opportunities both in and out of school. Implications for future research and practice are described in the context of supporting students with and without IDD to increase social interactions and develop friendships."
ZACHARY ROSSETTI,Developing collaborative partnerships with culturally and linguistically diverse families during the IEP process,"Family participation in the special education process has been federally mandated for 40 years, and educators recognize that effective collaboration with their students’ families leads to improved academic and social outcomes for students. However, while some family-school relationships are positive and collaborative, many are not, particularly for culturally and linguistically diverse (CLD) families. This article provides practice guidelines based in research for teachers who seek to improve their practices when working with CLD families who have children served by special education."
ZACHARY ROSSETTI,Developing collaborative partnerships with culturally and linguistically diverse families during the IEP process,"Family participation in the special education process has been federally mandated for 40 years, and educators recognize that effective collaboration with their students’ families leads to improved academic and social outcomes for students. However, while some family-school relationships are positive and collaborative, many are not, particularly for culturally and linguistically diverse (CLD) families. This article provides practice guidelines based in research for teachers who seek to improve their practices when working with CLD families who have children served by special education."
ZACHARY ROSSETTI,The nature of friendship between students with and without severe disabilities,"Friendships are developmentally important and personally beneficial relationships for all children and youth. Despite emphasis from families and educators of students with severe disabilities on the importance of promoting and supporting friendships with their typically developing (TD) peers in inclusive settings, such relationships remain infrequent. We conducted an integrative thematic literature review of research that directly examined the nature of friendship between students with and without severe disabilities to better understand how researchers define friendship, identify participants, and confirm participants’ friendships. Implications for future research are discussed. We also sought to identify themes in extant research to guide future intervention. The thematic findings point to the importance of adults providing direct support while fading their proximity to students, and of TD peers negotiating the ongoing tension between the roles of helper and friend."
ZACHARY ROSSETTI,Parent involvement in meaningful post-school experiences for young adults with IDD and pervasive support needs,"Despite initiatives supporting young adults with intellectual and developmental disabilities (IDD) to engage in post-secondary education and integrated employment, those with more intensive support needs are not as easily involved in these post-school experiences. In an effort to learn from positive examples, we examined parent involvement in meaningful post-school experiences by eight young adults with IDD and pervasive support needs. Secondary analysis of data from a prior interview study yielded this smaller sample of eight young adults with meaningful post-school experiences. Their parents were actively involved as fierce advocates and creative problem solvers. The active involvement of parents included: a) attitudinal facilitators, b) advocacy efforts and perceptions, and c) strategic actions. Implications for future research and practice are described."
ZACHARY ROSSETTI,Parent perceptions of time spent meaningfully by young adults with pervasive support needs,"This article describes a qualitative study that examined how 23 young adults with pervasive support needs and limited functional communication spent their time and how their parents (n=23) and direct support professionals (DSPs; n=2) defined meaningfulness in relation to the young adults’ experiences. Data were collected through semi-structured interviews with the parents and DSPs. Findings indicated that most of the young adults spent time in their communities, though typically without friends and not engaged in integrated employment. The participants defined meaningfulness according to three dimensions: community participation, individual indicators, and the nature of activities in the young adults’ schedules. They also described both episodic and ongoing challenges that hindered their ability to focus on time spent meaningfully. Finally, their definitions, which reflected basic care needs and community participation goals, raised questions related to the awareness, availability, and utilization of services and supports in the adult developmental disabilities system."
ZACHARY ROSSETTI,Perspectives about adult sibling relationships: a dyadic analysis of siblings with and without intellectual and developmental disabilities,"Most siblings of individuals with intellectual and developmental disabilities (IDD) report positive sibling relationships. However, extant research often only examines the perspective of the nondisabled sibling; it is unclear whether siblings with IDD report close sibling relationships. Thus, the aim of this study was to understand adult sibling relationships from the perspectives of both siblings with and without IDD. Using dyadic interviews, we examined the perspectives of eight adult sibling dyads. The study was conducted in the United States. Data were analyzed using constant comparative analysis and cross-case analysis to identify themes within and across dyads. Overall, siblings with and without IDD reported enjoying spending time with one another. However, siblings with and without Down syndrome (versus autism spectrum disorder) reported more reciprocal sibling relationships, more frequent contact, and a greater range of shared activities. Implications for future research and practice are discussed."
JOHN FORMAN,High-throughput screening in larval zebrafish identifies novel potent sedative-hypnotics,"BACKGROUND: Many general anesthetics were discovered empirically, but primary screens to find new sedative-hypnotics in drug libraries have not used animals, limiting the types of drugs discovered. The authors hypothesized that a sedative-hypnotic screening approach using zebrafish larvae responses to sensory stimuli would perform comparably to standard assays, and efficiently identify new active compounds. METHODS: The authors developed a binary outcome photomotor response assay for zebrafish larvae using a computerized system that tracked individual motions of up to 96 animals simultaneously. The assay was validated against tadpole loss of righting reflexes, using sedative-hypnotics of widely varying potencies that affect various molecular targets. A total of 374 representative compounds from a larger library were screened in zebrafish larvae for hypnotic activity at 10 µM. Molecular mechanisms of hits were explored in anesthetic-sensitive ion channels using electrophysiology, or in zebrafish using a specific reversal agent. RESULTS: Zebrafish larvae assays required far less drug, time, and effort than tadpoles. In validation experiments, zebrafish and tadpole screening for hypnotic activity agreed 100% (n = 11; P = 0.002), and potencies were very similar (Pearson correlation, r > 0.999). Two reversible and potent sedative-hypnotics were discovered in the library subset. CMLD003237 (EC50, ~11 µM) weakly modulated γ-aminobutyric acid type A receptors and inhibited neuronal nicotinic receptors. CMLD006025 (EC50, ~13 µM) inhibited both N-methyl-D-aspartate and neuronal nicotinic receptors. CONCLUSIONS: Photomotor response assays in zebrafish larvae are a mechanism-independent platform for high-throughput screening to identify novel sedative-hypnotics. The variety of chemotypes producing hypnosis is likely much larger than currently known."
STEPHEN ESPOSITO,"“A grief observed: Tecmessa and her sadness-work in Sophocles’ Ajax” in Looking at Ajax, ed. David Stuttard (Bloomsbury, 2019)",
GREGORY VIGLIANTI,PPARγ and LXR Signaling Inhibit Dendritic Cell-Mediated HIV-1 Capture and trans-Infection,"Dendritic cells (DCs) contribute to human immunodeficiency virus type 1 (HIV-1) transmission and dissemination by capturing and transporting infectious virus from the mucosa to draining lymph nodes, and transferring these virus particles to CD4+ T cells with high efficiency. Toll-like receptor (TLR)-induced maturation of DCs enhances their ability to mediate trans-infection of T cells and their ability to migrate from the site of infection. Because TLR-induced maturation can be inhibited by nuclear receptor (NR) signaling, we hypothesized that ligand-activated NRs could repress DC-mediated HIV-1 transmission and dissemination. Here, we show that ligands for peroxisome proliferator-activated receptor gamma (PPARγ) and liver X receptor (LXR) prevented proinflammatory cytokine production by DCs and inhibited DC migration in response to the chemokine CCL21 by preventing the TLR-induced upregulation of CCR7. Importantly, PPARγ and LXR signaling inhibited both immature and mature DC-mediated trans-infection by preventing the capture of HIV-1 by DCs independent of the viral envelope glycoprotein. PPARγ and LXR signaling induced cholesterol efflux from DCs and led to a decrease in DC-associated cholesterol, which has previously been shown to be required for DC capture of HIV-1. Finally, both cholesterol repletion and the targeted knockdown of the cholesterol transport protein ATP-binding cassette A1 (ABCA1) restored the ability of NR ligand treated cells to capture HIV-1 and transfer it to T cells. Our results suggest that PPARγ and LXR signaling up-regulate ABCA1-mediated cholesterol efflux from DCs and that this accounts for the decreased ability of DCs to capture HIV-1. The ability of NR ligands to repress DC mediated trans-infection, inflammation, and DC migration underscores their potential therapeutic value in inhibiting HIV-1 mucosal transmission. Author SummaryHeterosexual transmission is the primary mode of HIV transmission worldwide. In the absence of an effective vaccine, there is an increasing demand for the development of effective microbicides that block HIV sexual transmission. Dendritic cells (DCs) play a critical role in HIV transmission by efficiently binding virus particles, migrating to lymph nodes, and transmitting them to CD4+ T cells, a process called trans-infection. In addition, DCs secrete proinflammatory cytokines that create a favorable environment for virus replication. DC maturation by pathogen-encoded TLR ligands or proinflammatory cytokines dramatically increases their capacity to capture HIV, migrate to lymphoid tissue, and trans-infect T cells. Here, we report that signaling through the nuclear receptors PPARγ and LXR prevents DC maturation and proinflammatory cytokine production, as well as migration. In addition, PPARγ and LXR signaling prevents efficient DC capture and transfer of infectious HIV by increasing ABCA1-mediated cholesterol efflux. Our studies suggest that PPARγ and LXR may be targets for drugs that can inhibit specific aspects of HIV mucosal transmission, namely inflammation, migration, and virus capture and transfer. These findings provide a rationale for considering PPARγ and LXR agonists as potential combination therapies with conventional anti-viral microbicides that target other aspects of mucosal HIV transmission."
COURTNEY T GOTO,Focus: Spring 2014,
COURTNEY T GOTO,Hybridity: retrieving the real-life messiness erased by a reified concept,
COURTNEY T GOTO,Reflecting theologically by creating art: giving form to more than we can say,
COURTNEY T GOTO,The ubiquity of ignorance: a practical theological challenge of our time,
COURTNEY T GOTO,Create an altar at home: a pandemic invitation,
SARAH PHILLIPS,Collaborating across institutions: Lessons in planning a co-hosted conference,This session discusses the successes and opportunities for improvement from the Boston College/Boston University collaboration to co-host OpenCon 2018 Boston. We hope our experiences will inform how others manage similar events in the future.
SARAH PHILLIPS,Varied effects of algal symbionts on transcription factor NF-κB in a sea anemone and a coral: possible roles in symbiosis and thermotolerance,"Many cnidarians, including the reef-building corals, undergo symbiotic mutualisms with photosynthetic dinoflagellate algae of the family Symbiodiniaceae. These partnerships are sensitive to temperature extremes, which cause symbiont loss and increased coral mortality. Previous studies have implicated host immunity and specifically immunity transcription factor NF-κB as having a role in the maintenance of the cnidarian-algal symbiosis. Here we have further investigated a possible role for NF-κB in establishment and loss of symbiosis in various strains of the anemone Exaiptasia (Aiptasia) and in the coral Pocillopora damicornis. Our results show that NF-κB expression is reduced in Aiptasia larvae and adults that host certain algae strains. Treatment of Aiptasia larvae with a known symbiosis-promoting cytokine, transforming growth factor β, also led to decreased NF-κB expression. We also show that aposymbiotic Aiptasia (with high NF-κB expression) have increased survival following infection with the pathogenic bacterium Serratia marcescens as compared to symbiotic Aiptasia (low NF-κB expression). Furthermore, a P. damicornis coral colony hosting Durusdinium spp. (formerly clade D) symbionts had higher basal NF-κB expression and decreased heat-induced bleaching as compared to two individuals hosting Cladocopium spp. (formerly clade C) symbionts. Lastly, genome-wide gene expression profiling and genomic promoter analysis identified putative NF-κB target genes that may be involved in thermal bleaching, symbiont maintenance, and/or immune protection in P. damicornis. Our results provide further support for the hypothesis that modulation of NF-κB and immunity plays a role in some, but perhaps not all, cnidarian-Symbiodiniaceae partnerships as well as in resistance to pathogens and bleaching."
RICHARD E RYAN,First M87 Event Horizon Telescope results. III. Data processing and calibration,"We present the calibration and reduction of Event Horizon Telescope (EHT) 1.3 mm radio wavelength observations of the supermassive black hole candidate at the center of the radio galaxy M87 and the quasar 3C 279, taken during the 2017 April 5–11 observing campaign. These global very long baseline interferometric observations include for the first time the highly sensitive Atacama Large Millimeter/submillimeter Array (ALMA); reaching an angular resolution of 25 μas, with characteristic sensitivity limits of ~1 mJy on baselines to ALMA and ~10 mJy on other baselines. The observations present challenges for existing data processing tools, arising from the rapid atmospheric phase fluctuations, wide recording bandwidth, and highly heterogeneous array. In response, we developed three independent pipelines for phase calibration and fringe detection, each tailored to the specific needs of the EHT. The final data products include calibrated total intensity amplitude and phase information. They are validated through a series of quality assurance tests that show consistency across pipelines and set limits on baseline systematic errors of 2% in amplitude and 1° in phase. The M87 data reveal the presence of two nulls in correlated flux density at ~3.4 and ~8.3 Gλ and temporal evolution in closure quantities, indicating intrinsic variability of compact structure on a timescale of days, or several light-crossing times for a few billion solar-mass black hole. These measurements provide the first opportunity to image horizon-scale structure in M87."
RICHARD E RYAN,First M87 Event Horizon Telescope results. V. Physical origin of the asymmetric ring,"The Event Horizon Telescope (EHT) has mapped the central compact radio source of the elliptical galaxy M87 at 1.3 mm with unprecedented angular resolution. Here we consider the physical implications of the asymmetric ring seen in the 2017 EHT data. To this end, we construct a large library of models based on general relativistic magnetohydrodynamic (GRMHD) simulations and synthetic images produced by general relativistic ray tracing. We compare the observed visibilities with this library and confirm that the asymmetric ring is consistent with earlier predictions of strong gravitational lensing of synchrotron emission from a hot plasma orbiting near the black hole event horizon. The ring radius and ring asymmetry depend on black hole mass and spin, respectively, and both are therefore expected to be stable when observed in future EHT campaigns. Overall, the observed image is consistent with expectations for the shadow of a spinning Kerr black hole as predicted by general relativity. If the black hole spin and M87's large scale jet are aligned, then the black hole spin vector is pointed away from Earth. Models in our library of non-spinning black holes are inconsistent with the observations as they do not produce sufficiently powerful jets. At the same time, in those models that produce a sufficiently powerful jet, the latter is powered by extraction of black hole spin energy through mechanisms akin to the Blandford-Znajek process. We briefly consider alternatives to a black hole for the central compact object. Analysis of existing EHT polarization data and data taken simultaneously at other wavelengths will soon enable new tests of the GRMHD models, as will future EHT campaigns at 230 and 345 GHz."
RICHARD E RYAN,First M87 Event Horizon Telescope results. VI. The shadow and mass of the central black hole,"We present measurements of the properties of the central radio source in M87 using Event Horizon Telescope data obtained during the 2017 campaign. We develop and fit geometric crescent models (asymmetric rings with interior brightness depressions) using two independent sampling algorithms that consider distinct representations of the visibility data. We show that the crescent family of models is statistically preferred over other comparably complex geometric models that we explore. We calibrate the geometric model parameters using general relativistic magnetohydrodynamic (GRMHD) models of the emission region and estimate physical properties of the source. We further fit images generated from GRMHD models directly to the data. We compare the derived emission region and black hole parameters from these analyses with those recovered from reconstructed images. There is a remarkable consistency among all methods and data sets. We find that >50% of the total flux at arcsecond scales comes from near the horizon, and that the emission is dramatically suppressed interior to this region by a factor >10, providing direct evidence of the predicted shadow of a black hole. Across all methods, we measure a crescent diameter of 42 ± 3 μas and constrain its fractional width to be <0.5. Associating the crescent feature with the emission surrounding the black hole shadow, we infer an angular gravitational radius of GM/Dc^2 = 3.8 ± 0.4 μas. Folding in a distance measurement of {16.8}_{-0.7}^{+0.8}{Mpc} gives a black hole mass of M = 6.5 ± 0.2{| }_{stat} ± 0.7{| }_{sys} × {10}^{9} {M}_{odot }. This measurement from lensed emission near the event horizon is consistent with the presence of a central Kerr black hole, as predicted by the general theory of relativity."
RICHARD E RYAN,The Event Horizon general relativistic magnetohydrodynamic code comparison project,"Recent developments in compact object astrophysics, especially the discovery of merging neutron stars by LIGO, the imaging of the black hole in M87 by the Event Horizon Telescope, and high- precision astrometry of the Galactic Center at close to the event horizon scale by the GRAVITY experiment motivate the development of numerical source models that solve the equations of general relativistic magnetohydrodynamics (GRMHD). Here we compare GRMHD solutions for the evolution of a magnetized accretion flow where turbulence is promoted by the magnetorotational instability from a set of nine GRMHD codes: Athena++, BHAC, Cosmos++, ECHO, H-AMR, iharm3D, HARM-Noble, IllinoisGRMHD, and KORAL. Agreement among the codes improves as resolution increases, as measured by a consistently applied, specially developed set of code performance metrics. We conclude that the community of GRMHD codes is mature, capable, and consistent on these test problems."
RICHARD E RYAN,Gravitational test beyond the first post-Newtonian order with the shadow of the M87 black hole,"The 2017 Event Horizon Telescope (EHT) observations of the central source in M87 have led to the first measurement of the size of a black-hole shadow. This observation offers a new and clean gravitational test of the black-hole metric in the strong-field regime. We show analytically that spacetimes that deviate from the Kerr metric but satisfy weak-field tests can lead to large deviations in the predicted black-hole shadows that are inconsistent with even the current EHT measurements. We use numerical calculations of regular, parametric, non-Kerr metrics to identify the common characteristic among these different parametrizations that control the predicted shadow size. We show that the shadow-size measurements place significant constraints on deviation parameters that control the second post-Newtonian and higher orders of each metric and are, therefore, inaccessible to weak-field tests. The new constraints are complementary to those imposed by observations of gravitational waves from stellar-mass sources."
RICHARD E RYAN,Monitoring the mmorphology of M87* in 2009–2017 with the Event Horizon Telescope,"The Event Horizon Telescope (EHT) has recently delivered the first resolved images of M87*, the supermassive black hole in the center of the M87 galaxy. These images were produced using 230 GHz observations performed in April 2017. Additional observations are required to investigate the persistence of the primary image feature – a ring with azimuthal brightness asymmetry – and to quantify the image variability on event horizon scales. To address this need, we analyze M87* data collected with prototype EHT arrays in 2009, 2011, 2012, and 2013. While these observations do not contain enough information to produce images, they are sufficient to constrain simple geometric models. We develop a modeling approach based on the framework utilized for the 2017 EHT data analysis and validate our procedures using synthetic data. Applying the same approach to the observational data sets, we find the M87* morphology in 2009–2017 to be consistent with a persistent asymmetric ring of 40 as diameter. The position angle of peak intensity varies in time. In particular, we find a significant difference between the position angle measured in 2013 and 2017. These variations are in broad agreement with predictions of a subset of general relativistic magnetohydrodynamic simulations. We show that quantifying the variability across multiple observational epochs has the potential to constrain physical properties of the source, such as the accretion state or the black hole spin."
RICHARD E RYAN,THEMIS: a parameter estimation framework for the Event Horizon Telescope,"The Event Horizon Telescope (EHT) provides the unprecedented ability to directly resolve the structure and dynamics of black hole emission regions on scales smaller than their horizons. This has the potential to critically probe the mechanisms by which black holes accrete and launch outflows, and the structure of supermassive black hole spacetimes. However, accessing this information is a formidable analysis challenge for two reasons. First, the EHT natively produces a variety of data types that encode information about the image structure in nontrivial ways; these are subject to a variety of systematic effects associated with very long baseline interferometry and are supplemented by a wide variety of auxiliary data on the primary EHT targets from decades of other observations. Second, models of the emission regions and their interaction with the black hole are complex, highly uncertain, and computationally expensive to construct. As a result, the scientific utilization of EHT observations requires a flexible, extensible, and powerful analysis framework. We present such a framework, Themis, which defines a set of interfaces between models, data, and sampling algorithms that facilitates future development. We describe the design and currently existing components of Themis, how Themis has been validated thus far, and present additional analyses made possible by Themis that illustrate its capabilities. Importantly, we demonstrate that Themis is able to reproduce prior EHT analyses, extend these, and do so in a computationally efficient manner that can efficiently exploit modern high-performance computing facilities. Themis has already been used extensively in the scientific analysis and interpretation of the first EHT observations of M87."
RICHARD E RYAN,"Cosmology intertwined: a review of the particle physics, astrophysics, and cosmology associated with the cosmological tensions and anomalies",
RICHARD E RYAN,"First Sagittarius A* Event Horizon Telescope results. II. EHT and multiwavelength observations, data processing, and calibration","We present Event Horizon Telescope (EHT) 1.3 mm measurements of the radio source located at the position of the supermassive black hole Sagittarius A* (Sgr A*), collected during the 2017 April 5–11 campaign. The observations were carried out with eight facilities at six locations across the globe. Novel calibration methods are employed to account for Sgr A*'s flux variability. The majority of the 1.3 mm emission arises from horizon scales, where intrinsic structural source variability is detected on timescales of minutes to hours. The effects of interstellar scattering on the image and its variability are found to be subdominant to intrinsic source structure. The calibrated visibility amplitudes, particularly the locations of the visibility minima, are broadly consistent with a blurred ring with a diameter of ∼50 μas, as determined in later works in this series. Contemporaneous multiwavelength monitoring of Sgr A* was performed at 22, 43, and 86 GHz and at near-infrared and X-ray wavelengths. Several X-ray flares from Sgr A* are detected by Chandra, one at low significance jointly with Swift on 2017 April 7 and the other at higher significance jointly with NuSTAR on 2017 April 11. The brighter April 11 flare is not observed simultaneously by the EHT but is followed by a significant increase in millimeter flux variability immediately after the X-ray outburst, indicating a likely connection in the emission physics near the event horizon. We compare Sgr A*’s broadband flux during the EHT campaign to its historical spectral energy distribution and find that both the quiescent emission and flare emission are consistent with its long-term behavior."
RICHARD E RYAN,Broadband multi-wavelength properties of M87 during the 2017 Event Horizon Telescope campaign,"In 2017, the Event Horizon Telescope (EHT) Collaboration succeeded in capturing the first direct image of the center of the M87 galaxy. The asymmetric ring morphology and size are consistent with theoretical expectations for a weakly accreting supermassive black hole of mass ∼6.5 × 109 M ⊙. The EHTC also partnered with several international facilities in space and on the ground, to arrange an extensive, quasi-simultaneous multi-wavelength campaign. This Letter presents the results and analysis of this campaign, as well as the multi-wavelength data as a legacy data repository. We captured M87 in a historically low state, and the core flux dominates over HST-1 at high energies, making it possible to combine core flux constraints with the more spatially precise very long baseline interferometry data. We present the most complete simultaneous multi-wavelength spectrum of the active nucleus to date, and discuss the complexity and caveats of combining data from different spatial scales into one broadband spectrum. We apply two heuristic, isotropic leptonic single-zone models to provide insight into the basic source properties, but conclude that a structured jet is necessary to explain M87’s spectrum. We can exclude that the simultaneous γ-ray emission is produced via inverse Compton emission in the same region producing the EHT mm-band emission, and further conclude that the γ-rays can only be produced in the inner jets (inward of HST-1) if there are strongly particle-dominated regions. Direct synchrotron emission from accelerated protons and secondaries cannot yet be excluded."
RICHARD E RYAN,Event Horizon Telescope imaging of the archetypal blazar 3C 279 at an extreme 20 microarcsecond resolution,"3C 279 is an archetypal blazar with a prominent radio jet that show broadband flux density variability across the entire electromagnetic spectrum. We use an ultra-high angular resolution technique – global Very Long Baseline Interferometry (VLBI) at 1.3 mm (230 GHz) – to resolve the innermost jet of 3C 279 in order to study its fine-scale morphology close to the jet base where highly variable γ-ray emission is thought to originate, according to various models. The source was observed during four days in April 2017 with the Event Horizon Telescope at 230 GHz, including the phased Atacama Large Millimeter/submillimeter Array (ALMA), at an angular resolution of ∼20 μas (at a redshift of z = 0.536 this corresponds to ∼0.13 pc  ∼ 1700 Schwarzschild radii with a black hole mass M<jats:sub>BH</jats:sub> = 8 × 10^8 M_⊙). Imaging and model-fitting techniques were applied to the data to parameterize the fine-scale source structure and its variation. We find a multicomponent inner jet morphology with the northernmost component elongated perpendicular to the direction of the jet, as imaged at longer wavelengths. The elongated nuclear structure is consistent on all four observing days and across different imaging methods and model-fitting techniques, and therefore appears robust. Owing to its compactness and brightness, we associate the northern nuclear structure as the VLBI “core”. This morphology can be interpreted as either a broad resolved jet base or a spatially bent jet. We also find significant day-to-day variations in the closure phases, which appear most pronounced on the triangles with the longest baselines. Our analysis shows that this variation is related to a systematic change of the source structure. Two inner jet components move non-radially at apparent speeds of ∼15 c and ∼20 c (∼1.3 and ∼1.7 μas day^−1, respectively), which more strongly supports the scenario of traveling shocks or instabilities in a bent, possibly rotating jet. The observed apparent speeds are also coincident with the 3C 279 large-scale jet kinematics observed at longer (cm) wavelengths, suggesting no significant jet acceleration between the 1.3 mm core and the outer jet. The intrinsic brightness temperature of the jet components are ≲10^10 K, a magnitude or more lower than typical values seen at ≥7 mm wavelengths. The low brightness temperature and morphological complexity suggest that the core region of 3C 279 becomes optically thin at short (mm) wavelengths."
RICHARD E RYAN,First M87 Event Horizon Telescope results. II. Array and instrumentation,"The Event Horizon Telescope (EHT) is a very long baseline interferometry (VLBI) array that comprises millimeter- and submillimeter-wavelength telescopes separated by distances comparable to the diameter of the Earth. At a nominal operating wavelength of ~1.3 mm, EHT angular resolution (λ/D) is ~25 μas, which is sufficient to resolve nearby supermassive black hole candidates on spatial and temporal scales that correspond to their event horizons. With this capability, the EHT scientific goals are to probe general relativistic effects in the strong-field regime and to study accretion and relativistic jet formation near the black hole boundary. In this Letter we describe the system design of the EHT, detail the technology and instrumentation that enable observations, and provide measures of its performance. Meeting the EHT science objectives has required several key developments that have facilitated the robust extension of the VLBI technique to EHT observing wavelengths and the production of instrumentation that can be deployed on a heterogeneous array of existing telescopes and facilities. To meet sensitivity requirements, high-bandwidth digital systems were developed that process data at rates of 64 gigabit s−1, exceeding those of currently operating cm-wavelength VLBI arrays by more than an order of magnitude. Associated improvements include the development of phasing systems at array facilities, new receiver installation at several sites, and the deployment of hydrogen maser frequency standards to ensure coherent data capture across the array. These efforts led to the coordination and execution of the first Global EHT observations in 2017 April, and to event-horizon-scale imaging of the supermassive black hole candidate in M87."
RICHARD E RYAN,First M87 Event Horizon Telescope results. I. The shadow of the supermassive black hole,"When surrounded by a transparent emission region, black holes are expected to reveal a dark shadow caused by gravitational light bending and photon capture at the event horizon. To image and study this phenomenon, we have assembled the Event Horizon Telescope, a global very long baseline interferometry array observing at a wavelength of 1.3 mm. This allows us to reconstruct event-horizon-scale images of the supermassive black hole candidate in the center of the giant elliptical galaxy M87. We have resolved the central compact radio source as an asymmetric bright emission ring with a diameter of 42 ± 3 μas, which is circular and encompasses a central depression in brightness with a flux ratio gsim10:1. The emission ring is recovered using different calibration and imaging schemes, with its diameter and width remaining stable over four different observations carried out in different days. Overall, the observed image is consistent with expectations for the shadow of a Kerr black hole as predicted by general relativity. The asymmetry in brightness in the ring can be explained in terms of relativistic beaming of the emission from a plasma rotating close to the speed of light around a black hole. We compare our images to an extensive library of ray-traced general-relativistic magnetohydrodynamic simulations of black holes and derive a central mass of M = (6.5 ± 0.7) × 10^9 M ⊙. Our radio-wave observations thus provide powerful evidence for the presence of supermassive black holes in centers of galaxies and as the central engines of active galactic nuclei. They also present a new tool to explore gravity in its most extreme limit and on a mass scale that was so far not accessible."
RICHARD E RYAN,Taking the pulse of Earth's tropical forests using networks of highly distributed plots,"Tropical forests are the most diverse and productive ecosystems on Earth. While better understanding of these forests is critical for our collective future, until quite recently efforts to measure and monitor them have been largely disconnected. Networking is essential to discover the answers to questions that transcend borders and the horizons of funding agencies. Here we show how a global community is responding to the challenges of tropical ecosystem research with diverse teams measuring forests tree-by-tree in thousands of long-term plots. We review the major scientific discoveries of this work and show how this process is changing tropical forest science. Our core approach involves linking long-term grassroots initiatives with standardized protocols and data management to generate robust scaled-up results. By connecting tropical researchers and elevating their status, our Social Research Network model recognises the key role of the data originator in scientific discovery. Conceived in 1999 with RAINFOR (South America), our permanent plot networks have been adapted to Africa (AfriTRON) and Southeast Asia (T-FORCES) and widely emulated worldwide. Now these multiple initiatives are integrated via ForestPlots.net cyber-infrastructure, linking colleagues from 54 countries across 24 plot networks. Collectively these are transforming understanding of tropical forests and their biospheric role. Together we have discovered how, where and why forest carbon and biodiversity are responding to climate change, and how they feedback on it. This long-term pan-tropical collaboration has revealed a large long-term carbon sink and its trends, as well as making clear which drivers are most important, which forest processes are affected, where they are changing, what the lags are, and the likely future responses of tropical forests as the climate continues to change. By leveraging a remarkably old technology, plot networks are sparking a very modern revolution in tropical forest science. In the future, humanity can benefit greatly by nurturing the grassroots communities now collectively capable of generating unique, long-term understanding of Earth's most precious forests."
RICHARD E RYAN,Reproductive inequality in humans and other mammals,"To address claims of human exceptionalism, we determine where humans fit within the greater mammalian distribution of reproductive inequality. We show that humans exhibit lower reproductive skew (i.e., inequality in the number of surviving offspring) among males and smaller sex differences in reproductive skew than most other mammals, while nevertheless falling within the mammalian range. Additionally, female reproductive skew is higher in polygynous human populations than in polygynous nonhumans mammals on average. This patterning of skew can be attributed in part to the prevalence of monogamy in humans compared to the predominance of polygyny in nonhuman mammals, to the limited degree of polygyny in the human societies that practice it, and to the importance of unequally held rival resources to women's fitness. The muted reproductive inequality observed in humans appears to be linked to several unusual characteristics of our species-including high levels of cooperation among males, high dependence on unequally held rival resources, complementarities between maternal and paternal investment, as well as social and legal institutions that enforce monogamous norms."
RICHARD E RYAN,First Sagittarius A* Event Horizon Telescope results. I. The shadow of the supermassive black hole in the center of the Milky Way,"We present the first Event Horizon Telescope (EHT) observations of Sagittarius A* (Sgr A*), the Galactic center source associated with a supermassive black hole. These observations were conducted in 2017 using a global interferometric array of eight telescopes operating at a wavelength of λ = 1.3 mm. The EHT data resolve a compact emission region with intrahour variability. A variety of imaging and modeling analyses all support an image that is dominated by a bright, thick ring with a diameter of 51.8 ± 2.3 μas (68% credible interval). The ring has modest azimuthal brightness asymmetry and a comparatively dim interior. Using a large suite of numerical simulations, we demonstrate that the EHT images of Sgr A* are consistent with the expected appearance of a Kerr black hole with mass ∼4 × 106 M ⊙, which is inferred to exist at this location based on previous infrared observations of individual stellar orbits, as well as maser proper-motion studies. Our model comparisons disfavor scenarios where the black hole is viewed at high inclination (i &gt; 50°), as well as nonspinning black holes and those with retrograde accretion disks. Our results provide direct evidence for the presence of a supermassive black hole at the center of the Milky Way, and for the first time we connect the predictions from dynamical measurements of stellar orbits on scales of 103–105 gravitational radii to event-horizon-scale images and variability. Furthermore, a comparison with the EHT results for the supermassive black hole M87* shows consistency with the predictions of general relativity spanning over three orders of magnitude in central mass."
RICHARD E RYAN,The long-baseline neutrino experiment: exploring fundamental symmetries of the universe,"The preponderance of matter over antimatter in the early Universe, the dynamics of the supernova bursts that produced the heavy elements necessary for life and whether protons eventually decay --- these mysteries at the forefront of particle physics and astrophysics are key to understanding the early evolution of our Universe, its current state and its eventual fate. The Long-Baseline Neutrino Experiment (LBNE) represents an extensively developed plan for a world-class experiment dedicated to addressing these questions. LBNE is conceived around three central components: (1) a new, high-intensity neutrino source generated from a megawatt-class proton accelerator at Fermi National Accelerator Laboratory, (2) a near neutrino detector just downstream of the source, and (3) a massive liquid argon time-projection chamber deployed as a far detector deep underground at the Sanford Underground Research Facility. This facility, located at the site of the former Homestake Mine in Lead, South Dakota, is approximately 1,300 km from the neutrino source at Fermilab -- a distance (baseline) that delivers optimal sensitivity to neutrino charge-parity symmetry violation and mass ordering effects. This ambitious yet cost-effective design incorporates scalability and flexibility and can accommodate a variety of upgrades and contributions. With its exceptional combination of experimental configuration, technical capabilities, and potential for transformative discoveries, LBNE promises to be a vital facility for the field of particle physics worldwide, providing physicists from around the globe with opportunities to collaborate in a twenty to thirty year program of exciting science. In this document we provide a comprehensive overview of LBNE's scientific objectives, its place in the landscape of neutrino physics worldwide, the technologies it will incorporate and the capabilities it will possess."
JONATHAN RIBNER,L'Année terrible Viewed by John Tenniel,
JONATHAN RIBNER,"John Ruskin, Philip Henry Gosse, William Dyce, and the contemplation of time at midcentury",
JONATHAN RIBNER,Resistance and persistence: on the fortunes and reciprocal international influences of French romanticism,"Resistance and Persistence: On the Fortunes and Reciprocal International Influences of French Romanticism Abstract This article addresses ambivalence toward Romanticism on the part of Romantic artists and writers active in France - a group that includes Heinrich Heine, Eugène Delacroix, Alfred de Musset and Théophile Gautier. In counterpoint, the argument sets forth the persistence of the Romantic legacy in the work of the ostensibly anti-Romantic Gustave Courbet. I contend that the unease of Romantics vis-à-vis Romanticism is inseparable from their quixotic quest to transgress convention; that, in the face of negation and ridicule, signal characteristics of the movement endured, affecting the outlook of even its most bitter enemies (e.g., the Catholic royalist writers associated with the paper L'Action française and their admirer, the London art critic and philosopher T.E. Hulme); that, in the art of Van Gogh and Rodin, new life was breathed into Romanticism through contact with its ostensible opposite, Realism; and that Romanticism continued to speak to the concerns of artists active long after the mid-nineteenth century. I conclude with a consideration of how the negative view of Romantic pathos fostered by twentieth-century Formalism has been challenged, since the 1950s, by revisionist art historians."
JONATHAN RIBNER,"Jonathan P. Ribner, book review of Narrative Painting in Nineteenth-Century Europe by Nina Lübbren, Nineteenth-Century Art Worldwide 22, no. 2 (Autumn 2023)",
ANNE G. SHORT,High time for conservation: adding the environment to the debate on marijuana liberalization,"The liberalization of marijuana policies, including the legalization of medical and recreational marijuana, is sweeping the United States and other countries. Marijuana cultivation can have significant negative collateral effects on the environment that are often unknown or overlooked. Focusing on the state of California, where by some estimates 60%–70% of the marijuana consumed in the United States is grown, we argue that (a) the environmental harm caused by marijuana cultivation merits a direct policy response, (b) current approaches to governing the environmental effects are inadequate, and (c) neglecting discussion of the environmental impacts of cultivation when shaping future marijuana use and possession policies represents a missed opportunity to reduce, regulate, and mitigate environmental harm."
ANNE G. SHORT,Multiple Independent Loci at Chromosome 15q25.1 Affect Smoking Quantity: a Meta-Analysis and Comparison with Lung Cancer and COPD,"Recently, genetic association findings for nicotine dependence, smoking behavior, and smoking-related diseases converged to implicate the chromosome 15q25.1 region, which includes the CHRNA5-CHRNA3-CHRNB4 cholinergic nicotinic receptor subunit genes. In particular, association with the nonsynonymous CHRNA5 SNP rs16969968 and correlates has been replicated in several independent studies. Extensive genotyping of this region has suggested additional statistically distinct signals for nicotine dependence, tagged by rs578776 and rs588765. One goal of the Consortium for the Genetic Analysis of Smoking Phenotypes (CGASP) is to elucidate the associations among these markers and dichotomous smoking quantity (heavy versus light smoking), lung cancer, and chronic obstructive pulmonary disease (COPD). We performed a meta-analysis across 34 datasets of European-ancestry subjects, including 38,617 smokers who were assessed for cigarettes-per-day, 7,700 lung cancer cases and 5,914 lung-cancer-free controls (all smokers), and 2,614 COPD cases and 3,568 COPD-free controls (all smokers). We demonstrate statistically independent associations of rs16969968 and rs588765 with smoking (mutually adjusted p-values<10−35 and >10−8 respectively). Because the risk alleles at these loci are negatively correlated, their association with smoking is stronger in the joint model than when each SNP is analyzed alone. Rs578776 also demonstrates association with smoking after adjustment for rs16969968 (p<10−6). In models adjusting for cigarettes-per-day, we confirm the association between rs16969968 and lung cancer (p<10−20) and observe a nominally significant association with COPD (p = 0.01); the other loci are not significantly associated with either lung cancer or COPD after adjusting for rs16969968. This study provides strong evidence that multiple statistically distinct loci in this region affect smoking behavior. This study is also the first report of association between rs588765 (and correlates) and smoking that achieves genome-wide significance; these SNPs have previously been associated with mRNA levels of CHRNA5 in brain and lung tissue. Author Summary Nicotine binds to cholinergic nicotinic receptors, which are composed of a variety of subunits. Genetic studies for smoking behavior and smoking-related diseases have implicated a genomic region that encodes the alpha5, alpha3, and beta4 subunits. We examined genetic data across this region for over 38,000 smokers, a subset of which had been assessed for lung cancer or chronic obstructive pulmonary disease. We demonstrate strong evidence that there are at least two statistically independent loci in this region that affect risk for heavy smoking. One of these loci represents a change in the protein structure of the alpha5 subunit. This work is also the first to report strong evidence of association between smoking and a group of genetic variants that are of biological interest because of their links to expression of the alpha5 cholinergic nicotinic receptor subunit gene. These advances in understanding the genetic influences on smoking behavior are important because of the profound public health burdens caused by smoking and nicotine addiction."
NICOLETTE MANGLOS WEBER,Congregants and citizens: religious membership and naturalization among U.S. immigrants,"Scholars and pundits have long debated whether religion helps new immigrants integrate politically in the United States. Those who see religion as an integrative institution cite the country’s history of vibrant religious congregationalism that supports connections between the native and foreign born, while critics point to anti-immigrant hostility, Christian nationalism, and patterns of religious membership that can reinforce social segregation. This article aims to adjudicate this debate, using a large sample of survey data, the New Immigrant Survey (NIS), fielded among new legal residents in 2003/2004. I find that religious membership is associated with increased probability of naturalizing in a short (3.5–7 years) timeframe and is stronger for those with greater human capital and income and longer tenure in the United States. Involvement in US-origin congregations also exhibits a stronger effect on naturalization than involvement in national-origin congregations. Additionally, I find that religious minorities, though less likely to be members of congregations, are independently more likely than Christian immigrants to naturalize in the same timeframe. These results are interpreted as support for a view of organized religion as a setting for American identity formation and a basis for mobilizing resources in response to anti-immigrant sentiment. For certain groups, organized religion seems to support a type of selective acculturation that combines American citizenship with the establishment and/or retention of a distinct ethno-religious identity. The article thus affirms, with caveats, the broader relevance of a long tradition of ethnographic scholarship on immigrant religion in the United States."
NICOLETTE MANGLOS WEBER,"Expanding the reflexive space: resilient young adults, institutional cultures, and cognitive schemas","For many U.S. young adults, being resilient to stressful events hinges on making meaning of such events and thereby minimizing their negative emotional impact. Yet why are some better able to do this than others? In this study, which uses an innovative outlier sampling strategy and linked survey and interview data, we argue that one important factor is connection to institutional cultures associated with higher education, religion/spirituality, and the military. Such cultures provide material for the development of cognitive schemas that can be adopted and applied to their stressful experiences, which include narratives of social progress, divine providence, and self‐discipline. Using a metaphor adapted from the pragmatist philosopher Charles Sanders Peirce, we argue the resulting schemas have the effect of “expanding the space” of reflexive thought, providing new cognitive material for interpreting stress and supporting resilience. Finally, we argue this framing improves in several ways on the concept of meaning making often used in stress process research."
DANIEL P MILLER,Shared and distinct transcriptomic cell types across neocortical areas,"The neocortex contains a multitude of cell types that are segregated into layers and functionally distinct areas. To investigate the diversity of cell types across the mouse neocortex, here we analysed 23,822 cells from two areas at distant poles of the mouse neocortex: the primary visual cortex and the anterior lateral motor cortex. We define 133 transcriptomic cell types by deep, single-cell RNA sequencing. Nearly all types of GABA (γ-aminobutyric acid)-containing neurons are shared across both areas, whereas most types of glutamatergic neurons were found in one of the two areas. By combining single-cell RNA sequencing and retrograde labelling, we match transcriptomic types of glutamatergic neurons to their long-range projection specificity. Our study establishes a combined transcriptomic and projectional taxonomy of cortical cell types from functionally distinct areas of the adult mouse cortex."
DANIEL P MILLER,Father involvement and socioeconomic disparities in child academic outcomes,"OBJECTIVE This article explores whether father involvement can reduce socioeconomic disparities in child academic outcomes. BACKGROUND An emerging body of literature points to the benefits to children of involvement by low‐socioeconomic status (SES) fathers. Research has not systematically investigated whether differences in father involvement can account for SES‐based disparities in child outcomes. METHOD This study used data from 12,030 unique children from the 1998 Early Childhood Longitudinal Study. Using multiple regression models and novel simulation analyses, it investigated whether accounting for SES‐based differences in either the amount or effect of involvement by biological fathers explains gaps in reading scores, math scores, and rates of grade retention between low‐SES and high‐SES children. RESULTS Father residence, resident father school involvement, and a comprehensive index of nonresident father involvement were associated with better child academic outcomes. Associations between residence and nonresident father involvement and child outcomes were consistent for fathers in all SES quintiles. School involvement by low‐SES resident fathers was more beneficial than involvement by the highest SES fathers. Simulation analyses indicated that increasing the amount of involvement by low‐SES fathers to that of high‐SES fathers would result in minimal decreases in SES disparities in reading and math scores, but more sizeable decreases in rates of grade retention. CONCLUSION Increasing some types of father involvement may help to narrow academic gaps between low‐ and high‐SES children."
DANIEL P MILLER,Food insecurity in veteran households: findings from nationally representative data,"OBJECTIVE: The present study is the first to use nationally representative data to compare rates of food insecurity among households with veterans of the US Armed Forces and non-veteran households. DESIGN: We used data from the 2005-2013 waves of the Current Population Survey - Food Security Supplement to identify rates of food insecurity and very low food security in veteran and non-veteran households. We estimated the odds and probability of food insecurity in veteran and non-veteran households in uncontrolled and controlled models. We replicated these results after separating veteran households by their most recent period of service. We weighted models to create nationally representative estimates. SETTING: Nationally representative data from the 2005-2013 waves of the Current Population Survey - Food Security Supplement. SUBJECTS: US households (n 388 680). RESULTS: Uncontrolled models found much lower rates of food insecurity (8·4 %) and very low food security (3·3 %) among veteran households than in non-veteran households (14·4 % and 5·4 %, respectively), with particularly low rates among households with older veterans. After adjustment, average rates of food insecurity and very low food security were not significantly different for veteran households. However, the probability of food insecurity was significantly higher among some recent veterans and significantly lower for those who served during the Vietnam War. CONCLUSIONS: Although adjusting eliminated many differences between veteran and non-veteran households, veterans who served from 1975 and onwards may be at higher risk for food insecurity and should be the recipients of targeted outreach to improve nutritional outcomes."
DANIEL P MILLER,"Caribbean Corals in Crisis: Record Thermal Stress, Bleaching, and Mortality in 2005","BACKGROUND. The rising temperature of the world's oceans has become a major threat to coral reefs globally as the severity and frequency of mass coral bleaching and mortality events increase. In 2005, high ocean temperatures in the tropical Atlantic and Caribbean resulted in the most severe bleaching event ever recorded in the basin. METHODOLOGY/PRINCIPAL FINDINGS. Satellite-based tools provided warnings for coral reef managers and scientists, guiding both the timing and location of researchers' field observations as anomalously warm conditions developed and spread across the greater Caribbean region from June to October 2005. Field surveys of bleaching and mortality exceeded prior efforts in detail and extent, and provided a new standard for documenting the effects of bleaching and for testing nowcast and forecast products. Collaborators from 22 countries undertook the most comprehensive documentation of basin-scale bleaching to date and found that over 80% of corals bleached and over 40% died at many sites. The most severe bleaching coincided with waters nearest a western Atlantic warm pool that was centered off the northern end of the Lesser Antilles. CONCLUSIONS/SIGNIFICANCE. Thermal stress during the 2005 event exceeded any observed from the Caribbean in the prior 20 years, and regionally-averaged temperatures were the warmest in over 150 years. Comparison of satellite data against field surveys demonstrated a significant predictive relationship between accumulated heat stress (measured using NOAA Coral Reef Watch's Degree Heating Weeks) and bleaching intensity. This severe, widespread bleaching and mortality will undoubtedly have long-term consequences for reef ecosystems and suggests a troubled future for tropical marine ecosystems under a warming climate."
DANIEL P MILLER,Overeating and binge eating among immigrants in the United States: new terrain for the healthy immigrant hypothesis,"BACKGROUND: Prior research indicates that, compared to individuals born in the United States (US), immigrants are less likely to experience mental health and inhibitory control problems. However, our understanding of overeating and binge eating-both related to mental health and inhibitory control-among immigrants in the US remains limited. Drawing from a large national study, we report the prevalence of overeating and binge eating among immigrants vis-à-vis the US-born. METHODS: The data source used for the present study is the National Epidemiologic Survey on Alcohol and Related Conditions (NESARC-III, 2012-2013), a nationally representative survey of 36,309 civilian, non-institutionalized adults ages 18 and older in the US. Logistic regression was employed to examine the relationship between immigrant status and key outcomes. RESULTS: The prevalence of any (immigrants = 7.8%, US-born = 17.0%) and recurrent overeating (immigrants = 2.9%, US-born = 5.3%) was lower among immigrants than US-born individuals. Among those reporting recurrent overeating, the prevalence of binge eating with loss of control was comparable among immigrant (37.2%) and US-born participants (39.9%), in general. However, stratified analyses revealed that risk of binge eating with loss of control was lower among immigrant women compared to US-born women (AOR 0.54, 95% CI 0.29-0.98). CONCLUSIONS: Findings from the present study provide clear results that immigrants are substantially less likely to overeat as compared to US-born individuals and that, among women but not men, immigrant status is associated with lower risk of binge eating with loss of control."
DANIEL P MILLER,The long-baseline neutrino experiment: exploring fundamental symmetries of the universe,"The preponderance of matter over antimatter in the early Universe, the dynamics of the supernova bursts that produced the heavy elements necessary for life and whether protons eventually decay --- these mysteries at the forefront of particle physics and astrophysics are key to understanding the early evolution of our Universe, its current state and its eventual fate. The Long-Baseline Neutrino Experiment (LBNE) represents an extensively developed plan for a world-class experiment dedicated to addressing these questions. LBNE is conceived around three central components: (1) a new, high-intensity neutrino source generated from a megawatt-class proton accelerator at Fermi National Accelerator Laboratory, (2) a near neutrino detector just downstream of the source, and (3) a massive liquid argon time-projection chamber deployed as a far detector deep underground at the Sanford Underground Research Facility. This facility, located at the site of the former Homestake Mine in Lead, South Dakota, is approximately 1,300 km from the neutrino source at Fermilab -- a distance (baseline) that delivers optimal sensitivity to neutrino charge-parity symmetry violation and mass ordering effects. This ambitious yet cost-effective design incorporates scalability and flexibility and can accommodate a variety of upgrades and contributions. With its exceptional combination of experimental configuration, technical capabilities, and potential for transformative discoveries, LBNE promises to be a vital facility for the field of particle physics worldwide, providing physicists from around the globe with opportunities to collaborate in a twenty to thirty year program of exciting science. In this document we provide a comprehensive overview of LBNE's scientific objectives, its place in the landscape of neutrino physics worldwide, the technologies it will incorporate and the capabilities it will possess."
PETER J SCHWARTZ,"Interaction of Stress, Lead Burden, and Age on Cognition in Older Men: The VA Normative Aging Study","BACKGROUND. Low-level exposure to lead and to chronic stress may independently influence cognition. However, the modifying potential of psychosocial stress on the neurotoxicity of lead and their combined relationship to aging-associated decline have not been fully examined. OBJECTIVES. We examined the cross-sectional interaction between stress and lead exposure on Mini-Mental State Examination (MMSE) scores among 811 participants in the Normative Aging Study, a cohort of older U.S. men. METHODS. We used two self-reported measures of stress appraisal-a self-report of stress related to their most severe problem and the Perceived Stress Scale (PSS). Indices of lead exposure were blood lead and bone (tibia and patella) lead. RESULTS. Participants with higher self-reported stress had lower MMSE scores, which were adjusted for age, education, computer experience, English as a first language, smoking, and alcohol intake. In multivariable-adjusted tests for interaction, those with higher PSS scores had a 0.57-point lower (95% confidence interval, -0.90 to 0.24) MMSE score for a 2-fold increase in blood lead than did those with lower PSS scores. In addition, the combination of high PSS scores and high blood lead categories on one or both was associated with a 0.05-0.08 reduction on the MMSE for each year of age compared with those with low PSS score and blood lead level (p < 0.05). CONCLUSIONS. Psychological stress had an independent inverse association with cognition and also modified the relationship between lead exposure and cognitive performance among older men. Furthermore, high stress and lead together modified the association between age and cognition."
PETER J SCHWARTZ,Formulating a thesis; or: chaos and cosmos,
PETER J SCHWARTZ,Labour in a single shot: critical perspectives on Antje Ehmann and Harun Farocki's global video project,"This collection of essays offers a critical assessment of Labour in a Single Shot, a groundbreaking documentary video workshop. From 2011 to 2014, curator Antje Ehmann and film- and videomaker Harun Farocki produced an art project of truly global proportions. They travelled to fifteen cities around the world to conduct workshops inspired by cinema history’s first film, Workers Leaving the Lumière Factory, shot in 1895 by the Lumière brothers in France. While the workshop videos are in colour and the camera was not required to remain static, Ehmann and Farocki’s students were tasked with honouring the original Lumière film’s basic parameters of theme and style. The fascinating result is a collection of more than 550 short videos that have appeared in international exhibitions and on an open-access website, offering the widest possible audience the opportunity to ponder contemporary labour in multiple contexts around the world."
PETER J SCHWARTZ,"BMQ : Boston medical quarterly: v. 17, no. 1-3",
PETER J SCHWARTZ,"The ideological antecedents of the first-series renminbi worker-and-peasant banknote, or what Mao Tse-tung may have owed to Dziga Vertov","This paper traces the history of an iconic Socialist Realist image—that of the worker, peasant, soldier, or leader viewed from below whilst gazing heroically into the symbolic dawn of a Socialist future—from its origins in mid-1920s Soviet Russia through its use on three banknotes in Communist China’s first renminbi series of 1949 to its effective dissolution in the iconography of Deng-era currency. It argues that this iconic type—familiar not only from Stalinist but also from Italian Fascist and German National Socialist imagery—arose initially as a consequence of the legitimation crisis provoked in the USSR by Lenin’s death in January 1924, and that it may have originated in cinema before spreading from there to photography and poster art. An examination especially of the film work of Dziga Vertov shows that the icon encodes in its visual syntax techniques of political, technological, and media pedagogy meant both to form the “new Soviet man” and to orient populations within a chain of symbolic identifications supporting the charismatic authority of their leaders. It is suggested that Mao’s documented decision to use this image on renminbi instead of his own otherwise ubiquitous portrait reflects a perception of the propagandistic value of this visual syntax, and that both Mao’s posthumous reappearance on Chinese currency and the icon’s transformation on fourth-series renminbi from class pairs gazing upward to ethnic pairs gazing laterally reflects, among other things, the Deng-era shift from a hieratic semantics of charismatic legitimation to a more sober strategy of legitimation by political and economic rationalization."
PETER J SCHWARTZ,Multiple Independent Loci at Chromosome 15q25.1 Affect Smoking Quantity: a Meta-Analysis and Comparison with Lung Cancer and COPD,"Recently, genetic association findings for nicotine dependence, smoking behavior, and smoking-related diseases converged to implicate the chromosome 15q25.1 region, which includes the CHRNA5-CHRNA3-CHRNB4 cholinergic nicotinic receptor subunit genes. In particular, association with the nonsynonymous CHRNA5 SNP rs16969968 and correlates has been replicated in several independent studies. Extensive genotyping of this region has suggested additional statistically distinct signals for nicotine dependence, tagged by rs578776 and rs588765. One goal of the Consortium for the Genetic Analysis of Smoking Phenotypes (CGASP) is to elucidate the associations among these markers and dichotomous smoking quantity (heavy versus light smoking), lung cancer, and chronic obstructive pulmonary disease (COPD). We performed a meta-analysis across 34 datasets of European-ancestry subjects, including 38,617 smokers who were assessed for cigarettes-per-day, 7,700 lung cancer cases and 5,914 lung-cancer-free controls (all smokers), and 2,614 COPD cases and 3,568 COPD-free controls (all smokers). We demonstrate statistically independent associations of rs16969968 and rs588765 with smoking (mutually adjusted p-values<10−35 and >10−8 respectively). Because the risk alleles at these loci are negatively correlated, their association with smoking is stronger in the joint model than when each SNP is analyzed alone. Rs578776 also demonstrates association with smoking after adjustment for rs16969968 (p<10−6). In models adjusting for cigarettes-per-day, we confirm the association between rs16969968 and lung cancer (p<10−20) and observe a nominally significant association with COPD (p = 0.01); the other loci are not significantly associated with either lung cancer or COPD after adjusting for rs16969968. This study provides strong evidence that multiple statistically distinct loci in this region affect smoking behavior. This study is also the first report of association between rs588765 (and correlates) and smoking that achieves genome-wide significance; these SNPs have previously been associated with mRNA levels of CHRNA5 in brain and lung tissue. Author Summary Nicotine binds to cholinergic nicotinic receptors, which are composed of a variety of subunits. Genetic studies for smoking behavior and smoking-related diseases have implicated a genomic region that encodes the alpha5, alpha3, and beta4 subunits. We examined genetic data across this region for over 38,000 smokers, a subset of which had been assessed for lung cancer or chronic obstructive pulmonary disease. We demonstrate strong evidence that there are at least two statistically independent loci in this region that affect risk for heavy smoking. One of these loci represents a change in the protein structure of the alpha5 subunit. This work is also the first to report strong evidence of association between smoking and a group of genetic variants that are of biological interest because of their links to expression of the alpha5 cholinergic nicotinic receptor subunit gene. These advances in understanding the genetic influences on smoking behavior are important because of the profound public health burdens caused by smoking and nicotine addiction."
PETER J SCHWARTZ,Priorities for synthesis research in ecology and environmental science,
PETER J SCHWARTZ,Rube stories and paradigmatic crimes as narrative modulators at thresholds of cultural change,"This essay investigates two species of a larger genus of narrative (“narrative modulators”) characterized by its function as a sort of compromise formation addressing recurrent anxieties and tensions at major thresholds of cultural change. One of these is a story type linked with cinema’s early reception: that of the “credulous spectator,” figured in early film and film lore as the country bumpkin or “rube” who, misperceiving the projected image as real, runs from the oncoming train or from the wet of onscreen waves or tries to enter the story; I extend this type beyond cinema to include precinematic literary examples. I’ve coined the term “paradigmatic crimes” to describe stories of criminal acts used to address pressing cultural concerns at given historical junctures as a second type of “narrative modulator.” As with “rube stories,” what unifies “paradigmatic crimes” as a story type is their specific function as “narrative modulators” in moments of cultural change. My hypothesis is that functionally similar stories appear at structurally comparable thresholds of media change in various cultures at various times, and that the similarities are to be explained mainly morphologically (i.e. mainly at the abstract level of their capacity to modulate cultural change)."
CYNTHIA A. BRADHAM,Ethanol exposure perturbs sea urchin development and disrupts developmental timing,"Ethanol is a known vertebrate teratogen that causes craniofacial defects as a component of fetal alcohol syndrome (FAS). Our results show that sea urchin embryos treated with ethanol similarly show broad skeletal patterning defects, potentially analogous to the defects associated with FAS. The sea urchin larval skeleton is a simple patterning system that involves only two cell types: the primary mesenchymal cells (PMCs) that secrete the calcium carbonate skeleton and the ectodermal cells that provide migratory, positional, and differentiation cues for the PMCs. Perturbations in RA biosynthesis and Hh signaling pathways are thought to be causal for the FAS phenotype in vertebrates. Surprisingly, our results indicate that these pathways are not functionally relevant for the teratogenic effects of ethanol in developing sea urchins. We found that developmental morphology as well as the expression of ectodermal and PMC genes was delayed by ethanol exposure. Temporal transcriptome analysis revealed significant impacts of ethanol on signaling and metabolic gene expression, and a disruption in the timing of GRN gene expression that includes both delayed and precocious gene expression throughout the specification network. We conclude that the skeletal patterning perturbations in ethanol-treated embryos likely arise from a loss of temporal synchrony within and between the instructive and responsive tissues."
CYNTHIA A. BRADHAM,Polychrome labeling reveals skeletal triradiate and elongation dynamics and abnormalities in patterning cue-perturbed embryos,
CYNTHIA A. BRADHAM,ICAT: a novel algorithm to robustly identify cell states following perturbations in single cell transcriptomes,
CYNTHIA A. BRADHAM,The developmental transcriptome for Lytechinus variegatus exhibits temporally punctuated gene expression changes,"Embryonic development is arguably the most complex process an organism undergoes during its lifetime, and understanding this complexity is best approached with a systems-level perspective. The sea urchin has become a highly valuable model organism for understanding developmental specification, morphogenesis, and evolution. As a non-chordate deuterostome, the sea urchin occupies an important evolutionary niche between protostomes and vertebrates. Lytechinus variegatus (Lv) is an Atlantic species that has been well studied, and which has provided important insights into signal transduction, patterning, and morphogenetic changes during embryonic and larval development. The Pacific species, Strongylocentrotus purpuratus (Sp), is another well-studied sea urchin, particularly for gene regulatory networks (GRNs) and cis-regulatory analyses. A well-annotated genome and transcriptome for Sp are available, but similar resources have not been developed for Lv. Here, we provide an analysis of the Lv transcriptome at 11 timepoints during embryonic and larval development. Temporal analysis suggests that the gene regulatory networks that underlie specification are well-conserved among sea urchin species. We show that the major transitions in variation of embryonic transcription divide the developmental time series into four distinct, temporally sequential phases. Our work shows that sea urchin development occurs via sequential intervals of relatively stable gene expression states that are punctuated by abrupt transitions."
CYNTHIA A. BRADHAM,Voltage-gated sodium channel activity mediates sea urchin larval skeletal patterning through spatial regulation of Wnt5 expression,
CYNTHIA A. BRADHAM,ICAT: a novel algorithm to robustly identify cell states following perturbations in single-cell transcriptomes,"MOTIVATION: The detection of distinct cellular identities is central to the analysis of single-cell RNA sequencing (scRNA-seq) experiments. However, in perturbation experiments, current methods typically fail to correctly match cell states between conditions or erroneously remove population substructure. Here, we present the novel, unsupervised algorithm Identify Cell states Across Treatments (ICAT) that employs self-supervised feature weighting and control-guided clustering to accurately resolve cell states across heterogeneous conditions. RESULTS: Using simulated and real datasets, we show ICAT is superior in identifying and resolving cell states compared with current integration workflows. While requiring no a priori knowledge of extant cell states or discriminatory marker genes, ICAT is robust to low signal strength, high perturbation severity, and disparate cell type proportions. We empirically validate ICAT in a developmental model and find that only ICAT identifies a perturbation-unique cellular response. Taken together, our results demonstrate that ICAT offers a significant improvement in defining cellular responses to perturbation in scRNA-seq data. AVAILABILITY AND IMPLEMENTATION: https://github.com/BradhamLab/icat."
CYNTHIA A. BRADHAM,Genomic insights of body plan transitions from bilateral to pentameral symmetry in echinoderms,"Echinoderms are an exceptional group of bilaterians that develop pentameral adult symmetry from a bilaterally symmetric larva. However, the genetic basis in evolution and development of this unique transformation remains to be clarified. Here we report newly sequenced genomes, developmental transcriptomes, and proteomes of diverse echinoderms including the green sea urchin (L. variegatus), a sea cucumber (A. japonicus), and with particular emphasis on a sister group of the earliest-diverged echinoderms, the feather star (A. japonica). We learned that the last common ancestor of echinoderms retained a well-organized Hox cluster reminiscent of the hemichordate, and had gene sets involved in endoskeleton development. Further, unlike in other animal groups, the most conserved developmental stages were not at the body plan establishing phase, and genes normally involved in bilaterality appear to function in pentameric axis development. These results enhance our understanding of the divergence of protostomes and deuterostomes almost 500 Mya."
CYNTHIA A. BRADHAM,Derivedness index for estimating degree of phenotypic evolution of embryos: a study of comparative transcriptomic analyses of chordates and echinoderms,"Species retaining ancestral features, such as species called living fossils, are often regarded as less derived than their sister groups, but such discussions are usually based on qualitative enumeration of conserved traits. This approach creates a major barrier, especially when quantifying the degree of phenotypic evolution or degree of derivedness, since it focuses only on commonly shared traits, and newly acquired or lost traits are often overlooked. To provide a potential solution to this problem, especially for inter-species comparison of gene expression profiles, we propose a new method named ""derivedness index"" to quantify the degree of derivedness. In contrast to the conservation-based approach, which deals with expressions of commonly shared genes among species being compared, the derivedness index also considers those that were potentially lost or duplicated during evolution. By applying our method, we found that the gene expression profiles of penta-radial phases in echinoderm tended to be more highly derived than those of the bilateral phase. However, our results suggest that echinoderms may not have experienced much larger modifications to their developmental systems than chordates, at least at the transcriptomic level. In vertebrates, we found that the mid-embryonic and organogenesis stages were generally less derived than the earlier or later stages, indicating that the conserved phylotypic period is also less derived. We also found genes that potentially explain less derivedness, such as Hox genes. Finally, we highlight technical concerns that may influence the measured transcriptomic derivedness, such as read depth and library preparation protocols, for further improvement of our method through future studies. We anticipate that this index will serve as a quantitative guide in the search for constrained developmental phases or processes."
CYNTHIA A. BRADHAM,RNA-Seq identifies SPGs as a ventral skeletal patterning cue in sea urchins,"The sea urchin larval skeleton offers a simple model for formation of developmental patterns. The calcium carbonate skeleton is secreted by primary mesenchyme cells (PMCs) in response to largely unknown patterning cues expressed by the ectoderm. To discover novel ectodermal cues, we performed an unbiased RNA-Seq-based screen and functionally tested candidates; we thereby identified several novel skeletal patterning cues. Among these, we show that SLC26a2/7 is a ventrally expressed sulfate transporter that promotes a ventral accumulation of sulfated proteoglycans, which is required for ventral PMC positioning and skeletal patterning. We show that the effects of SLC perturbation are mimicked by manipulation of either external sulfate levels or proteoglycan sulfation. These results identify novel skeletal patterning genes and demonstrate that ventral proteoglycan sulfation serves as a positional cue for sea urchin skeletal patterning."
DAVID KOPP,The diboson excess: experimental situation and classification of explanations; a Les Houches pre-proceeding,"We examine the 'diboson' excess at ∼ 2 TeV seen by the LHC experiments in various channels. We provide a comparison of the excess significances as a function of the mass of the tentative resonance and give the signal cross sections needed to explain the excesses. We also present a survey of available theoretical explanations of the resonance, classified in three main approaches. Beyond that, we discuss methods to verify the anomaly, determining the major properties of the various surpluses and exploring how different models can be discriminated. Finally, we give a tabular summary of the numerous explanations, presenting their main phenomenological features."
DAVID KOPP,Tracing MYC expression for small molecule discovery,"Our inability to effectively ""drug"" targets such as MYC for therapeutic purposes requires the development of new approaches. We report on the implementation of a phenotype-based assay for monitoring MYC expression in multiple myeloma cells. The open reading frame (ORF) encoding an unstable variant of GFP was engineered immediately downstream of the MYC ORF using CRISPR/Cas9, resulting in co-expression of both proteins from the endogenous MYC locus. Using fluorescence readout as a surrogate for MYC expression, we implemented a pilot screen in which ∼10,000 compounds were prosecuted. Among known MYC expression inhibitors, we identified cardiac glycosides and cytoskeletal disruptors to be quite potent. We demonstrate the power of CRISPR/Cas9 engineering in establishing phenotype-based assays to identify gene expression modulators."
DAVID KOPP,The long-baseline neutrino experiment: exploring fundamental symmetries of the universe,"The preponderance of matter over antimatter in the early Universe, the dynamics of the supernova bursts that produced the heavy elements necessary for life and whether protons eventually decay --- these mysteries at the forefront of particle physics and astrophysics are key to understanding the early evolution of our Universe, its current state and its eventual fate. The Long-Baseline Neutrino Experiment (LBNE) represents an extensively developed plan for a world-class experiment dedicated to addressing these questions. LBNE is conceived around three central components: (1) a new, high-intensity neutrino source generated from a megawatt-class proton accelerator at Fermi National Accelerator Laboratory, (2) a near neutrino detector just downstream of the source, and (3) a massive liquid argon time-projection chamber deployed as a far detector deep underground at the Sanford Underground Research Facility. This facility, located at the site of the former Homestake Mine in Lead, South Dakota, is approximately 1,300 km from the neutrino source at Fermilab -- a distance (baseline) that delivers optimal sensitivity to neutrino charge-parity symmetry violation and mass ordering effects. This ambitious yet cost-effective design incorporates scalability and flexibility and can accommodate a variety of upgrades and contributions. With its exceptional combination of experimental configuration, technical capabilities, and potential for transformative discoveries, LBNE promises to be a vital facility for the field of particle physics worldwide, providing physicists from around the globe with opportunities to collaborate in a twenty to thirty year program of exciting science. In this document we provide a comprehensive overview of LBNE's scientific objectives, its place in the landscape of neutrino physics worldwide, the technologies it will incorporate and the capabilities it will possess."
ALEXANDER OLSHEVSKY,Gradient descent for sparse rank-one matrix completion for crowd-sourced aggregation of sparsely interacting workers,"We consider worker skill estimation for the singlecoin Dawid-Skene crowdsourcing model. In practice skill-estimation is challenging because worker assignments are sparse and irregular due to the arbitrary, and uncontrolled availability of workers. We formulate skill estimation as a rank-one correlation-matrix completion problem, where the observed components correspond to observed label correlation between workers. We show that the correlation matrix can be successfully recovered and skills identifiable if and only if the sampling matrix (observed components) is irreducible and aperiodic. We then propose an efficient gradient descent scheme and show that skill estimates converges to the desired global optima for such sampling matrices. Our proof is original and the results are surprising in light of the fact that even the weighted rank-one matrix factorization problem is NP hard in general. Next we derive sample complexity bounds for the noisy case in terms of spectral properties of the signless Laplacian of the sampling matrix. Our proposed scheme achieves state-of-art performance on a number of real-world datasets."
ALEXANDER OLSHEVSKY,Minimal reachability is hard to approximate,"In this note, we consider the problem of choosing, which nodes of a linear dynamical system should be actuated so that the state transfer from the system's initial condition to a given final state is possible. Assuming a standard complexity hypothesis, we show that this problem cannot be efficiently solved or approximated in polynomial, or even quasi-polynomial, time."
ALEXANDER OLSHEVSKY,A small gain analysis of single timescale actor critic,
ALEXANDER OLSHEVSKY,On the performance of temporal difference learning with neural networks,
ALEXANDER OLSHEVSKY,Convergence of actor-critic with multi-layer neural networks,
LORA SABIN,The Ghana retention on ART study (ROARS): keeping HIV-positive patients on antiretroviral therapy,"This report presents the findings of a study that employed qualitative research methods to explore the beliefs, attitudes, and behaviors of people living with HIV (PLHIV) in Ghana who are either in care and on antiretroviral therapy (ART), or are no longer in care and have been lost to follow-up. The study was designed to deepen our understanding of the challenges ART patients face in continuing on ART in Ghana and to contribute information with the potential to improve retention in care and outcomes for PLHIV in Ghana.This study was carried out by a collaborative team of researchers based at Boston University’s Center for Global and Health and Development (CGHD) and the Kwame Nkrumah University of Science and Technology’s (KNUST) School of Medical Sciences. The team conducted this research in Kumasi, Ghana’s second largest urban center. It is a component of the ‘Operations Research among Key Populations in Ghana’ project funded by the United States Agency for International Development (USAID). We designed and conducted the research in collaboration with the Ghana AIDS Commission (GAC).Expanding access to ART among HIV-positive individuals has been a major goal of the Ghana AIDS Commission and Ghana Health Service. Since 2005, Ghana has scaled up ART rapidly; by 2011, 150 health facilities were providing ART to over 60,000 people, an increase from fewer than 5,000 just six years earlier. At the same time, like in most countries in sub-Saharan Africa, ensuring that those who begin ART remain on treatment has proven a major challenge. Previous studies suggest that retention in care for 12 months or longer is approximately 70-80% in Ghana, similar to the rate in many other low-resource settings. While research elsewhere in sub-Saharan Africa indicates that a number of barriers affect retention in care, little research on this topic has been conducted in Ghana. Given that ART is currently the only known way to prolong life for PLHIV, it is critical to identify barriers that affect different groups of patients and to find ways to support them in remaining on treatment.This study was motivated by a desire to increase understanding of the challenges of and facilitators to retention in care among individuals on ART in Kumasi, Ghana. We conducted it in collaboration with the Suntreso Government Hospital, one of Kumasi’s largest medical facilities, and specifically with the hospital’s STI (sexually transmitted infection)/HIV clinic, which has experienced high levels of patient dropout from care and treatment. Together with staff at the clinic, we designed this research with the aim of contributing to understanding of the range of barriers PLHIV in Ghana experience trying to stay on treatment, the reasons they default, and the types of supports they believe would help themselves and other patients remain on or return to treatment if they do default. Our hope is that the study’s findings will add in a meaningful way to the evidence base on strategies and approaches for improving retention in treatment, thereby maximizing the potential benefits of ART, for PLHIV in Ghana."
LORA SABIN,"HIV vulnerability of men and women who inject drugs in Kumasi, Ghana","Reducing vulnerability to HIV infection among key populations in Ghana is a major goal for the National AIDS Control Program (NACP) and the GAC. While a number of studies have explored HIV risk behaviours among several key vulnerable populations in Ghana including female sex workers, men who have sex with men, and prisoners, little is known about the drug use and sexual vulnerability of people who inject drugs (PWID). In addition, no programs have been implemented to reduce the vulnerability among this population. This report provides the findings from a qualitative study that aimed to understand the social, economic and behavioral vulnerability to HIV of PWID in Kumasi and to inform the development and implementation of HIV prevention programs for this population. The research was conducted by a collaborative team comprised of researchers from Boston University’s Center for Global and Health and Development (CGHD) and the Kwame Nkrumah University of Science and Technology (KNUST) School of Medical Sciences. It is one of nine studies under the Operations Research on Key Populations project funded by the United States Agency for International Development (USAID). The study was designed and carried out in collaboration with the Ghana AIDS Commission (GAC)."
LORA SABIN,Health facility and skilled birth deliveries among poor women with Jamkesmas health insurance in Indonesia: a mixed-methods study,"BACKGROUND: The growing momentum for quality and affordable health care for all has given rise to the recent global universal health coverage (UHC) movement. As part of Indonesia’s strategy to achieve the goal of UHC, large investments have been made to increase health access for the poor, resulting in the implementation of various health insurance schemes targeted towards the poor and near-poor, including the Jamkesmas program. In the backdrop of Indonesia’s aspiration to reach UHC is the high rate of maternal mortality that disproportionally affects poor women. The objective of this study was to evaluate the association of health facility and skilled birth deliveries among poor women with and without Jamkesmas and explore perceived barriers to health insurance membership and maternal health service utilization. METHODS: We used a mixed-methods design. Utilizing data from the 2012 Indonesian Demographic and Health Survey (n = 45,607), secondary analysis using propensity score matching was performed on key outcomes of interest: health facility delivery (HFD) and skilled birth delivery (SBD). In-depth interviews (n = 51) were conducted in the provinces of Jakarta and Banten among poor women, midwives, and government representatives. Thematic framework analysis was performed on qualitative data to explore perceived barriers. RESULTS: In 2012, 63.0% of women did not have health insurance; 19.1% had Jamkesmas. Poor women with Jamkesmas were 19% (OR = 1.19 [1.03–1.37]) more likely to have HFD and 17% (OR = 1.17 [1.01–1.35]) more likely to have SBD compared to poor women without insurance. Qualitative interviews highlighted key issues, including: lack of proper documentation for health insurance registration; the preference of pregnant women to deliver in their parents’ village; the use of traditional birth attendants; distance to health facilities; shortage of qualified health providers; overcrowded health facilities; and lack of health facility accreditation. CONCLUSION: Poor women with Jamkesmas membership had a modest increase in HFD and SBD. These findings are consistent with economic theory that health insurance coverage can reduce financial barriers to care and increase service uptake. However, factors such as socio-cultural beliefs, accessibility, and quality of care are important elements that need to be addressed as part of the national UHC agenda to improve maternal health services in Indonesia."
LORA SABIN,Etiology of severe pneumonia in Ecuadorian children,"INTRODUCTION: In Latin America, community-acquired pneumonia remains a major cause of morbidity and mortality among children. Few studies have examined the etiology of pneumonia in Ecuador. METHODS: This observational study was part of a randomized, double blind, placebo-controlled clinical trial conducted among children aged 2–59 months with severe pneumonia in Quito, Ecuador. Nasopharyngeal and blood samples were tested for bacterial and viral etiology by polymerase chain reaction. Risk factors for specific respiratory pathogens were also evaluated. RESULTS: Among 406 children tested, 159 (39.2%) had respiratory syncytial virus (RSV), 71 (17.5%) had human metapneumovirus (hMPV), and 62 (15.3%) had adenovirus. Streptococcus pneumoniae was identified in 37 (9.2%) samples and Mycoplasma pneumoniae in three (0.74%) samples. The yearly circulation pattern of RSV (P = 0.0003) overlapped with S. pneumoniae, (P = 0.03) with most cases occurring in the rainy season. In multivariable analysis, risk factors for RSV included younger age (adjusted odds ratio [aOR] = 1.9, P = 0.01) and being underweight (aOR = 1.8, P = 0.04). Maternal education (aOR = 0.82, P = 0.003), pulse oximetry (aOR = 0.93, P = 0.005), and rales (aOR = 0.25, P = 0.007) were associated with influenza A. Younger age (aOR = 3.5, P = 0.007) and elevated baseline respiratory rate were associated with HPIV-3 infection (aOR = 0.94, P = 0.03). CONCLUSION: These results indicate the importance of RSV and influenza, and potentially modifiable risk factors including undernutrition and future use of a RSV vaccine, when an effective vaccine becomes available."
LORA SABIN,Using Electronic Drug Monitor Feedback to Improve Adherence to Antiretroviral Therapy Among HIV-Positive Patients in China,"Effective antiretroviral therapy (ART) requires excellent adherence. Little is known about how to improve ART adherence in many HIV/AIDS-affected countries, including China. We therefore assessed an adherence intervention among HIV-positive patients in southwestern China. Eighty subjects were enrolled and monitored for 6 months. Sixty-eight remaining subjects were randomized to intervention/control arms. In months 7–12, intervention subjects were counseled using EDM feedback; controls continued with standard of care. Among randomized subjects, mean adherence and CD4 count were 86.8 vs. 83.8% and 297 vs. 357 cells/μl in intervention vs. control subjects, respectively. At month 12, among 64 subjects who completed the trial, mean adherence had risen significantly among intervention subjects to 96.5% but remained unchanged in controls. Mean CD4 count rose by 90 cells/μl and declined by 9 cells/μl among intervention and control subjects, respectively. EDM feedback as a counseling tool appears promising for management of HIV and other chronic diseases."
LORA SABIN,"Burden of Malaria in Pregnancy in Jharkhand State, India","BACKGROUND. Past studies in India included only symptomatic pregnant women and thus may have overestimated the proportion of women with malaria. Given the large population at risk, a cross sectional study was conducted in order to better define the burden of malaria in pregnancy in Jharkhand, a malaria-endemic state in central-east India. METHODS Cross-sectional surveys at antenatal clinics and delivery units were performed over a 12-month period at two district hospitals in urban and semi-urban areas, and a rural mission hospital. Malaria was diagnosed by Giemsa-stained blood smear and/or rapid diagnostic test using peripheral or placental blood. RESULTS 2,386 pregnant women were enrolled at the antenatal clinics and 718 at the delivery units. 1.8% (43/2382) of the antenatal clinic cohort had a positive diagnostic test for malaria (53.5% Plasmodium falciparum, 37.2% Plasmodium vivax, and 9.3% mixed infections). Peripheral parasitaemia was more common in pregnant women attending antenatal clinics in rural sites (adjusted relative risk [aRR] 4.31, 95%CI 1.84-10.11) and in those who were younger than 20 years (aRR 2.68, 95%CI 1.03-6.98). Among delivery unit participants, 1.7% (12/717) had peripheral parasitaemia and 2.4% (17/712) had placental parasitaemia. Women attending delivery units were more likely to be parasitaemic if they were in their first or second pregnancy (aRR 3.17, 95%CI 1.32-7.61), had fever in the last week (aRR 5.34, 95%CI 2.89-9.90), or had rural residence (aRR 3.10, 95%CI 1.66-5.79). Malaria control measures including indoor residual spraying (IRS) and untreated bed nets were common, whereas insecticide-treated bed nets (ITN) and malaria chemoprophylaxis were rarely used. CONCLUSION The prevalence of malaria among pregnant women was relatively low. However, given the large at-risk population in this malaria-endemic region of India, there is a need to enhance ITN availability and use for prevention of malaria in pregnancy, and to improve case management of symptomatic pregnant women."
LORA SABIN,Community Case Management of Fever Due to Malaria and Pneumonia in Children Under Five in Zambia: A Cluster Randomized Controlled Trial,"In a cluster randomized trial, Kojo Yeboah-Antwi and colleagues find that integrated management of malaria and pneumonia in children under five by community health workers is both feasible and effective. BACKGROUND. Pneumonia and malaria, two of the leading causes of morbidity and mortality among children under five in Zambia, often have overlapping clinical manifestations. Zambia is piloting the use of artemether-lumefantrine (AL) by community health workers (CHWs) to treat uncomplicated malaria. Valid concerns about potential overuse of AL could be addressed by the use of malaria rapid diagnostics employed at the community level. Currently, CHWs in Zambia evaluate and treat children with suspected malaria in rural areas, but they refer children with suspected pneumonia to the nearest health facility. This study was designed to assess the effectiveness and feasibility of using CHWs to manage nonsevere pneumonia and uncomplicated malaria with the aid of rapid diagnostic tests (RDTs). METHODS AND FINDINGS. Community health posts staffed by CHWs were matched and randomly allocated to intervention and control arms. Children between the ages of 6 months and 5 years were managed according to the study protocol, as follows. Intervention CHWs performed RDTs, treated test-positive children with AL, and treated those with nonsevere pneumonia (increased respiratory rate) with amoxicillin. Control CHWs did not perform RDTs, treated all febrile children with AL, and referred those with signs of pneumonia to the health facility, as per Ministry of Health policy. The primary outcomes were the use of AL in children with fever and early and appropriate treatment with antibiotics for nonsevere pneumonia. A total of 3,125 children with fever and/or difficult/fast breathing were managed over a 12-month period. In the intervention arm, 27.5% (265/963) of children with fever received AL compared to 99.1% (2066/2084) of control children (risk ratio 0.23, 95% confidence interval 0.14–0.38). For children classified with nonsevere pneumonia, 68.2% (247/362) in the intervention arm and 13.3% (22/203) in the control arm received early and appropriate treatment (risk ratio 5.32, 95% confidence interval 2.19–8.94). There were two deaths in the intervention and one in the control arm. CONCLUSIONS. The potential for CHWs to use RDTs, AL, and amoxicillin to manage both malaria and pneumonia at the community level is promising and might reduce overuse of AL, as well as provide early and appropriate treatment to children with nonsevere pneumonia."
LORA SABIN,"Research report: Exploring the beliefs, attitudes, and behaviors of MSM engaged in substance use and transactional sex in Ghana","This report presents findings from a qualitative study examining the vulnerability to HIV of young men who have sex with men (MSM) in Kumasi, Ghana, and their prevention needs. The study was jointly conducted in Kumasi, Ghana’s second largest urban center, by Boston University’s Center for Global and Health and Development (CGHD) and the Kwame Nkrumah University of Science and Technology (KNUST). It was carried out as a component of Project SEARCH funded by the United States Agency for International Development. The study was designed and conducted in collaboration with FHI 360 (formerly Family Health International (FHI)), an international non‐governmental organization based in the capital city of Accra which operates programs targeting MSM and other key populations in Kumasi, and the Ghana AIDS Commission (GAC). Preventing HIV among key populations in Ghana is a major goal for the National AIDS Control Program (NACP) and the GAC.1 MSM are a particularly stigmatized population in Ghana, in part because male‐to‐male sex has traditionally been viewed as illegal, making them a difficult yet critical to reach population with HIV/AIDS‐related services. This qualitative study was conducted in order to enhance understanding of the beliefs, attitudes, and behaviors of adolescent and young MSM (aged 15‐29). In this population, we particularly sought to focus on two sub‐groups: MSM who engage in transactional sex and those who use alcohol or illicit substances (hereinafter “substances”). The specific objectives were to explore: 1) the types and extent of substance use by MSM; 2) the overlap between substance use and transactional sex among MSM; 3) the beliefs and attitudes related to substance use and transactional sex; 4) knowledge and risk behaviors of both subgroups. The study’s broader goal was to collect and analyze in‐depth data that can be used to improve the outreach and effectiveness of local programs that aim to reach these groups with important HIV prevention and treatment information and with services appropriate to their needs."
LORA SABIN,Attitudes and behaviors among older MSM in Ghana,"This report provides the findings of a qualitative study that explored vulnerability to HIV of men who have sex with men (MSM) in Kumasi, Ghana. It is the second of two related studies focusing on MSM. The first study, “Exploring the beliefs, attitudes, and behaviors of MSM engaged in substance use and transactional sex in Ghana,”1 focused on adolescent and young adult MSM aged 15 to 29 years. This companion study focused on ‘older MSM’, encompassing individuals aged 30 years and above. This research was conducted by a collaborative team comprised of researchers from Boston University’s Center for Global and Health and Development (CGHD) and the Kwame Nkrumah University of Science and Technology (KNUST). The team conducted this research in Kumasi, Ghana’s second largest urban center. It is a component of the ‘Operations Research for Key Populations in Ghana’ Program funded by the United States Agency for International Development (USAID). We designed and carried out the study in collaboration with FHI 360, an organization based in the capital of Accra that operates programs targeting MSM and other high‐risk individuals in Ghana, as well as the Ghana AIDS Commission (GAC). Reducing vulnerability to HIV infection among high‐risk populations in Ghana is a major goal for the National AIDS Control Program (NACP) and the GAC. MSM are highly stigmatized in Ghana, in part because male‐to‐male sex is illegal. This makes it extremely challenging to understand the challenges these men face and ensure that they have access to HIV‐ and AIDS‐related services. We designed this qualitative study to add to what is known about the beliefs, attitudes, and behaviors of older MSM in Ghana. We focused on two groups among older MSM: those aged 30‐39 years and those aged 40 years and above. Given the need for more data on these groups to better reach them with effective HIV prevention and treatment information, the study aimed to explore: 1) How older MSM find their sex partners; 2) Their views of HIV risk; 3) Their risky behaviors, including those situations in which they are most likely to engage in risky sex; 4) HIV‐related services they receive; and 5) What services would be most helpful to them. The broad goal of the study was to collect and analyze in‐depth data in order to improve the outreach and effectiveness of local programs that aim to reach older MSM with important HIV prevention and treatment information and with services appropriate to their needs."
LORA SABIN,Attitudes and behaviors among older MSM in Ghana,"Men who have sex with men (MSM) are a particularly stigmatized group in Ghana. Male-tomale sex is viewed as “unnatural” and therefore illegal. MSM are a critical, though difficult, population to reach with HIV-related services. Preventing HIV among key populations is a goal of the National AIDS Control Program (NACP) and the Ghana AIDS Commission (GAC).1 Until recently, specific data on MSM in the country were limited. The Ghana Men’s Study (GMS), which collected information from 1,302 MSM in five regions in 2011, provides detailed data on HIV and sexually transmitted infection (STI) prevalence and risk behaviors among MSM. Whereas adult HIV prevalence in Ghana has been estimated 1.31% in 2013,2 the GMS documented a nationwide average prevalence in 2011 of 17.5% among MSM, with the rate in Accra estimated at 34.3% and 13.7% in Kumasi.3 Boston University’s Center for Global Health and Development (BU CGHD) and the Kwame Nkrumah University of Science and Technology (KNUST), in collaboration with the GAC and FHI 360, conducted a qualitative study to examine HIV vulnerability among “older” MSM in Kumasi, Ghana’s second largest urban area. It is the second of two studies focusing on MSM in Ghana undertaken by CGHD/KNUST. The first, “Exploring the beliefs, attitudes, and behaviors of MSM engaged in substance use and transactional sex in Ghana,”4 focused on adolescent and young adult MSM aged 15 to 29 years. This companion study included MSM aged 30 years and above. The research is designed to complement and supplement information on MSM obtained by the GMS. The study’s goal was to collect and analyze data to improve the outreach and effectiveness of local programs that aim to reach older MSM with important HIV prevention and treatment information and with services appropriate to their needs. In-depth interviews (IDIs) and focus group discussions (FGDs) were used to collect data from two MSM groups: those aged 30 to 39 years and those aged forty and older. A total of 44 MSM participated in the study, 22 in each age group."
LORA SABIN,"Program brief: Exploring the beliefs, attitudes, and behaviors of msm engaged in substance use and transactional sex in Ghana","Preventing HIV among key populations is a goal of the National AIDS Control Program (NACP) and the Ghana AIDS Commission (GAC).1 Men who have sex with men (MSM) are a particularly stigmatized group in Ghana, in part because male-to-male sex is viewed as “unnatural” and therefore illegal. MSM are a critical though difficult population to reach with HIV-related services. Until recently, specific data on MSM in the country were limited. The Ghana Men’s Study (GMS), which collected data from 1,302 MSM in five regions in 2011, has detailed information on HIV and sexually transmitted infection (STI) prevalence and risk behaviors among MSM. Whereas adult HIV prevalence in Ghana has been estimated at 1.31% in 2013,2 the GMS documented a nationwide average prevalence in 2011 of 17.5% among MSM, with the rate in Accra estimated at 34.3% and 13.7% in Kumasi.3 This qualitative study was designed to complement and supplement quantitative findings about MSM from the GMS. It was conducted by Boston University’s Center for Global Health and Development and the Kwame Nkrumah University of Science and Technology (KNUST) in collaboration with FHI 360 and with funding from the United States Agency for International Development (USAID)/Ghana. It is the first of two qualitative studies focusing on MSM in Ghana. The objectives were to explore: (1) the types and extent of substance use by MSM; (2) the overlap between substance use and transactional sex among MSM; (3) the beliefs and attitudes related to substance use and transactional sex; and (4) knowledge and risk behaviors of both subgroups. In-depth interviews (IDI) and focus group discussions (FGD) were used to collect data from four participant groups: two age groups, adolescent MSM (aged 15-17 years) and young adult MSM (aged 18-29 years), with each group including men who consume high levels of alcohol and/ or use drugs and men who engage in transactional sex (TS). Transactional sex is defined here as self-reported sex with another man in exchange for money, gifts, or favors."
LORA SABIN,Availability and utilization of malaria prevention strategies in pregnancy in Eastern India,"BACKGROUND. Malaria in pregnancy in India, as elsewhere, is responsible for maternal anemia and adverse pregnancy outcomes such as low birth weight and preterm birth. It is not known whether prevention and treatment strategies for malaria in pregnancy (case management, insecticide-treated bednets, intermittent preventive therapy) are widely utilized in India. METHODS. This cross-sectional study was conducted during 2006-2008 in two states of India, Jharkhand and Chhattisgarh, at 7 facilities representing a range of rural and urban populations and areas of more versus less stable malaria transmission. 280 antenatal visits (40/site) were observed by study personnel coupled with exit interviews of pregnant women to assess emphasis upon, availability and utilization of malaria prevention practices by health workers and pregnant women. The facilities were assessed for the availability of antimalarials, lab supplies and bednets. RESULTS. All participating facilities were equipped to perform malaria blood smears; none used rapid diagnostic tests. Chloroquine, endorsed for chemoprophylaxis during pregnancy by the government at the time of the study, was stocked regularly at all facilities although the quantity stocked varied. Availability of alternative antimalarials for use in pregnancy was less consistent. In Jharkhand, no health worker recommended bednet use during the antenatal visit yet over 90% of pregnant women had bednets in their household. In Chhattisgarh, bednets were available at all facilities but only 14.4% of health workers recommended their use. 40% of the pregnant women interviewed had bednets in their household. Only 1.4% of all households owned an insecticide-treated bednet; yet 40% of all women reported their households had been sprayed with insecticide. Antimalarial chemoprophylaxis with chloroquine was prescribed in only 2 (0.7%) and intermittent preventive therapy prescribed in only one (0.4%) of the 280 observed visits. CONCLUSIONS. A disconnect remains between routine antenatal practices in India and known strategies to prevent and treat malaria in pregnancy. Prevention strategies, in particular the use of insecticide-treated bednets, are underutilized. Gaps highlighted by this study combined with recent estimates of the prevalence of malaria during pregnancy in these areas should be used to revise governmental policy and target increased educational efforts among health care workers and pregnant women."
P ROBERT KOTIUGA,"On the topological characterization of near force-free magnetic fields, and the work of late-onset visually-impaired topologists","The Giroux correspondence and the notion of a near force-free magnetic field are used to topologically characterize near force-free magnetic fields which describe a variety of physical processes, including plasma equilibrium. As a byproduct, the topological characterization of force-free magnetic fields associated with current-carrying links, as conjectured by Crager and Kotiuga, is shown to be necessary and conditions for sufficiency are given. Along the way a paradox is exposed: The seemingly unintuitive mathematical tools, often associated to higher dimensional topology, have their origins in three dimensional contexts but in the hands of late-onset visually impaired topologists. This paradox was previously exposed in the context of algorithms for the visualization of three-dimensional magnetic fields. For this reason, the paper concludes by developing connections between mathematics and cognitive science in this specific context."
P ROBERT KOTIUGA,"Iron rings, Doctor Honoris Causa Raoul Bott, Carl Herz, and a hidden hand","The degree of Doctor of Sciences, honoris causa, was conferred on Raoul Bott by McGill University in 1987. Much of the work to make this happen was done by Carl Herz. Some of the author's personal recollections of both professors are included, along with some context for the awarding of this degree and ample historical tangents. Some cultural aspects occurring in the addresses are elaborated on, primarily, the Canadian engineer's iron ring. This paper also reprints both the convocation address of Raoul Bott and the presentation of Carl Herz on that occasion."
P ROBERT KOTIUGA,EIT in multimodal imaging for avoiding biopsies of false positive results in mamography,"EIT, in the context of false positives in mammography is considered where repeated negative results of biopsies can lead patients to avoid future mammograms. Our approach is to consider the conditional probabilities associated with use of EIT in conjunction to mammography, not for increasing the overall rate of detection of breast cancer, but for maintaining the best possible rate of cancer detection with fewer biopsies."
P ROBERT KOTIUGA,Dzyaloshinskii-Moriya chiral magnets and boundary conditions in Skyrmion electronics,"Skyrmion-based electronic devices are a subset of spintronic nanodevices based on chiral materials (1, 2). The Dzyaloshinskii-Moriya (D-M) interaction is a chiral magnetic interaction which models chiral magnetic materials showing particular promise for extending CMOS compatible Skyrmionel ectronics at scales where silicon devices can no longer compete. There are several approaches to realizing such materials in practice. One is to focus on realizing D-M interactions as a fundamental problem in materials science supported by first principles quantum field theoretic models incorporating Majorana spinnors. Another very successful approach is to extend phenomenological micro-scale models of magnetism based on the Landau-Lifschitz-Gilbert (LLG) equation to the nanoscale by incorporating spin-torque coupling. However, this phenomenological approach obscures ties to more fundamental physics and the resulting boundary conditions can be a mystery. The present work uses well established mathematical techniques to show how Majorana spinnors and Skyrmions can appear in phenomenological models. There are three key aspects in this geometric/topological approach: • The first are Weitzenboeck identities and the Gaffney inequality (3). In electromagnetic theory, they enable us to study the distinction between Maxwell and Lame eigenmodes of cavity resonators; in micromagnetics they enable us to rewrite exchange energy in terms of fewer squares. • The second set of tools is familiar from the investigation of instantons; namely the identification of suitable divergence terms which enable one to rewrite a Hamiltonian in terms of the fewest number of squares. It is in this later step that the Majorana spinnors emerge without considerations of quantum mechanics and the Skyrmion solutions become apparent in a broader geometric context than the customary thin film scenarios. • Third, is the geometric observation that the LLG equation projects the magnetization vector so as to leave its length invariant. This enables us to consider the Hamiltonian of the system modulo the rescaling of the magnetization vector. As a result of this geometric reformulation, a clearer understanding of the use of the LLG equation at the nanoscale emerges as well as a more geometric connection to the underlying quantum phenomena. Finally, the role of chirality emerges more cleanly and it points to the role of topology in the possibility of near reversible computing generating a minimum of entropy and heat (4, 5, 6)."
P ROBERT KOTIUGA,Chiral magnet models and boundary condition geometry in Skyrmion electronics,"Field theoretic techniques are used to relate (i) the Landau-Lifschitz approach to Skyrmion devices based on Dzyaloshinskii-Moriya (D-M) chiral magnets, and (ii) the mathematical approaches to quantum magnetism. This results in a geometric understanding of micromagnetic singularities and boundary conditions without the usual thin-film assumptions."
SPENCER PISTON,"IMPACT: The Journal of the Center for Interdisciplinary Teaching and Learning. Volume 7, Issue 2, Summer 2018","In the weeks and months following August 12, 2017, members of the Boston University community struggled — like Americans everywhere — to comprehend the series of troubling, and tragic, events which would come, almost immediately, to be denoted in the national imagination by the metonym “Charlottesville.” This special issue of Impact: The Journal of the Center for Interdisciplinary Teaching & Learning comprises a series of responses to these events and their aftermath, as well as the conditions which enabled them, by faculty members from across the BU campus."
SPENCER PISTON,Revisiting the theory of broken windows policing,"How has the academy contributed to the horrors of policing in the United States? While many scholars study policing, few do so from a self-reflective position, which would examine how the production of knowledge has often legitimized policing’s harms. As part of a larger effort to encourage researchers to come to terms with the role we have played in facilitating contemporary atrocities, here I reconsider political scientist James Q. Wilson and criminologist George L. Kelling’s 1982 “Broken Windows” essay, as well as its intellectual legacy. Their essay is best known for speculating that police foot-patrols, by cracking down on low-level offenses, will reduce serious crime. While this speculation has become the subject of much public and academic debate, the relationship between policing and crime is only a secondary point in the article. Unfortunately, focusing on this secondary point has led scholarly and public discourse to distort the essay’s arguments. I correct this distortion through a close reading of the essay. Wilson and Kelling argue that the primary objective of the police should be to maintain order rather than to prevent crime or even to enforce the law. As such, police should discourage behavior inconsistent with neighborhood standards (even if it is not criminal) and should also remove “disorderly” people from public life (even if they are not breaking the law). Indeed, Wilson and Kelling actually endorse illegal actions in certain instances: when these actions are committed by either police or vigilantes to fashion and maintain the authoritarian, classist, ableist, and racist order that the authors envision. After discussing how an accurate understanding of the original “Broken Windows” article has the potential to reorient contemporary studies policing, I conclude by locating broken windows theory as an important member of a family of harmful ideas, generated by academics, that have underwritten a wide range of authoritarian policing practices."
SPENCER PISTON,Trickle-down racism: Trump's effect on whites’ racist dehumanizing attitudes,
SPENCER PISTON,The limits of criminal justice reform: an analysis of elite rhetoric in four cities,"As the coronavirus pandemic swept the nation in 2020, many emphasized that carceral spaces were hotspots for the virus, leaving Black and Brown people especially vulnerable to infection. In combination with other critiques of racism in the carceral state, these observations created pressure to decarcerate, especially on the political left. How did political elites discuss the carceral state in this changed atmosphere? To answer this question, we analyze rhetoric in public statements across four liberal metropolitan areas during the spring and summer of 2020. In these statements, we find a long-standing discourse of racially paternalist penal welfarism, retrofitted to pandemic times and accompanied by a distinction between “deserving” and “undeserving” criminals. Accommodating portrayals of incarcerated people as vulnerable to COVID-19 and in desperate need of care, this pattern of rhetoric positioned the carceral state as a protector in order to justify continued incarceration."
ANDREA VEDOLIN,Robustness and dynamic sentiment,"Errors in survey expectations display waves of pessimism and optimism and significant sluggishness. This paper develops a novel theoretical framework of time-varying beliefs capturing these empirical characteristics. The dynamic beliefs arise endogenously due to agents’ attitude toward alternative models. Decision-maker’s distorted beliefs generate countercyclical risk aversion, procyclical portfolio weights, countercyclical equilibrium asset returns, and excess volatility. A calibrated version of our model is shown to match salient features in equity markets.
 Errors in survey expectations display waves of pessimism and optimism and significant sluggishness. This paper develops a novel theoretical framework of time-varying beliefs capturing these empirical facts. In our model, the dynamic beliefs arise endogenously due to agents’ attitude toward alternative models. Decision-maker’s distorted beliefs generate countercyclical risk aversion, procyclical portfolio weights, countercyclical equilibrium asset returns, and excess volatility. A calibrated version of our model is shown to match salient features in equity markets.
 "
VIJAYA B KOLACHALAMA,"Smartphone-based neuropsychological assessment in Parkinson's disease: feasibility, validity, and contextually driven variability in cognition","OBJECTIVES: The prevalence of neurodegenerative disorders demands methods of accessible assessment that reliably captures cognition in daily life contexts. We investigated the feasibility of smartphone cognitive assessment in people with Parkinson's disease (PD), who may have cognitive impairment in addition to motor-related problems that limit attending in-person clinics. We examined how daily-life factors predicted smartphone cognitive performance and examined the convergent validity of smartphone assessment with traditional neuropsychological tests. METHODS: Twenty-seven nondemented individuals with mild-moderate PD attended one in-lab session and responded to smartphone notifications over 10 days. The smartphone app queried participants 5x/day about their location, mood, alertness, exercise, and medication state and administered mobile games of working memory and executive function. RESULTS: Response rate to prompts was high, demonstrating feasibility of the approach. Between-subject reliability was high on both cognitive games. Within-subject variability was higher for working memory than executive function. Strong convergent validity was seen between traditional tests and smartphone working memory but not executive function, reflecting the latter's ceiling effects. Participants performed better on mobile working memory tasks when at home and after recent exercise. Less self-reported daytime sleepiness and lower PD symptom burden predicted a stronger association between later time of day and higher smartphone test performance. CONCLUSIONS: These findings support feasibility and validity of repeat smartphone assessments of cognition and provide preliminary evidence of the effects of context on cognitive variability in PD. Further development of this accessible assessment method could increase sensitivity and specificity regarding daily cognitive dysfunction for PD and other clinical populations."
VIJAYA B KOLACHALAMA,Deep-learning-driven quantification of interstitial fibrosis in digitized kidney biopsies,"Interstitial fibrosis and tubular atrophy (IFTA) on a renal biopsy are strong indicators of disease chronicity and prognosis. Techniques that are typically used for IFTA grading remain manual, leading to variability among pathologists. Accurate IFTA estimation using computational techniques can reduce this variability and provide quantitative assessment. Using trichrome-stained whole-slide images (WSIs) processed from human renal biopsies, we developed a deep-learning framework that captured finer pathologic structures at high resolution and overall context at the WSI level to predict IFTA grade. WSIs (n = 67) were obtained from The Ohio State University Wexner Medical Center. Five nephropathologists independently reviewed them and provided fibrosis scores that were converted to IFTA grades: ≤10% (none or minimal), 11% to 25% (mild), 26% to 50% (moderate), and >50% (severe). The model was developed by associating the WSIs with the IFTA grade determined by majority voting (reference estimate). Model performance was evaluated on WSIs (n = 28) obtained from the Kidney Precision Medicine Project. There was good agreement on the IFTA grading between the pathologists and the reference estimate (κ = 0.622 ± 0.071). The accuracy of the deep-learning model was 71.8% ± 5.3% on The Ohio State University Wexner Medical Center and 65.0% ± 4.2% on Kidney Precision Medicine Project data sets. Our approach to analyzing microscopic- and WSI-level changes in renal biopsies attempts to mimic the pathologist and provides a regional and contextual estimation of IFTA. Such methods can assist clinicopathologic diagnosis."
VIJAYA B KOLACHALAMA,Automated detection of mild cognitive impairment and dementia from voice recordings: A natural language processing approach,"INTRODUCTION: Automated computational assessment of neuropsychological tests would enable widespread, cost-effective screening for dementia. METHODS: A novel natural language processing approach is developed and validated to identify different stages of dementia based on automated transcription of digital voice recordings of subjects' neuropsychological tests conducted by the Framingham Heart Study (n = 1084). Transcribed sentences from the test were encoded into quantitative data and several models were trained and tested using these data and the participants' demographic characteristics. RESULTS: Average area under the curve (AUC) on the held-out test data reached 92.6%, 88.0%, and 74.4% for differentiating Normal cognition from Dementia, Normal or Mild Cognitive Impairment (MCI) from Dementia, and Normal from MCI, respectively. DISCUSSION: The proposed approach offers a fully automated identification of MCI and dementia based on a recorded neuropsychological test, providing an opportunity to develop a remote screening tool that could be adapted easily to any language."
VIJAYA B KOLACHALAMA,Large language models in neurology research and future practice,"Recent advancements in generative artificial intelligence, particularly using large language models (LLMs), are gaining increased public attention. We provide a perspective on the potential of LLMs to analyze enormous amounts of data from medical records and gain insights on specific topics in neurology. In addition, we explore use cases for LLMs, such as early diagnosis, supporting patient and caregivers, and acting as an assistant for clinicians. We point to the potential ethical and technical challenges raised by LLMs, such as concerns about privacy and data security, potential biases in the data for model training, and the need for careful validation of results. Researchers must consider these challenges and take steps to address them to ensure that their work is conducted in a safe and responsible manner. Despite these challenges, LLMs offer promising opportunities for improving care and treatment of various neurologic disorders."
MARTHA C TOMPSON,A latent class analysis of parental bipolar disorder: examining associations with offspring psychopathology,"Bipolar disorder (BD) is highly heterogeneous, and course variations are associated with patient outcomes. This diagnostic complexity challenges identification of patients in greatest need of intervention. Additionally, course variations have implications for offspring risk. First, latent class analysis (LCA) categorized parents with BD based on salient illness characteristics: BD type, onset age, polarity of index episode, pole of majority of episodes, rapid cycling, psychosis, anxiety comorbidity, and substance dependence. Fit indices favored three parental classes with some substantively meaningful patterns. Two classes, labeled “Earlier-Onset Bipolar-I” (EO-I) and “Earlier-Onset Bipolar-II” (EO-II), comprised parents who had a mean onset age in mid-adolescence, with EO-I primarily BD-I parents and EO-II entirely BD-II parents. The third class, labeled “Later-Onset BD” (LO) had an average onset age in adulthood. Classes also varied on probability of anxiety comorbidity, substance dependence, psychosis, rapid cycling, and pole of majority of episodes. Second, we examined rates of disorders in offspring (ages 4–33, Mage=13.46) based on parental latent class membership. Differences emerged for offspring anxiety disorders only such that offspring of EO-I and EO-II parents had higher rates, compared to offspring of LO parents, particularly for daughters. Findings may enhance understanding of BD and its nosology"
MARTHA C TOMPSON,Maternal depression and youth internalizing and externalizing symptomatology: severity and chronicity of past maternal depression and current maternal depressive symptoms,"Maternal depression is a well-documented risk factor for youth depression, and taking into account its severity and chronicity may provide important insight into the degree of risk conferred. This study explored the degree to which the severity/chronicity of maternal depression history explained variance in youth internalizing and externalizing symptoms above and beyond current maternal depressive symptoms among 171 youth (58 % male) ages 8 to 12 over a span of 3 years. Severity and chronicity of past maternal depression and current maternal depressive symptoms were examined as predictors of parent-reported youth internalizing and externalizing symptomatology, as well as youth self-reported depressive symptoms. Severity and chronicity of past maternal depression did not account for additional variance in youth internalizing and externalizing symptoms at Time 1 beyond what was accounted for by maternal depressive symptoms at Time 1. Longitudinal growth curve modeling indicated that prior severity/chronicity of maternal depression predicted levels of youth internalizing and externalizing symptoms at each time point when controlling for current maternal depressive symptoms at each time point. Chronicity of maternal depression, apart from severity, also predicted rate of change in youth externalizing symptoms over time. These findings highlight the importance of screening and assessing for current maternal depressive symptoms, as well as the nature of past depressive episodes. Possible mechanisms underlying the association between severity/chronicity of maternal depression and youth outcomes, such as residual effects from depressive history on mother–child interactions, are discussed."
MARTHA C TOMPSON,Childhood mental health: an ecological analysis of the effects of neighborhood characteristics,"Research on childhood mental illness traditionally examines risk factors most proximal to the child. However, current trends reflect growing interest in how broader contextual factors contribute to psychopathology risk. In this study, we examined neighborhood‐level indicators as potential sources of chronic strain in a sample of 156 mother–child dyads; children were 8 to 12 years old. For most neighborhood indicators, data were collected at the level of census tracts using publicly available data sets. We hypothesized that these indicators would be both associated with greater overall mental health symptoms and specifically predictive of childhood symptoms of depression. We also examined potential mediators (maternal functioning and family cohesion) and moderators (maternal depression). Neighborhood indicators correlated with parents’ ratings of children's overall mental health problems, but did not correlate with children's self‐report of depression symptoms. Maternal functioning mediated neighborhood effects on children's overall mental health problems. Implications and directions for future research are presented."
MARTHA C TOMPSON,Family-focused treatment for childhood depression: model and case illustrations,"Although the evidence base for treatment of depressive disorders in adolescents has strengthened in recent years, less is known about the treatment of depression in middle to late childhood. A family-based treatment may be optimal in addressing the interpersonal problems and symptoms frequently evident among depressed children during this developmental phase, particularly given data indicating that attributes of the family environment predict recovery versus continuing depression among depressed children. Family-Focused Treatment for Childhood Depression (FFT-CD) is designed as a 15-session family treatment with both the youth and parents targeting two putative mechanisms involved in recovery: (a) enhancing family support, specifically decreasing criticism and increasing supportive interactions; and (b) strengthening specific cognitive-behavioral skills within a family context that have been central to CBT for depression, specifically behavioral activation, communication, and problem solving. This article describes in detail the FFT-CD protocol and illustrates its implementation with three depressed children and their families. Common themes/challenges in treatment included family stressors, comorbidity, parental mental health challenges, and inclusion/integration of siblings into sessions. These three children experienced positive changes from pre- to posttreatment on assessor-rated depressive symptoms, parent- and child-rated depressive symptoms, and parent-rated internalizing and externalizing symptoms. These changes were maintained at follow-up evaluations 4 and 9 months following treatment completion."
MARTHA C TOMPSON,A randomized clinical trial comparing family-focused treatment and individual supportive therapy for depression in childhood and early adolescence,"OBJECTIVE: Despite the morbidity and negative outcomes associated with early-onset depression, few studies have examined the efficacy of psychosocial treatment for depressive disorders during childhood. Integrating family in treatment could have particularly salutary effects during this developmental period. This trial compared immediate posttreatment effects of family-focused treatment for childhood depression (FFT-CD) with those of individual supportive psychotherapy (IP) for children 7 to 14 years old with depressive disorders. METHOD: Children were randomized to 15 sessions of FFT-CD (n = 67) or IP (n = 67) over 4 months. The primary treatment outcome was adequate clinical depression response, defined as at least a 50% decrease in score on the Children's Depression Rating Scale-Revised (CDRS-R). Additional outcomes included patient-centered outcomes (parent- and child-reported treatment satisfaction), remission (defined as CDRS-R score ≤28), change in continuous CDRS-R score, and change in child and parent reports of depressive and non-depressive symptoms and social adjustment. RESULTS: Significant improvement was evident across groups for depressive and non-depressive symptoms, global response, and functioning and social adjustment. Compared with children randomized to IP, children randomized to FFT-CD showed higher rates of adequate clinical depression response (77.7% versus 59.9%; number needed to treat = 5.72; odds ratio 2.29; 95% CI 1.001-5.247; t = 1.97, p = .0498). Across treatments, families reported high satisfaction; compared with IP families, FFT-CD families reported greater knowledge and skills for managing depression. There were no significant differences between treatment arms on secondary outcomes. CONCLUSION: Results support the value of psychosocial intervention, emphasize the important role that families play, and highlight the potential for FFT-CD for supporting recovery in children with depression. Clinical trial registration information-Systems of Support Study for Childhood Depression; http://clinicaltrials.gov; NCT01159041."
YOONSOOK HA,Massachusetts early care and education provider survey – recommendations from pilot surveys,
YOONSOOK HA,Child care providers’ experiences during COVID-19,
YOONSOOK HA,The impact of subsidy reimbursement rate and family copayment changes on access to child care: initial ideas from key informant interview findings,
CARA L. LEWIS,Effects of additional anterior body mass on gait,"BACKGROUND: Gradual increases in mass such as during pregnancy are associated with changes in gait at natural velocities. The purpose of this study was to examine how added mass at natural and imposed slow walking velocities would affect gait parameters. METHODS: Eighteen adult females walked at two velocities (natural and 25 % slower than their natural pace) under four mass conditions (initial harness only (1 kg), 4.535 kg added anteriorly, 9.07 kg added anteriorly, and final harness only (1 kg)). We collected gait kinematics (100 Hz) using a motion capture system. RESULTS: Added anterior mass decreased cycle time and stride length. Stride width decreased once the mass was removed (p < .01). Added mass resulted in smaller peak hip extension angles (p < .01). The imposed slow walking velocity increased cycle time, double limb support time and decreased stride length, peak hip extension angles, and peak plantarflexion angles (p < .01). With added anterior mass and an imposed slow walking velocity, participants decreased cycle time when mass was added and increased cycle time once the mass was removed (p < .01). CONCLUSIONS: Gait adaptations may be commensurate with the magnitude of additional mass when walking at imposed slow versus natural velocities. This study presents a method for understanding how increased mass and imposed speed might affect gait independent of other effects related to pregnancy. Examining how added body mass and speed influence gait is one step in better understanding how women adapt to walking under different conditions."
CARA L. LEWIS,Postural correction reduces hip pain in adult with acetabular dysplasia: A case report,"Developmental dysplasia of the hip is often diagnosed in infancy, but less severe cases of acetabular dysplasia are being detected in young active adults. The purpose of this case report is to present a non-surgical intervention for a 31-year-old female with mild acetabular dysplasia and an anterior acetabular labral tear. The patient presented with right anterior hip and groin pain, and she stood with the trunk swayed posterior to the pelvis (swayback posture). The hip pain was reproduced with the anterior impingement test. During gait, the patient maintained the swayback posture and reported 6/10 hip pain. Following correction of the patient's posture, the patient's pain rating was reduced to a 2/10 while walking. The patient was instructed to maintain the improved posture. At the 1 year follow-up, she demonstrated significantly improved posture in standing and walking. She had returned to recreational running and was generally pain-free. The patient demonstrated improvement on self-reported questionnaires for pain, function, and activity. These findings suggest that alteration of posture can have an immediate and lasting effect on hip pain in persons with structural abnormality and labral pathology."
CARA L. LEWIS,Successful rehabilitation of a young adult with total hip arthroplasty a decade after a Girdlestone procedure: a case report,"This is a case presentation of a female patient who underwent a Girdlestone arthroplasty at age 10 years and a total hip arthroplasty at age 21. Despite early postoperative rehabilitation, the patient experienced increasing pain, progressive gait deviations, and functional limitations during the year after surgery. This course of care was initiated 1 year after surgery and focused on motor retraining to address pain and gait deviations. This case demonstrates that positive outcomes can be achieved after longstanding musculoskeletal dysfunction is corrected, but that prolonged rehabilitation may be necessary to produce changes in movement patterns at both the local (joint and muscle) and central (cortical) levels. Correction of both the structural problem and the learned movement patterns is necessary for a successful outcome."
CARA L. LEWIS,Short-Term Locomotor Adaptation to a Robotic Ankle Exoskeleton Does not Alter Soleus Hoffmann Reflex Amplitude,"BACKGROUND To improve design of robotic lower limb exoskeletons for gait rehabilitation, it is critical to identify neural mechanisms that govern locomotor adaptation to robotic assistance. Previously, we demonstrated soleus muscle recruitment decreased by ~35% when walking with a pneumatically-powered ankle exoskeleton providing plantar flexor torque under soleus proportional myoelectric control. Since a substantial portion of soleus activation during walking results from the stretch reflex, increased reflex inhibition is one potential mechanism for reducing soleus recruitment when walking with exoskeleton assistance. This is clinically relevant because many neurologically impaired populations have hyperactive stretch reflexes and training to reduce the reflexes could lead to substantial improvements in their motor ability. The purpose of this study was to quantify soleus Hoffmann (H-) reflex responses during powered versus unpowered walking. METHODS We tested soleus H-reflex responses in neurologically intact subjects (n=8) that had trained walking with the soleus controlled robotic ankle exoskeleton. Soleus H-reflex was tested at the mid and late stance while subjects walked with the exoskeleton on the treadmill at 1.25 m/s, first without power (first unpowered), then with power (powered), and finally without power again (second unpowered). We also collected joint kinematics and electromyography. RESULTS When the robotic plantar flexor torque was provided, subjects walked with lower soleus electromyographic (EMG) activation (27-48%) and had concomitant reductions in H-reflex amplitude (12-24%) compared to the first unpowered condition. The H-reflex amplitude in proportion to the background soleus EMG during powered walking was not significantly different from the two unpowered conditions. CONCLUSION These findings suggest that the nervous system does not inhibit the soleus H-reflex in response to short-term adaption to exoskeleton assistance. Future studies should determine if the findings also apply to long-term adaption to the exoskeleton."
KATHERINE A GERGEN BARNETT,COVID-19 shines a light on health inequities in communities of color: a youth-driven photovoice inquiry,"This manuscript reports on a youth-driven health assessment engaging youth of color in identifying community health priorities during the coronavirus disease 2019 (COVID-19) pandemic. Photovoice, a participatory visual ethnographic health assessment strategy, was used to explore the question: What does health or healthiness mean to you and/or your community? Youth captured images that represented their priorities. The photos were discussed using the SHOWed framework and analyzed thematically. Four themes related to community health were identified. Additionally, youth captured their narrative of COVID-19 as ""a revealing force that highlights systemic inequities, driving individuals and communities to both cultivate their resilience and take healthcare into their own hands in response to government and policy level failures."" Youth are acutely aware of the historical and structural inequities that create multi-level barriers to healthcare access. Health inequities existed long before the pandemic, but the current crisis requires us to examine ways to transform the healthcare landscape moving forward."
ANNE DONOHUE,"IMPACT: The Journal of the Center for Interdisciplinary Teaching and Learning. Volume 7, Issue 1, Winter 2018","How do our students learn what it means to be a human being, with all the attendant responsibilities and joys? How do we learn to teach in a truly interdisciplinary manner? These are some of the questions that preoccupy this issue’s contributors."
ANNE DONOHUE,Public health advocacy and journalism: Towards a healthy population lessons from Boston University’s Program for Global Health Storytelling,"This presentation was given at Lesall College on September 24, 2019. We provided an overview of the Boston University Program for Global Health Storytelling and the graduate class we have been since 2018. We are particularly interested in the intersection where public health and journalism meet and sometimes clash. Collaboration between our fields is vital but not always easy."
DANIEL C WEINER,"Cosmology intertwined: a review of the particle physics, astrophysics, and cosmology associated with the cosmological tensions and anomalies",
JOSEPH HARRIS,"Bostonia: v. 13, no. 1-10",
JOSEPH HARRIS,"D-cycloserine augmentation of exposure-based cognitive behavior therapy for anxiety, obsessive-compulsive, and posttraumatic stress disorders: a systematic review and meta-analysis of individual participant data","Importance: Whether and under which conditions D-cycloserine (DCS) augments the effects of exposure-based cognitive behavior therapy for anxiety, obsessive-compulsive, and posttraumatic stress disorders is unclear. Objective: To clarify whether DCS is superior to placebo in augmenting the effects of cognitive behavior therapy for anxiety, obsessive-compulsive, and posttraumatic stress disorders and to evaluate whether antidepressants interact with DCS and the effect of potential moderating variables. Data Sources: PubMed, EMBASE, and PsycINFO were searched from inception to February 10, 2016. Reference lists of previous reviews and meta-analyses and reports of randomized clinical trials were also checked. Study Selection: Studies were eligible for inclusion if they were (1) double-blind randomized clinical trials of DCS as an augmentation strategy for exposure-based cognitive behavior therapy and (2) conducted in humans diagnosed as having specific phobia, social anxiety disorder, panic disorder with or without agoraphobia, obsessive-compulsive disorder, or posttraumatic stress disorder. Data Extraction and Synthesis: Raw data were obtained from the authors and quality controlled. Data were ranked to ensure a consistent metric across studies (score range, 0-100). We used a 3-level multilevel model nesting repeated measures of outcomes within participants, who were nested within studies. Results: Individual participant data were obtained for 21 of 22 eligible trials, representing 1047 of 1073 eligible participants. When controlling for antidepressant use, participants receiving DCS showed greater improvement from pretreatment to posttreatment (mean difference, -3.62; 95% CI, -0.81 to -6.43; P = .01; d = -0.25) but not from pretreatment to midtreatment (mean difference, -1.66; 95% CI, -4.92 to 1.60; P = .32; d = -0.14) or from pretreatment to follow-up (mean difference, -2.98, 95% CI, -5.99 to 0.03; P = .05; d = -0.19). Additional analyses showed that participants assigned to DCS were associated with lower symptom severity than those assigned to placebo at posttreatment and at follow-up. Antidepressants did not moderate the effects of DCS. None of the prespecified patient-level or study-level moderators was associated with outcomes. Conclusions and Relevance: D-cycloserine is associated with a small augmentation effect on exposure-based therapy. This effect is not moderated by the concurrent use of antidepressants. Further research is needed to identify patient and/or therapy characteristics associated with DCS response."
JOSEPH HARRIS,Inquiry into the interests of certain eighth-grade science pupils,
JOSEPH HARRIS,"BMQ : Boston medical quarterly: v. 11, no. 1-4",
JOSEPH HARRIS,Dabbling to increase student engagement in remote and hybrid teaching,
JOSEPH HARRIS,"Bostonia: v. 9, no. 1-10",
JOSEPH HARRIS,Science and democracy reconsidered,"To what extent is the normative commitment of STS to the democratization of science a product of the democratic contexts where it is most often produced? STS scholars have historically offered a powerful critical lens through which to understand the social construction of science, and seminal contributions in this area have outlined ways in which citizens have improved both the conduct of science and its outcomes. Yet, with few exceptions, it remains that most STS scholarship has eschewed study of more problematic cases of public engagement of science in rich, supposedly mature Western democracies, as well as examination of science-making in poorer, sometimes non-democratic contexts. How might research on problematic cases and dissimilar political contexts traditionally neglected by STS scholars push the field forward in new ways? This paper responds to themes that came out of papers from two Eastern Sociological Society Presidential Panels on Science and Technology Studies in an Era of Anti-Science. It considers implications of the normative commitment by sociologists working in the STS tradition to the democratization of science."
JOSEPH HARRIS,"The use of reason in ethics: E.S. Brightman, C.I. Lewis, and S.E. Toulmin","Brightman defines reason as the ideal function of experience that brings the disparate elements given in experience into inclusive, systematic harmony. Lewis defines reason as consistency in attitude and in prepared manner of response to the situations in which the doer finds himself. Both thinkers agree that reason can be used to make true value judgments and good value choices, despite some differences in their analysis of valuation. Brightman holds that value-claims, or what is thought to be good, must be tested by norms which are themselves principles for the coherent organization of such claims. Lewis also speaks of valuations as value-claims, but adds that goodness is an objective quality of objects given in experience that no criticism can wholly remove. For Brightman, a rational value-choice is one that contributes to the organization of all value-claims in an internally harmonious pattern that ultimately involves fruitful interaction with other persons and with the total environment of the individual. But Lewis holds that value-choices will be rational (or right) when they conform with rules of consistent doing and such choices will be intelligible (or good) when they include an appraisal of the value potentialities of the objective situation in which the doer finds himself. Despite initial differences in value analysis, both thinkers agree that the summum bonum is a life of consistently chosen and coherently organized valuations which all persons ought to choose. Their common view of the good life seems open to two objections: (a) one may prefer intrinsic values other than the ideal of coherently chosen values without moral disapprobation; and (b) the use of ""ought"" can mean either what is fitting or what is a duty to do in a situation, and these two meanings do not always coincide as they suggest. Brightman and Lewis hold that the content of moral rightness consists of what is both objectively good and in conformity with the principle of universalization. This view is open to the objections that: (a) it makes duty consist of whatever is thought to be objectively good, rather than 11hat is objectively right; (b) it makes it impossible to settle a conflict between duties, where such a conflict is not about some good end but is about which alternative course of action is morally right; and (c) being under a specific obligation seems a different kind of experience from valuing something. Toulmin is concerned with establishing the validity of the use of argument in ethical disputes so that ""good"" or sufficient reasons can be found to terminate such disputes. The ""good reasons"" approach essentially consists of the derivation of criteria for evaluation from a given field of discourse in which arguments first arise. Toulmin found only two ways in which ethical arguments can be terminated. First, an argument about the rightness of an act can be terminated if the act in question is found to conform with the moral code of the community. Secondly, an argument about the goodness of a moral rule can be terminated by asking if the rule in question contributes to the fecundity of the community. Two criticisms have been made of the ideal utilitarian context in which Toulmin discusses ethical reasoning: (a) the use of the principle of fecundity to terminate arguments about moral rules functions as a definition of goodness and rightness and as such is open to the objections made against utilitarianism--objections that Toulmin does not consider; and (b) his dismissal of the deontological point of view as ""primitive"" is not entailed by the ""good reasons"" approach to ethics and so the deontologist may find good reasons for rejecting utilitarianism."
PAULA A QUATROMONI,Feasibility and acceptability of dietary intake assessment via 24-hour recall and food frequency questionnaire among women with low socioeconomic status,"BACKGROUND: Comprehensive evaluation of dietary interventions depends on effective and efficient measurement to quantify behavior change. To date, little is known regarding which self-reported measure of dietary intake is most feasible and acceptable for use in evaluation of the effectiveness of diet intervention studies among underserved populations. OBJECTIVE: This research focused on evaluating feasibility and acceptability of two self-report measures of diet. DESIGN: Cross-sectional. PARTICIPANTS/SETTING: Two interviewer-administered 24-hour recalls and a 110-item food frequency questionnaire (FFQ) were administered to both English- and Spanish-speaking participants (n=36) by native English- and Spanish-speaking research assistants. On completion of both dietary assessments, participants were interviewed regarding their preference of measure. MAIN OUTCOME MEASURES: Feasibility for completion of the dietary assessment measures was determined for contacts and retention. Acceptability of the measures was determined through responses to open- and closed-ended questions. RESULTS: During the 5-month trial, 36 participants were enrolled; 29 completed both intake measures, and 26 completed both measures and the interview. Participants were mainly Hispanic/Latina (72%), with a mean age of 37.0 (±7.6) years. Feasibility targets were met for contacts (1.9, 1.6, 1.8 contact attempts to complete each diet assessment measure with a target of ≤2) and for retention with 89% and 91% completing two 24-hour recalls and the FFQ, respectively. Participants indicated both diet assessment methods were generally acceptable; both positive and negative comments were received for use of the FFQ. CONCLUSION: Dietary assessment with the use of 24-hour recalls or an FFQ can be feasible and acceptable among women with low socioeconomic status, although care should be taken to address cultural appropriateness in the selection of the measurement method. Copyright © 2018 Academy of Nutrition and Dietetics. Published by Elsevier Inc. All rights reserved."
PAULA A QUATROMONI,Relationship between stress and healthy lifestyle factors of college students,"OBJECTIVES: We assessed the correlation between college students' perceived stress (PS) and healthy lifestyle factors (HLFs) in this cross-sectional study. METHODS: Data were collected from 1396 undergraduates enrolled in an introductory nutrition course. We measured PS and 5 HLFs (physically active, healthy diet, non-smoker, non-binge drinker, healthy BMI). RESULTS: The mean PS score was 15.0 ± 0.2 (maximum, 40) and the mean number of HLFs reported was 2.9 ± 0.03. Females were more likely to report 4-5 HLFs than males (31% vs 20%). We found a statistically significant inverse correlation between PS and HLFs for women (p < .01). CONCLUSIONS: Health promotion interventions that support healthy food choices, physical activity and low-risk substance use may reduce perceived stress in the college population."
PAULA A QUATROMONI,Body mass index and sociodemographic predictors of school lunch purchase behavior during a year-long environmental intervention in middle school,"Modifying the school food environment is on the national agenda as one strategy to improve the nutritional quality of children's diets. Because few environmental-level interventions have been rigorously evaluated, the evidence base to inform programs and policies is limited. Of concern is the impact that changes to cafeteria offerings will have on participation in school meal programs. This study evaluates school lunch participation in the setting of a year-long middle school cafeteria intervention by examining the association between body mass index (BMI), sociodemographics, and the purchases of school lunch meals. IMOVE meals were healthier choices that met stringent nutritional criteria and were offered alongside standard lunch meals. Students who were overweight had a significantly higher purchase rate for both types of meals compared to those with a healthy BMI. Non-white race, younger age, being male, and low-income status were also significantly associated with participation in school lunch. Results indicate that nutritionally vulnerable students participate in school lunch and are equally likely to buy healthy alternatives or standard meals. This behavioral observation has important implications for school foodservice programs and policies. These results are timely given recent federal legislation to improve the school food environment to influence students' food choice behaviors."
PAULA A QUATROMONI,Managing type 2 diabetes or prediabetes and binge eating disorder: a qualitative study of patients' perceptions and lived experiences,"BACKGROUND: The overlap in prevalence between type 2 diabetes and binge eating disorder is substantial, with adverse physical and mental health consequences. Little is known about patients' efforts at managing these two conditions simultaneously. The research objective was to explore patients' experiences managing co-existing type 2 diabetes or prediabetes and binge eating disorder. METHODS: This is a qualitative descriptive study using semi-structured interviews. Participants included 21 women with type 2 diabetes or prediabetes (90% non-Hispanic White; mean age 49 ± 14.8 years, mean BMI 43.8 ± 8.4; 48% with type 2 diabetes and mean HbA1c was 8.4%). Interviews were analyzed using thematic analysis and NVivo software. RESULTS: Qualitative analysis revealed that participants reported binge episodes frequently started in childhood or adolescence and went undiagnosed for decades; notably, they recalled that diabetes diagnosis preceded the binge eating disorder diagnosis. They also described trying to lose weight throughout their lives and how feelings of deprivation, shame, and failure exacerbated binge eating. Participants further reported how binge eating made diabetes self-care and outcomes worse. Finally, participants observed that when binge eating disorder treatment and diabetes management were synergistically integrated, they experienced improvements in both binge eating and glycemic outcomes. This integration included reframing negative thoughts surrounding binge eating disorder and diabetes self-management and increasing their understanding of how the two disorders were inter-related. CONCLUSION: Findings highlight the importance of increasing healthcare providers' awareness of and screening for binge eating disorder in the treatment of diabetes and inform specific integrated interventions that address both diagnoses. From this study where we interviewed 21 women with binge eating disorder (BED) and type 2 diabetes/prediabetes, we learned how binge eating impacted diabetes management and how diabetes impacted BED. Most participants reported receiving the diabetes diagnosis before being diagnosed with BED despite the earlier onset of binge eating, pointing to the need for BED screening. Participants described trying to lose weight throughout their lives and reported feelings of failure and shame, which made binge eating worse. Binge eating made diabetes management harder, but when diabetes and BED treatment were aligned, participants experienced improvements in binge symptoms and diabetes outcomes."
PAULA A QUATROMONI,"The association among diet, dietary fiber, and bowel preparation at colonoscopy","BACKGROUND AND AIMS: Pre-colonoscopy dietary restrictions vary widely and lack evidence-based guidance. We investigated whether fiber and various other foods/macronutrients consumed during the 3 days before colonoscopy are associated with bowel preparation quality. METHODS: This was a prospective observational study among patients scheduled for outpatient colonoscopy. Patients received instructions including split-dose polyethylene glycol, avoidance of vegetables/beans 2 days before colonoscopy, and a clear liquid diet the day before colonoscopy. Two 24-hour dietary recall interviews and 1 patient-recorded food log measured dietary intake on the 3 days before colonoscopy. The Nutrition Data System for Research was used to estimate dietary exposures. Our primary outcome was the quality of bowel preparation measured by the Boston Bowel Preparation Scale (BBPS). RESULTS: We enrolled 201 patients from November 2015 to September 2016 with complete data for 168. The mean age was 59 years (standard deviation, 7 years), and 90% of colonoscopies were conducted for screening/surveillance. Only 17% and 77% of patients complied with diet restrictions 2 and 1 day(s) before colonoscopy, respectively. We found no association between foods consumed 2 and 3 days before colonoscopy and BBPS scores. However, BPPS was positively associated with intake of gelatin, and inversely associated with intake of red meat, poultry, and vegetables on the day before colonoscopy. CONCLUSIONS: Our findings support recent guidelines encouraging unrestricted diets >1 day before colonoscopy if using a split-dose bowel regimen. Furthermore, we found no evidence to restrict dietary fiber 1 day before colonoscopy. We also found evidence to promote consumption of gelatin and avoidance of red meat, poultry, and vegetables 1 day before colonoscopy."
PAULA A QUATROMONI,Eating disorders in male athletes: factors associated with onset and maintenance,"Male athletes are underrepresented in eating disorders research. This phenomenological study investigated the experiences of male athletes who self-identified as having an eating disorder, disordered eating, or compulsive exercise behaviors. Eight male collegiate athletes were interviewed, and qualitative analysis identified factors associated with the onset and maintenance of disordered behaviors. Among the novel findings was the salient influence of social media as a driver of body dissatisfaction and disordered behaviors. The participants described a perceived sense of control and feeling of pride associated with the use of behaviors, cultural norms in a male sport environment that sustained these behaviors, and a shared belief that, until they experienced a loss of control over their use of behaviors, they would not likely ask for help or seek treatment. These findings have implications for additional research, as well as individual and systems-level strategies for the prevention, screening, and treatment of eating and exercise disorders in male sport."
PAULA A QUATROMONI,Women's perceptions of weight stigma and experiences of weight-neutral treatment for binge eating disorder: a qualitative study,"BACKGROUND: The detrimental effects of weight stigma are a growing concern as a contributor to negative physical and mental health outcomes, disparities in care, and healthcare avoidance. Research exploring the impact of weight-neutral healthcare is limited but suggests weight-neutral interventions are associated with positive psychological and behavioral outcomes. Little is known about patients' lived experiences receiving weight-neutral healthcare. METHODS: We conducted semi-structured interviews between Feb 5, 2019 and Feb 25, 2020 with 21 women (90% non-Hispanic white, mean age 49 ± 14.8 years) who had type 2 diabetes or prediabetes and high body weight (mean body mass index 43.8 ± 8.4, range: 30.2-63.9) and previously attended a specialized treatment program for binge eating disorder. We recruited individuals with type 2 diabetes or prediabetes who completed of >2 weeks of a specialized binge eating disorder treatment program with the ability to participate in an English-spoken interview and did not have cognitive impairment or severe psychopathology that would limit recall or engagement in the interview. Interviews were analysed using thematic analysis and Nvivo software. The main outcome we studied was patients' lived experience in healthcare settings and in a weight-neutral eating disorder treatment program. FINDINGS: Participants reported experiencing weight stigma in healthcare encounters and believed this decreased the quality of care they received. While participants frequently attempted to lose weight, they experienced embarrassment, internalized a sense of failure, and felt blamed for their weight and health conditions. In describing experiences within a weight-neutral paradigm, participants reported that helpful elements included consistency in the eating pattern (emphasizing adequate, varied, and nourishing intake), sufficient and specific education, and comprehensive support. Reported impacts included decreased binge episodes, experiencing less shame, and increased resiliency following treatment. Some participants experienced the weight-neutral treatment recommendations and the absence of the pursuit of weight loss as challenging. INTERPRETATION: Weight-neutral treatment may improve psychological and behavioral outcomes regarding binge eating, and longitudinal, quantitative research is warranted. These findings are useful to decrease weight stigma in provider-patient interactions. FUNDING: The Dudley Allen Sargent Research Fund, Boston University."
PAULA A QUATROMONI,Long-term yogurt consumption and risk of incident hypertension in adults,
MARGARITA GUILLORY,Spiritual and social transformation in African American spiritual churches: more than conjurers,"At the core of African American religion’s response to social inequalities has been a symbiotic relationship between socio-political activism and spiritual restoration. Drawing on archival material and ethnographic fieldwork with African American Spiritual Churches in the USA, this book examines how their spiritual and social work can shed light on the interplay between corporate activism and individual spirituality. This book traces the development of this “politico-spiritual” approach to injustice from the beginning of the twentieth century through the opening decade of the twenty-first century, using the work of African American Spiritual Churches as a lens through which to observe its progression. Addressing subjects such as spiritual healing, support of the homeless, gender equality and the aftermath of hurricane Katrina, it demonstrates that these communities are clearly motivated by the dual concerns of the soul and the community. This study diversifies our understanding of the African American religious landscape, highlighting an approach to social injustice that conjoins both political and spiritual transformations. As such, it will be of significant interest to scholars of religious studies, African American studies and politics."
MERAV SHOHET,"Universalism without uniformity: explorations in mind & culture. Julia L. Cassaniti and Usha Menon, eds., Chicago: University of Chicago Press, 2017, 317 pp.","Universalism without Uniformity is a powerful homage to Richard A. Shweder’s generative work in cultural psychology. At the volume’s center is one of Shweder’s enduring mantras and intellectual commitments, “universalism without uniformity.” This entails several other foundational principles that trace their lineage, as do the volume’s contributors, to John and Beatrice Whiting’s mid-20th-century interdisciplinary, psychological anthropological comparative work."
MERAV SHOHET,"Troubling love: gender, class, and sideshadowing the ""happy family"" in Vietnam","Though socially and politically different, Vietnam's Confucian, colonial, socialist, and marketizing regimes share a common master narrative of ideal women as the moral bedrock of their nation: virtuous, self‐sacrificing mothers. Drawing on ethnographic material collected in Đà Nẵng, this essay examines how women deploy discourses about ethical sentiments and national development to make sense of their experiences of love. I focus on women's moral struggles with and reasoning about sacrifice and care to complicate understandings of romantic love as linked to capitalist individualism and modernity. Instead, I show how women subtly critique, yet remain committed to, forms of love that reinforce—through state policy and common practice—hierarchical gender, intergenerational, and class relations. This is achieved through the telling and living of sideshadowing narratives, that is, subjunctive tales that invite contingency and contradiction. This nonteleological narrative practice reveals the precarious nature of ethical life and the ways love entangles political economy, moral sentiments, and moral reasoning. [morality and ethics, love, class and gender, narrative practice, Vietnam]
 Résumé: Quoique socialement et politiquement différents, les régimes confucéen, colonial, socialiste et de marché partagent undiscours commun sur la femme idéale, fondation morale de la nation vietnamienne, en tant que mère vertueuseet sacrificielle. Sur la base d’une enquête ethnographique menée àĐàNẵng, cet article examine comment les femmes vietnamiennes signifient leur expérienceamoureuseà travers des discours sur les sentiments moraux et le développement national. En mettant l’accent sur les conflits moraux et les raisonnements sur le sacrifice et le care, il approfondit la compréhensions de l’amour romantique en lien avec l’individualisme inhérent au capitalismeet la modernité. Il montre que les femmes critiquent subtilement–tout en y restant attachées–des formes d’amour qui renforcent, sous l’effet de politiqueset de pratiques, des rapports hiérarchiques de genre, de génération et de classe. Cette critique est rendue possible par l’expression de discours latéraux et évolutifs (sideshadowing), notamment des récits subjunctifs qui évoquent la contingence et la contradiction. Ces pratiquesnarrativesrévèlentla nature précaire de la vie morale et l’enchevêtrement de l’amour avec l’économie politique, les sentiments moraux et le raisonnement éthique.
 Tóm tắt: Mặc dù khác nhau trong khía cạnh xã hội và chính trị, các chếđộKhổng giáo, thực dân, xã hội chủnghĩa, và thịtrường tại Việt Nam có cùng một diễn ngôn chủđạo vềngười đàn bà lý tưởng tạo thành nền tảng luân lý của dân tộc: những người mẹđức hạnh và giàu lòng hy sinh. Dựa vào dữliệu thu thập theo phương pháp điều tra dân tộc học thực hiện tại Đà Nẵng, tôi khảo sát cách phụnữsửdụng những diễn ngôn vềcảm xúc đạo đức và sựphát triển đất nước trong cách hiểu của họvềtình yêu thương. Tôi tập trung vào những đấu tranh đạo đức trong cách họlý giải sựhy sinh và chăm sóc nhằm phức tạp hoá cách hiểu vềsựliên kết giữa tình yêu và chủnghĩa tư bản cá nhânhoặc chủnghĩa hiện đại.Thay vào đó, tôi cho thấy rằng phụnữphê phán một cách tếnhịnhưng vẫn hướng đến những hình thức yêu thương mang tính củng cốcho sựphân tầng vềgiới, thếhệvà giai cấp xã hội, thông qua các chính sách nhà nước và lối hành xửthông thường. Họlàm điều này bằng lối kểchuyện và sống ‘theo bóng bên lề’, nghĩa là những câu chuyện kểthuộc loại ‘phải chi’đểkhơi ngợinhững khảnăng vềmột hiện thực khác, vềnhững ngờvực và mâu thuẫn. Lối tựtruyện phi mục đích này cho thấy tính bất định của đời sống đạo đức và những đan xen chằngchịtgiữa tình yêu, tình cảm với kinh tếchính trị, cảm xúc đạo đức và lý giải mang tính luân lý.
 "
MERAV SHOHET,Beyond the clinic? Eluding a medical diagnosis of anorexia through narrative,"The persistence and recurrence of anorexia nervosa poses a clinical challenge, and provides support for critiques of oppressive and injurious facets of society inscribed on women’s bodies. This essay illustrates how a phenomenological, linguistic anthropological approach fruitfully traverses clinical and cultural perspectives by directing attention beyond the embodied experience of patients diagnosed with anorexia nervosa to those who are not clinically diagnosed. Extending a model of illness and recovery as entailing sufferers’ emplotting of past, present, and imagined future selves, I argue that women’s accounts of their experiences do not simply reflect lived reality, but actually propel health-relevant states of being by enlivening and creating these realities in the process of their telling. In indexical interaction with public and clinical discourses, narratives’ grammar, lexicon, and plot structures modify subjects’ experiences and interpretations of the events and feelings recounted. This article builds on the insight that linear narratives of “full recovery” that adopt a clinical and feminist voice can help tellers stay recovered, whereas for those “struggling to recover,” a genre of contingent, uncertain, sideshadowing narratives alternatively renders recovery an elusive and ambivalently desired object. This essay then identifies a third narrative genre, eluding a diagnosis, which combines elements of the first two genres to paradoxically keep its teller simultaneously sheltered from, and invisible to the well-meaning clutches of medical care, leaving her suffering, yet free, to starve. This focus on narrative genres illustrates the utility of linguistic analyses for discerning and interpreting distress in subclinical populations."
MERAV SHOHET,Two deaths and a funeral: ritual inscriptions' affordances for mourning and moral personhood in Vietnam,"Mortuary rituals constitute the social nature of death and mourning, often working to ease painful transitions for the deceased and bereaved. In Vietnam, such rituals involve objects, including commodified yet personalized text‐artifacts like banners and placards bearing inscriptions in various scripts that are associated with various affects and different political‐economic regimes. The material, orthographic, semantic, spatial, and temporal organization of these text‐artifacts mobilize sentiments and structure ethical relations at a funeral. Together, they act as prescriptive affordances intended to discipline mourners’ grief. Yet while these objects reflect how subjects valorize “tradition,” their affective force exceeds the bounded subjunctive world fostered by ritual, and it may retrospectively limit possibilities for moral personhood."
JUNENETTE L. PETERS,"Interaction of Stress, Lead Burden, and Age on Cognition in Older Men: The VA Normative Aging Study","BACKGROUND. Low-level exposure to lead and to chronic stress may independently influence cognition. However, the modifying potential of psychosocial stress on the neurotoxicity of lead and their combined relationship to aging-associated decline have not been fully examined. OBJECTIVES. We examined the cross-sectional interaction between stress and lead exposure on Mini-Mental State Examination (MMSE) scores among 811 participants in the Normative Aging Study, a cohort of older U.S. men. METHODS. We used two self-reported measures of stress appraisal-a self-report of stress related to their most severe problem and the Perceived Stress Scale (PSS). Indices of lead exposure were blood lead and bone (tibia and patella) lead. RESULTS. Participants with higher self-reported stress had lower MMSE scores, which were adjusted for age, education, computer experience, English as a first language, smoking, and alcohol intake. In multivariable-adjusted tests for interaction, those with higher PSS scores had a 0.57-point lower (95% confidence interval, -0.90 to 0.24) MMSE score for a 2-fold increase in blood lead than did those with lower PSS scores. In addition, the combination of high PSS scores and high blood lead categories on one or both was associated with a 0.05-0.08 reduction on the MMSE for each year of age compared with those with low PSS score and blood lead level (p < 0.05). CONCLUSIONS. Psychological stress had an independent inverse association with cognition and also modified the relationship between lead exposure and cognitive performance among older men. Furthermore, high stress and lead together modified the association between age and cognition."
JUNENETTE L. PETERS,Stress as a Potential Modifier of the Impact of Lead Levels on Blood Pressure: The Normative Aging Study,"BACKGROUND. Lead exposure and psychological stress have been independently associated with hypertension in various populations, and animal studies suggest that when they co-occur, their effects may be exacerbated. OBJECTIVES. We examined whether psychological stress modifies the impact of cumulative lead exposure (measured as bone lead levels) on hypertension and blood pressure in Boston-area community-exposed men participating in the Normative Aging Study. METHODS. We evaluated the modifying effect of stress on lead exposure on baseline hypertension status (513 participants) and on blood pressure in those without hypertension (237 participants), cross-sectionally. In baseline nonhypertensives, we examined the same risk factors in relation to prospective risk of developing hypertension. RESULTS. Cross-sectional analysis revealed a positive interaction between stress and tibia lead on systolic blood pressure, after adjusting for age, body mass index, family history of high blood pressure, education, smoking, alcohol consumption, physical activity, and nutritional factors. In prospective multivariate analyses, high stress also modified the effect of tibia lead and patella lead on the risk of developing hypertension. Those reporting high stress had 2.66 [95% confidence interval (CI), 1.43-4.95] times the risk of developing hypertension per standard deviation increase in tibia lead and had 2.64 (95% CI, 1.42-4.92) times the risk per standard deviation increase in patella lead. CONCLUSION. To our knowledge, these are the first analyses to look at interactive effects of stress and lead on hypertension in humans. These results suggest that the effect of lead on hypertension is most pronounced among highly stressed individuals, independent of demographic and behavioral risk factors."
MICHAEL J CORWIN,The long-baseline neutrino experiment: exploring fundamental symmetries of the universe,"The preponderance of matter over antimatter in the early Universe, the dynamics of the supernova bursts that produced the heavy elements necessary for life and whether protons eventually decay --- these mysteries at the forefront of particle physics and astrophysics are key to understanding the early evolution of our Universe, its current state and its eventual fate. The Long-Baseline Neutrino Experiment (LBNE) represents an extensively developed plan for a world-class experiment dedicated to addressing these questions. LBNE is conceived around three central components: (1) a new, high-intensity neutrino source generated from a megawatt-class proton accelerator at Fermi National Accelerator Laboratory, (2) a near neutrino detector just downstream of the source, and (3) a massive liquid argon time-projection chamber deployed as a far detector deep underground at the Sanford Underground Research Facility. This facility, located at the site of the former Homestake Mine in Lead, South Dakota, is approximately 1,300 km from the neutrino source at Fermilab -- a distance (baseline) that delivers optimal sensitivity to neutrino charge-parity symmetry violation and mass ordering effects. This ambitious yet cost-effective design incorporates scalability and flexibility and can accommodate a variety of upgrades and contributions. With its exceptional combination of experimental configuration, technical capabilities, and potential for transformative discoveries, LBNE promises to be a vital facility for the field of particle physics worldwide, providing physicists from around the globe with opportunities to collaborate in a twenty to thirty year program of exciting science. In this document we provide a comprehensive overview of LBNE's scientific objectives, its place in the landscape of neutrino physics worldwide, the technologies it will incorporate and the capabilities it will possess."
MICHAEL ALOSCO,Clinicopathological evaluation of chronic traumatic encephalopathy in players of American football,"IMPORTANCE: Players of American football may be at increased risk of long-term neurological conditions, particularly chronic traumatic encephalopathy (CTE). OBJECTIVE: To determine the neuropathological and clinical features of deceased football players with CTE. DESIGN, SETTING, AND PARTICIPANTS: Case series of 202 football players whose brains were donated for research. Neuropathological evaluations and retrospective telephone clinical assessments (including head trauma history) with informants were performed blinded. Online questionnaires ascertained athletic and military history. EXPOSURES: Participation in American football at any level of play. MAIN OUTCOMES AND MEASURES: Neuropathological diagnoses of neurodegenerative diseases, including CTE, based on defined diagnostic criteria; CTE neuropathological severity (stages I to IV or dichotomized into mild [stages I and II] and severe [stages III and IV]); informant-reported athletic history and, for players who died in 2014 or later, clinical presentation, including behavior, mood, and cognitive symptoms and dementia. RESULTS: Among 202 deceased former football players (median age at death, 66 years [interquartile range, 47-76 years]), CTE was neuropathologically diagnosed in 177 players (87%; median age at death, 67 years [interquartile range, 52-77 years]; mean years of football participation, 15.1 [SD, 5.2]), including 0 of 2 pre–high school, 3 of 14 high school (21%), 48 of 53 college (91%), 9 of 14 semiprofessional (64%), 7 of 8 Canadian Football League (88%), and 110 of 111 National Football League (99%) players. Neuropathological severity of CTE was distributed across the highest level of play, with all 3 former high school players having mild pathology and the majority of former college (27 [56%]), semiprofessional (5 [56%]), and professional (101 [86%]) players having severe pathology. Among 27 participants with mild CTE pathology, 26 (96%) had behavioral or mood symptoms or both, 23 (85%) had cognitive symptoms, and 9 (33%) had signs of dementia. Among 84 participants with severe CTE pathology, 75 (89%) had behavioral or mood symptoms or both, 80 (95%) had cognitive symptoms, and 71 (85%) had signs of dementia. CONCLUSIONS AND RELEVANCE: In a convenience sample of deceased football players who donated their brains for research, a high proportion had neuropathological evidence of CTE, suggesting that CTE may be related to prior participation in football."
SHARON GOLDBERG,TumbleBit: an untrusted Bitcoin-compatible anonymous payment hub,"This paper presents TumbleBit, a new unidirectional unlinkable payment hub that is fully compatible with today s Bitcoin protocol. TumbleBit allows parties to make fast, anonymous, off-blockchain payments through an untrusted intermediary called the Tumbler. TumbleBits anonymity properties are similar to classic Chaumian eCash: no one, not even the Tumbler, can link a payment from its payer to its payee. Every payment made via TumbleBit is backed by bitcoins, and comes with a guarantee that Tumbler can neither violate anonymity, nor steal bitcoins, nor print money by issuing payments to itself. We prove the security of TumbleBit using the real/ideal world paradigm and the random oracle model. Security follows from the standard RSA assumption and ECDSA unforgeability. We implement TumbleBit, mix payments from 800 users and show that TumbleBits offblockchain payments can complete in seconds."
SHARON GOLDBERG,The use of maxLength in the RPKI,This document recommends that operators avoid using the maxLength attribute when issuing Route Origin Authorizations (ROAs) in the Resource Public Key Infrastructure (RPKI). These recommendations complement those in [RFC7115].
SHARON GOLDBERG,Verifiable Random Functions (VRFs),"A Verifiable Random Function (VRF) is the public-key version of a keyed cryptographic hash. Only the holder of the private key can compute the hash, but anyone with public key can verify the correctness of the hash. VRFs are useful for preventing enumeration of hash-based data structures. This document specifies several VRF constructions that are secure in the cryptographic random oracle model. One VRF uses RSA and the other VRF uses Eliptic Curves (EC)."
SHARON GOLDBERG,MaxLength considered harmful to the RPKI,"User convenience and strong security are often at odds, and most security applications need to find some sort of balance between these two (often opposing) goals. The Resource Public Key Infrastructure (RPKI), a security infrastructure built on top of interdomain routing, is not immune to this issue. The RPKI uses the maxLength attribute to reduce the amount of information that must be explicitly recorded in its cryptographic objects. MaxLength also allows operators to easily reconfigure their networks without modifying their RPKI objects. Our network measurements, however, suggest that the maxLength attribute strikes the wrong balance between security and user convenience. We therefore believe that operators should avoid using maxLength. We give operational recommendations and develop software that allow operators to reap many of the benefits of maxLength without its security costs."
SHARON GOLDBERG,Message authentication codes for the Network Time Protocol,"RFC 5905 [RFC5905] states that Network Time Protocol (NTP) packets should be authenticated by appending a 128-bit key to the NTP data, and hashing the result with MD5 to obtain a 128-bit tag. This document deprecates MD5-based authentication, which is considered to be too weak, and recommends the use of AES-CMAC [RFC4493] as a replacement."
SHARON GOLDBERG,The security of NTP's datagram protocol,"For decades, the Network Time Protocol (NTP) has been used to synchronize computer clocks over untrusted network paths. This work takes a new look at the security of NTP’s datagram protocol. We argue that NTP’s datagram protocol in RFC5905 is both underspecified and flawed. The NTP specifications do not sufficiently respect (1) the conflicting security requirements of different NTP modes, and (2) the mechanism NTP uses to prevent off-path attacks. A further problem is that (3) NTP’s control-query interface reveals sensitive information that can be exploited in off-path attacks. We exploit these problems in several attacks that remote attackers can use to maliciously alter a target’s time. We use network scans to find millions of IPs that are vulnerable to our attacks. Finally, we move beyond identifying attacks by developing a cryptographic model and using it to prove the security of a new backwards-compatible client/server protocol for NTP."
SHARON GOLDBERG,Efficient noninteractive certification of RSA moduli and beyond,"In many applications, it is important to verify that an RSA public key (N, e) specifies a permutation over the entire space ℤ𝑁 , in order to prevent attacks due to adversarially-generated public keys. We design and implement a simple and efficient noninteractive zero-knowledge protocol (in the random oracle model) for this task. Applications concerned about adversarial key generation can just append our proof to the RSA public key without any other modifications to existing code or cryptographic libraries. Users need only perform a one-time verification of the proof to ensure that raising to the power e is a permutation of the integers modulo N. For typical parameter settings, the proof consists of nine integers modulo N; generating the proof and verifying it both require about nine modular exponentiations. We extend our results beyond RSA keys and also provide efficient noninteractive zero-knowledge proofs for other properties of N, which can be used to certify that N is suitable for the Paillier cryptosystem, is a product of two primes, or is a Blum integer. As compared to the recent work of Auerbach and Poettering (PKC 2018), who provide two-message protocols for similar languages, our protocols are more efficient and do not require interaction, which enables a broader class of applications."
SHARON GOLDBERG,Passport: enabling accurate country-level router geolocation using inaccurate sources,"When does Internet traffic cross international borders? This question has major geopolitical, legal and social implications and is surprisingly difficult to answer. A critical stumbling block is a dearth of tools that accurately map routers traversed by Internet traffic to the countries in which they are located. This paper presents Passport: a new approach for efficient, accurate country-level router geolocation and a system that implements it. Passport provides location predictions with limited active measurements, using machine learning to combine information from IP geolocation databases, router hostnames, whois records, and ping measurements. We show that Passport substantially outperforms existing techniques, and identify cases where paths traverse countries with implications for security, privacy, and performance."
SHARON GOLDBERG,Impacting IP prefix reachability via RPKI manipulations,"The RPKI is an infrastructure that will provide digitally signed attestations for the hierarchical allocation and suballocation of IP addresses. Its goal is to improve security of interdomain routing by providing reliable data showing which autonomous system (AS) is authorized to originate which IP prefix. We discuss how the hierarchical nature of the RPKI makes it technically possible for any party above a target IP prefix in the RPKI hierarchy to revoke that target IP prefix. We show that such revocation can be ``surgical''---i.e., impacting only the desired IP address or prefix---and difficult to detect. We also discuss the impact such revocation has on routing. This note focuses only on the issues of technical feasibility (rather than legal or operational issues), and should not be taken as recommendation for or against the use of the RPKI."
SHARON GOLDBERG,Technology diffusion in communication networks,"The deployment of new technologies in the Internet is notoriously difficult, as evidence by the myriad of well-developed networking technologies that still have not seen widespread adoption (e.g., secure routing, IPv6, etc.) A key hurdle is the fact that the Internet lacks a centralized authority that can mandate the deployment of a new technology. Instead, the Internet consists of thousands of nodes, each controlled by an autonomous, profit-seeking firm, that will deploy a new networking technology only if it obtains sufficient local utility by doing so. For the technologies we study here, local utility depends on the set of nodes that can be reached by traversing paths consisting only of nodes that have already deployed the new technology. To understand technology diffusion in the Internet, we propose a new model inspired by work on the spread of influence in social networks. Unlike traditional models, where a node's utility depends only its immediate neighbors, in our model, a node can be influenced by the actions of remote nodes. Specifically, we assume node v activates (i.e. deploys the new technology) when it is adjacent to a sufficiently large connected component in the subgraph induced by the set of active nodes; namely, of size exceeding node v's threshold value \theta(v). We are interested in the problem of choosing the right seedset of nodes to activate initially, so that the rest of the nodes in the network have sufficient local utility to follow suit. We take the graph and thresholds values as input to our problem. We show that our problem is both NP-hard and does not admit an (1-o(1) ln|V| approximation on general graphs. Then, we restrict our study to technology diffusion problems where (a) maximum distance between any pair of nodes in the graph is r, and (b) there are at most \ell possible threshold values. Our set of restrictions is quite natural, given that (a) the Internet graph has constant diameter, and (b) the fact that limiting the granularity of the threshold values makes sense given the difficulty in obtaining empirical data that parameterizes deployment costs and benefits. We present algorithm that obtains a solution with guaranteed approximation rate of O(r^2 \ell \log|V|) which is asymptotically optimal, given our hardness results. Our approximation algorithm is a linear-programming relaxation of an 0-1 integer program along with a novel randomized rounding scheme."
SHARON GOLDBERG,Can NSEC5 be practical for DNSSEC deployments?,"NSEC5 is proposed modification to DNSSEC that simultaneously guarantees two security properties: (1) privacy against offline zone enumeration, and (2) integrity of zone contents, even if an adversary compromises the authoritative nameserver responsible for responding to DNS queries for the zone. This paper redesigns NSEC5 to make it both practical and performant. Our NSEC5 redesign features a new fast verifiable random function (VRF) based on elliptic curve cryptography (ECC), along with a cryptographic proof of its security. This VRF is also of independent interest, as it is being standardized by the IETF and being used by several other projects. We show how to integrate NSEC5 using our ECC-based VRF into the DNSSEC protocol, leveraging precomputation to improve performance and DNS protocol-level optimizations to shorten responses. Next, we present the first full-fledged implementation of NSEC5—extending widely-used DNS software to present a nameserver and recursive resolver that support NSEC5—and evaluate their performance under aggressive DNS query loads. Our performance results indicate that our redesigned NSEC5 can be viable even for high-throughput scenarios"
SHARON GOLDBERG,Let the market drive deployment: a strategy for transitioning to BGP security,"With a cryptographic root-of-trust for Internet routing (RPKI) on the horizon, we can finally start planning the deployment of one of the secure interdomain routing protocols proposed over a decade ago (Secure BGP, secure origin BGP). However, if experience with IPv6 is any indicator, this will be no easy task. Security concerns alone seem unlikely to provide sufficient local incentive to drive the deployment process forward. Worse yet, the security benefits provided by the S*BGP protocols do not even kick in until a large number of ASes have deployed them. Instead, we appeal to ISPs' interest in increasing rev\-enue-generating traffic. We propose a strategy that governments and industry groups can use to harness ISPs' local business objectives and drive global S*BGP deployment. We evaluate our deployment strategy using theoretical analysis and large-scale simulations on empirical data. Our results give evidence that the market dynamics created by our proposal can transition the majority of the Internet to S*BGP."
SHARON GOLDBERG,"NSEC5, DNSSEC authenticated denial of existence","The Domain Name System Security Extensions (DNSSEC) introduced two resource records (RR) for authenticated denial of existence: the NSEC RR and the NSEC3 RR. This document introduces NSEC5 as an alternative mechanism for DNSSEC authenticated denial of existence. NSEC5 uses verifiable random functions (VRFs) to prevent offline enumeration of zone contents. NSEC5 also protects the integrity of the zone contents even if an adversary compromises one of the authoritative servers for the zone. Integrity is preserved because NSEC5 does not require private zone-signing keys to be present on all authoritative servers for the zone, in contrast to DNSSEC online signing schemes like NSEC3 White Lies."
SHARON GOLDBERG,Modeling on quicksand: dealing with the lack of ground truth in interdomain routing data,"Researchers studying the interdomain routing system, its properties and new protocols, face many challenges in performing realistic evaluations and simulations. Modeling decisions with respect to AS-level topology, routing policies and tra c matrices are complicated by a dearth of ground truth for each of these components. Moreover, scalability issues arise when attempting to simulate over large (although still incomplete) empirically-derived AS-level topologies. In this paper, we discuss our approach for analyzing the robustness of our results to incomplete empirical data. We do this by (1) developing fast simulation algorithms that enable us to (2) running multiple simulations with varied parameters that test the sensitivity of our research results."
SHARON GOLDBERG,Low-resource eclipse attacks on Ethereum’s peer-to-peer network,"We present eclipse attacks on Ethereum nodes that exploit the peer-to-peer network used for neighbor discovery. Our attacks can be launched using only two hosts, each with a single IP address. Our eclipse attacker monopolizes all of the victim’s incoming and outgoing connections, thus isolating the victim from the rest of its peers in the network. The attacker can then filter the victim’s view of the blockchain, or co-opt the victim’s computing power as part of more sophisticated attacks. We argue that these eclipse-attack vulnerabilities result from Ethereum’s adoption of the Kademlia peer-to-peer protocol, and present countermeasures that both harden the network against eclipse attacks and cause it to behave differently from the traditional Kademlia protocol. Several of our countermeasures have been incorporated in the Ethereum geth 1.8 client released on February 14, 2018."
SHARON GOLDBERG,The Zenith attack: vulnerabilities and countermeasures,"In this paper we identify and define Zenith attacks, a new class of attacks on content-distribution systems, which seek to expose the popularity (i.e. access frequency) of individual items of content. As the access pattern to most real-world content exhibits Zipf-like characteristics, there is a small set of dominating items which account for the majority of accesses. Identifying such items enables an adversary to perform follow up adversarial actions targeting these items, including mounting denial of service attacks, deploying censorship mechanisms, and eavesdropping on or prosecution of the host or recipient. We instantiate a Zenith attack on the Kademlia and Chord structured overlay networks and quantify the cost of such an attack. As a countermeasure to these attacks we propose Crypsis, a system to conceal the lookup frequency of individual keys through aggregation over ranges of the keyspace. Crypsis provides provable security guarantees for concealment of lookup frequency while maintaining logarithmic routing and state bounds."
SHARON GOLDBERG,RFC8573: Message authentication code for the network time protocol,"The Network Time Protocol (NTP), as described in RFC 5905, states that NTP packets should be authenticated by appending NTP data to a 128-bit key and hashing the result with MD5 to obtain a 128-bit tag. This document deprecates MD5-based authentication, which is considered too weak, and recommends the use of AES-CMAC as described in RFC 4493 as a replacement."
SHARON GOLDBERG,Efficient noninteractive certification of RSA moduli and beyond,"In many applications, it is important to verify that an RSA public key (N; e) speci es a permutation over the entire space ZN, in order to prevent attacks due to adversarially-generated public keys. We design and implement a simple and e cient noninteractive zero-knowledge protocol (in the random oracle model) for this task. Applications concerned about adversarial key generation can just append our proof to the RSA public key without any other modi cations to existing code or cryptographic libraries. Users need only perform a one-time veri cation of the proof to ensure that raising to the power e is a permutation of the integers modulo N. For typical parameter settings, the proof consists of nine integers modulo N; generating the proof and verifying it both require about nine modular exponentiations. We extend our results beyond RSA keys and also provide e cient noninteractive zero- knowledge proofs for other properties of N, which can be used to certify that N is suitable for the Paillier cryptosystem, is a product of two primes, or is a Blum integer. As compared to the recent work of Auerbach and Poettering (PKC 2018), who provide two-message protocols for similar languages, our protocols are more e cient and do not require interaction, which enables a broader class of applications."
SHARON GOLDBERG,Certifying RSA public keys with an efficient NIZK,"In many applications, it is important to verify that an RSA public key ( N,e ) specifies a permutation, in order to prevent attacks due to adversarially-generated public keys. We design and implement a simple and efficient noninteractive zero-knowledge protocol (in the random oracle model) for this task. The key feature of our protocol is compatibility with existing RSA implementations and standards. The protocol works for any choice of e. Applications concerned about adversarial key generation can just append our proof to the RSA public key without any other modifications to existing code or cryptographic libraries. Users need only perform a one- time verification of the proof to ensure that raising to the power e is a permutation of the integers modulo N . For typical parameter settings, the proof consists of nine integers modulo N; generating the proof and verifying it both require about nine modular exponentiations."
JESSICA LEIBLER,Heat stress and heat strain among outdoor workers in El Salvador and Nicaragua,"BACKGROUND: There is growing attention on occupational heat stress in Central America, as workers in this region are affected by a unique form of chronic kidney disease. Previous studies have examined wet bulb globe temperatures and estimated metabolic rates to assess heat stress, but there are limited data characterizing heat strain among these workers. OBJECTIVE: The aims were to characterize heat stress and heat strain and examine whether job task, break duration, hydration practices, and kidney function were associated with heat strain. METHODS: We used data from the MesoAmerican Nephropathy Occupational Study, a cohort of 569 outdoor workers in El Salvador and Nicaragua who underwent workplace exposure monitoring, including continuous measurement of core body temperature (Tc), heart rate (HR), physical activity, and wet bulb globe temperature (WBGT), over the course of three days in January 2018 - May 2018. Participants represented five industries: sugarcane, corn, plantain, brickmaking, and construction. RESULTS: Median WBGTs were relatively high (>27 °C) at most sites, particularly when work shifts spanned the afternoon hours (e.g., 29.2 °C among plantain workers). Sugarcane workers, especially cane cutters in both countries and Nicaraguan agrichemical applicators, had the highest estimated metabolic rates (medians: 299-318 kcal/hr). Most workers spent little time on break (<10% of the shift), as determined by physical activity data. Overall, sugarcane workers-particularly those in Nicaragua-experienced the highest Tc and HR values. However, a few workers in other industries reached high Tc (>39 °C) as well. Impaired kidney function (estimated glomerular filtration rate <90 mL/min/1.73 m2) was associated with higher Tc and HR values, even after adjustment. SIGNIFICANCE: This is the largest study to-date examining heat stress and strain among outdoor workers in Central America. Workers at sugar companies regularly experienced Tc > 38°C (76.9% of monitored person-days at Nicaraguan companies; 46.5% at Salvadoran companies). Workers with impaired kidney function had higher measures of Tc and HR. IMPACT STATEMENT: This study examined levels of occupational heat stress and heat strain experienced among outdoor workers in five industries in El Salvador and Nicaragua. We characterized heat stress using wet bulb globe temperatures and estimated metabolic rate and heat strain using core body temperature and heart rate. Sugarcane workers, particularly cane cutters and Nicaraguan agrichemical applicators, performed more strenuous work and experienced greater levels of heat strain. Impaired kidney function was associated with higher heart rates and core body temperatures."
KEITH TORNHEIM,Whorl: 2020,
KEITH TORNHEIM,Whorl: 2024,
JUAN ORTNER,A theory of political gridlock,"This paper studies how electoral incentives influence the outcomes of political negotiations. It considers a game between two political parties that have to bargain over which policy to implement. While bargaining, the parties' popularity varies over time. Changes in popularity are partly exogenous and partly driven by the parties' actions. There is an election scheduled at a future date and the party with more popularity at the election date wins the vote. Electoral incentives can have substantial effects on bargaining outcomes. Periods of gridlock may arise when the election is close and parties have similar levels of popularity."
JUAN ORTNER,Searching for policy reforms,"We construct a model of policy reform in which two players continually search for Pareto improving policies. The players have imperfect control over the proposals that are considered. Inefficient gridlock takes place due to the difficulty in finding moderate policies. The reform process is path dependent, with early agreements determining long-run outcomes. The process may also be cyclical, as players alternate between being more and less accommodating. Our model provides a noncooperative foundation for the “Raiffa path”, by which bargainers gradually approach the Pareto frontier."
JUAN ORTNER,A continuous time model of bilateral bargaining,"This paper constructs a continuous-time model of bilateral bargaining to study how fluctuations in bargaining power affect the outcomes of negotiations. The paper deals with the technical complexities that arise when modeling games in continuous time by building strategy restrictions into the equilibrium definition. These restrictions select a unique equilibrium, which is characterized by a system of ordinary differential equations. This unique equilibrium corresponds to the limiting subgame perfect equilibrium of discrete-time bargaining games with frequent offers."
JUAN ORTNER,Durable goods monopoly with stochastic costs,"I study the problem of a durable goods monopolist who lacks commitment power and whose marginal cost of production varies stochastically over time. I show that a monopolist with stochastic costs usually serves the different types of consumers at different times and charges them different prices. When the distribution of consumer valuations is discrete, the monopolist exercises market power and there is inefficient delay. When there is a continuum of types, the monopolist cannot extract rents and the market outcome is efficient."
JUAN ORTNER,"Making corruption harder: asymmetric information, collusion, and crime","We model criminal investigation as a principal-agent-monitor problem in which the agent can bribe the monitor to destroy evidence. Building on insights from Laffont and Martimort (1997) we study whether the principal can profitably introduce asymmetric information between agent and monitor by randomizing the monitor’s incentives. We show it can be the case, but the optimality of random incentives depends on unobserved pre-existing patterns of private information. We provide a data-driven framework for policy evaluation requiring only unverified reports. A potential local policy change is an improvement if, everything else equal, it is associated with greater reports of crime."
JUAN ORTNER,Progressive learning,"We study a dynamic principal–agent relationship with adverse selection and limited commitment. We show that when the relationship is subject to productivity shocks, the principal may be able to improve her value over time by progressively learning the agent's private information. She may even achieve her first‐best payoff in the long run. The relationship may also exhibit path dependence, with early shocks determining the principal's long‐run value. These findings contrast sharply with the results of the ratchet effect literature, in which the principal persistently obtains low payoffs, giving up substantial informational rents to the agent."
JUAN ORTNER,Pooling and tranching under belief disagreement,"We study optimal security design when issuer and market participants disagree about the characteristics of the underlying asset. We show that pooling and tranching assets can be preferable to selling optimal securities backed by individual assets: pooling can be a response to belief disagreement between issuer and investors; tranching allows the issuer to exploit belief disagreement among investors. Moreover, differences in beliefs can make pooling and tranching complements; asymmetric information alone cannot."
JUAN ORTNER,Data-driven regulation: theory and application to missing bids,"We document a novel bidding pattern observed in procurement auctions from Japan: winning bids tend to be isolated. There is a missing mass of close losing bids. This pattern is suspicious in the following sense: it is inconsistent with competitive behavior under arbitrary information structures. Building on this observation, we develop a theory of data-driven regulation based on “safe tests,” i.e. tests that are passed with probability one by competitive bidders, but need not be passed by non-competitive ones. We provide a general class of safe tests exploiting weak equilibrium conditions, and show that such tests reduce the set of equilibrium strategies that cartels can use to sustain collusion. We provide an empirical exploration of various safe tests in our data, as well as discuss collusive rationales for missing bids."
JUAN ORTNER,Bargaining with persistent private information,"I study how the arrival of new private information affects bargaining outcomes. A seller makes offers to a buyer. The buyer is privately informed about her valuation, and the seller privately observes her stochastically changing cost of delivering the good. The seller's time-varying private information gives rise to new dynamics. Prices fall gradually at the early stages of negotiations, and trade is inefficiently delayed. Inefficiencies persist even when gains from trade are common knowledge. Privately observed costs lead to lower welfare, higher seller revenue and lower buyer surplus (especially for high value buyers) relative to a setting with publicly observed costs."
JUAN ORTNER,Dynamic contracting with limited liability constraints,"We study a dynamic mechanism design problem in which a buyer seeks to procure an item from a single seller in multiple periods. The seller is privately informed about her procurement cost at each period, and this cost may be serially correlated over time. We restrict the buyer to use mechanisms satisfying a limited liability constraint: the seller’s flow payoffs must be non-negative at each period. Limited liability constraints give rise to new dynamic distortions and inefficiencies.The optimal mechanism is path dependent, favoring sellers who had low cost realizations in the past."
JUAN ORTNER,Disagreement and security design,"We study optimal security design when the issuer and market participants agree to disagree about the characteristics of the asset to be securitized. We show that pooling assets can be optimal because it mitigates the effects of disagreement between issuer and investors, whereas tranching a cash-flow stream allows the issuer to exploit disagreement between investors. Interestingly, pooling and tranching can be complements. The optimality of debt with or without call provisions can be derived as a special case. In a model with multiple financing rounds, convertible securities naturally emerge to finance highly skewed ventures."
JUAN ORTNER,The value of privacy in cartels: an analysis of the inner workings of a bidding ring,"We study the inner workings of a bidding cartel focusing on the way in which bidders communicate with one another regarding how each bidder should bid. We show that the designated winner of the cartel can attain higher payoffs by randomizing its bid and keeping it secret from other bidders when defection is a concern. Intuitively, randomization makes defection less attractive as potential defectors face the risk of not winning the auction even if they deviate. We illustrate how our theoretical predictions are borne out in practice by studying a bidding cartel that operated in the town of Kumatori, Japan."
JUAN ORTNER,Screening adaptive cartels,"We propose a theory of equilibrium antitrust oversight in which: (i) regulators launch investigations on the basis of suspicious bidding patters; (ii) cartels can adapt to the statistical screens used by regulators, and may in fact use them to enforce cartel compliance. We emphasize the use of safe tests, i.e. tests that can be passed by competitive players under a broad class of environments. Such tests do not hurt competitive industries and do not help cartels support new collusive equilibria. We show that optimal collusive schemes in plausible environments fail natural safe tests, and that cartel responses to such tests explain unusual patterns in bidding data from procurement auctions held in Japan. This provides evidence that adaptive responses from cartels is a real concern that data-driven antitrust frameworks should take into account."
JUAN ORTNER,Using bid rotation and incumbency to detect collusion: a regression discontinuity approach,
JUAN ORTNER,Collusion in auctions with constrained bids: Theory and evidence from public procurement,"We study the mechanics of cartel enforcement and its interaction with bidding constraints in the context of repeated procurement auctions. Under collusion, bidding constraints weaken cartels by limiting the scope of punishment. This yields a test of collusive behavior exploiting the counterintuitive prediction that introducing minimum prices can lower the winning-bid distribution. The model’s predictions are borne out in Japanese procurement data, where we find evidence that minimum prices weakened collusion. A robust design insight is that setting a minimum price at the bottom of the observed winning-bid distribution necessarily improves over a minimum price of zero."
FRANCISCO J NAYA,A hearty dose of noncoding RNAs: the imprinted DLK1-DIO3 locus in cardiac development and disease,"The imprinted Dlk1-Dio3 genomic region harbors a noncoding RNA cluster encoding over fifty microRNAs (miRNAs), three long noncoding RNAs (lncRNAs), and a small nucleolar RNA (snoRNA) gene array. These distinct noncoding RNAs (ncRNAs) are thought to arise from a single polycistronic transcript that is subsequently processed into individual ncRNAs, each with important roles in diverse cellular contexts. Considering these ncRNAs are derived from a polycistron, it is possible that some coordinately regulate discrete biological processes in the heart. Here, we provide a comprehensive summary of Dlk1-Dio3 miRNAs and lncRNAs, as they are currently understood in the cellular and organ-level context of the cardiovascular system. Highlighted are expression profiles, mechanistic contributions, and functional roles of these ncRNAs in heart development and disease. Notably, a number of these ncRNAs are implicated in processes often perturbed in heart disease, including proliferation, differentiation, cell death, and fibrosis. However, most literature falls short of characterizing precise mechanisms for many of these ncRNAs, warranting further investigation. Taken together, the Dlk1-Dio3 locus represents a largely unexplored noncoding regulator of cardiac homeostasis, harboring numerous ncRNAs that may serve as therapeutic targets for cardiovascular disease."
FRANCISCO J NAYA,"The key Lnc (RNA)s in cardiac and skeletal muscle development, regeneration, and disease","Non-coding RNAs (ncRNAs) play a key role in the regulation of transcriptional and epigenetic activity in mammalian cells. Comprehensive analysis of these ncRNAs has revealed sophisticated gene regulatory mechanisms which finely tune the proper gene output required for cellular homeostasis, proliferation, and differentiation. However, this elaborate circuitry has also made it vulnerable to perturbations that often result in disease. Among the many types of ncRNAs, long non-coding RNAs (lncRNAs) appear to have the most diverse mechanisms of action including competitive binding to miRNA targets, direct binding to mRNA, interactions with transcription factors, and facilitation of epigenetic modifications. Moreover, many lncRNAs display tissue-specific expression patterns suggesting an important regulatory role in organogenesis, yet the molecular mechanisms through which these molecules regulate cardiac and skeletal muscle development remains surprisingly limited. Given the structural and metabolic similarities of cardiac and skeletal muscle, it is likely that several lncRNAs expressed in both of these tissues have conserved functions in establishing the striated muscle phenotype. As many aspects of regeneration recapitulate development, understanding the role lncRNAs play in these processes may provide novel insights to improve regenerative therapeutic interventions in cardiac and skeletal muscle diseases. This review highlights key lncRNAs that function as regulators of development, regeneration, and disease in cardiac and skeletal muscle. Finally, we highlight lncRNAs encoded by imprinted genes in striated muscle and the contributions of these loci on the regulation of gene expression."
FRANCISCO J NAYA,CMYA5 establishes cardiac dyad architecture and positioning,"Cardiac excitation-contraction coupling requires dyads, the nanoscopic microdomains formed adjacent to Z-lines by apposition of transverse tubules and junctional sarcoplasmic reticulum. Disruption of dyad architecture and function are common features of diseased cardiomyocytes. However, little is known about the mechanisms that modulate dyad organization during cardiac development, homeostasis, and disease. Here, we use proximity proteomics in intact, living hearts to identify proteins enriched near dyads. Among these proteins is CMYA5, an under-studied striated muscle protein that co-localizes with Z-lines, junctional sarcoplasmic reticulum proteins, and transverse tubules in mature cardiomyocytes. During cardiac development, CMYA5 positioning adjacent to Z-lines precedes junctional sarcoplasmic reticulum positioning or transverse tubule formation. CMYA5 ablation disrupts dyad architecture, dyad positioning at Z-lines, and junctional sarcoplasmic reticulum Ca2+ release, leading to cardiac dysfunction and inability to tolerate pressure overload. These data provide mechanistic insights into cardiomyopathy pathogenesis by demonstrating that CMYA5 anchors junctional sarcoplasmic reticulum to Z-lines, establishes dyad architecture, and regulates dyad Ca2+ release."
FRANCISCO J NAYA,miR-410 and miR-495 are dynamically regulated in diverse cardiomyopathies and their inhibition attenuates pathological hypertrophy,"Noncoding RNAs have emerged as important modulators in cardiac development and pathological remodeling. Recently, we demonstrated that regulation of the Gtl2-Dio3 noncoding RNA locus is dependent on the MEF2 transcription factor in cardiac muscle, and that two of its encoded miRNAs, miR-410 and miR-495, induce robust cardiomyocyte proliferation. Given the possibility of manipulating the expression of these miRNAs to repair the damaged heart by stimulating cardiomyocyte proliferation, it is important to determine whether the Gtl2-Dio3 noncoding RNAs are regulated in cardiac disease and whether they function downstream of pathological cardiac stress signaling. Therefore, we examined expression of the above miRNAs processed from the Gtl2-Dio3 locus in various cardiomyopathies. These noncoding RNAs were upregulated in all cardiac disease models examined including myocardial infarction (MI) and chronic angiotensin II (Ang II) stimulation, and in the cardiomyopathies associated with muscular dystrophies. Consistent with these observations, we show that the Gtl2-Dio3 proximal promoter is activated by stress stimuli in cardiomyocytes and requires MEF2 for its induction. Furthermore, inhibiting miR-410 or miR-495 in stressed cardiomyocytes attenuated the hypertrophic response. Thus, the Gtl2-Dio3 noncoding RNA locus is a novel marker of cardiac disease and modulating the activity of its encoded miRNAs may mitigate pathological cardiac remodeling in these diseases."
FRANCISCO J NAYA,Transcriptome analysis of cardiac hypertrophic growth in MYBPC3-null mice suggests early responders in hypertrophic remodeling,"RATIONALE: With a prevalence of 1 in 200 individuals, hypertrophic cardiomyopathy (HCM) is thought to be the most common genetic cardiac disease, with potential outcomes that include severe hypertrophy, heart failure, and sudden cardiac death (SCD). Though much research has furthered our understanding of how HCM-causing mutations in genes such as cardiac myosin-binding protein C (MYBPC3) impair contractile function, it remains unclear how such dysfunction leads to hypertrophy and/or arrhythmias, which comprise the HCM phenotype. Identification of early response mediators could provide rational therapeutic targets to reduce disease severity. Our goal was to differentiate physiologic and pathophysiologic hypertrophic growth responses and identify early genetic mediators in the development of cardiomegaly in the cardiac myosin-binding protein C-null (cMyBP-C-/-) mouse model of HCM. METHODS AND RESULTS: We performed microarray analysis on left ventricles of wild-type (WT) and cMyBPC-/- mice (n = 7 each) at postnatal day (PND) 1 and PND 9, before and after the appearance of an overt HCM phenotype. Applying the criteria of ≥2-fold change, we identified genes whose change was exclusive to pathophysiologic growth (n = 61), physiologic growth (n = 30), and genes whose expression changed ≥2-fold in both WT and cMyBP-C-/- hearts (n = 130). Furthermore, we identified genes that were dysregulated in PND1 cMyBP-C-/- hearts prior to hypertrophy, including genes in mechanosensing pathways and potassium channels linked to arrhythmias. One gene of interest, Xirp2, and its protein product, are regulated during growth but also show early, robust prehypertrophic upregulation in cMyBP-C-/- hearts. Additionally, the transcription factor Zbtb16 also shows prehypertrophic upregulation at both gene and protein levels. CONCLUSION: Our transcriptome analysis generated a comprehensive data set comparing physiologic vs. hypertrophic growth in mice lacking cMyBP-C. It highlights the importance of extracellular matrix pathways in hypertrophic growth and early dysregulation of potassium channels. Prehypertrophic upregulation of Xirp2 in cMyBP-C-/- hearts supports a growing body of evidence suggesting Xirp2 has the capacity to elicit both hypertrophy and arrhythmias in HCM. Dysregulation of Xirp2, as well as Zbtb16, along with other genes associated with mechanosensing regions of the cardiomyocyte implicate stress-sensing in these regions as a potentially important early response in HCM."
FRANCISCO J NAYA,"The function of the MEF2 family of transcription factors in cardiac development, cardiogenomics, and direct reprogramming","Proper formation of the mammalian heart requires precise spatiotemporal transcriptional regulation of gene programs in cardiomyocytes. Sophisticated regulatory networks have evolved to not only integrate the activities of distinct transcription factors to control tissue-specific gene programs but also, in many instances, to incorporate multiple members within these transcription factor families to ensure accuracy and specificity in the system. Unsurprisingly, perturbations in this elaborate transcriptional circuitry can lead to severe cardiac abnormalities. Myocyte enhancer factor-2 (MEF2) transcription factor belongs to the evolutionarily conserved cardiac gene regulatory network. Given its central role in muscle gene regulation and its evolutionary conservation, MEF2 is considered one of only a few core cardiac transcription factors. In addition to its firmly established role as a differentiation factor, MEF2 regulates wide variety of, sometimes antagonistic, cellular processes such as cell survival and death. Vertebrate genomes encode multiple MEF2 family members thereby expanding the transcriptional potential of this core transcription factor in the heart. This review highlights the requirement of the MEF2 family and their orthologs in cardiac development in diverse animal model systems. Furthermore, we describe the recently characterized role of MEF2 in direct reprogramming and genome-wide cardiomyocyte gene regulation. A thorough understanding of the regulatory functions of the MEF2 family in cardiac development and cardiogenomics is required in order to develop effective therapeutic strategies to repair the diseased heart."
CHRISTOPHER WALSH,Myogenic Akt Signaling Upregulates the Utrophin-Glycoprotein Complex and Promotes Sarcolemma Stability in Muscular Dystrophy,"Duchenne muscular dystrophy is caused by dystrophin mutations that lead to structural instability of the sarcolemma membrane, myofiber degeneration/regeneration and progressive muscle wasting. Here we show that myogenic Akt signaling in mouse models of dystrophy promotes increased expression of utrophin, which replaces the function of dystrophin thereby preventing sarcolemma damage and muscle wasting. In contrast to previous suggestions that increased Akt in dystrophy was a secondary consequence of pathology, our findings demonstrate a pivotal role for this signaling pathway such that modulation of Akt can significantly affect disease outcome by amplification of existing, physiological compensatory mechanisms."
CHRISTOPHER WALSH,Soft exosuits increase walking speed and distance after stroke,Finalist for best poster abstract and presentation
CHRISTOPHER WALSH,Carbon Free Boston: Transportation Technical Report,"OVERVIEW: Transportation connects Boston’s workers, residents and tourists to their livelihoods, health care, education, recreation, culture, and other aspects of life quality. In cities, transit access is a critical factor determining upward mobility. Yet many urban transportation systems, including Boston’s, underserve some populations along one or more of those dimensions. Boston has the opportunity and means to expand mobility access to all residents, and at the same time reduce GHG emissions from transportation. This requires the transformation of the automobile-centric system that is fueled predominantly by gasoline and diesel fuel. The near elimination of fossil fuels—combined with more transit, walking, and biking—will curtail air pollution and crashes, and dramatically reduce the public health impact of transportation. The City embarks on this transition from a position of strength. Boston is consistently ranked as one of the most walkable and bikeable cities in the nation, and one in three commuters already take public transportation. There are three general strategies to reaching a carbon-neutral transportation system: • Shift trips out of automobiles to transit, biking, and walking;1 • Reduce automobile trips via land use planning that encourages denser development and affordable housing in transit-rich neighborhoods; • Shift most automobiles, trucks, buses, and trains to zero-GHG electricity. Even with Boston’s strong transit foundation, a carbon-neutral transportation system requires a wholesale change in Boston’s transportation culture. Success depends on the intelligent adoption of new technologies, influencing behavior with strong, equitable, and clearly articulated planning and investment, and effective collaboration with state and regional partners."
CHRISTOPHER WALSH,"Caribbean Corals in Crisis: Record Thermal Stress, Bleaching, and Mortality in 2005","BACKGROUND. The rising temperature of the world's oceans has become a major threat to coral reefs globally as the severity and frequency of mass coral bleaching and mortality events increase. In 2005, high ocean temperatures in the tropical Atlantic and Caribbean resulted in the most severe bleaching event ever recorded in the basin. METHODOLOGY/PRINCIPAL FINDINGS. Satellite-based tools provided warnings for coral reef managers and scientists, guiding both the timing and location of researchers' field observations as anomalously warm conditions developed and spread across the greater Caribbean region from June to October 2005. Field surveys of bleaching and mortality exceeded prior efforts in detail and extent, and provided a new standard for documenting the effects of bleaching and for testing nowcast and forecast products. Collaborators from 22 countries undertook the most comprehensive documentation of basin-scale bleaching to date and found that over 80% of corals bleached and over 40% died at many sites. The most severe bleaching coincided with waters nearest a western Atlantic warm pool that was centered off the northern end of the Lesser Antilles. CONCLUSIONS/SIGNIFICANCE. Thermal stress during the 2005 event exceeded any observed from the Caribbean in the prior 20 years, and regionally-averaged temperatures were the warmest in over 150 years. Comparison of satellite data against field surveys demonstrated a significant predictive relationship between accumulated heat stress (measured using NOAA Coral Reef Watch's Degree Heating Weeks) and bleaching intensity. This severe, widespread bleaching and mortality will undoubtedly have long-term consequences for reef ecosystems and suggests a troubled future for tropical marine ecosystems under a warming climate."
CHRISTOPHER WALSH,Dynamic oligopoly and regulation in developing countries,"This dissertation consists of three essays studying the dynamic and strategic interactions of oligopolistic firms in developing countries using dynamic structural models. We focus on industries which have positive social benefits for the communities in which they operate, namely radio and banking. We use the estimated models to simulate counterfactual policies aimed at improving access for individuals in underserved areas. The first essay studies the social impacts of the liberalization of the radio broadcasting sector in Ghana. I analyze how the regulator affects commercial stations' decisions to enter and the resulting effects of coverage spillovers in rural areas. I exploit random variation in radio coverage caused by coverage spilling through gaps in mountainous areas and use this to estimate the effects of coverage on malaria incidence and development. I then estimate a dynamic structural entry model for commercial stations. In counterfactual simulations, I find that the allowance of more powerful transmitters is particularly effective in delivering the social benefits of radio to new communities. The second essay (joint with Calixte Ahokossi) studies voter turnout and regulatory inefficiency in the radio broadcasting market in Benin. We find an inverted-U relationship between the number of radio stations and voter turnout. We estimate a dynamic structural model for radio stations, taking into account the regulatory inefficiency in the market. Counterfactual simulations suggest that either removing the regulatory inefficiency or introducing targeted entry subsidies can spur entry in areas without radio stations, which would increase voter turnout in these areas. The third essay (joint with Marc Rysman and Robert M. Townsend) studies the banking sector in Thailand. Here, we argue that the effect of financial crises on bank branch location choices provides an unexplored channel by which crises affect access to credit. We estimate a dynamic structural model of oligopolistic location choice, allowing for complementarity in payoffs for bank branches in nearby locations, as well as competitive effects between rival banks. Using this model, we can predict counterfactual expansions of the bank branch network under policies focused on opening rural bank branches, or in the absence of the 1997 financial crisis."
CHRISTOPHER WALSH,NFIA Haploinsufficiency Is Associated with a CNS Malformation Syndrome and Urinary Tract Defects,"Complex central nervous system (CNS) malformations frequently coexist with other developmental abnormalities, but whether the associated defects share a common genetic basis is often unclear. We describe five individuals who share phenotypically related CNS malformations and in some cases urinary tract defects, and also haploinsufficiency for the NFIA transcription factor gene due to chromosomal translocation or deletion. Two individuals have balanced translocations that disrupt NFIA. A third individual and two half-siblings in an unrelated family have interstitial microdeletions that include NFIA. All five individuals exhibit similar CNS malformations consisting of a thin, hypoplastic, or absent corpus callosum, and hydrocephalus or ventriculomegaly. The majority of these individuals also exhibit Chiari type I malformation, tethered spinal cord, and urinary tract defects that include vesicoureteral reflux. Other genes are also broken or deleted in all five individuals, and may contribute to the phenotype. However, the only common genetic defect is NFIA haploinsufficiency. In addition, previous analyses of Nfia−/− knockout mice indicate that Nfia deficiency also results in hydrocephalus and agenesis of the corpus callosum. Further investigation of the mouse Nfia+/− and Nfia−/− phenotypes now reveals that, at reduced penetrance, Nfia is also required in a dosage-sensitive manner for ureteral and renal development. Nfia is expressed in the developing ureter and metanephric mesenchyme, and Nfia+/− and Nfia−/− mice exhibit abnormalities of the ureteropelvic and ureterovesical junctions, as well as bifid and megaureter. Collectively, the mouse Nfia mutant phenotype and the common features among these five human cases indicate that NFIA haploinsufficiency contributes to a novel human CNS malformation syndrome that can also include ureteral and renal defects. Author Summary Central nervous system (CNS) and urinary tract abnormalities are common human malformations, but their variability and genetic complexity make it difficult to identify the responsible genes. Analysis of human chromosomal abnormalities associated with such disorders offers one approach to this problem. In five individuals described herein, a novel human syndrome that involves both CNS and urinary tract defects is associated with chromosomal disruption or deletion of NFIA, encoding a member of the Nuclear Factor I (NFI) family of transcription factors. This syndrome includes brain abnormalities (abnormal corpus callosum, hydrocephalus, ventriculomegaly, and Chiari type I malformation), spinal abnormalities (tethered spinal cord), and urinary tract abnormalities (vesicoureteral reflux). Nfia disruption in mice was already known to cause hydrocephalus and abnormal corpus callosum, and is now shown to exhibit renal defects and disturbed ureteral development. Other genes besides NFIA are also disrupted or deleted and may contribute to the observed phenotype. However, loss of one copy of NFIA is the only genetic defect common to all five patients. The authors thus provide evidence that genetic loss of NFIA contributes to a distinct CNS malformation syndrome with urinary tract defects of variable penetrance."
ALEXANDER A GREEN,Broadband multi-wavelength properties of M87 during the 2017 Event Horizon Telescope campaign,"In 2017, the Event Horizon Telescope (EHT) Collaboration succeeded in capturing the first direct image of the center of the M87 galaxy. The asymmetric ring morphology and size are consistent with theoretical expectations for a weakly accreting supermassive black hole of mass ∼6.5 × 109 M ⊙. The EHTC also partnered with several international facilities in space and on the ground, to arrange an extensive, quasi-simultaneous multi-wavelength campaign. This Letter presents the results and analysis of this campaign, as well as the multi-wavelength data as a legacy data repository. We captured M87 in a historically low state, and the core flux dominates over HST-1 at high energies, making it possible to combine core flux constraints with the more spatially precise very long baseline interferometry data. We present the most complete simultaneous multi-wavelength spectrum of the active nucleus to date, and discuss the complexity and caveats of combining data from different spatial scales into one broadband spectrum. We apply two heuristic, isotropic leptonic single-zone models to provide insight into the basic source properties, but conclude that a structured jet is necessary to explain M87’s spectrum. We can exclude that the simultaneous γ-ray emission is produced via inverse Compton emission in the same region producing the EHT mm-band emission, and further conclude that the γ-rays can only be produced in the inner jets (inward of HST-1) if there are strongly particle-dominated regions. Direct synchrotron emission from accelerated protons and secondaries cannot yet be excluded."
ALEXANDER A GREEN,MAGIC and H.E.S.S. detect VHE gamma rays from the blazar OT081 for the first time: a deep multiwavelength study,
KATHERINE LEVINE EINSTEIN,Land of the freeholder: how property rights make local voting rights,"A large body of research documents the dominance of homeowners in local politics. There has been little scholarship, however, on the role that voting institutions have played in empowering homeowners from the inception of the United States; indeed, most accounts describe property qualifications for voting and officeholding as largely fading from view by the mid-1800s. Combining a novel analysis of state constitutions and constitutional conventions with data on state statutes, this article explores the emergence of property qualifications for voting, with a particular emphasis on their role in local politics. We find that, counter most historical narratives, property requirements persisted well into the 20th century, with almost 90 percent of property requirements restricting voting and officeholding at the local level. Most centered on local bond referenda, school districts, and land use — suggesting that homeowner citizens were granted particular political control over local taxation and public services. These requirements were largely clustered in the American South and West — emerging alongside Jim Crow laws and mass availability of federal public lands — and were not eliminated until the Supreme Court took action in 1969 and 1970. This article illuminates the important role that voting institutions played in linking homeownership with American democratic citizenship, especially at the local level."
KATHERINE LEVINE EINSTEIN,"As the Trump administration retreats on climate change, US cities are moving forward",
KATHERINE LEVINE EINSTEIN,2018 Menino Survey of Mayors,"The 2018 Menino Survey of Mayors represents the fifth scientifically rigorous and nationally representative survey of American mayors released by the Boston University Initiatives on Cities and supported by Citi Community Development and The Rockefeller Foundation. The Survey, based on interviews with 110 sitting mayors conducted in 2018, reveals mayoral views on economic development—including corporate recruitment, financial incentives, the sharing economy, and social mobility—as well as public health, housing, and intergovernmental relations."
KATHERINE LEVINE EINSTEIN,Do mayors run for higher office? New evidence on progressive ambition,"The mayor’s office potentially offers a launchpad for statewide and national political ambitions. We know relatively little, however, about how frequently mayors actually run for higher office, and which mayors choose to do so. This article combines longitudinal data on the career paths of the mayors of 200 big cities with new survey and interview data to investigate these questions. While we find that individual and city traits—especially gender—have some predictive power, the overwhelming story is that relatively few mayors—just under one-fifth—ever seek higher office. We suggest that ideological, institutional, and electoral factors all help to explain why so few mayors exhibit progressive ambition."
KATHERINE LEVINE EINSTEIN,Mayoral views on housing production: do planning goals match reality?,"Mayoral Views on Housing Production: Do Planning Goals Match Reality? evaluates mayoral priorities relative to actual need. Based on our analysis, even the most ambitious mayors are not prioritizing sufficient development necessary to meet the demand for housing and to address the affordability crisis. The authors recommend reforming local zoning codes and reducing regulatory barriers to the construction of multifamily housing to help address this shortfall."
KATHERINE LEVINE EINSTEIN,Mayoral views on racism and discrimination,"This report, which draws on data from the 2017 Menino Survey of Mayors, explores how mayors of medium-sized and large cities understand race, discrimination and equity in their communities and on a national level. The report cites three key findings: 1) Mayors believe that the four groups most discriminated against in their cities and across the country are immigrants, transgender individuals, black people and Muslims. In relation to these group and others, mayors perceive far more discrimination in the country as a whole than in their own communities. 2) Mayors believe that access to public services is significantly better for white people than for people of color, except for subsidized housing. More than half of all mayors report that white people have better access to jobs, educational opportunities, housing and healthcare, and are treated better by police and the courts. 3) While mayors see disparities in access to services, they overwhelmingly believe that the quality of services is largely equal across different groups of people, except for educational services, which they think is worse for people of color. The report also highlights several successful initiatives that cities, including Anaheim, Boston, Louisville and New Orleans, have undertaken in combating discrimination."
KATHERINE LEVINE EINSTEIN,City learning: evidence of policy information diffusion from a survey of U.S. mayors,"Most studies of policy diffusion attempt to infer the processes through which policies spread by observing outputs (policy adoptions). We approach these issues from the other direction by directly analyzing a key policymaking input—information about others’ policies. Moreover, we do so by investigating policy diffusion in cities rather than states. Using a survey of U.S. mayors, more specifically, mayors’ own lists of cities they look to for ideas, we find evidence that distance, similarity, and capacity all influence the likelihood of a policy maker looking to a particular jurisdiction for policy information. We also consider whether these traits are complements or substitutes and provide some evidence for the latter. Specifically, we find that, at times, mayors eschew similarity and distance to look to highly respected “high capacity” cities but that there is no tradeoff between distance and similarity."
KATHERINE LEVINE EINSTEIN,Who participates in local government? Evidence from meeting minutes,"Scholars and policymakers have highlighted institutions that enable community participation as a potential buffer against existing political inequalities. Yet these venues may bias policy discussions in favor of an unrepresentative group of individuals. To explore who participates, we compile a novel data set by coding thousands of instances of citizens speaking at planning and zoning board meetings concerning housing development. We match individuals to a voter file to investigate local political participation in housing and development policy. We find that individuals who are older, male, longtime residents, voters in local elections, and homeowners are significantly more likely to participate in these meetings. These individuals overwhelmingly (and to a much greater degree than the general public) oppose new housing construction. These participatory inequalities have important policy implications and may be contributing to rising housing costs."
KATHERINE LEVINE EINSTEIN,Does race affect access to government services? An experiment exploring street-level bureaucrats and access to public housing,"While experimental studies of local election officials have found evidence of racial discrimination, we know little about whether these biases manifest in bureaucracies that provide access to valuable government programs and are less tied to politics. We address these issues in the context of affordable housing programs using a randomized field experiment. We explore responsiveness to putative white, black, and Hispanic requests for aid in the housing application process. In contrast to prior findings, public housing officials respond at equal rates to black and white email requests. We do, however, find limited evidence of responsiveness discrimination toward Hispanics. Moreover, we observe substantial differences in email tone. Hispanic housing applicants were 20 percentage points less likely to be greeted by name than were their black and white counterparts. This disparity in tone is somewhat more muted in more diverse locations, but it does not depend on whether a housing official is Hispanic."
KATHERINE LEVINE EINSTEIN,Mayoral Policy Making: Results from the 21st Century Mayors Leadership Survey,"Mayoral Policy-Making: Results from the 21st Century Mayors Leadership survey represents the first nationally representative survey of American mayoral priorities. The report, released by the Boston University Initiative on Cities, is based on interviews with over seventy American mayors from cities of all sizes and affluence. Sitting mayors offered their perspectives on challenges facing their cities, personal policy priorities and planned political capital expenditures, and responded to a series of trade off questions related to gentrification, income inequality and climate change. It highlights the importance mayors place on the physical, fiscal and social infrastructure of their cities, and – contrary to prior research - suggests that party affiliation has a significant influence on mayoral priority-setting."
KATHERINE LEVINE EINSTEIN,2019 Menino Survey of Mayors,"The 2019 Menino Survey of Mayors represents the sixth nationally representative survey of American mayors and is based on interviews with 119 sitting mayors from 38 states. The 2019 Survey explores mayoral views on issues ranging from infrastructure and transportation priorities — including mobility and public safety — to the changing nature of work. The 2019 Survey also provides the first in-depth examination of mayors’ reactions to and expectations for the Opportunity Zones program, a significant new federal initiative to stimulate urban development. The 2019 Survey continues with the support of Citi Community Development and The Rockefeller Foundation."
KATHERINE LEVINE EINSTEIN,2017 Menino Survey of Mayors,"The 2017 Menino Survey of Mayors represents the fourth scientifically rigorous and nationally representative survey of American mayors released by the Boston University Initiatives on Cities. The Menino Survey, based on interviews with 115 sitting mayors conducted in 2017, provides insight into mayoral priorities, policy views and relationships with their key partners, including other levels of government. Researchers spoke with mayors about a range of topics including affordable housing, climate change, city-to-city networks, and data-driven decision-making."
KATHERINE LEVINE EINSTEIN,Counting the city: mayoral views on the 2020 Census,"As the 2020 Census concludes at the end of September, a large majority of the mayors of America’s major cities are extremely concerned that their cities’ populations will be undercounted. According to Boston University’s 2020 Menino Survey of Mayors – the only national representative survey of American mayors – 82% of local leaders are “very” or “somewhat concerned” about undercounting their cities’ populations; only 6% of mayors were “not concerned at all.” While there is a small partisan difference in level of concern (19% of Republican mayors are “not concerned at all” compared to 4% of Democratic mayors), nearly two-thirds of Republican mayors are somewhat or very concerned that their populations will be undercounted."
KATHERINE LEVINE EINSTEIN,2020 Menino Survey of Mayors: COVID-19 recovery and the future of cities,"The 2020 Menino Survey of Mayors details insights and perspectives shared by a representative sample of 130 mayors leading U.S. cities with populations of more than 75,000 residents. This year’s Survey explores mayoral views on COVID-19 recovery and implications, policing and protests, parks and greenspace, and the 2020 Census. This report focuses on the COVD-19 related findings and outlines mayors’ responses to the global pandemic, perceptions of its impact, and expectations for the future of their cities. The 2020 Survey continues with the support of Citi and The Rockefeller Foundation."
KATHERINE LEVINE EINSTEIN,2015 Menino Survey of Mayors,"The 2015 Menino Survey of Mayors represents the second nationally representative survey of American mayors released by the Boston University Initiatives on Cities. The Survey, based on interviews with 89 sitting mayors conducted in 2015, provides insight into mayoral priorities, policy views and relationships with their key partners, including other levels of government. Sitting mayors shared insight on their specific infrastructure needs and spending priorities, from roads and transit to water treatment and bike lanes, and reacted to police reforms proposed by the White House. They also shed light on the difficult choices they must often make, to promote affordable housing or improve the fiscal health of their city. A significant portion of the Survey is devoted to mayoral leadership, including areas of mayoral control and constituent approval, as well as constraints they confront under increasingly politicized and polarized state legislatures."
KATHERINE LEVINE EINSTEIN,2016 Menino Survey of Mayors,"The 2016 Menino Survey of Mayors represents the third scientifically rigorous and nationally representative survey of American mayors released by the Boston University Initiatives on Cities. The Menino Survey, based on interviews with 102 sitting mayors conducted in 2016, provides insight into mayoral priorities, policy views and relationships with their key partners, including other levels of government. This year's research was largely focused on Mayors' ""people priorities"" on subjects like poverty, immigration, inclusion, and city image. Mayors also discussed the impact of the 2016 presidential election on their cities and their hopes for the Trump administration."
KATHERINE LEVINE EINSTEIN,2023 Menino Survey of Mayors: building for a Green Future: Cities and the IRA,"The 2023 Menino Survey of Mayors represents the tenth nationally representative survey of American mayors and is based on interviews with 118 sitting mayors from 39 states. The 2023 Survey explores mayoral views on Inflation Reduction Act (IRA) implementation and issues ranging from clean energy and permitting, to public messaging, to capacity challenges, to government accountability and control. The first set of findings, Building for a Green Future: Cities & the IRA, released in March 2024, details mayors’ initial experiences with the Inflation Reduction Act (IRA) and identifies key challenges at the local level to realizing the law’s potential."
KATHERINE LEVINE EINSTEIN,Political lessons learned from the initial MBTA Communities Act Rollout,"In response to the region’s growing housing crisis, Massachusetts passed the MBTA Communities Act (MBTA-C) in 2021. The law requires all communities served by the region’s mass transit system to revise their zoning to allow an increased amount of housing close to transit. Specifically, the state mandates1: (1) Minimum gross density of 15 units per acre (2) Located not more than 0.5 miles from a commuter rail station, subway station, ferry terminal or bus station, if applicable (3) No age restrictions and suitable for families with children. The state required that communities served by the MBTA’s rapid transit system pass zoning changes complying with the state law by December 31, 2023. These “rapid transit communities” spent the year drafting, reviewing, discussing, and debating these plans across dozens of public meetings before voting on them in Fall and Winter 2023. As part of the Boston University Initiative on Cities’ MetroBridge Program, students in the political science seminar Inequality in American Politics partnered with the Metropolitan Area Planning Council (MAPC), to analyze the initial implementation of this policy in Arlington, Brookline, Milton, and Newton. Students attended public hearings and town meetings, interviewed local officials and advocates on both sides of the debate, reviewed previous meetings and plans, and observed local online forums. This report summarizes four key recommendations from this first year of implementation."
KATHERINE LEVINE EINSTEIN,2023 Menino Survey: Mayoral Accountability and Control,"The 2023 Menino Survey of Mayors represents the tenth nationally representative survey of American mayors and is based on interviews with 118 sitting mayors from 39 states. The 2023 Survey explores mayoral views on Inflation Reduction Act (IRA) implementation and issues ranging from clean energy and permitting, to public messaging, to capacity challenges, to government accountability and control. The second set of findings, Mayoral Accountability and Control, released in April 2024, examines how mayors view their control and accountability over a variety of elements of local government, and how these perceptions have changed in recent years."
PETRO LISOWSKY,"Transfer pricing: strategies, practices, and tax minimization","Using a survey of tax executives from multinational corporations, we document that some firms set their transfer pricing strategy to minimize tax payments, but more firms focus on tax compliance. We estimate that a firm focusing on minimizing taxes has a GAAP effective tax rate that is 6.6 percentage points lower and generates about $43 million more in tax savings, on average, than a firm focusing on tax compliance. Available COMPUSTAT data on sample firms confirm our survey‐based inferences. We also find that transfer pricing‐related tax savings are greater when higher foreign income, tax haven use, and R&D activities are combined with a tax minimization strategy. Finally, compliance‐focused firms report lower FIN 48 tax reserves than tax‐minimizing firms, consistent with the former group using less uncertain transfer pricing arrangements. Collectively, our study provides direct evidence that multinational firms have differing internal priorities for transfer pricing, and that these differences are strongly related to the taxes reported by these firms."
PETRO LISOWSKY,The silent majority: private U.S. firms and the market for financial reporting,"This study examines the financial reporting choices of medium-to-large private U.S. firms. Using a comprehensive panel of tax returns from private U.S. firms with assets of $10 million or more, we find that nearly two-thirds of these firms do not produce audited GAAP financial statements. Using an agency theory framework to motivate our tests, we find that size, ownership dispersion, external debt levels, and trade credit are positively associated with the choice to produce audited GAAP financial statements, while asset tangibility and internal debt are negatively related to this choice. The results also reveal that young, high-growth firms lacking tangible assets and raising outside equity find audited GAAP reporting particularly net beneficial. While the firms in our panel deploy over $9 trillion in capital and vastly outnumber public firms across all industries, even among firms with revenues exceeding $100 million, substantial unexplained variation in audited GAAP financial reporting remains. Collectively, we contribute new insights on financial reporting choices in this economically significant segment of the U.S. economy."
PETRO LISOWSKY,Measurement matters: financial reporting and productivity,"We examine the relation between financial measurement practices and firm-level productivity. Using two proprietary data sets, including a comprehensive panel of firm tax returns, we find that financial measurement quality explains 10-20% of the intra-industry dispersion of total factor productivity (TFP), a magnitude similar to that of other structured management practices identified in prior studies. We provide evidence of two mechanisms for this result. First, cross-sectional and panel analyses are consistent with high-quality measurement as a management practice causing higher productivity. Second, using plausibly exogenous differences in misreporting incentives, we show that external auditors attenuate reporting biases in administrative data. Thus we show that a portion of measured productivity heterogeneity is the direct result of reporting differences across firms. While short of identifying causal treatment effects, the economic magnitude of our results suggests that firms’ accounting practices are an important area for explaining the vast heterogeneity in reported productivity."
PETRO LISOWSKY,Competitive externalities of tax cuts,"We examine how tax cuts that benefit some firms are related to the economic performance of their direct competitors. Consistent with tax cuts decreasing the cost associated with initiating competitive strategies, we find that the decrease in the tax burden for only a certain group of firms in the U.S. economy has a negative economic effect on the performance of its direct competitors not directly exposed to the same tax cut. This negative externality is stronger when competitors face financial constraints, operate in more concentrated markets, and have similar products to their rivals. We also find that both investors and lenders price the negative externality manifested in these competitors’ economic performance."
PETRO LISOWSKY,The economic effects of special purpose entities on corporate tax avoidance,"This study provides the first large‐sample evidence on the economic tax effects of special purpose entities (SPEs). These increasingly common organizational structures facilitate corporate tax savings by enabling sponsor‐firms to increase tax‐advantaged activities and/or enhance their tax efficiency (i.e., relative tax savings of a given activity). Using path analysis, we find that SPEs facilitate greater tax avoidance, such that an economically large amount of cash tax savings from research and development (R&D), depreciable assets, net operating loss carryforwards, intangible assets, foreign operations, and tax havens occur in conjunction with SPE use. We estimate that SPEs help generate over $330 billion of incremental cash tax savings, or roughly 6% of total U.S. federal corporate income tax collections during the sample period. Interaction analyses reveal that SPEs enhance the tax efficiency of intangibles and R&D by 61.5% to 87.5%. Overall, these findings provide economic insight into complex organizational structures supporting corporate tax avoidance."
PETRO LISOWSKY,Economic growth and financial statement verification,"We use a proprietary data set of financial statements collected by banks to examine whether economic growth is related to the use of financial statement verification in debt financing. Exploiting the distinct economic growth and contraction patterns of the construction industry over the years 2002–2011, our estimates reveal that banks reduced their collection of unqualified audited financial statements from construction firms at nearly twice the rate of firms in other industries during the housing boom period before 2008. This reduction was most severe in the regions that experienced the most significant construction growth. These trends reversed during the subsequent housing crisis in 2008–2011 when construction activity contracted. Moreover, using bank‐ and firm‐level data, we find a strong negative (positive) relation between audited financial statements during the growth period, and subsequent loan losses (construction firm survival) during the contraction period. Collectively, our results reveal that macroeconomic fluctuations produce temporal shifts in the overall level of financial statement verification and temporal shifts in verification are related to bank loan portfolio quality and borrower performance."
PETRO LISOWSKY,Do smoothing activities indicate higher or lower financial reporting quality? Evidence from effective tax rates,"Prior literature is mixed as to whether smoothing through accruals indicates higher or lower financial reporting quality. Motivated by the unique features and incentives of tax expense, we provide new evidence by examining the link between smoothing of GAAP effective tax rates (ETRs) and financial restatement likelihoods. Different from earnings smoothing’s insignificant relation with restatements, we find that ETR smoothing through tax accruals is associated with a lower likelihood of financial restatement and tax-related financial reporting fraud. Further investigation reveals that these associations are stronger in firms with a higher level of discretion in tax reporting and when the demand for transparent reporting is higher. We also document that smoothing through tax accruals increases the informativeness of GAAP ETRs for predicting future cash ETRs. Collectively, our results contribute to the accounting literature by providing evidence that smoothing activities pertaining to tax accruals are consistent with higher financial reporting quality."
PHILIP MUIRHEAD,The transit transmission spectrum of a cold gas giant planet,"We use solar occultations observed by the Visual and Infrared Mapping Spectrometer aboard the Cassini Spacecraft to extract the 1 to 5 micron transmission spectrum of Saturn, as if it were a transiting exoplanet. We detect absorption from methane, ethane, acetylene, aliphatic hydrocarbons, and possibly carbon monoxide with peak-to-peak features of up to 90 parts-per-million despite the presence of ammonia clouds. We also find that atmospheric refraction, as opposed to clouds or haze, determines the minimum altitude that could be probed during mid-transit. Self-consistent exoplanet atmosphere models show good agreement with Saturn's transmission spectrum but fail to reproduce a large absorption feature near 3.4 microns likely caused by gaseous ethane and a C-H stretching mode of an unknown aliphatic hydrocarbon. This large feature is located in one of the Spitzer Space Telescope bandpasses and could alter interpretations of transmission spectra if not properly modeled. The large signal in Saturn's transmission spectrum suggests that transmission spectroscopy of cold, long-period gaseous exoplanets should be possible with current and future observatories. Motivated by these results, we briefly consider the feasibility of a survey to search for and characterize cold exoplanets analogous to Jupiter and Saturn using a target-of-opportunity approach."
PHILIP MUIRHEAD,"A physically motivated and empirically calibrated method to measure the effective temperature, metallicity, and Ti abundance of M dwarfs","The ability to perform detailed chemical analysis of Sun-like F-, G-, and K-type stars is a powerful tool with many applications, including studying the chemical evolution of the Galaxy and constraining planet formation theories. Unfortunately, complications in modeling cooler stellar atmospheres hinders similar analyses of M dwarf stars. Empirically calibrated methods to measure M dwarf metallicity from moderate-resolution spectra are currently limited to measuring overall metallicity and rely on astrophysical abundance correlations in stellar populations. We present a new, empirical calibration of synthetic M dwarf spectra that can be used to infer effective temperature, Fe abundance, and Ti abundance. We obtained high-resolution (R ~ 25,000), Y-band (~1 μm) spectra of 29 M dwarfs with NIRSPEC on Keck II. Using the PHOENIX stellar atmosphere modeling code (version 15.5), we generated a grid of synthetic spectra covering a range of temperatures, metallicities, and alpha-enhancements. From our observed and synthetic spectra, we measured the equivalent widths of multiple Fe i and Ti i lines and a temperature-sensitive index based on the FeH band head. We used abundances measured from widely separated solar-type companions to empirically calibrate transformations to the observed indices and equivalent widths that force agreement with the models. Our calibration achieves precisions in T eff, [Fe/H], and [Ti/Fe] of 60 K, 0.1 dex, and 0.05 dex, respectively, and is calibrated for 3200 K < T eff < 4100 K, −0.7 < [Fe/H] < +0.3, and −0.05 < [Ti/Fe] < +0.3. This work is a step toward detailed chemical analysis of M dwarfs at a precision similar to what has been achieved for FGK stars."
PHILIP MUIRHEAD,Multiwavelength transit observations of the candidate disintegrating planetesimals orbiting WD 1145+017,"We present multiwavelength, ground-based follow-up photometry of the white dwarf WD 1145+017, which has recently been suggested to be orbited by up to six or more short-period, low-mass, disintegrating planetesimals. We detect nine significant dips in flux of between 10% and 30% of the stellar flux in our ~32 hr of photometry, suggesting that WD 1145+017 is indeed being orbited by multiple, short-period objects. Through fits to the asymmetric transits that we observe, we confirm that the transit egress is usually longer than the ingress, and that the transit duration is longer than expected for a solid body at these short periods, all suggesting that these objects have cometary tails streaming behind them. The precise orbital periods of the planetesimals are unclear, but at least one object, and likely more, have orbital periods of ~4.5 hr. We are otherwise unable to confirm the specific periods that have been reported, bringing into question the long-term stability of these periods. Our high-precision photometry also displays low-amplitude variations, suggesting that dusty material is consistently passing in front of the white dwarf, either from discarded material from these disintegrating planetesimals or from the detected dusty debris disk. We compare the transit depths in the V- and R-bands of our multiwavelength photometry, and find no significant difference; therefore, for likely compositions, the radius of single-size particles in the cometary tails streaming behind the planetesimals must be ~0.15 μm or larger, or ~0.06 μm or smaller, with 2σ confidence."
PHILIP MUIRHEAD,"Magnetic inflation and Stellar Mass. II. On the radii of wingle, rapidly rotating, fully convective M-dwarf stars","Main-sequence, fully convective M dwarfs in eclipsing binaries are observed to be larger than stellar evolutionary models predict by as much as 10%–15%. A proposed explanation for this discrepancy involves effects from strong magnetic fields, induced by rapid rotation via the dynamo process. Although, a handful of single, slowly rotating M dwarfs with radius measurements from interferometry also appear to be larger than models predict, suggesting that rotation or binarity specifically may not be the sole cause of the discrepancy. We test whether single, rapidly rotating, fully convective stars are also larger than expected by measuring their $R\sin i$ distribution. We combine photometric rotation periods from the literature with rotational broadening ($v\sin i$) measurements reported in this work for a sample of 88 rapidly rotating M dwarf stars. Using a Bayesian framework, we find that stellar evolutionary models underestimate the radii by $10 \% \mbox{--}15{ \% }_{-2.5}^{+3}$, but that at higher masses (0.18 < M < 0.4 M Sun), the discrepancy is only about 6% and comparable to results from interferometry and eclipsing binaries. At the lowest masses (0.08 < M < 0.18 M Sun), we find that the discrepancy between observations and theory is 13%–18%, and we argue that the discrepancy is unlikely to be due to effects from age. Furthermore, we find no statistically significant radius discrepancy between our sample and the handful of M dwarfs with interferometric radii. We conclude that neither rotation nor binarity are responsible for the inflated radii of fully convective M dwarfs, and that all fully convective M dwarfs are larger than models predict."
PHILIP MUIRHEAD,"Kepler-445, Kepler-446 and the occurrence of compact multiples orbiting mid-M dwarf stars","We confirm and characterize the exoplanetary systems Kepler-445 and Kepler-446: two mid-M dwarf stars, each with multiple, small, short-period transiting planets. Kepler-445 is a metal-rich ([Fe/H] = +0.25 ± 0.10) M4 dwarf with three transiting planets, and Kepler-446 is a metal-poor ([Fe/H] = –0.30 ± 0.10) M4 dwarf also with three transiting planets. Kepler-445c is similar to GJ 1214b: both in planetary radius and the properties of the host star. The Kepler-446 system is similar to the Kepler-42 system: both are metal-poor with large galactic space velocities and three short-period, likely rocky transiting planets that were initially assigned erroneously large planet-to-star radius ratios. We independently determined stellar parameters from spectroscopy and searched for and fitted the transit light curves for the planets, imposing a strict prior on stellar density in order to remove correlations between the fitted impact parameter and planet-to-star radius ratio for short-duration transits. Combining Kepler-445, Kepler-446, and Kepler-42, and isolating all mid-M dwarf stars observed by Kepler with the precision necessary to detect similar systems, we calculate that 21$^{+7}_{-5}$% of mid-M dwarf stars host compact multiples (multiple planets with periods of less than 10 days) for a wide range of metallicities. We suggest that the inferred planet masses for these systems support highly efficient accretion of protoplanetary disk metals by mid-M dwarf protoplanets."
PHILIP MUIRHEAD,Kepler transit depths contaminated by a phantom star,"We present ground-based observations from the Discovery Channel Telescope (DCT) of three transits of Kepler-445c—a supposed super-Earth exoplanet with properties resembling GJ 1214b—and demonstrate that the transit depth is ~50% shallower than the depth previously inferred from Kepler spacecraft data. The resulting decrease in planetary radius significantly alters the interpretation of the exoplanet's bulk composition. Despite the faintness of the M4 dwarf host star, our ground-based photometry clearly recovers each transit and achieves repeatable 1σ precision of ~0.2% (2 millimags). The transit parameters estimated from the DCT data are discrepant with those inferred from the Kepler data to at least 17σ confidence. This inconsistency is due to a subtle miscalculation of the stellar crowding metric during the Kepler pre-search data conditioning (PDC). The crowding metric, or CROWDSAP, is contaminated by a non-existent phantom star originating in the USNO-B1 catalog and inherited by the Kepler Input Catalog (KIC). Phantom stars in the KIC are likely rare, but they have the potential to affect statistical studies of Kepler targets that use the PDC transit depths for a large number of exoplanets where an individual follow-up observation of each is not possible. The miscalculation of Kepler-445c's transit depth emphasizes the importance of stellar crowding in the Kepler data, and provides a cautionary tale for the analysis of data from the Transiting Exoplanet Survey Satellite, which will have even larger pixels than Kepler."
PHILIP MUIRHEAD,NEWS: the near-infrared Echelle for wideband spectroscopy,"We present an updated optical and mechanical design of NEWS: the Near-infrared Echelle for Wide-band Spectroscopy (formerly called HiJaK: the High-resolution J, H and K spectrometer), a compact, high-resolution, near-infrared spectrometer for 5-meter class telescopes. NEWS provides a spectral resolution of 60,000 and covers the full 0.8-2.5 micron range in 5 modes. We adopt a compact, lightweight, monolithic design and developed NEWS to be mounted to the instrument cube at the Cassegrain focus of the the new 4.3-meter Discovery Channel Telescope."
PHILIP MUIRHEAD,No timing variations observed in third transit of snow-line exoplanet Kepler-421b,"We observed Kepler-421 during the anticipated third transit of the snow-line exoplanet Kepler-421b in order to constrain the existence and extent of transit timing variations (TTVs). Previously, the Kepler Spacecraft only observed two transits of Kepler-421b leaving the planet's transit ephemeris unconstrained. Our visible light, time-series observations from the 4.3-meter Discovery Channel Telescope were designed to capture pre-transit baseline and the partial transit of Kepler-421b barring significant TTVs. We use the light curves to assess the probabilities of various transit models using both the posterior odds ratio and the Bayesian Information Criterion (BIC) and find that a transit model with no TTVs is favored to 3.6-sigma confidence. These observations suggest that Kepler-421b is either alone in its system or is only experiencing minor dynamic interactions with an unseen companion. With the Kepler-421b ephemeris constrained, we calculate future transit times and discuss the opportunity to characterize the atmosphere of this cold, long-period exoplanet via transmission spectroscopy. Our investigation emphasizes the difficulties associated with observing long-period exoplanet transits and the consequences that arise from failing to refine transit ephemerides."
PHILIP MUIRHEAD,"High-resolution broadband spectroscopy using externally dispersed interferometry at the Hale telescope: Part 1, data analysis and results","High-resolution broadband spectroscopy at near-infrared wavelengths (950 to 2450 nm) has been performed using externally dispersed interferometry (EDI) at the Hale telescope at Mt. Palomar. Observations of stars were performed with the “TEDI” interferometer mounted within the central hole of the 200-in. primary mirror in series with the comounted TripleSpec near-infrared echelle spectrograph. These are the first multidelay EDI demonstrations on starlight, as earlier measurements used a single delay or laboratory sources. We demonstrate very high (10×) resolution boost, from original 2700 to 27,000 with current set of delays (up to 3 cm), well beyond the classical limits enforced by the slit width and detector pixel Nyquist limit. Significantly, the EDI used with multiple delays rather than a single delay as used previously yields an order of magnitude or more improvement in the stability against native spectrograph point spread function (PSF) drifts along the dispersion direction. We observe a dramatic (20×) reduction in sensitivity to PSF shift using our standard processing. A recently realized method of further reducing the PSF shift sensitivity to zero is described theoretically and demonstrated in a simple simulation which produces a 350× times reduction. We demonstrate superb rejection of fixed pattern noise due to bad detector pixels—EDI only responds to changes in pixel intensity synchronous to applied dithering. This part 1 describes data analysis, results, and instrument noise. A section on theoretical photon limited sensitivity is in a companion paper, part 2."
PHILIP MUIRHEAD,"Miniature exoplanet radial velocity array I: design, commissioning, and early photometric results","The MINiature Exoplanet Radial Velocity Array (MINERVA) is a US-based observational facility dedicated to the discovery and characterization of exoplanets around a nearby sample of bright stars. MINERVA employs a robotic array of four 0.7 m telescopes outfitted for both high-resolution spec- troscopy and photometry, and is designed for completely autonomous operation. The primary science program is a dedicated radial velocity survey and the secondary science objective is to obtain high precision transit light curves. The modular design of the facility and the flexibility of our hardware allows for both science programs to be pursued simultaneously, while the robotic control software provides a robust and efficient means to carry out nightly observations. In this article, we describe the design of MINERVA including major hardware components, software, and science goals. The telescopes and photometry cameras are characterized at our test facility on the Caltech campus in Pasadena, CA, and their on-sky performance is validated. New observations from our test facility demonstrate sub-mmag photometric precision of one of our radial velocity survey targets, and we present new transit observations and fits of WASP-52b—a known hot-Jupiter with an inflated radius and misaligned orbit. The process of relocating the MINERVA hardware to its final destination at the Fred Lawrence Whipple Observatory in southern Arizona has begun, and science operations are expected to commence within 2015."
PHILIP MUIRHEAD,Magnetic inflation and stellar mass. I. Revised parameters for the component stars of the Kepler low-mass eclipsing binary T-Cyg1-12664,"Several low-mass eclipsing binary stars show larger than expected radii for their measured mass, metallicity, and age. One proposed mechanism for this radius inflation involves inhibited internal convection and starspots caused by strong magnetic fields. One particular eclipsing binary, T-Cyg1-12664, has proven confounding to this scenario. Çakırlı et al. measured a radius for the secondary component that is twice as large as model predictions for stars with the same mass and age, but a primary mass that is consistent with predictions. Iglesias-Marzoa et al. independently measured the radii and masses of the component stars and found that the radius of the secondary is not in fact inflated with respect to models, but that the primary is, which is consistent with the inhibited convection scenario. However, in their mass determinations, Iglesias-Marzoa et al. lacked independent radial velocity measurements for the secondary component due to the star’s faintness at optical wavelengths. The secondary component is especially interesting, as its purported mass is near the transition from partially convective to a fully convective interior. In this article, we independently determined the masses and radii of the component stars of T-Cyg1-12664 using archival Kepler data and radial velocity measurements of both component stars obtained with IGRINS on the Discovery Channel Telescope and NIRSPEC and HIRES on the Keck Telescopes. We show that neither of the component stars is inflated with respect to models. Our results are broadly consistent with modern stellar evolutionary models for main-sequence M dwarf stars and do not require inhibited convection by magnetic fields to account for the stellar radii."
PHILIP MUIRHEAD,The gold standard: accurate stellar and planetary parameters for eight Kepler M dwarf systems enabled by parallaxes,"We report parallaxes and proper motions from the Hawaii Infrared Parallax Program for eight nearby M dwarf stars with transiting exoplanets discovered by Kepler. We combine our directly measured distances with mass-luminosity and radius–luminosity relationships to significantly improve constraints on the host stars’ properties. Our astrometry enables the identification of wide stellar companions to the planet hosts. Within our limited sample, all the multi-transiting planet hosts (three of three) appear to be single stars, while nearly all (four of five) of the systems with a single detected planet have wide stellar companions. By applying strict priors on average stellar density from our updated radius and mass in our transit fitting analysis, we measure the eccentricity probability distributions for each transiting planet. Planets in single-star systems tend to have smaller eccentricities than those in binaries, although this difference is not significant in our small sample. In the case of Kepler-42bcd, where the eccentricities are known to be ≃0, we demonstrate that such systems can serve as powerful tests of M dwarf evolutionary models by working in L⋆ − ρ⋆ space. The transit-fit density for Kepler- 42bcd is inconsistent with model predictions at 2.1σ (22%), but matches more empirical estimates at 0.2σ (2%), consistent with earlier results showing model radii of M dwarfs are underinflated. Gaia will provide high-precision parallaxes for the entire Kepler M dwarf sample, and TESS will identify more planets transiting nearby, late-type stars, enabling significant improvements in our understanding of the eccentricity distribution of small planets and the parameters of late-type dwarfs."
PHILIP MUIRHEAD,The physical mechanism behind M dwarf metallicity indicators and the role of C and O abundances,"We present near-infrared (NIR) synthetic spectra based on PHOENIX stellar atmosphere models of typical early and mid-M dwarfs with varied C and O abundances. We apply multiple recently published methods for determining M dwarf metallicity to our models to determine the effects of C and O abundances on metallicity indicators. We find that the pseudo-continuum level is very sensitive to C/O and that all metallicity indicators show a dependence on C and O abundances, especially in lower T eff models. In some cases, the inferred metallicity ranges over a full order of magnitude (>1 dex) when [C/Fe] and [O/Fe] are varied independently by ±0.2. We also find that [(O−C)/Fe], the difference in O and C abundances, is a better tracer of the pseudo-continuum level than C/O. Models of mid-M dwarfs with [C/Fe], [O/Fe], and [M/H] that are realistic in the context of galactic chemical evolution suggest that variation in [(O−C)/Fe] is the primary physical mechanism behind the M dwarf metallicity tracers investigated here. Empirically calibrated metallicity indicators are still valid for most nearby M dwarfs due to the tight correlation between [(O−C)/Fe] and [Fe/H] evident in spectroscopic surveys of solar neighborhood FGK stars. Variations in C and O abundances also affect the spectral energy distribution of M dwarfs. Allowing [O/Fe] to be a free parameter provides better agreement between the synthetic spectra and observed spectra of metal-rich M dwarfs. We suggest that flux-calibrated, low-resolution, NIR spectra can provide a path toward measuring C and O abundances in M dwarfs and breaking the degeneracy between C/O and [Fe/H] present in M dwarf metallicity indicators."
PHILIP MUIRHEAD,"Long-term, multiwavelength light curves of ultra-cool dwarfs: I. An interplay of starspots & clouds likely drive the variability of the L3. 5 dwarf 2MASS 0036+ 18","We present multi-telescope, ground-based, multiwavelength optical and near-infrared photometry of the variable L3.5 ultra-cool dwarf 2MASSW J0036159+182110. We present 22 nights of photometry of 2MASSW J0036159+182110, including 7 nights of simultaneous, multiwavelength photometry, spread over ∼120 days allowing us to determine the rotation period of this ultra-cool dwarf to be 3.080 ± 0.001 hr. Our many nights of multiwavelength photometry allow us to observe the evolution, or more specifically the lack thereof, of the light curve over a great many rotation periods. The lack of discernible phase shifts in our multiwavelength photometry, and that the amplitude of variability generally decreases as one moves to longer wavelengths for 2MASSW J0036159+182110, is generally consistent with starspots driving the variability on this ultra-cool dwarf, with starspots that are ∼100 degrees K hotter or cooler than the ∼1700 K photosphere. Also, reasonably thick clouds are required to fit the spectra of 2MASSW J0036159+182110, suggesting there likely exists some complex interplay between the starspots driving the variability of this ultra-cool dwarf and the clouds that appear to envelope this ultra-cool dwarf."
PHILIP MUIRHEAD,Characterizing the cool KOIs. VII. Refined physical properties of the transiting brown dwarf LHS 6343 C,"We present an updated analysis of LHS 6343, a triple system in the Kepler field which consists of a brown dwarf transiting one member of a widely separated M+M binary system. By analyzing the full Kepler data set and 34 Keck/HIgh Resolution Echelle Spectrometer radial velocity observations, we measure both the observed transit depth and Doppler semiamplitude to 0.5% precision. With Robo-AO and Palomar/PHARO adaptive optics imaging as well as TripleSpec spectroscopy, we measure a model-dependent mass for LHS 6343 C of 62.1 ± 1.2 M Jup and a radius of 0.783 ± 0.011 R Jup. We detect the secondary eclipse in the Kepler data at 3.5σ, measuring ecos ω = 0.0228 ± 0.0008. We also derive a method to measure the mass and radius of a star and transiting companion directly, without any direct reliance on stellar models. The mass and radius of both objects depend only on the orbital period, stellar density, reduced semimajor axis, Doppler semiamplitude, eccentricity, and inclination, as well as the knowledge that the primary star falls on the main sequence. With this method, we calculate a mass and radius for LHS 6343 C to a precision of 3% and 2%, respectively."
PHILIP MUIRHEAD,Attaining Doppler precision of 10 cm s(-1) with a lock-in amplified spectrometer,"We explore the radial velocity performance benefits of coupling starlight to a fast-scanning interferometer and a fast-readout spectrometer with zero readout noise. By rapidly scanning an interferometer, we can decouple wavelength calibration errors from precise radial velocity measurements, exploiting the advantages of lock-in amplification. In a Bayesian framework, we investigate the correlation between wavelength calibration errors and resulting radial velocity errors. We construct an end-to-end simulation of this approach to address the feasibility of achieving 10 cm s-1 radial velocity precision on a typical Sun-like star using existing, 5 m-class telescopes. We find that such a precision can be reached in a single night, opening up possibilities for ground-based detections of Earth-Sun analog systems."
PHILIP MUIRHEAD,Characterizing the cool KOIs. VIII. Parameters of the planets orbiting Kepler's coolest dwarfs,"The coolest dwarf stars targeted by the Kepler Mission constitute a relatively small but scientifically valuable subset of the Kepler target stars, and provide a high-fidelity, nearby sample of transiting planetary systems. Using archival Kepler data spanning the entire primary mission, we perform a uniform analysis to extract, confirm, and characterize the transit signals discovered by the Kepler pipeline toward M-type dwarf stars. We recover all but two of the signals reported in a recent listing from the Exoplanet Archive resulting in 163 planet candidates associated with a sample of 104 low-mass stars. We fitted the observed light curves to transit models using a Markov Chain Monte Carlo method and we have made the posterior samples publicly available to facilitate further studies. We fitted empirical transit times to individual transit signals with significantly non-linear ephemerides for accurate recovery of transit parameters and precise measuring of transit timing variations. We also provide the physical parameters for the stellar sample, including new measurements of stellar rotation, allowing the conversion of transit parameters into planet radii and orbital parameters."
PHILIP MUIRHEAD,Validation of 12 small Kepler transiting planets in the habitable zone,"We present an investigation of 12 candidate transiting planets from Kepler with orbital periods ranging from 34 to 207 days, selected from initial indications that they are small and potentially in the habitable zone (HZ) of their parent stars. Few of these objects are known. The expected Doppler signals are too small to confirm them by demonstrating that their masses are in the planetary regime. Here we verify their planetary nature by validating them statistically using the BLENDER technique, which simulates large numbers of false positives and compares the resulting light curves with the Kepler photometry. This analysis was supplemented with new follow-up observations (high-resolution optical and near-infrared spectroscopy, adaptive optics imaging, and speckle interferometry), as well as an analysis of the flux centroids. For 11 of them (KOI-0571.05, 1422.04, 1422.05, 2529.02, 3255.01, 3284.01, 4005.01, 4087.01, 4622.01, 4742.01, and 4745.01) we show that the likelihood they are true planets is far greater than that of a false positive, to a confidence level of 99.73% (3σ ) or higher. For KOI-4427.01 the confidence level is about 99.2% (2.6σ ). With our accurate characterization of the GKM host stars, the derived planetary radii range from 1.1 to 2.7R⊕. All 12 objects are confirmed to be in the HZ, and nine are small enough to be rocky. Excluding three of them that have been previously validated by others, our study doubles the number of known rocky planets in the HZ. KOI-3284.01 (Kepler-438b) and KOI-4742.01 (Kepler-442b) are the planets most similar to the Earth discovered to date when considering their size and incident flux jointly."
PHILIP MUIRHEAD,Friends of hot Jupiters. II. No correspondence between hot-Jupiter spin-orbit misalignment and the incidence of directly imaged stellar companions,"Multi-star systems are common, yet little is known about a stellar companion's influence on the formation and evolution of planetary systems. For instance, stellar companions may have facilitated the inward migration of hot Jupiters toward to their present day positions. Many observed short-period gas giant planets also have orbits that are misaligned with respect to their star's spin axis, which has also been attributed to the presence of a massive outer companion on a non-coplanar orbit. We present the results of a multi-band direct imaging survey using Keck NIRC2 to measure the fraction of short-period gas giant planets found in multi-star systems. Over three years, we completed a survey of 50 targets (""Friends of Hot Jupiters"") with 27 targets showing some signature of multi-body interaction (misaligned or eccentric orbits) and 23 targets in a control sample (well-aligned and circular orbits). We report the masses, projected separations, and confirmed common proper motion for the 19 stellar companions found around 17 stars. Correcting for survey incompleteness, we report companion fractions of 48% ± 9%, 47% ± 12%, and 51% ± 13% in our total, misaligned/eccentric, and control samples, respectively. This total stellar companion fraction is 2.8σ larger than the fraction of field stars with companions approximately 50-2000 AU. We observe no correlation between misaligned/eccentric hot Jupiter systems and the incidence of stellar companions. Combining this result with our previous radial velocity survey, we determine that 72% ± 16% of hot Jupiters are part of multi-planet and/or multi-star systems."
PHILIP MUIRHEAD,Friends of hot Jupiters. III. An infrared spectroscopic search for low-mass stellar companions,"Surveys of nearby field stars indicate that stellar binaries are common, yet little is known about the effects that these companions may have on planet formation and evolution. The Friends of Hot Jupiters project uses three complementary techniques to search for stellar companions to known planet-hosting stars: radial velocity monitoring, adaptive optics imaging, and near-infrared spectroscopy. In this paper, we examine high-resolution K band infrared spectra of fifty stars hosting gas giant planets on short-period orbits. We use spectral fitting to search for blended lines due to the presence of cool stellar companions in the spectra of our target stars, where we are sensitive to companions with temperatures between 3500 and 5000 K and projected separations less than 100 AU in most systems. We identify eight systems with candidate low-mass companions, including one companion that was independently detected in our AO imaging survey. For systems with radial velocity accelerations, a spectroscopic non-detection rules out scenarios involving a stellar companion in a high inclination orbit. We use these data to place an upper limit on the stellar binary fraction at small projected separations, and show that the observed population of candidate companions is consistent with that of field stars and also with the population of wide-separation companions detected in our previous AO survey. We find no evidence that spectroscopic stellar companions are preferentially located in systems with short-period gas giant planets on eccentric and/or misaligned orbits."
PHILIP MUIRHEAD,LHS 1610A: a nearby mid-M dwarf with a companion that is likely a brown dwarf,"We present the spectroscopic orbit of LHS 1610A, a newly discovered single-lined spectroscopic binary with a trigonometric distance placing it at 9.9 ± 0.2 pc. We obtained spectra with the TRES instrument on the 1.5 m Tillinghast Reflector at the Fred Lawrence Whipple Observatory located on Mt. Hopkins in AZ. We demonstrate the use of the TiO molecular bands at 7065–7165 Å to measure radial velocities and achieve an average estimated velocity uncertainty of 28 m s−1. We measure the orbital period to be 10.6 days and calculate a minimum mass of 44.8 ± 3.2 M Jup for the secondary, indicating that it is likely a brown dwarf. We place an upper limit to 3σ of 2500 K on the effective temperature of the companion from infrared spectroscopic observations using IGRINS on the 4.3 m Discovery Channel Telescope. In addition, we present a new photometric rotation period of 84.3 days for the primary star using data from the MEarth-South Observatory, with which we show that the system does not eclipse."
PHILIP MUIRHEAD,A catalog of cool dwarf targets for the Transiting Exoplanet Survey Satellite,"We present a catalog of cool dwarf targets (V−J > 2.7, T eff ≲ 4000K) and their stellar properties for the upcoming Transiting Exoplanet Survey Satellite (TESS), for the purpose of determining which cool dwarfs should be observed using two-minute observations. TESS has the opportunity to search tens of thousands of nearby, cool, late K and M-type dwarfs for transiting exoplanets, an order of magnitude more than current or previous transiting exoplanet surveys, such as {\it Kepler}, K2 and ground-based programs. This necessitates a new approach to choosing cool dwarf targets. Cool dwarfs were chosen by collating parallax and proper motion catalogs from the literature and subjecting them to a variety of selection criteria. We calculate stellar parameters and TESS magnitudes using the best possible relations from the literature while maintaining uniformity of methods for the sake of reproducibility. We estimate the expected planet yield from TESS observations using statistical results from the Kepler Mission, and use these results to choose the best targets for two-minute observations, optimizing for small planets for which masses can conceivably be measured using follow up Doppler spectroscopy by current and future Doppler spectrometers. The catalog is incorporated into the TESS Input Catalog and TESS Candidate Target List until a more complete and accurate cool dwarf catalog identified by ESA's Gaia Mission can be incorporated."
PHILIP MUIRHEAD,"The Perkins INfrared Exosatellite Survey (PINES) I. survey overview, reduction pipeline, and early results","We describe the Perkins INfrared Exosatellite Survey (PINES), a near-infrared photometric search for short-period transiting planets and moons around a sample of 393 spectroscopically confirmed L- and T-type dwarfs. PINES is performed with Boston University’s 1.8 m Perkins Telescope Observatory, located on Anderson Mesa, Arizona. We discuss the observational strategy of the survey, which was designed to optimize the number of expected transit detections, and describe custom automated observing procedures for performing PINES observations. We detail the steps of the PINES Analysis Toolkit (PAT), software that is used to create light curves from PINES images. We assess the impact of second-order extinction due to changing precipitable water vapor on our observations and find that the magnitude of this effect is minimized in Mauna Kea Observatories J band. We demonstrate the validity of PAT through the recovery of a transit of WASP-2 b and known variable brown dwarfs, and use it to identify a new variable L/T transition object: the T2 dwarf WISE J045746.08-020719.2. We report on the measured photometric precision of the survey and use it to estimate our transit-detection sensitivity. We find that for our median brightness targets, assuming contributions from white noise only, we are sensitive to the detection of 2.5 R ⊕ planets and larger. PINES will test whether the increase in sub-Neptune-sized planet occurrence with decreasing host mass continues into the L- and T-dwarf regime."
PHILIP MUIRHEAD,The SPHINX M-dwarf spectral grid. I. benchmarking new model atmospheres to derive fundamental M-dwarf properties,"About 70%–80% of stars in our solar and Galactic neighborhood are M dwarfs. They span a range of low masses and temperatures relative to solar-type stars, facilitating molecule formation throughout their atmospheres. Standard stellar atmosphere models primarily designed for FGK stars face challenges when characterizing broadband molecular features in spectra of cool stars. Here, we introduce SPHINX—a new 1D self-consistent radiative–convective thermochemical equilibrium chemistry model grid of atmospheres and spectra for M dwarfs in low resolution (R ∼ 250). We incorporate the latest precomputed absorption cross sections with pressure broadening for key molecules dominant in late-K, early/main-sequence-M stars. We then validate our grid models by determining fundamental properties (T eff, log g, [M/H], radius, and C/O) for 10 benchmark M+G binary stars with known host metallicities and 10 M dwarfs with interferometrically measured angular diameters. Incorporating the Gaussian process inference tool Starfish, we account for correlated and systematic noise in low-resolution (spectral stitching of SpeX, SNIFS, and STIS) observations and derive robust estimates of fundamental M-dwarf atmospheric parameters. Additionally, we assess the influence of photospheric heterogeneity on inferred [M/H] and find that it could explain some deviations from observations. We also probe whether the adopted convective mixing length parameter influences inferred radii, effective temperature, and [M/H] and again find that may explain discrepancies between interferometric observations and model-derived parameters for cooler M dwarfs. Mainly, we show the unique strength in leveraging broadband molecular absorption features occurring in low-resolution M dwarf spectra and demonstrate the ability to improve constraints on fundamental properties of exoplanet hosts and brown-dwarf companions."
PHILIP MUIRHEAD,Radii of 88 M subdwarfs and updated radius relations for low-metallicity M-dwarf stars,"M subdwarfs are low-metallicity M dwarfs that typically inhabit the halo population of the Galaxy. Metallicity controls the opacity of stellar atmospheres; in metal-poor stars, hydrostatic equilibrium is reached at a smaller radius, leading to smaller radii for a given effective temperature. We compile a sample of 88 stars that span spectral classes K7 to M6 and include stars with metallicity classes from solar-metallicity dwarf stars to the lowest metallicity ultra subdwarfs to test how metallicity changes the stellar radius. We fit models to Palomar Double Spectrograph (DBSP) optical spectra to derive effective temperatures (T_ eff) and we measure bolometric luminosities (L_ bol) by combining broad wavelength-coverage photometry with Gaia parallaxes. Radii are then computed by combining the T_ eff and L_ bol using the Stefan–Boltzman law. We find that for a given temperature, ultra subdwarfs can be as much as five times smaller than their solar-metallicity counterparts. We present color-radius and color-surface brightness relations that extend down to [Fe/H] of −2.0 dex, in order to aid the radius determination of M subdwarfs, which will be especially important for the WFIRST exoplanetary microlensing survey."
PHILIP MUIRHEAD,Magnetic inflation and stellar mass. IV. four low-mass kepler eclipsing binaries consistent with non-magnetic stellar evolutionary models,"Low-mass eclipsing binaries (EBs) show systematically larger radii than model predictions for their mass, metallicity, and age. Prominent explanations for the inflation involve enhanced magnetic fields generated by rapid rotation of the star that inhibit convection and/or suppress flux from the star via starspots. However, derived masses and radii for individual EB systems often disagree in the literature. In this paper, we continue to investigate low-mass EBs observed by NASA’s Kepler spacecraft, deriving stellar masses and radii using high-quality spacebased light curves and radial velocities from high-resolution infrared spectroscopy. We report masses and radii for three Kepler EBs, two of which agree with previously published masses and radii (KIC 11922782 and KIC 9821078). For the third EB (KIC 7605600), we report new masses and show the secondary component is likely fully convective (M2 = 0.17 ± 0.01M☉ and = - ☉ + R2 0.199 0.002R 0.001 ). Combined with KIC 10935310 from Han et al., we find that the masses and radii for four low-mass Kepler EBs are consistent with modern stellar evolutionary models for M dwarf stars and do not require inhibited convection by magnetic fields to account for the stellar radii."
PHILIP MUIRHEAD,Constraining planet occurrence around ultracool dwarfs observed by K2,"Though we expect many planets around ultracool dwarfs, few have been detected. The K2 mission presents a unique opportunity to search for transiting planets around a large sample of ultracool dwarfs and place constraints on planet occurrence at the bottom of the main sequence. Planet detection using the transit method is dependent not only on geometric transit probability but also the effectiveness of transit-searching methods. In this work, we use K2 observations to measure transit detection efficiency in ultracool dwarfs and use our transit detection efficiency to calculate an upper limit on the planet occurrence rate. We measure our ability to recover various types of transits around dwarfs at the M/L transition. We inject synthetic planetary transits of radii from 0.1 to 3.5 Earth radii and of periods from 0.3 to 26 days into 382 K2 light curves of late-type M and L dwarfs. We attempt to recover them using Box-Least Squares and Levenberg-Marquardt optimization methods. We then calculate a detection efficiency, or fraction recovered, and a threshold of detectability relating to orbital period and radius for each dwarf. We present an upper limit on the planet occurrence rate, as well as constraints on the probability of seeing no planets around a given number of ultracool dwarfs."
PHILIP MUIRHEAD,Are exoplanets orbiting m dwarfs extreme?,"M dwarf stars have long spin-down timescales, long activity lifetimes and persistent magnetic activity, all of which have implications for the potential habitability of orbiting planets. I will present results from several research programs investigating M dwarf rotation, activity and evolution. I will discuss a new technique to measure chemical-kinematic ages of main-sequence M dwarf stars. We applied that technique to a variety of nearby M dwarfs, both planet hosts and non-planet hosts, and rapid (young) and slow (old) rotators. We find that relatively slow rotators (P 100 days) do not appear to be α enriched, indicating that they are not over 10 Gyrs old. Second, for the rapid rotators, we see clear evidence of Zeeman enhancement of Y-band Ti I lines as a function of Rossby number. While other activity indicators, such as H-α and X-ray emission, appear to saturate with low Rossby number, Zeeman enhancement does not, indicating that the saturation mechanism is confined to the chromosphere and corona. Finally, I will present new results on the M dwarf radius problem. Using spectral synthesis methods, we find that large magnetic star spot fractions are primarily responsible for observed discrepancies between model and measured stellar radii in fully convective M dwarf stars. As most M dwarfs appear discrepant, our results suggest the vast majority of M dwarfs have large spot fractions and correspondingly high localization of magnetic fields."
PHILIP MUIRHEAD,Enhanced exoplanet biosignature detection from an interferometer addition to low resolution spectrographs,"The physics of molecular vibration causes absorption spectra of atmospheric molecules to be a group of approximately periodic fine lines. This is fortuitous for detecting exoplanet biosignificant molecules, since it approximately matches the periodic sinusoidal transmission of an interferometer. The series addition of a 0.6 cm interferometer with a dispersive spectrograph creates moire patterns. These enhance detection by several orders of magnitude for initially low resolution spectrographs. We simulate the Gemini Planet Imager integral field spectrograph observing a telluric spectrum of native resolutions 40 and 70 for 1.65 and 2 micron bands– too low to resolve the fine lines. The interferometer addition increases the detectability of the molecular signal, relative to photon noise, to a level similar to a R=4400 (at 1.65 micron) or R=3900 (at 2 micron) spectrograph."
PHILIP MUIRHEAD,Externally dispersed interferometry for terrestrial exoplanet detection,"Terrestrial exoplanets are observationally challenging to detect and characterize. Compared to gas giant exoplanets, terrestrial exoplanets introduce significantly smaller radial velocity signals and transit depths on their host stars. The signals are larger for terrestrial exoplanets orbiting M-dwarf stars, which have lower masses and radii than Sun-like F, G and K-type stars, and dominate stellar populations by number. Detecting exoplanets around M dwarfs is itself difficult because of their lower luminosities and lower flux at visible wavelengths, where most radial velocity and transit exoplanet surveys operate. I present here the motivation, development and results from a radial velocity program conducted on M dwarfs using near-infrared wavelengths, where M dwarf spectra peak in flux. To achieve high radial-velocity precision, I have used a technique called externally dispersed interferometry. It involves the combination of an interferometer and a moderate-resolution spectrograph on the 200 inch (5.1 m) Hale Telescope at Palomar Observatory. The TripleSpec Exoplanet Discovery Instrument, or TEDI, is the first such instrument to operate at nearinfrared wavelengths. Our results indicate that contamination by narrow absorption lines introduced by the Earth's atmosphere limit radial velocity performance to that which can detect gas giant planets. I have conducted a survey of nearby M dwarfs, and can rule out with 3σ confidence the presence of short-period gas giant planets in circular orbits around a few nearby M dwarfs. The results of this experiment direct future extrasolar planet instrumentation toward spectral regions with little telluric contamination and with higher resolution, to detect terrestrial exoplanets orbiting M dwarfs."
PHILIP MUIRHEAD,The TESS Input Catalog and Candidate Target List,"The Transiting Exoplanet Survey Satellite (TESS) will be conducting a nearly all-sky photometric survey over two years, with a core mission goal to discover small transiting exoplanets orbiting nearby bright stars. It will obtain 30 minute cadence observations of all objects in the TESS fields of view, along with two-minute cadence observations of 200,000–400,000 selected stars. The choice of which stars to observe at the two-minute cadence is driven by the need to detect small transiting planets, which leads to the selection of primarily bright, cool dwarfs. We describe the catalogs assembled and the algorithms used to populate the TESS Input Catalog (TIC), including plans to update the TIC with the incorporation of the Gaia second data release in the near future. We also describe a ranking system for prioritizing stars according to the smallest transiting planet detectable, and assemble a Candidate Target List (CTL) using that ranking. We discuss additional factors that affect the ability to photometrically detect and dynamically confirm small planets, and we note additional stellar populations of interest that may be added to the final target list. The TIC is available on the STScI MAST server, and an enhanced CTL is available through the Filtergraph data visualization portal system at the URL http://filtergraph.com/tess_ctl."
PHILIP MUIRHEAD,Portraying the hosts: Stellar science from planet searches,"We present a compendium of the splinter session on stellar science from planet searches that was organized as part of the Cool Stars 18 conference. Seven speakers discussed techniques to infer stellar information from radial velocity, transit and microlensing data, as well as new instrumentation and missions designed for planet searches that will provide useful for the study of the cool stars."
PHILIP MUIRHEAD,Shallow Ultraviolet Transits of WD 1145+017,"WD 1145+017 is a unique white dwarf system that has a heavily polluted atmosphere, an infrared excess from a dust disk, numerous broad absorption lines from circumstellar gas, and changing transit features, likely from fragments of an actively disintegrating asteroid. Here, we present results from a large photometric and spectroscopic campaign with Hubble Space Telescope, Keck, Very Large Telescope (VLT), Spitzer, and many other smaller telescopes from 2015 to 2018. Somewhat surprisingly the ultraviolet (UV) transit depths are always shallower than those in the optical. We develop a model that can quantitatively explain the observed ""bluing"" and confirm the previous finding that: (1) the transiting objects, circumstellar gas, and white dwarf are all aligned along our line of sight; (2) the transiting object is blocking a larger fraction of the circumstellar gas than of the white dwarf itself. Because most circumstellar lines are concentrated in the UV, the UV flux appears to be less blocked compared to the optical during a transit, leading to a shallower UV transit. This scenario is further supported by the strong anticorrelation between optical transit depth and circumstellar line strength. We have yet to detect any wavelength-dependent transits caused by the transiting material around WD 1145+017."
PHILIP MUIRHEAD,Confirmation of a dynamical model for the TRAPPIST-1 exoplanetary system,We present a new transit of TRAPPIST-1 d from 2021 August 25. The measured mid-point of this transit agrees with the prediction from a recently published dynamical model for the TRAPPIST-1 system and differs significantly from a naive prediction from a simple linear ephemeris. This difference underlines the importance for using dynamical models to predict future transit times in the TRAPPIST-1 system.
PHILIP MUIRHEAD,The Perkins INfrared Exosatellite Survey (PINES). II. transit candidates and implications for planet occurrence around L and T dwarfs,"We describe a new transit-detection algorithm designed to detect single-transit events in discontinuous Perkins INfrared Exosatellite Survey (PINES) observations of L and T dwarfs. We use this algorithm to search for transits in 131 PINES light curves and identify two transit candidates: 2MASS J18212815+1414010 (2MASS J1821+1414) and 2MASS J08350622+1953050 (2MASS J0835+1953). We disfavor 2MASS J1821+1414 as a genuine transit candidate due to the known variability properties of the source. We cannot rule out the planetary nature of 2MASS J0835+1953's candidate event and perform follow-up observations in an attempt to recover a second transit. A repeat event has yet to be observed, but these observations suggest that target variability is an unlikely cause of the candidate transit. We perform a Markov Chain Monte Carlo simulation of the light curve and estimate a planet radius ranging from <?CDATA ${4.2}_{-1.6}^{+3.5}{R}_{\oplus }$?> <mml:math xmlns:mml=""http://www.w3.org/1998/Math/MathML"" overflow=""scroll""> <mml:msubsup> <mml:mrow> <mml:mn>4.2</mml:mn> </mml:mrow> <mml:mrow> <mml:mo>−</mml:mo> <mml:mn>1.6</mml:mn> </mml:mrow> <mml:mrow> <mml:mo>+</mml:mo> <mml:mn>3.5</mml:mn> </mml:mrow> </mml:msubsup> <mml:msub> <mml:mrow> <mml:mi>R</mml:mi> </mml:mrow> <mml:mrow> <mml:mo>⊕</mml:mo> </mml:mrow> </mml:msub> </mml:math> to <?CDATA ${5.8}_{-2.1}^{+4.8}{R}_{\oplus }$?> <mml:math xmlns:mml=""http://www.w3.org/1998/Math/MathML"" overflow=""scroll""> <mml:msubsup> <mml:mrow> <mml:mn>5.8</mml:mn> </mml:mrow> <mml:mrow> <mml:mo>−</mml:mo> <mml:mn>2.1</mml:mn> </mml:mrow> <mml:mrow> <mml:mo>+</mml:mo> <mml:mn>4.8</mml:mn> </mml:mrow> </mml:msubsup> <mml:msub> <mml:mrow> <mml:mi>R</mml:mi> </mml:mrow> <mml:mrow> <mml:mo>⊕</mml:mo> </mml:mrow> </mml:msub> </mml:math> , depending on the host’s age. Finally, we perform an injection and recovery simulation on our light-curve sample. We inject planets into our data using measured M-dwarf planet occurrence rates and attempt to recover them using our transit-search algorithm. Our detection rates suggest that, assuming M-dwarf planet occurrence rates, we should have roughly a 1% chance of detecting a candidate that could cause the transit depth we observe for 2MASS J0835+1953. If 2MASS J0835+1953 b is confirmed, it would suggest an enhancement in the occurrence of short-period planets around L and T dwarfs in comparison to M dwarfs, which would challenge predictions from planet formation models."
PHILIP MUIRHEAD,Predicting the yield of small transiting exoplanets around mid-M and ultracool dwarfs in the Nancy Grace Roman Space Telescope Galactic Bulge Time Domain Survey,"We simulate the yield of small (0.5–4.0 R ⊕) transiting exoplanets around single mid-M and ultracool dwarfs (UCDs) in the Nancy Grace Roman Space Telescope Galactic Bulge Time Domain Survey. We consider multiple approaches for simulating M3–T9 sources within the survey fields, including scaling local space densities and using Galactic stellar population synthesis models. These approaches independently predict ∼100,000 single mid-M dwarfs and UCDs brighter than a Roman F146 magnitude of 21 that are within the survey fields. Assuming planet occurrence statistics previously measured for early-to-mid-M dwarfs, we predict that the survey will discover <?CDATA ${1347}_{-124}^{+208}$?> <mml:math xmlns:mml=""http://www.w3.org/1998/Math/MathML"" overflow=""scroll""> <mml:msubsup> <mml:mrow> <mml:mn>1347</mml:mn> </mml:mrow> <mml:mrow> <mml:mo>−</mml:mo> <mml:mn>124</mml:mn> </mml:mrow> <mml:mrow> <mml:mo>+</mml:mo> <mml:mn>208</mml:mn> </mml:mrow> </mml:msubsup> </mml:math> small transiting planets around these sources, each to a significance of 7.1σ or greater. Significant departures from this prediction would test whether the occurrence rates of small planets increase or decrease around mid-M dwarfs and UCDs compared to early-M dwarfs. We predict the detection of <?CDATA ${13}_{-3}^{+4}$?> <mml:math xmlns:mml=""http://www.w3.org/1998/Math/MathML"" overflow=""scroll""> <mml:msubsup> <mml:mrow> <mml:mn>13</mml:mn> </mml:mrow> <mml:mrow> <mml:mo>−</mml:mo> <mml:mn>3</mml:mn> </mml:mrow> <mml:mrow> <mml:mo>+</mml:mo> <mml:mn>4</mml:mn> </mml:mrow> </mml:msubsup> </mml:math> habitable, terrestrial planets (R p &lt; 1.23 R ⊕) in the survey. However, atmospheric characterization of these planets will be challenging with current or near-future space telescope facilities due to the faintness of the host stars. Nevertheless, accurate statistics for the occurrence of small planets around mid-M dwarfs and UCDs will enable direct tests of predictions from planet formation theories and will determine our understanding of planet demographics around the objects at the bottom of the main sequence. This understanding is critical given the prevalence of such objects in our galaxy, whose planets may therefore comprise the bulk of the galactic census of exoplanets."
PHILIP MUIRHEAD,"High-resolution broadband spectroscopy using externally dispersed interferometry at the Hale telescope: part 2, photon noise theory","High-resolution broadband spectroscopy at near-infrared (NIR) wavelengths (950 to 2450 nm) has been performed using externally dispersed interferometry (EDI) at the Hale telescope at Mt. Palomar, with the TEDI interferometer mounted within the central hole of the 200-in. primary mirror in series with the comounted TripleSpec NIR echelle spectrograph. These are the first multidelay EDI demonstrations on starlight. We demonstrated very high (10×) resolution boost and dramatic (20× or more) robustness to point spread function wavelength drifts in the native spectrograph. Data analysis, results, and instrument noise are described in a companion paper (part 1). This part 2 describes theoretical photon limited and readout noise limited behaviors, using simulated spectra and instrument model with noise added at the detector. We show that a single interferometer delay can be used to reduce the high frequency noise at the original resolution (1× boost case), and that except for delays much smaller than the native response peak half width, the fringing and nonfringing noises act uncorrelated and add in quadrature. This is due to the frequency shifting of the noise due to the heterodyning effect. We find a sum rule for the noise variance for multiple delays. The multiple delay EDI using a Gaussian distribution of exposure times has noise-to-signal ratio for photon-limited noise similar to a classical spectrograph with reduced slitwidth and reduced flux, proportional to the square root of resolution boost achieved, but without the focal spot limitation and pixel spacing Nyquist limitations. At low boost (∼1×) EDI has ∼1.4× smaller noise than conventional, and at >10× boost, EDI has ∼1.4× larger noise than conventional. Readout noise is minimized by the use of three or four steps instead of 10 of TEDI. Net noise grows as step phases change from symmetrical arrangement with wavenumber across the band. For three (or four) steps, we calculate a multiplicative bandwidth of 1.8:1 (2.3:1), sufficient to handle the visible band (400 to 700 nm, 1.8:1) and most of TripleSpec (2.6:1)."
PHILIP MUIRHEAD,Chemo-kinematic ages of eccentric-planet-hosting M dwarf stars,"The M dwarf stars are exciting targets for exoplanet investigations; however, their fundamental stellar properties are difficult to measure. Perhaps the most challenging property is stellar age. Once on the main sequence, M dwarfs change imperceptibly in their temperature and luminosity, necessitating novel statistical techniques for estimating their ages. In this paper, we infer ages for known eccentric-planet-hosting M dwarfs using a combination of kinematics and α-element enrichment, both shown to correlate with age for Sun-like FGK stars. We calibrate our method on FGK stars in a Bayesian context. To measure α-enrichment, we use publicly available spectra from the CARMENES exoplanet survey and a recently developed [Ti/Fe] calibration utilizing individual Ti i and Fe i absorption lines in the Y band. Tidal effects are expected to circularize the orbits of short-period planets on short timescales; however, we find a number of mildly eccentric, close-in planets orbiting old (~8 Gyr) stars. For these systems, we use our ages to constrain the tidal dissipation parameter of the planets, Q p. For two mini-Neptune planets, GJ 176 b and GJ 536 b, we find that they have Q p values more similar to the ice giants than to the terrestrial planets in our solar system. For GJ 436 b, we estimate an age of ${8.9}_{-2.1}^{+2.3}\,\mathrm{Gyr}$ and constrain the Q p to be >105, in good agreement with constraints from its inferred tidal heating. We find that GJ 876 d has likely undergone significant orbital evolution over its ${8.4}_{-2.0}^{+2.2}\,\mathrm{Gyr}$ lifetime, potentially influenced by its three outer companions that orbit in a Laplace resonance."
PHILIP MUIRHEAD,Dramatic robustness of a multiple delay dispersed interferometer to spectrograph errors: how mixing delays reduces or cancels wavelength drift,"We describe demonstrations of remarkable robustness to instrumental noises by using a multiple delay externally dispersed interferometer (EDI) on stellar observations at the Hale telescope. Previous observatory EDI demonstrations used a single delay. The EDI (also called “TEDI”) boosted the 2,700 resolution of the native TripleSpec NIR spectrograph (950-2450 nm) by as much as 10x to 27,000, using 7 overlapping delays up to 3 cm. We observed superb rejection of fixed pattern noises due to bad pixels, since the fringing signal responds only to changes in multiple exposures synchronous to the applied delay dithering. Remarkably, we observed a ~20x reduction of reaction in the output spectrum to PSF shifts of the native spectrograph along the dispersion direction, using our standard processing. This allowed high resolution observations under conditions of severe and irregular PSF drift otherwise not possible without the interferometer. Furthermore, we recently discovered an improved method of weighting and mixing data between pairs of delays that can theoretically further reduce the net reaction to PSF drift to zero. We demonstrate a 350x reduction in reaction to a native PSF shift using a simple simulation. This technique could similarly reduce radial velocity noise for future EDI’s that use two delays overlapped in delay space (or a single delay overlapping the native peak). Finally, we show an extremely high dynamic range EDI measurement of our ThAr lamp compared to a literature ThAr spectrum, observing weak features (~0.001x height of nearest strong line) that occur between the major lines. Because of individuality of each reference lamp, accurate knowledge of its spectrum between the (unfortunately) sparse major lines is important for precision radial velocimetry."
PHILIP MUIRHEAD,"A 2+1+1 quadruple star system containing the most eccentric, low-mass, short-period, eclipsing binary known","We present an analysis of a newly discovered 2+1+1 quadruple system with TESS containing an unresolved eclipsing binary (EB) as part of TIC 121088960 and a close neighbor TIC 121088959. The EB consists of two very low-mass M dwarfs in a highly-eccentric (e = 0.709) short-period (P = 3.04358 d) orbit. Given the large pixel size of TESS and the small separation (3${^{\prime\prime}_{.}}$9) between TIC 121088959 and TIC 121088960 we used light centroid analysis of the difference image between in-eclipse and out-of-eclipse data to show that the EB likely resides in TIC 121088960, but contributes only ∼10% of its light. Radial velocity data were acquired with iSHELL at NASA’s Infrared Facility and the Coudé spectrograph at the McDonald 2.7-m telescope. For both images, the measured RVs showed no variation over the 11-day observational baseline, and the RV difference between the two images was 8 ± 0.3 km s−1. The similar distances and proper motions of the two images indicate that TIC 121088959 and TIC 121088960 are a gravitationally bound pair. Gaia’s large RUWE and astrometric_excess_noise parameters for TIC 121088960, further indicate that this image is the likely host of the unresolved EB and is itself a triple star. We carried out an SED analysis and calculated stellar masses for the four stars, all of which are in the M dwarf regime: 0.19 M⊙ and 0.14 M⊙ for the EB stars and 0.43 M⊙ and 0.39 M⊙ for the brighter visible stars, respectively. Lastly, numerical simulations show that the orbital period of the inner triple is likely the range 1 to 50 years."
PHILIP MUIRHEAD,"Revised stellar parameters for V471 Tau, a post-common envelope binary in the Hyades","V471 Tau is a post-common-envelope binary consisting of an eclipsing DA white dwarf and a K-type main-sequence star in the Hyades star cluster. We analyzed publicly available photometry and spectroscopy of V471 Tau to revise the stellar and orbital parameters of the system. We used archival K2 photometry, archival Hubble Space Telescope spectroscopy, and published radial-velocity measurements of the K-type star. Employing Gaussian processes to fit for rotational modulation of the system flux by the main-sequence star, we recovered the transits of the white dwarf in front of the main-sequence star for the first time. The transits are shallower than would be expected from purely geometric occultations owing to gravitational microlensing during transit, which places an additional constraint on the white-dwarf mass. Our revised mass and radius for the main-sequence star is consistent with single-star evolutionary models given the age and metallicity of the Hyades. However, as noted previously in the literature, the white dwarf is too massive and too hot to be the result of single-star evolution given the age of the Hyades, and may be the product of a merger scenario. We independently estimate the conditions of the system at the time of common envelope that would result in the measured orbital parameters today."
PHILIP MUIRHEAD,Characterization of the atmosphere of the hot Jupiter HAT-P-32Ab and the M-dwarf companion HAT-P-32B,"We report secondary eclipse photometry of the hot Jupiter HAT-P-32Ab, taken with Hale/WIRC in H and KS bands and with Spitzer/IRAC at 3.6 and 4.5 μm. We carried out adaptive optics imaging of the planet host star HAT-P-32A and its companion HAT-P-32B in the near-IR and the visible. We clearly resolve the two stars from each other and find a separation of 2.′′923 ± 0.′′004 and a position angle 110.◦64 ± 0.◦12. We measure the flux ratios of the binary in g′r′i′z′ and H & KS bands, and determine Teff = 3565 ± 82 K for the companion star, corresponding to an M1.5 dwarf. We use PHOENIX stellar atmosphere models to correct the dilution of the secondary eclipse depths of the hot Jupiter due to the presence of the M1.5 companion. We also improve the secondary eclipse photometry by accounting for the non-classical, flux-dependent nonlinearity of the WIRC IR detector in the H band. We measure planet-to-star flux ratios of 0.090 ± 0.033%, 0.178 ± 0.057%, 0.364 ± 0.016%, and 0.438 ± 0.020% in the H, KS, 3.6 and 4.5 μm bands, respectively. We compare these with planetary atmospheric models, and find they prefer an atmosphere with a temperature inversion and inefficient heat redistribution. However, we also find that the data are equally well-described by a blackbody model for the planet with Tp = 2042 ± 50 K. Finally, we measure a secondary eclipse timing offset of 0.3 ± 1.3 min from the predicted mid-eclipse time, which constrains e = 0.0072+0.0700 −0.0064 when combined with RV data and is more consistent with a circular orbit."
PHILIP MUIRHEAD,Direct acceleration: cosmic and exoplanet synergies,"Direct measurement of acceleration is a key scientific goal for both cosmology and exoplanets. For cosmology, the concept of redshift drift (more than 60 years old by the 2020s) could directly establish the Friedmann-Lema{\^\i}tre-Robertson-Walker model. It would increase the dark energy figure of merit by a factor of 3 beyond Stage 4 experiments, in combination with cosmic microwave background measurements. For exoplanets, the same technology required provides unprecedented radial velocity accuracy, enabling detection of Earth mass planets in the habitable zone. Other science cases include mapping the Milky Way gravitational potential and testing its dark matter distribution."
PHILIP MUIRHEAD,Effective temperatures of low-mass stars from high-resolution H-band spectroscopy,"High-resolution, near-infrared spectra will be the primary tool for finding and characterizing Earth-like planets around low-mass stars. Yet, the properties of exoplanets cannot be precisely determined without accurate and precise measurements of the host star. Spectra obtained with the Immersion Grating Infrared Spectrometer simultaneously provide diagnostics for most stellar parameters, but the first step in any analysis is the determination of the effective temperature. Here we report the calibration of high-resolution H-band spectra to accurately determine the effective temperature for stars between 4000 and 3000 K (∼K8–M5) using absorption line-depths of Fe I, OH, and Al I. The field star sample used here contains 254 K and M stars with temperatures derived using BT-Settl synthetic spectra. We use 106 stars with precise temperatures in the literature to calibrate our method, with typical errors of about 140 K, and systematic uncertainties less than ∼120 K. For the broadest applicability, we present Teff–line-depth-ratio relationships, which we test on 12 members of the TW Hydrae Association and at spectral resolving powers between ∼10,000 and 120,000. These ratios offer a simple but accurate measure of effective temperatures in cool stars that are distance and reddening independent."
PHILIP MUIRHEAD,Magnetic inflation and stellar mass. III. revised parameters for the component stars of NSVS 07394765,"We perform a new analysis of the M-dwarf–M-dwarf eclipsing binary system NSVS 07394765 in order to investigate the reported hyper-inflated radius of one of the component stars. Our analysis is based on archival photometry from the Wide Angle Search for Planets, new photometry from the 32 cm Command Module Observatory telescope in Arizona and the 70 cm telescope at Thacher Observatory in California, and new high-resolution infrared spectra obtained with the Immersion Grating Infrared Spectrograph on the Discovery Channel Telescope. The masses and radii we measure for each component star disagree with previously reported measurements. We show that both stars are early M-type main-sequence stars without evidence for youth or hyper-inflation ( = - ☉ M M + 1 0.661 0.036 0.008 , = - ☉ M M + 2 0.608 0.028 0.003 , = - ☉ + R1 0.599 0.019 R 0.032 , = - ☉ + R2 0.625 0.027 R 0.012 ), and we update the orbital period and eclipse ephemerides for the system. We suggest that the likely cause of the initial hyper-inflated result is the use of moderate-resolution spectroscopy for precise radial velocity measurements."
PHILIP MUIRHEAD,A super-earth and sub-neptune transiting the late-type M Dwarf LP 791-18,"Planets occur most frequently around cool dwarfs, but only a handful of specific examples are known to orbit the latest-type M stars. Using TESS photometry, we report the discovery of two planets transiting the low-mass star called LP 791-18 (identified by TESS as TOI 736). This star has spectral type M6V, effective temperature 2960 K, and radius 0.17 R ⊙, making it the third-coolest star known to host planets. The two planets straddle the radius gap seen for smaller exoplanets; they include a 1.1R ⊕ planet on a 0.95 day orbit and a 2.3R ⊕ planet on a 5 day orbit. Because the host star is small the decrease in light during these planets' transits is fairly large (0.4% and 1.7%). This has allowed us to detect both planets' transits from ground-based photometry, refining their radii and orbital ephemerides. In the future, radial velocity observations and transmission spectroscopy can both probe these planets' bulk interior and atmospheric compositions, and additional photometric monitoring would be sensitive to even smaller transiting planets."
PHILIP MUIRHEAD,Upper limits on planet occurrence around ultracool dwarfs with K2,"The occurrence of planets orbiting ultracool dwarfs is poorly constrained. We present results from a guest observer program on NASA's K2 spacecraft to search for transiting planets orbiting a sample of 827 ultracool dwarfs. Having found no transiting planets in our sample, we determined an upper limit on the occurrence of planets. We simulated planets orbiting our sample for a range of orbital periods and sizes. For the simulated planets that transit their host, we injected the transit light curve into the real K2 light curves, then attempted to recover the injected planets. For a given occurrence rate, we calculated the probability of seeing no planets, and use the results to place an upper limit on planet occurrence as a function of planet radius and orbital period. We find that short-period, mini-Neptune- and Jupiter-sized planets are rare around ultracool dwarfs, consistent with results for early- and mid-type M dwarf stars. We constrain the occurrence rate η for planets between 0.5 and 10 R_⊕ with orbital periods between 1 and 26.3 days."
PHILIP MUIRHEAD,Magnetic inflation and stellar mass. V. Intensification and saturation of M-dwarf absorption lines with Rossby number,"In young Sun-like stars and field M-dwarf stars, chromospheric and coronal magnetic activity indicators such as Hα, X-ray, and radio emission are known to saturate with low Rossby number (Ro lesssim 0.1), defined as the ratio of rotation period to convective turnover time. The mechanism for the saturation is unclear. In this paper, we use photospheric Ti i and Ca i absorption lines in the Y band to investigate magnetic field strength in M dwarfs for Rossby numbers between 0.01 and 1.0. The equivalent widths of the lines are magnetically enhanced by photospheric spots, a global field, or a combination of the two. The equivalent widths behave qualitatively similar to the chromospheric and coronal indicators: we see increasing equivalent widths (increasing absorption) with decreasing Ro and saturation of the equivalent widths for Ro lesssim 0.1. The majority of M dwarfs in this study are fully convective. The results add to mounting evidence that the magnetic saturation mechanism occurs at or beneath the stellar photosphere."
PHILIP MUIRHEAD,An updated cool dwarf catalog for the transiting exoplanet survey satellite using Gaia DR2,"We present an updated catalog of cool dwarf stars for the recently launched Transiting Exoplanet Survey Satellite (TESS) for the purpose of selecting targets for two-minute cadence observations. At launch, TESS was provided a similar catalog of cool dwarfs whose stellar parameters were approximated using proper motions and — where they existed — archival parallax measurements. Most targets therefore have significant uncertainties. Now, with the highly anticipated Gaia DR2 parallax measurements released in April 2018, we updated stellar parameters where we are able to determine a cross-match with confidence, as well as determined new targets from a cross-match between Gaia and 2MASS. We anticipate delivery to TESS by the end of 2018, at which point it will have completed about one fourth of its mission. With the updated catalog, we hope that TESS will discover Earth-sized and sub-Earth-sized exoplanets around late K and M-dwarf type stars with a higher planet yield. This project was supported in part by the NSF REU grant AST-1757321 and by the Nantucket Maria Mitchell Association."
PHILIP MUIRHEAD,Design considerations for a ground-based search for transiting planets around L and T dwarfs,"We present design considerations for a ground-based survey for transiting exoplanets around L and T dwarfs, spectral classes that have yet to be thoroughly probed for planets. We simulate photometry for L and T targets with a variety of red-optical and near-infrared (NIR) detectors, and compare the scatter in the photometry to anticipated transit depths. Based on these results, we recommend the use of a low-dark-current detector with H-band NIR photometric capabilities. We then investigate the potential for performing a survey for Earth-sized planets for a variety of telescope sizes. We simulate planetary systems around a set of spectroscopically confirmed L and T dwarfs using measured M dwarf planet occurrence rates from Kepler (e.g. Dressing & Charbonneau 2015), and simulate their observation in surveys ranging in duration from 120 to 600 nights, randomly discarding 30% of nights to simulate weather losses. We find that an efficient survey design uses a 2-meter class telescope with a NIR instrument and 360─480 observing nights, observing multiple L and T targets each night with a dithering strategy. Surveys conducted in such a manner have over an 80% chance of detecting at least one planet, and detect around 2 planets, on average. The number of expected detections depends on the true planet occurrence rate, however, which may in fact be higher for L and T dwarfs than for M dwarfs. Poster at a 2-day meeting ""BROWN DWARF TO EXOPLANET CONNECTION III"" or BDEXOCON III"
PHILIP MUIRHEAD,Design considerations for a ground-based search for transiting planets around L and T dwarfs,"We present design considerations for a ground-based survey for transiting exoplanets around L and T dwarfs, spectral classes that have yet to be thoroughly probed for planets. We simulate photometry for L and T targets with a variety of red-optical and near-infrared (NIR) detectors, and compare the scatter in the photometry to anticipated transit depths. Based on these results, we recommend the use of a low-dark-current detector with H-band NIR photometric capabilities. We then investigate the potential for performing a survey for Earth-sized planets for a variety of telescope sizes. We simulate planetary systems around a set of spectroscopically confirmed L and T dwarfs using measured M dwarf planet occurrence rates from Kepler, and simulate their observation in surveys ranging in duration from 120 to 600 nights, randomly discarding 30% of nights to simulate weather losses. We find that an efficient survey design uses a 2 m class telescope with a NIR instrument and 360–480 observing nights, observing multiple L and T targets each night with a dithering strategy. Surveys conducted in such a manner have over an 80% chance of detecting at least one planet, and detect around 2 planets, on average. The number of expected detections depends on the true planet occurrence rate, however, which may in fact be higher for L and T dwarfs than for M dwarfs."
PHILIP MUIRHEAD,Searching for exosatellites orbiting L and T dwarfs: connecting planet formation to moon formation and finding new temperate worlds,"L-type and T-type dwarfs span the boundaries between main-sequence stars, brown dwarfs, and planetary-mass objects. For these reasons, L and T dwarfs are the perfect laboratories for exploring the relationship between planet formation and moon formation, and evidence suggests they may be swarming with close-in rocky satellites, though none have been found to date. The discovery of satellites orbiting L or T dwarfs will have transformative implications for the nature of planets, moons and even life in the Universe. These transiting satellites will be prime targets for characterization with NASA's James Webb Space Telescope. In this white paper, we discuss the scientific motivations behind searching for transiting satellites orbiting L and T dwarfs and argue that robotizing current 1-to-2-meter US optical/infrared (O/IR) facilities and equipping them with recently developed low-cost infrared imagers will enable these discoveries in the next decade. Furthermore, robotizing the 1-to-2-meter O/IR fleet is highly synergistic with rapid follow-up of transient and multi-messenger events."
PHILIP MUIRHEAD,The JWST weather report from the nearest brown dwarfs I: multiperiod JWST NIRSpec + MIRI monitoring of the benchmark binary brown dwarf WISE 1049AB,"We report results from 8 h of JWST/MIRI low resolution spectroscopic (LRS) monitoring directly followed by 7 h of JWST/NIRSpec prism spectroscopic monitoring of the benchmark binary brown dwarf WISE 1049AB, the closest, brightest brown dwarfs known. We find water, methane, and CO absorption features in both components, including the 3.3 μm methane absorption feature and a tentative detection of small grain (< 1μm) silicate absorption at >8.5 μm in WISE 1049A. Both components vary significantly (> 1per cent), with WISE 1049B displaying larger variations than WISE 1049A. Using K-means clustering, we find three main transition points in wavelength for both components of the binary: (1) change in behaviour at ∼2.3 μm coincident with a CO absorption bandhead, (2) change in behaviour at 4.2 μm, close to the CO fundamental band at λ >  4.4 µm, and (3) change in behaviour at 8.3–8.5 µm, potentially corresponding to silicate absorption. We interpret the light curves observed with both NIRSpec and MIRI as likely stemming from (1) a deep pressure level driving the double-peaked variability seen in WISE 1049B at wavelengths <2.3 and >8.5 µm, (2) an intermediate pressure level shaping the light-curve morphology between 2.3 and 4.2 µm, and (3) a higher altitude pressure level producing single-peaked and plateaued light-curve behaviour between 4.2 and 8.5 µm."
PHILIP MUIRHEAD,Tests of the planetary hypothesis for PTFO 8-8695b,"The T Tauri star PTFO 8-8695 exhibits periodic fading events that have been interpreted as the transits of a giant planet on a precessing orbit. Here we present three tests of the planet hypothesis. First, we sought evidence for the secular changes in light-curve morphology that are predicted to be a consequence of orbital precession. We observed 28 fading events spread over several years and did not see the expected changes. Instead, we found that the fading events are not strictly periodic. Second, we attempted to detect the planet's radiation, based on infrared observations spanning the predicted times of occultations. We ruled out a signal of the expected amplitude. Third, we attempted to detect the Rossiter–McLaughlin effect by performing high-resolution spectroscopy throughout a fading event. No effect was seen at the expected level, ruling out most (but not all) possible orientations for the hypothetical planetary orbit. Our spectroscopy also revealed strong, time-variable, high-velocity Hα and Ca H & K emission features. All these observations cast doubt on the planetary hypothesis, and suggest instead that the fading events represent starspots, eclipses by circumstellar dust, or occultations of an accretion hotspot."
PHILIP MUIRHEAD,GJ 1252 b: A 1.2 R ⊕ planet transiting an M3 dwarf at 20.4 pc,"We report the discovery of GJ 1252 b, a planet with a radius of 1.193 ± 0.074 R⊕ and an orbital period of 0.52 days around an M3-type star (0.381 ± 0.019 M⊙, 0.391 ± 0.020 R⊙) located 20.385 ± 0.019 pc away. We use TESS data, ground-based photometry and spectroscopy, Gaia astrometry, and high angular resolution imaging to show that the transit signal seen in the TESS data must originate from a transiting planet. We do so by ruling out all false positive scenarios that attempt to explain the transit signal as originating from an eclipsing stellar binary. Precise Doppler monitoring also leads to a tentative mass measurement of 2.09 ± 0.56 M⊕. The host star proximity, brightness (V = 12.19 mag, K = 7.92 mag), low stellar activity, and the system’s short orbital period make this planet an attractive target for detailed characterization, including precise mass measurement, looking for other objects in the system, and planet atmosphere characterization."
PHILIP MUIRHEAD,Multiple patchy cloud layers in the planetary-mass object SIMP 0136+0933,"Multiwavelength photometry of brown dwarfs and planetary-mass objects provides insight into their atmospheres and cloud layers. We present near-simultaneous J- and K_s -band multiwavelength observations of the highly variable T2.5 planetary-mass object, SIMP J013656.5+093347. We reanalyze observations acquired over a single night in 2015 using a recently developed data reduction pipeline. For the first time, we detect a phase shift between J- and K_s -band light curves, which we measure to be 39°.9_-1.1^+3.6. Previously, phase shifts between near-infrared and mid-infrared observations of this object were detected and attributed to probing different depths of the atmosphere, and thus different cloud layers. Using the Sonora Bobcat models, we expand on this idea to show that at least two different patchy cloud layers must be present to explain the measured phase shift. Our results are generally consistent with recent atmospheric retrievals of this object and other similar L/T transition objects."
PHILIP MUIRHEAD,"Three red suns in the sky: A transiting, terrestrial planet in a triple M-dwarf system at 6.9 pc","We present the discovery from Transiting Exoplanet Survey Satellite (TESS) data of LTT 1445Ab. At a distance of 6.9 pc, it is the second nearest transiting exoplanet system found to date, and the closest one known for which the primary is an M dwarf. The host stellar system consists of three mid-to-late M dwarfs in a hierarchical configuration, which are blended in one TESS pixel. We use MEarth data and results from the Science Processing Operations Center data validation report to determine that the planet transits the primary star in the system. The planet has a radius of ${1.38}_{-0.12}^{+0.13}$ ${R}_{\oplus }$, an orbital period of ${5.35882}_{-0.00031}^{+0.00030}$ days, and an equilibrium temperature of ${433}_{-27}^{+28}$ K. With radial velocities from the High Accuracy Radial Velocity Planet Searcher, we place a 3σ upper mass limit of 8.4 ${M}_{\oplus }$ on the planet. LTT 1445Ab provides one of the best opportunities to date for the spectroscopic study of the atmosphere of a terrestrial world. We also present a detailed characterization of the host stellar system. We use high-resolution spectroscopy and imaging to rule out the presence of any other close stellar or brown dwarf companions. Nineteen years of photometric monitoring of A and BC indicate a moderate amount of variability, in agreement with that observed in the TESS light-curve data. We derive a preliminary astrometric orbit for the BC pair that reveals an edge-on and eccentric configuration. The presence of a transiting planet in this system hints that the entire system may be co-planar, implying that the system may have formed from the early fragmentation of an individual protostellar core."
PHILIP MUIRHEAD,The effects of telluric contamination in iodine-calibrated precise radial velocities,"We characterized the effects of telluric absorption lines on the radial velocity (RV) precision of stellar spectra taken through an iodine cell. To isolate the effects induced by telluric contamination from other stellar, instrumental, or numerical systematic RV noise, we extracted RVs from simulated iodine-calibrated spectra of three RV standard stars regularly observed by Keck/HIRES. We add in water absorption lines according to measured precipitable water vapor (PWV) contents over a one-year period. We conclude that telluric contamination introduces additional RV noise and spurious periodic signals at the level of 10–20 cm s−1, consistent with similar previous studies. Our findings show that forward modeling the telluric lines effectively recovers the RV precision and accuracy, with no prior knowledge of the PWV needed. Such a recovery is less effective when the water absorption lines are relatively deep in the stellar template used in the forward modeling. Overall, telluric contamination plays an insignificant role in typical iodine-calibrated RV programs aiming at ~1–2 m s−1, but we recommend adding modeling of telluric lines and taking stellar template observations on nights with low humidity for programs aiming to achieve a precision of better than 1 m s–1."
PHILIP MUIRHEAD,Radial velocity prospects current and future: A white paper report prepared by the Study Analysis Group 8 for the Exoplanet Program Analysis Group (ExoPAG),"In this white paper report, we present an assessment of the current capabilities and the future potential of the precise radial velocity (PRV) method to advance the NASA goal to “search for planetary bodies and Earth-like planets in orbit around other stars.” (U.S. National Space Policy, June 28, 2010). PRVs complement other exoplanet detection methods, for example offering a direct path to obtaining the bulk density and thus the structure and composition of transiting exoplanets."
PHILIP MUIRHEAD,First radial velocity results from the MINiature Exoplanet Radial Velocity Array (MINERVA),"The MINiature Exoplanet Radial Velocity Array (MINERVA) is a dedicated observatory of four 0.7 m robotic telescopes fiber-fed to a KiwiSpec spectrograph. The MINERVA mission is to discover super-Earths in the habitable zones of nearby stars. This can be accomplished with MINERVA's unique combination of high precision and high cadence over long time periods. In this work, we detail changes to the MINERVA facility that have occurred since our previous paper. We then describe MINERVA's robotic control software, the process by which we perform 1D spectral extraction, and our forward modeling Doppler pipeline. In the process of improving our forward modeling procedure, we found that our spectrograph's intrinsic instrumental profile is stable for at least nine months. Because of that, we characterized our instrumental profile with a time-independent, cubic spline function based on the profile in the cross dispersion direction, with which we achieved a radial velocity precision similar to using a conventional ""sum-of-Gaussians"" instrumental profile: 1.8 m s−1 over 1.5 months on the RV standard star HD 122064. Therefore, we conclude that the instrumental profile need not be perfectly accurate as long as it is stable. In addition, we observed 51 Peg and our results are consistent with the literature, confirming our spectrograph and Doppler pipeline are producing accurate and precise radial velocities."
PHILIP MUIRHEAD,The CARMENES search for exoplanets around M dwarfs,"We report the discovery of a Neptune-like planet (LP 714-47 b, P = 4.05204 d, m_b = 30.8 ± 1.5M_⊕, R_b = 4.7 ± 0.3 R_⊕) located in the “hot Neptune desert”. Confirmation of the TESS Object of Interest (TOI 442.01) was achieved with radial-velocity follow-up using CARMENES, ESPRESSO, HIRES, iSHELL, and PFS, as well as from photometric data using TESS, Spitzer, and ground-based photometry from MuSCAT2, TRAPPIST-South, MONET-South, the George Mason University telescope, the Las Cumbres Observatory Global Telescope network, the El Sauce telescope, the TÜBİTAK National Observatory, the University of Louisville Manner Telescope, and WASP-South. We also present high-spatial resolution adaptive optics imaging with the Gemini Near-Infrared Imager. The low uncertainties in the mass and radius determination place LP 714-47 b among physically well-characterised planets, allowing for a meaningful comparison with planet structure models. The host star LP 714-47 is a slowly rotating early M dwarf (T_eff = 3950 ± 51 K) with a mass of 0.59 ± 0.02M_⊙ and a radius of 0.58 ± 0.02R_⊙. From long-term photometric monitoring and spectroscopic activity indicators, we determine a stellar rotation period of about 33 d. The stellar activity is also manifested as correlated noise in the radial-velocity data. In the power spectrum of the radial-velocity data, we detect a second signal with a period of 16 days in addition to the four-day signal of the planet. This could be shown to be a harmonic of the stellar rotation period or the signal of a second planet. It may be possible to tell the difference once more TESS data and radial-velocity data are obtained."
PHILIP MUIRHEAD,"The L 98-59 system: three transiting, terrestrial-size planets orbiting a nearby M dwarf","We report the Transiting Exoplanet Survey Satellite (TESS) discovery of three terrestrial-size planets transiting L 98-59 (TOI-175, TIC 307210830)—a bright M dwarf at a distance of 10.6 pc. Using the Gaia-measured distance and broadband photometry, we find that the host star is an M3 dwarf. Combined with the TESS transits from three sectors, the corresponding stellar parameters yield planet radii ranging from 0.8 R ⊕ to 1.6 R ⊕. All three planets have short orbital periods, ranging from 2.25 to 7.45 days with the outer pair just wide of a 2:1 period resonance. Diagnostic tests produced by the TESS Data Validation Report and the vetting package DAVE rule out common false-positive sources. These analyses, along with dedicated follow-up and the multiplicity of the system, lend confidence that the observed signals are caused by planets transiting L 98-59 and are not associated with other sources in the field. The L 98-59 system is interesting for a number of reasons: the host star is bright (V = 11.7 mag, K = 7.1 mag) and the planets are prime targets for further follow-up observations including precision radial-velocity mass measurements and future transit spectroscopy with the James Webb Space Telescope; the near-resonant configuration makes the system a laboratory to study planetary system dynamical evolution; and three planets of relatively similar size in the same system present an opportunity to study terrestrial planets where other variables (age, metallicity, etc.) can be held constant. L 98-59 will be observed in four more TESS sectors, which will provide a wealth of information on the three currently known planets and have the potential to reveal additional planets in the system."
PHILIP MUIRHEAD,"Friends of hot Jupiters. IV. Stellar companions beyond 50 au might facilitate giant planet formation, but most are unlikely to cause Kozai-Lidov migration","Stellar companions can influence the formation and evolution of planetary systems, but there are currently few observational constraints on the properties of planet-hosting binary star systems. We search for stellar companions around 77 transiting hot Jupiter systems to explore the statistical properties of this population of companions as compared to field stars of similar spectral type. After correcting for survey incompleteness, we find that $47 \% \pm 7 \% $ of hot Jupiter systems have stellar companions with semimajor axes between 50 and 2000 au. This is 2.9 times larger than the field star companion fraction in this separation range, with a significance of $4.4\sigma $. In the 1–50 au range, only ${3.9}_{-2.0}^{+4.5} \% $ of hot Jupiters host stellar companions, compared to the field star value of $16.4 \% \pm 0.7 \% $, which is a $2.7\sigma $ difference. We find that the distribution of mass ratios for stellar companions to hot Jupiter systems peaks at small values and therefore differs from that of field star binaries which tend to be uniformly distributed across all mass ratios. We conclude that either wide separation stellar binaries are more favorable sites for gas giant planet formation at all separations, or that the presence of stellar companions preferentially causes the inward migration of gas giant planets that formed farther out in the disk via dynamical processes such as Kozai–Lidov oscillations. We determine that less than 20% of hot Jupiters have stellar companions capable of inducing Kozai–Lidov oscillations assuming initial semimajor axes between 1 and 5 au, implying that the enhanced companion occurrence is likely correlated with environments where gas giants can form efficiently."
PHILIP MUIRHEAD,"Minerva-Australis. I. design, commissioning, and first photometric results","The Minerva-Australis telescope array is a facility dedicated to the follow-up, confirmation, characterization, and mass measurement of planets orbiting bright stars discovered by the Transiting Exoplanet Survey Satellite (TESS)—a category in which it is almost unique in the Southern Hemisphere. It is located at the University of Southern Queensland's Mount Kent Observatory near Toowoomba, Australia. Its flexible design enables multiple 0.7 m robotic telescopes to be used both in combination, and independently, for high-resolution spectroscopy and precision photometry of TESS transit planet candidates. Minerva-Australis also enables complementary studies of exoplanet spin–orbit alignments via Doppler observations of the Rossiter–McLaughlin effect, radial velocity searches for nontransiting planets, planet searches using transit timing variations, and ephemeris refinement for TESS planets. In this first paper, we describe the design, photometric instrumentation, software, and science goals of Minerva-Australis, and note key differences from its Northern Hemisphere counterpart, the Minerva array. We use recent transit observations of four planets, WASP-2b, WASP-44b, WASP-45b, and HD 189733b, to demonstrate the photometric capabilities of Minerva-Australis."
PHILIP MUIRHEAD,Kepler planet occurrence rates for mid-type M dwarfs as a function of spectral type,"Previous studies of planet occurrence rates largely relied on photometric stellar characterizations. In this paper, we present planet occurrence rates for mid-type M dwarfs using spectroscopy, parallaxes, and photometry to determine stellar characteristics. Our spectroscopic observations have allowed us to constrain spectral type, temperatures, and, in some cases, metallicities for 337 out of 561 probable mid-type M dwarfs in the primary Kepler field. We use a random forest classifier to assign a spectral type to the remaining 224 stars. Combining our data with Gaia parallaxes, we compute precise (~3%) stellar radii and masses, which we use to update planet parameters and occurrence rates for Kepler mid-type M dwarfs. Within the Kepler field, there are seven M3 V to M5 V stars that host 13 confirmed planets between 0.5 and 2.5 Earth radii and at orbital periods between 0.5 and 10 days. For this population, we compute a planet occurrence rate of ${1.19}_{-0.49}^{+0.70}$ planets per star. For M3 V, M4 V, and M5 V, we compute planet occurrence rates of ${0.86}_{-0.68}^{+1.32}$, ${1.36}_{-1.02}^{+2.30}$, and ${3.07}_{-2.49}^{+5.49}$ planets per star, respectively."
PHILIP MUIRHEAD,The first habitable-zone Earth-sized planet from TESS. II. Spitzer confirms TOI-700 d,"We present Spitzer 4.5 μm observations of the transit of TOI-700 d, a habitable-zone Earth-sized planet in a multiplanet system transiting a nearby M-dwarf star (TIC 150428135, 2MASS J06282325–6534456). TOI-700 d has a radius of 1.144_-0.061^+0.062R_⨁ and orbits within its host star's conservative habitable zone with a period of 37.42 days (T eq ~ 269 K). TOI-700 also hosts two small inner planets (R b = 1.037_-0.064^+0.065R_⨁ and R c = 2.65_-0.15^+0.16R_⨁) with periods of 9.98 and 16.05 days, respectively. Our Spitzer observations confirm the Transiting Exoplanet Survey Satellite (TESS) detection of TOI-700 d and remove any remaining doubt that it is a genuine planet. We analyze the Spitzer light curve combined with the 11 sectors of TESS observations and a transit of TOI-700 c from the LCOGT network to determine the full system parameters. Although studying the atmosphere of TOI-700 d is not likely feasible with upcoming facilities, it may be possible to measure the mass of TOI-700 d using state-of-the-art radial velocity (RV) instruments (expected RV semiamplitude of ~70 cm s^−1)."
PHILIP MUIRHEAD,The revised TESS Input Catalog and candidate target list,"We describe the catalogs assembled and the algorithms used to populate the revised TESS Input Catalog (TIC), based on the incorporation of the Gaia second data release. We also describe a revised ranking system for prioritizing stars for 2 minute cadence observations, and we assemble a revised Candidate Target List (CTL) using that ranking. The TIC is available on the Mikulski Archive for Space Telescopes server, and an enhanced CTL is available through the Filtergraph data visualization portal system at http://filtergraph.vanderbilt.edu/tess_ctl."
PHILIP MUIRHEAD,"Discovery of a hot, transiting, Earth-sized planet and a second temperate, non-transiting planet around the M4 dwarf GJ 3473 (TOI-488)","We present the confirmation and characterisation of GJ 3473 b (G 50–16, TOI-488.01), a hot Earth-sized planet orbiting an M4 dwarf star, whose transiting signal (P = 1.1980035 ± 0.0000018 d) was first detected by the Transiting Exoplanet Survey Satellite (TESS). Through a joint modelling of follow-up radial velocity observations with CARMENES, IRD, and HARPS together with extensive ground-based photometric follow-up observations with LCOGT, MuSCAT, and MuSCAT2, we determined a precise planetary mass, M_b = 1.86 ± 0.30 M_⨁, and radius, R_b = 1.264 ± 0.050 R_⊕. Additionally, we report the discovery of a second, temperate, non-transiting planet in the system, GJ 3473 c, which has a minimum mass, M_c sin i = 7.41 ± 0.91 M_⊕, and orbital period, P_c = 15.509 ± 0.033 d. The inner planet of the system, GJ 3473 b, is one of the hottest transiting Earth-sized planets known thus far, accompanied by a dynamical mass measurement, which makes it a particularly attractive target for thermal emission spectroscopy."
MARGARET LOMBE,"Self-efficacy, religiosity, and crime: profiles of African American youth in urban housing communities","Youth reporting independently elevated levels of religiosity and self-efficacy tend to abstain from externalizing behavior. However, little is known about the ways in which religiosity and self-efficacy interrelate to impact youth externalizing. Drawing from a sample of African American youth from public housing communities (N = 236), we use latent profile analysis to identify subtypes of youth based on self-reported religiosity and self-efficacy and, in turn, examine links with crime. Compared to youth in other subgroups, those classified as both highly religious and highly self-efficacious reported less involvement in minor and severe delinquency, but not violence."
JEFFREY W RUBIN,‘The whole process of gender’: a feminist culture of militancy in southern Brazil,"Women in the Movement of Rural Women Workers (Movimento de Mulheres Trabalhadoras Rurais or MMTR) in southern Brazil envisioned a social movement that represented their interests both as women and as small farmers and agricultural workers, while also allowing for a plurality of voices and strategies. This article describes the feminist and democratic culture of militancy that these women sought, from the 1980s through to the 2000s, and shows how difficult it was to establish and sustain such a culture. These women not only confronted the deep, ongoing difficulties of challenging gendered social relations, but also the pain, shame and silencing that intertwined with gains in voice and equality. They also confronted larger social movements whose leaders understood power differently to the way these women did. For the women described in this article, women’s activism requires a deep form of democracy where all voices are heard. Paradoxically, in the context of rural Rio Grande do Sul in southern Brazil and the panorama of movements that are active there, the rootedness in the everyday lived experience that made the movement relevant to women who advocated for this form of democracy also kept them from taking on powerholders within the movement who chose to ally with larger, more hierarchical movements, sacrificing significant forms of autonomy and voice in the process."
ASTRAEA AUGSBERGER,Factors influencing the underutilization of mental health services among Asian American women with a history of depression and suicide.,"BACKGROUND: Despite the substantially high prevalence of depression, suicidal ideation and suicide attempts among Asian American women who are children of immigrants, little is known about the prevalence of mental health utilization and the perceived barriers to accessing care. METHODS: The data were from the Asian American Women's Sexual Health Initiative Project (AWSHIP), a 5-year mixed methods study at Boston University. The quantitative analysis examined the differential proportion of mental health utilization among 701 survey participants based on their mental health risk profile determined by current moderate to severe depression symptoms and lifetime history of suicidality. Mental health risk groups were created based on participants' current depression symptoms and history of suicide behaviors: Group 1-low-risk; Group 2-medium-risk; Group 3-high-risk. Mental health care utilization outcomes were measured by any mental health care, minimally adequate mental health care, and intensive mental health care. The qualitative analysis explored the perceived barriers to mental health care among 17 participants from the medium and high-risk groups. RESULTS: Among 701 participants, 43% of women (n = 299) reported that they either suffered from current moderate to severe depression symptoms or a lifetime history of suicidal ideation or suicide attempt. Although the high-risk group demonstrated statistically significant higher mental health utilization compared to the low and medium-risk groups, more than 60% of the high-risk group did not access any mental health care, and more than 80% did not receive minimally adequate care. The qualitative analysis identified three underutilization factors: Asian family contributions to mental health stigma, Asian community contributions to mental health stigma, and a mismatch between cultural needs and available services. CONCLUSIONS: Despite the high prevalence of depression and suicidal behaviors among young Asian American women in the sample, the proportion of mental health care utilization was extremely low. The qualitative analysis underscores the influence of Asian family and community stigma on mental health utilization and the lack of culturally appropriate mental health interventions. Prevention and intervention efforts should focus on raising mental health awareness in the Asian American community and offering culturally sensitive services."
ASTRAEA AUGSBERGER,"Youth councils in municipal government: Examination of activities, impact and barriers","This study reports on youth councils in 24 municipalities in one major metropolitan area. Semi-structured interviews were conducted with one key adult stakeholder in each municipality in order to understand the scope, structure, functioning, activities, and impact of youth councils. These data were supplemented with review of documents and websites that described the councils. Findings indicated that youth councils were engaged in a wide-range of activities suggesting the model is fluid to meet the needs of both the youth and the community. Specific impacts were identified by participants some of which were directly related to the delivery of activities and others which influenced policy change. Among the barriers identified was the continuing need to identify a broader range of youth to participate in these initiatives. Despite a societal need for greater youth civic engagement and the generally positive attitude toward this idea, youth councils remain limited in practice and the research base is under-developed. Our study contributes to advancing both practice and research."
ASTRAEA AUGSBERGER,Youth Lead the Change: Participatory Budgeting,"The year 2015-2016 marks the third year of Youth Lead the Change: Participatory Budgeting Boston, a program that enables young people from across the city to suggest ideas for capital projects that will bring long-term physical improvements to city-owned property. This evaluation report examines the Youth Lead the Change process in its third year, drawing on qualitative and quantitative data from a variety of sources. The Boston University evaluation team reports their findings and summarizes the conclusions with recommendations to further develop this innovative effort to engage youth in city government."
ASTRAEA AUGSBERGER,Engaging youth in local government: Lessons from the Boston region.,"There is widespread consensus that young people have a right to be directly involved in decisions that affect them, and an understanding that adults are the ones who must create formal pathways of engagement. Yet there remains limited empirical information about the best ways to do so. This paper identifies key lessons gleaned from a multi-method study of twenty-four operating municipal youth councils throughout the greater Boston region. The insight assembled here is based on interviews with youth and adult stakeholders, observations of council meetings, a review of council documents, as well as a review of relevant academic literature. It is intended to guide practitioners in developing or reforming local youth councils."
ASTRAEA AUGSBERGER,Engaging Youth in Local Government: Lessons from the Boston Region,"There is widespread consensus that young people have a right to be directly involved in decisions that affect them, and an understanding that adults are the ones who must create formal pathways of engagement. Yet there remains limited empirical information about the best ways to do so. This paper identifies key lessons gleaned from a multi-method study of twenty-four operating municipal youth councils throughout the greater Boston region. The insight assembled here is based on interviews with youth and adult stakeholders, observations of council meetings, a review of council documents, as well as a review of relevant academic literature. It is intended to guide practitioners in developing or reforming local youth councils."
ASTRAEA AUGSBERGER,COVID-19 shines a light on health inequities in communities of color: a youth-driven photovoice inquiry,"This manuscript reports on a youth-driven health assessment engaging youth of color in identifying community health priorities during the coronavirus disease 2019 (COVID-19) pandemic. Photovoice, a participatory visual ethnographic health assessment strategy, was used to explore the question: What does health or healthiness mean to you and/or your community? Youth captured images that represented their priorities. The photos were discussed using the SHOWed framework and analyzed thematically. Four themes related to community health were identified. Additionally, youth captured their narrative of COVID-19 as ""a revealing force that highlights systemic inequities, driving individuals and communities to both cultivate their resilience and take healthcare into their own hands in response to government and policy level failures."" Youth are acutely aware of the historical and structural inequities that create multi-level barriers to healthcare access. Health inequities existed long before the pandemic, but the current crisis requires us to examine ways to transform the healthcare landscape moving forward."
ASTRAEA AUGSBERGER,Identifying the practice components of youth councils: contributions of theory,"Social workers are involved in numerous efforts to engage youth in programs, communities, and civic life. One potential strategy has focused on engagement and empowerment of youth through the form of youth councils. Multiple theoretical frames have characterized the scholarly literature. This has limited the conceptual coherence of the field. In this paper, we report empirical data on the operation of several youth councils. We analyze the data to identify the implicit frameworks in use and apply the data from our study to sort practice components within frameworks. This effort is designed to improve conceptualization of youth councils, to inform the development of councils, and eventually to improve outcomes of councils."
NATALIA RAMONDO,The life-cycle dynamics of exporters and multinational firms,"This paper studies the life-cycle dynamics of exporters and multinational enterprises (MNEs). Using rich firm-level data, we document a comprehensive set of facts on entry, exit, and growth of new exporters and new MNEs. Guided by these facts, we build a model based on the standard proximity-concentration trade-off extended to incorporate time-varying firm productivity and sunk costs of MNE entry. The calibrated version of the model goes far in matching cross-sectional and dynamic moments of the data on exporters and MNEs. Our results point to much higher sunk costs for MNE than for export activities. Finally, we show how including the choice to become an MNE affects the predicted export dynamics after a trade liberalization episode."
DAVID S WANG,Differential contributions of synaptic and intrinsic inhibitory currents to speech segmentation via flexible phase-locking in neural oscillators,"Current hypotheses suggest that speech segmentation-the initial division and grouping of the speech stream into candidate phrases, syllables, and phonemes for further linguistic processing-is executed by a hierarchy of oscillators in auditory cortex. Theta (∼3-12 Hz) rhythms play a key role by phase-locking to recurring acoustic features marking syllable boundaries. Reliable synchronization to quasi-rhythmic inputs, whose variable frequency can dip below cortical theta frequencies (down to ∼1 Hz), requires ""flexible"" theta oscillators whose underlying neuronal mechanisms remain unknown. Using biophysical computational models, we found that the flexibility of phase-locking in neural oscillators depended on the types of hyperpolarizing currents that paced them. Simulated cortical theta oscillators flexibly phase-locked to slow inputs when these inputs caused both (i) spiking and (ii) the subsequent buildup of outward current sufficient to delay further spiking until the next input. The greatest flexibility in phase-locking arose from a synergistic interaction between intrinsic currents that was not replicated by synaptic currents at similar timescales. Flexibility in phase-locking enabled improved entrainment to speech input, optimal at mid-vocalic channels, which in turn supported syllabic-timescale segmentation through identification of vocalic nuclei. Our results suggest that synaptic and intrinsic inhibition contribute to frequency-restricted and -flexible phase-locking in neural oscillators, respectively. Their differential deployment may enable neural oscillators to play diverse roles, from reliable internal clocking to adaptive segmentation of quasi-regular sensory inputs like speech."
DAVID S WANG,as-PSOCT: Volumetric microscopic imaging of human brain architecture and connectivity.,"Polarization sensitive optical coherence tomography (PSOCT) with serial sectioning has enabled the investigation of 3D structures in mouse and human brain tissue samples. By using intrinsic optical properties of back-scattering and birefringence, PSOCT reliably images cytoarchitecture, myeloarchitecture and fiber orientations. In this study, we developed a fully automatic serial sectioning polarization sensitive optical coherence tomography (as-PSOCT) system to enable volumetric reconstruction of human brain samples with unprecedented sample size and resolution. The 3.5 μm in-plane resolution and 50 μm through-plane voxel size allow inspection of cortical layers that are a single-cell in width, as well as small crossing fibers. We show the abilities of as-PSOCT in quantifying layer thicknesses of the cerebellar cortex and creating microscopic tractography of intricate fiber networks in the subcortical nuclei and internal capsule regions, all based on volumetric reconstructions. as-PSOCT provides a viable tool for studying quantitative cytoarchitecture and myeloarchitecture and mapping connectivity with microscopic resolution in the human brain."
DAVID S WANG,Active C4 electrodes for local field potential recording applications,"Extracellular neural recording, with multi-electrode arrays (MEAs), is a powerful method used to study neural function at the network level. However, in a high density array, it can be costly and time consuming to integrate the active circuit with the expensive electrodes. In this paper, we present a 4 mm × 4 mm neural recording integrated circuit (IC) chip, utilizing IBM C4 bumps as recording electrodes, which enable a seamless active chip and electrode integration. The IC chip was designed and fabricated in a 0.13 μm BiCMOS process for both in vitro and in vivo applications. It has an input-referred noise of 4.6 μV rms for the bandwidth of 10 Hz to 10 kHz and a power dissipation of 11.25 mW at 2.5 V, or 43.9 μW per input channel. This prototype is scalable for implementing larger number and higher density electrode arrays. To validate the functionality of the chip, electrical testing results and acute in vivo recordings from a rat barrel cortex are presented."
DAVID S WANG,Pericyte degeneration leads to neurovascular uncoupling and limits oxygen supply to brain,"Pericytes are perivascular mural cells of brain capillaries. They are positioned centrally in the neurovascular unit between endothelial cells, astrocytes and neurons. This position allows them to regulate key neurovascular functions of the brain. The role of pericytes in the regulation of cerebral blood flow (CBF) and neurovascular coupling remains, however, under debate. Using loss-of-function pericyte-deficient mice, here we show that pericyte degeneration diminishes global and individual capillary CBF responses to neuronal stimuli, resulting in neurovascular uncoupling, reduced oxygen supply to the brain and metabolic stress. Neurovascular deficits lead over time to impaired neuronal excitability and neurodegenerative changes. Thus, pericyte degeneration as seen in neurological disorders such as Alzheimer's disease may contribute to neurovascular dysfunction and neurodegeneration associated with human disease."
DAVID S WANG,Modifying Effects of the HFE Polymorphisms on the Association between Lead Burden and Cognitive Decline,"BACKGROUND. As iron and lead promote oxidative damage, and hemochromatosis (HFE) gene polymorphisms increase body iron burden, HFE variant alleles may modify the lead burden and cognitive decline relationship. OBJECTIVE. Our goal was to assess the modifying effects of HFE variants on the lead burden and cognitive decline relation in older adults. METHODS. We measured tibia and patella lead using K-X-ray fluorescence (1991-1999) among participants of the Normative Aging Study, a longitudinal study of community-dwelling men from greater Boston. We assessed cognitive function with the Mini-Mental State Examination (MMSE) twice (1993-1998 and 1995-2000) and genotyped participants for HFE polymorphisms. We estimated the adjusted mean differences in lead-associated annual cognitive decline across HFE genotype groups (n = 358). RESULTS. Higher tibia lead was associated with steeper cognitive decline among participants with at least one HFE variant allele compared with men with only wild-type alleles (p interaction = 0.03), such that a 15 μg/g increase in tibia lead was associated with a 0.2 point annual decrement in MMSE score among HFE variant allele carriers. This difference in scores among men with at least one variant allele was comparable to the difference in baseline MMSE scores that we observed among men who were 4 years apart in age. Moreover, the deleterious association between tibia lead and cognitive decline appeared progressively worse in participants with increasingly more copies of HFE variant alleles (p-trend = 0.008). Results for patella lead were similar. CONCLUSION. Our findings suggest that HFE polymorphisms greatly enhance susceptibility to lead-related cognitive impairment in a pattern consistent with allelelic dose."
DAVID S WANG,Noninvasive Assessment of Antenatal Hydronephrosis in Mice Reveals a Critical Role for Robo2 in Maintaining Anti-Reflux Mechanism,"Antenatal hydronephrosis and vesicoureteral reflux (VUR) are common renal tract birth defects. We recently showed that disruption of the Robo2 gene is associated with VUR in humans and antenatal hydronephrosis in knockout mice. However, the natural history, causal relationship and developmental origins of these clinical conditions remain largely unclear. Although the hydronephrosis phenotype in Robo2 knockout mice has been attributed to the coexistence of ureteral reflux and obstruction in the same mice, this hypothesis has not been tested experimentally. Here we used noninvasive high- resolution micro-ultrasonography and pathological analysis to follow the progression of antenatal hydronephrosis in individual Robo2-deficient mice from embryo to adulthood. We found that hydronephrosis progressed continuously after birth with no spontaneous resolution. With the use of a microbubble ultrasound contrast agent and ultrasound-guided percutaneous aspiration, we demonstrated that antenatal hydronephrosis in Robo2-deficient mice is caused by high-grade VUR resulting from a dilated and incompetent ureterovesical junction rather than ureteral obstruction. We further documented Robo2 expression around the developing ureterovesical junction and identified early dilatation of ureteral orifice structures as a potential fetal origin of antenatal hydronephrosis and VUR. Our results thus demonstrate that Robo2 is crucial for the formation of a normal ureteral orifice and for the maintenance of an effective anti-reflux mechanism. This study also establishes a reproducible genetic mouse model of progressive antenatal hydronephrosis and primary high- grade VUR."
DAVID S WANG,Inhibitory Effects of Robo2 on Nephrin: A Crosstalk between Positive and Negative Signals Regulating Podocyte Structure,"Robo2 is the cell surface receptor for the repulsive guidance cue Slit and is involved in axon guidance and neuronal migration. Nephrin is a podocyte slit- diaphragm protein that functions in the kidney glomerular filtration barrier. Here, we report that Robo2 is expressed at the basal surface of mouse podocytes and colocalizes with nephrin. Biochemical studies indicate that Robo2 forms a complex with nephrin in the kidney through adaptor protein Nck. In contrast to the role of nephrin that promotes actin polymerization, Slit2-Robo2 signaling inhibits nephrin-induced actin polymerization. In addition, the amount of F-actin associated with nephrin is increased in Robo2 knockout mice that develop an altered podocyte foot process structure. Genetic interaction study further reveals that loss of Robo2 alleviates the abnormal podocyte structural pheno- type in nephrin null mice. These results suggest that Robo2 signaling acts as a negative regulator on neph- rin to influence podocyte foot process architecture."
DAVID S WANG,Improving the characterization of ex vivo human brain optical properties using high numerical aperture optical coherence tomography by spatially constraining the confocal parameters,"SIGNIFICANCE: The optical properties of biological samples provide information about the structural characteristics of the tissue and any changes arising from pathological conditions. Optical coherence tomography (OCT) has proven to be capable of extracting tissue's optical properties using a model that combines the exponential decay due to tissue scattering and the axial point spread function that arises from the confocal nature of the detection system, particularly for higher numerical aperture (NA) measurements. A weakness in estimating the optical properties is the inter-parameter cross-talk between tissue scattering and the confocal parameters defined by the Rayleigh range and the focus depth. AIM: In this study, we develop a systematic method to improve the characterization of optical properties with high-NA OCT. APPROACH: We developed a method that spatially parameterizes the confocal parameters in a previously established model for estimating the optical properties from the depth profiles of high-NA OCT. RESULTS: The proposed parametrization model was first evaluated on a set of intralipid phantoms and then validated using a low-NA objective in which cross-talk from the confocal parameters is negligible. We then utilize our spatially parameterized model to characterize optical property changes introduced by a tissue index matching process using a simple immersion agent, 2,2'-thiodiethonal. CONCLUSIONS: Our approach improves the confidence of parameter estimation by reducing the degrees of freedom in the non-linear fitting model."
DAVID S WANG,Right hemisphere grey matter volume and language functions in stroke aphasia,"The role of the right hemisphere (RH) in recovery from aphasia is incompletely understood. The present study quantified RH grey matter (GM) volume in individuals with chronic stroke-induced aphasia and cognitively healthy people using voxel-based morphometry. We compared group differences in GM volume in the entire RH and in RH regions-of-interest. Given that lesion site is a critical source of heterogeneity associated with poststroke language ability, we used voxel-based lesion symptom mapping (VLSM) to examine the relation between lesion site and language performance in the aphasic participants. Finally, using results derived from the VLSM as a covariate, we evaluated the relation between GM volume in the RH and language ability across domains, including comprehension and production processes both at the word and sentence levels and across spoken and written modalities. Between-subject comparisons showed that GM volume in the RH SMA was reduced in the aphasic group compared to the healthy controls. We also found that, for the aphasic group, increased RH volume in the MTG and the SMA was associated with better language comprehension and production scores, respectively. These data suggest that the RH may support functions previously performed by LH regions and have important implications for understanding poststroke reorganization."
DAVID S WANG,Understanding the use of fauxtography on social media,"Despite the influence that image-based communication has on online discourse, the role played by images in disinformation is still not well understood. In this paper, we present the first large-scale study of fauxtography, analyzing the use of manipulated or misleading images in news discussion on online communities. First, we develop a computational pipeline geared to detect fauxtography, and identify over 61k instances of fauxtography discussed on Twitter, 4chan, and Reddit. Then, we study how posting fauxtography affects engagement of posts on social media, finding that posts containing it receive more interactions in the form of re-shares, likes, and comments. Finally, we show that fauxtography images are often turned into memes by Web communities. Our findings show that effective mitigation against disinformation need to take images into account, and highlight a number of challenges in dealing with image-based disinformation."
DAVID S WANG,Differential contributions of synaptic and intrinsic inhibitory currents to speech segmentation via flexible phase-locking in neural oscillators,"Current hypotheses suggest that speech segmentation – the initial division and grouping of the speech stream into candidate phrases, syllables, and phonemes for further linguistic processing – is executed by a hierarchy of oscillators in auditory cortex. Theta (~3-12 Hz) rhythms play a key role by phase-locking to recurring acoustic features marking syllable boundaries. Reliable synchronization to quasi-rhythmic inputs, whose variable frequency can dip below cortical theta frequencies (down to ~1 Hz), requires “flexible” theta oscillators whose underlying neuronal mechanisms remain unknown. Using biophysical computational models, we found that the flexibility of phase-locking in neural oscillators depended on the types of hyperpolarizing currents that paced them. Simulated cortical theta oscillators flexibly phase-locked to slow inputs when these inputs caused both (i) spiking and (ii) the subsequent buildup of outward current sufficient to delay further spiking until the next input. The greatest flexibility in phase-locking arose from a synergistic interaction between intrinsic currents that was not replicated by synaptic currents at similar timescales. Flexibility in phase-locking enabled improved entrainment to speech input, optimal at mid-vocalic channels, which in turn supported syllabic-timescale segmentation through identification of vocalic nuclei. Our results suggest that synaptic and intrinsic inhibition contribute to frequency-restricted and -flexible phase-locking in neural oscillators, respectively. Their differential deployment may enable neural oscillators to play diverse roles, from reliable internal clocking to adaptive segmentation of quasi-regular sensory inputs like speech. Author summary: Oscillatory activity in auditory cortex is believed to play an important role in auditory and speech processing. One suggested function of these rhythms is to divide the speech stream into candidate phonemes, syllables, words, and phrases, to be matched with learned linguistic templates. This requires brain rhythms to flexibly synchronize with regular acoustic features of the speech stream. How neuronal circuits implement this task remains unknown. In this study, we explored the contribution of inhibitory currents to flexible phase-locking in neuronal theta oscillators, believed to perform initial syllabic segmentation. We found that a combination of specific intrinsic inhibitory currents at multiple timescales, present in a large class of cortical neurons, enabled exceptionally flexible phase-locking, which could be used to precisely segment speech by identifying vowels at mid-syllable. This suggests that the cells exhibiting these currents are a key component in the brain’s auditory and speech processing architecture."
DAVID S WANG,Characterizing the optical properties of human brain tissue with high numerical aperture optical coherence tomography,"Quantification of tissue optical properties with optical coherence tomography (OCT) has proven to be useful in evaluating structural characteristics and pathological changes. Previous studies primarily used an exponential model to analyze low numerical aperture (NA) OCT measurements and obtain the total attenuation coefficient for biological tissue. In this study, we develop a systematic method that includes the confocal parameter for modeling the depth profiles of high NA OCT, when the confocal parameter cannot be ignored. This approach enables us to quantify tissue optical properties with higher lateral resolution. The model parameter predictions for the scattering coefficients were tested with calibrated microsphere phantoms. The application of the model to human brain tissue demonstrates that the scattering and back-scattering coefficients each provide unique information, allowing us to differentially identify laminar structures in primary visual cortex and distinguish various nuclei in the midbrain. The combination of the two optical properties greatly enhances the power of OCT to distinguish intricate structures in the human brain beyond what is achievable with measured OCT intensity information alone, and therefore has the potential to enable objective evaluation of normal brain structure as well as pathological conditions in brain diseases. These results represent a promising step for enabling the quantification of tissue optical properties from high NA OCT."
DAVID S WANG,Field Effect Transistor Nanosensor for Breast Cancer Diagnostics,"Silicon nanochannel field effect transistor (FET) biosensors are one of the most promising technologies in the development of highly sensitive and label-free analyte detection for cancer diagnostics. With their exceptional electrical properties and small dimensions, silicon nanochannels are ideally suited for extraordinarily high sensitivity. In fact, the high surface-to-volume ratios of these systems make single molecule detection possible. Further, FET biosensors offer the benefits of high speed, low cost, and high yield manufacturing, without sacrificing the sensitivity typical for traditional optical methods in diagnostics. Top down manufacturing methods leverage advantages in Complementary Metal Oxide Semiconductor (CMOS) technologies, making richly multiplexed sensor arrays a reality. Here, we discuss the fabrication and use of silicon nanochannel FET devices as biosensors for breast cancer diagnosis and monitoring."
DAVID S WANG,17th IEEE Real-Time Systems Symposium: Work in Progress Sessions,"Dear Colleagues: ￼￼￼￼This year marks the beginning of a new tradition within the Real-Time Systems Symposium, that of holding special sessions for the presentation of new and on-going projects in real-time systems. The prime purpose of these Work In Progress (WIP) sessions is to provide researchers in Academia and Industry an opportunity to discuss their evolving ideas and gather feedback thereon from the real-time community at large. The idea of holding these sessions is timely, and I am pleased to report that this year RTSS'96 WIP received 22 submissions, of which 14 have been accepted for presentation during the symposium and for inclusion in RTSS'96 WIP proceedings. Many people worked hard to make the idea of holding the WIP sessions a reality. In particular, I would like to thank Sang Son for his hard work in accommodating the WIP sessions within the busy schedule of RTSS'96. Also, I would like to thank all members of the RTSS'96 Program Committee, Al Mok and Doug Locke in particular, for their encouragement and constructive feedback regarding the organization of these sessions. Finally, I would like to thank all those who submitted their work to RTSS'96 WIP and those from RTSS'96 program committee who helped review these submissions. I hope these sessions will prove beneficial, both to the WIP presenters and to RTSS'96 attendees. Azer Bestavros RTSS'96 WIP Chair December 1996."
DAVID S WANG,A forward genetic screen identifies modifiers of rocaglate responsiveness,"Rocaglates are a class of eukaryotic translation initiation inhibitors that are being explored as chemotherapeutic agents. They function by targeting eukaryotic initiation factor (eIF) 4A, an RNA helicase critical for recruitment of the 40S ribosome (and associated factors) to mRNA templates. Rocaglates perturb eIF4A activity by imparting a gain-of-function activity to eIF4A and mediating clamping to RNA. To appreciate how rocaglates could best be enabled in the clinic, an understanding of resistance mechanisms is important, as this could inform on strategies to bypass such events as well as identify responsive tumor types. Here, we report on the results of a positive selection, ORFeome screen aimed at identifying cDNAs capable of conferring resistance to rocaglates. Two of the most potent modifiers of rocaglate response identified were the transcription factors FOXP3 and NR1I3, both of which have been implicated in ABCB1 regulation-the gene encoding P-glycoprotein (Pgp). Pgp has previously been implicated in conferring resistance to silvestrol, a naturally occurring rocaglate, and we show here that this extends to additional synthetic rocaglate derivatives. In addition, FOXP3 and NR1I3 impart a multi-drug resistant phenotype that is reversed upon inhibition of Pgp, suggesting a potential therapeutic combination strategy."
DAVID S WANG,EGenBio: A Data Management System for Evolutionary Genomics and Biodiversity,"BACKGROUND. Evolutionary genomics requires management and filtering of large numbers of diverse genomic sequences for accurate analysis and inference on evolutionary processes of genomic and functional change. We developed Evolutionary Genomics and Biodiversity (EGenBio; ) to begin to address this. DESCRIPTION. EGenBio is a system for manipulation and filtering of large numbers of sequences, integrating curated sequence alignments and phylogenetic trees, managing evolutionary analyses, and visualizing their output. EGenBio is organized into three conceptual divisions, Evolution, Genomics, and Biodiversity. The Genomics division includes tools for selecting pre-aligned sequences from different genes and species, and for modifying and filtering these alignments for further analysis. Species searches are handled through queries that can be modified based on a tree-based navigation system and saved. The Biodiversity division contains tools for analyzing individual sequences or sequence alignments, whereas the Evolution division contains tools involving phylogenetic trees. Alignments are annotated with analytical results and modification history using our PRAED format. A miscellaneous Tools section and Help framework are also available. EGenBio was developed around our comparative genomic research and a prototype database of mtDNA genomes. It utilizes MySQL-relational databases and dynamic page generation, and calls numerous custom programs. CONCLUSION. EGenBio was designed to serve as a platform for tools and resources to ease combined analysis in evolution, genomics, and biodiversity."
DAVID S WANG,Multiple Independent Loci at Chromosome 15q25.1 Affect Smoking Quantity: a Meta-Analysis and Comparison with Lung Cancer and COPD,"Recently, genetic association findings for nicotine dependence, smoking behavior, and smoking-related diseases converged to implicate the chromosome 15q25.1 region, which includes the CHRNA5-CHRNA3-CHRNB4 cholinergic nicotinic receptor subunit genes. In particular, association with the nonsynonymous CHRNA5 SNP rs16969968 and correlates has been replicated in several independent studies. Extensive genotyping of this region has suggested additional statistically distinct signals for nicotine dependence, tagged by rs578776 and rs588765. One goal of the Consortium for the Genetic Analysis of Smoking Phenotypes (CGASP) is to elucidate the associations among these markers and dichotomous smoking quantity (heavy versus light smoking), lung cancer, and chronic obstructive pulmonary disease (COPD). We performed a meta-analysis across 34 datasets of European-ancestry subjects, including 38,617 smokers who were assessed for cigarettes-per-day, 7,700 lung cancer cases and 5,914 lung-cancer-free controls (all smokers), and 2,614 COPD cases and 3,568 COPD-free controls (all smokers). We demonstrate statistically independent associations of rs16969968 and rs588765 with smoking (mutually adjusted p-values<10−35 and >10−8 respectively). Because the risk alleles at these loci are negatively correlated, their association with smoking is stronger in the joint model than when each SNP is analyzed alone. Rs578776 also demonstrates association with smoking after adjustment for rs16969968 (p<10−6). In models adjusting for cigarettes-per-day, we confirm the association between rs16969968 and lung cancer (p<10−20) and observe a nominally significant association with COPD (p = 0.01); the other loci are not significantly associated with either lung cancer or COPD after adjusting for rs16969968. This study provides strong evidence that multiple statistically distinct loci in this region affect smoking behavior. This study is also the first report of association between rs588765 (and correlates) and smoking that achieves genome-wide significance; these SNPs have previously been associated with mRNA levels of CHRNA5 in brain and lung tissue. Author Summary Nicotine binds to cholinergic nicotinic receptors, which are composed of a variety of subunits. Genetic studies for smoking behavior and smoking-related diseases have implicated a genomic region that encodes the alpha5, alpha3, and beta4 subunits. We examined genetic data across this region for over 38,000 smokers, a subset of which had been assessed for lung cancer or chronic obstructive pulmonary disease. We demonstrate strong evidence that there are at least two statistically independent loci in this region that affect risk for heavy smoking. One of these loci represents a change in the protein structure of the alpha5 subunit. This work is also the first to report strong evidence of association between smoking and a group of genetic variants that are of biological interest because of their links to expression of the alpha5 cholinergic nicotinic receptor subunit gene. These advances in understanding the genetic influences on smoking behavior are important because of the profound public health burdens caused by smoking and nicotine addiction."
DAVID S WANG,Cofilin Activation in Peripheral CD4 T Cells of HIV-1 Infected Patients: A Pilot Study,"Cofilin is an actin-depolymerizing factor that regulates actin dynamics critical for T cell migration and T cell activation. In unstimulated resting CD4 T cells, cofilin exists largely as a phosphorylated inactive form. Previously, we demonstrated that during HIV-1 infection of resting CD4 T cells, the viral envelope-CXCR4 signaling activates cofilin to overcome the static cortical actin restriction. In this pilot study, we have extended this in vitro observation and examined cofilin phosphorylation in resting CD4 T cells purified from the peripheral blood of HIV-1-infected patients. Here, we report that the resting T cells from infected patients carry significantly higher levels of active cofilin, suggesting that these resting cells have been primed in vivo in cofilin activity to facilitate HIV-1 infection. HIV-1-mediated aberrant activation of cofilin may also lead to abnormalities in T cell migration and activation that could contribute to viral pathogenesis."
DAVID S WANG,Melting the ICE: lessons from China and the West in the transition from the internal combustion engine to electric vehicles,"A decade after the launch of the contemporary global electric vehicle (EV) market, most cities face a major challenge preparing for rising EV demand. Some cities, and the leaders who shape them, are meeting and even leading demand for EV infrastructure. This book aggregates deep, groundbreaking research in the areas of urban EV deployment for city managers, private developers, urban planners, and utilities who want to understand and lead change."
DAVID S WANG,"Cosmology intertwined: a review of the particle physics, astrophysics, and cosmology associated with the cosmological tensions and anomalies",
DAVID S WANG,Insight into the fundamental trade-offs of diffusion MRI from polarization-sensitive optical coherence tomography in ex vivo human brain,"In the first study comparing high angular resolution diffusion MRI (dMRI) in the human brain to axonal orientation measurements from polarization-sensitive optical coherence tomography (PSOCT), we compare the accuracy of orientation estimates from various dMRI sampling schemes and reconstruction methods. We find that, if the reconstruction approach is chosen carefully, single-shell dMRI data can yield the same accuracy as multi-shell data, and only moderately lower accuracy than a full Cartesian-grid sampling scheme. Our results suggest that current dMRI reconstruction approaches do not benefit substantially from ultra-high b-values or from very large numbers of diffusion-encoding directions. We also show that accuracy remains stable across dMRI voxel sizes of 1 mm or smaller but degrades at 2 mm, particularly in areas of complex white-matter architecture. We also show that, as the spatial resolution is reduced, axonal configurations in a dMRI voxel can no longer be modeled as a small set of distinct axon populations, violating an assumption that is sometimes made by dMRI reconstruction techniques. Our findings have implications for in vivo studies and illustrate the value of PSOCT as a source of ground-truth measurements of white-matter organization that does not suffer from the distortions typical of histological techniques."
DAVID S WANG,"Research update: recent progress on 2D materials beyond graphene: from ripples, defects, intercalation, and valley dynamics to straintronics and power dissipation","The field of two-dimensional (2D) materials has witnessed several significant advancements in a short period of time. There have been extensive research efforts dedicated to this field and an expanding community of researchers built around the same. The focus of this review article is on the most recent milestones in several aspects of 2D materials with emphasis on transition metal dichalcogenides, such as improved synthesis and property engineering, approaching this from both experimental and theoretical viewpoints. There is also an attempt at highlighting some emerging material properties that are of interest and use of these 2D materials in several electronic applications."
DAVID S WANG,Broadband multi-wavelength properties of M87 during the 2017 Event Horizon Telescope campaign,"In 2017, the Event Horizon Telescope (EHT) Collaboration succeeded in capturing the first direct image of the center of the M87 galaxy. The asymmetric ring morphology and size are consistent with theoretical expectations for a weakly accreting supermassive black hole of mass ∼6.5 × 109 M ⊙. The EHTC also partnered with several international facilities in space and on the ground, to arrange an extensive, quasi-simultaneous multi-wavelength campaign. This Letter presents the results and analysis of this campaign, as well as the multi-wavelength data as a legacy data repository. We captured M87 in a historically low state, and the core flux dominates over HST-1 at high energies, making it possible to combine core flux constraints with the more spatially precise very long baseline interferometry data. We present the most complete simultaneous multi-wavelength spectrum of the active nucleus to date, and discuss the complexity and caveats of combining data from different spatial scales into one broadband spectrum. We apply two heuristic, isotropic leptonic single-zone models to provide insight into the basic source properties, but conclude that a structured jet is necessary to explain M87’s spectrum. We can exclude that the simultaneous γ-ray emission is produced via inverse Compton emission in the same region producing the EHT mm-band emission, and further conclude that the γ-rays can only be produced in the inner jets (inward of HST-1) if there are strongly particle-dominated regions. Direct synchrotron emission from accelerated protons and secondaries cannot yet be excluded."
DAVID S WANG,Celda: a Bayesian model to perform co-clustering of genes into modules and cells into subpopulations using single-cell RNA-seq data,"Single-cell RNA-seq (scRNA-seq) has emerged as a powerful technique to quantify gene expression in individual cells and to elucidate the molecular and cellular building blocks of complex tissues. We developed a novel Bayesian hierarchical model called Cellular Latent Dirichlet Allocation (Celda) to perform co-clustering of genes into transcriptional modules and cells into subpopulations. Celda can quantify the probabilistic contribution of each gene to each module, each module to each cell population and each cell population to each sample. In a peripheral blood mononuclear cell dataset, Celda identified a subpopulation of proliferating T cells and a plasma cell which were missed by two other common single-cell workflows. Celda also identified transcriptional modules that could be used to characterize unique and shared biological programs across cell types. Finally, Celda outperformed other approaches for clustering genes into modules on simulated data. Celda presents a novel method for characterizing transcriptional programs and cellular heterogeneity in scRNA-seq data."
DAVID S WANG,"Comprehensive generation, visualization, and reporting of quality control metrics for single-cell RNA sequencing data","Single-cell RNA sequencing (scRNA-seq) can be used to gain insights into cellular heterogeneity within complex tissues. However, various technical artifacts can be present in scRNA-seq data and should be assessed before performing downstream analyses. While several tools have been developed to perform individual quality control (QC) tasks, they are scattered in different packages across several programming environments. Here, to streamline the process of generating and visualizing QC metrics for scRNA-seq data, we built the SCTK-QC pipeline within the singleCellTK R package. The SCTK-QC workflow can import data from several single-cell platforms and preprocessing tools and includes steps for empty droplet detection, generation of standard QC metrics, prediction of doublets, and estimation of ambient RNA. It can run on the command line, within the R console, on the cloud platform or with an interactive graphical user interface. Overall, the SCTK-QC pipeline streamlines and standardizes the process of performing QC for scRNA-seq data."
DAVID S WANG,Decontamination of ambient RNA in single-cell RNA-seq with DecontX,"Droplet-based microfluidic devices have become widely used to perform single-cell RNA sequencing (scRNA-seq). However, ambient RNA present in the cell suspension can be aberrantly counted along with a cell's native mRNA and result in cross-contamination of transcripts between different cell populations. DecontX is a novel Bayesian method to estimate and remove contamination in individual cells. DecontX accurately predicts contamination levels in a mouse-human mixture dataset and removes aberrant expression of marker genes in PBMC datasets. We also compare the contamination levels between four different scRNA-seq protocols. Overall, DecontX can be incorporated into scRNA-seq workflows to improve downstream analyses."
DAVID S WANG,On the need for International Solar Terrestrial Program Next (ISTPNext),
DAVID S WANG,(Re)Framing resilience: a trajectory-based study involving emerging religious/spiritual leaders,"The COVID-19 pandemic has provided a unique circumstance for the study of resilience, and clergy resilience has garnered increased research attention due to greater recognition that religious/spiritual leaders are at risk for elevated levels of anxiety and burnout. We examined longitudinal patterns of change during the pandemic in a sample of emerging leaders (N = 751; Mage = 32.82; SD 11.37; 49.9% female; 59.8% White). In doing so, we offered a conceptual and methodological approach based on historical and critical evaluations of the study of resilience. Results revealed a subgroup that exhibited resilience over three waves of data. The labeling of this trajectory was based on established criteria for determining resilience: (a) significant adversity in the form of COVID-19 stress at time 1, which included the highest levels of the subjective appraisal of stress; (b) risk in the form of low religiousness/spirituality and greater likelihood of reporting marginalized identifications, relative to those who were flourishing; (c) a protective influence for transformative experiences to promote positive adaptation; and (d) interruption to the trajectory in the form of improvement in levels of symptoms and well-being. Practical implications center on the potential for transformative experiences to clarify emotional experience and construct new meaning."
DAVID S WANG,Treating depressive disorders with the unified protocol: a preliminary randomized evaluation,"OBJECTIVES: This study aims to examine the efficacy of the Unified Protocol for Transdiagnostic Treatment of Emotional Disorders (UP) for individuals diagnosed with a depressive disorder. METHOD: Participants included 44 adults who met criteria for major depressive disorder, persistent depressive disorder, or another specified depressive disorder according to the Anxiety Disorder Interview Schedule (ADIS). These individuals represent a subset of patients from a larger clinical trial comparing the UP to single-disorder protocols (SDPs) for discrete anxiety disorders and a waitlist control (WLC) condition (Barlow et al., 2017); inclusion criteria for the parent study required participants to have a principal anxiety disorder. RESULTS: Significant reductions in depressive symptoms were observed within the UP condition across clinician-rated and self-report measures of depression from baseline to post-treatment, as well as to the 12-month follow-up assessment. Compared to the WLC group, individuals in the UP condition demonstrated significantly lower levels on our continuous, clinician-rated measure of depressive symptoms at post-treatment. There were no differences between the UP and SDP conditions on depressive symptoms at post-treatment or at the 12-month follow-up timepoint. CONCLUSIONS: In this exploratory set of analyses, the UP evidenced efficacy for reduction of depressive symptoms, adding to the growing support for its utility in treating depression."
DAVID S WANG,First radial velocity results from the MINiature Exoplanet Radial Velocity Array (MINERVA),"The MINiature Exoplanet Radial Velocity Array (MINERVA) is a dedicated observatory of four 0.7 m robotic telescopes fiber-fed to a KiwiSpec spectrograph. The MINERVA mission is to discover super-Earths in the habitable zones of nearby stars. This can be accomplished with MINERVA's unique combination of high precision and high cadence over long time periods. In this work, we detail changes to the MINERVA facility that have occurred since our previous paper. We then describe MINERVA's robotic control software, the process by which we perform 1D spectral extraction, and our forward modeling Doppler pipeline. In the process of improving our forward modeling procedure, we found that our spectrograph's intrinsic instrumental profile is stable for at least nine months. Because of that, we characterized our instrumental profile with a time-independent, cubic spline function based on the profile in the cross dispersion direction, with which we achieved a radial velocity precision similar to using a conventional ""sum-of-Gaussians"" instrumental profile: 1.8 m s−1 over 1.5 months on the RV standard star HD 122064. Therefore, we conclude that the instrumental profile need not be perfectly accurate as long as it is stable. In addition, we observed 51 Peg and our results are consistent with the literature, confirming our spectrograph and Doppler pipeline are producing accurate and precise radial velocities."
DAVID S WANG,The CARMENES search for exoplanets around M dwarfs,"We report the discovery of a Neptune-like planet (LP 714-47 b, P = 4.05204 d, m_b = 30.8 ± 1.5M_⊕, R_b = 4.7 ± 0.3 R_⊕) located in the “hot Neptune desert”. Confirmation of the TESS Object of Interest (TOI 442.01) was achieved with radial-velocity follow-up using CARMENES, ESPRESSO, HIRES, iSHELL, and PFS, as well as from photometric data using TESS, Spitzer, and ground-based photometry from MuSCAT2, TRAPPIST-South, MONET-South, the George Mason University telescope, the Las Cumbres Observatory Global Telescope network, the El Sauce telescope, the TÜBİTAK National Observatory, the University of Louisville Manner Telescope, and WASP-South. We also present high-spatial resolution adaptive optics imaging with the Gemini Near-Infrared Imager. The low uncertainties in the mass and radius determination place LP 714-47 b among physically well-characterised planets, allowing for a meaningful comparison with planet structure models. The host star LP 714-47 is a slowly rotating early M dwarf (T_eff = 3950 ± 51 K) with a mass of 0.59 ± 0.02M_⊙ and a radius of 0.58 ± 0.02R_⊙. From long-term photometric monitoring and spectroscopic activity indicators, we determine a stellar rotation period of about 33 d. The stellar activity is also manifested as correlated noise in the radial-velocity data. In the power spectrum of the radial-velocity data, we detect a second signal with a period of 16 days in addition to the four-day signal of the planet. This could be shown to be a harmonic of the stellar rotation period or the signal of a second planet. It may be possible to tell the difference once more TESS data and radial-velocity data are obtained."
DAVID S WANG,Scintillation light detection in the 6-m drift-length ProtoDUNE Dual Phase liquid argon TPC,"DUNE is a dual-site experiment for long-baseline neutrino oscillation studies, neutrino astrophysics and nucleon decay searches. ProtoDUNE Dual Phase (DP) is a 6  ×  6  ×  6 m 3 liquid argon time-projection-chamber (LArTPC) that recorded cosmic-muon data at the CERN Neutrino Platform in 2019-2020 as a prototype of the DUNE Far Detector. Charged particles propagating through the LArTPC produce ionization and scintillation light. The scintillation light signal in these detectors can provide the trigger for non-beam events. In addition, it adds precise timing capabilities and improves the calorimetry measurements. In ProtoDUNE-DP, scintillation and electroluminescence light produced by cosmic muons in the LArTPC is collected by photomultiplier tubes placed up to 7 m away from the ionizing track. In this paper, the ProtoDUNE-DP photon detection system performance is evaluated with a particular focus on the different wavelength shifters, such as PEN and TPB, and the use of Xe-doped LAr, considering its future use in giant LArTPCs. The scintillation light production and propagation processes are analyzed and a comparison of simulation to data is performed, improving understanding of the liquid argon properties."
DAVID S WANG,Prospects for beyond the standard model physics searches at the deep underground neutrino experiment: DUNE collaboration,"The Deep Underground Neutrino Experiment (DUNE) will be a powerful tool for a variety of physics topics. The high-intensity proton beams provide a large neutrino flux, sampled by a near detector system consisting of a combination of capable precision detectors, and by the massive far detector system located deep underground. This configuration sets up DUNE as a machine for discovery, as it enables opportunities not only to perform precision neutrino measurements that may uncover deviations from the present three-flavor mixing paradigm, but also to discover new particles and unveil new interactions and symmetries beyond those predicted in the Standard Model (SM). Of the many potential beyond the Standard Model (BSM) topics DUNE will probe, this paper presents a selection of studies quantifying DUNE's sensitivities to sterile neutrino mixing, heavy neutral leptons, non-standard interactions, CPT symmetry violation, Lorentz invariance violation, neutrino trident production, dark matter from both beam induced and cosmogenic sources, baryon number violation, and other new physics topics that complement those at high-energy colliders and significantly extend the present reach."
DAVID S WANG,Identification and reconstruction of low-energy electrons in the ProtoDUNE-SP detector,
DAVID S WANG,The long-baseline neutrino experiment: exploring fundamental symmetries of the universe,"The preponderance of matter over antimatter in the early Universe, the dynamics of the supernova bursts that produced the heavy elements necessary for life and whether protons eventually decay --- these mysteries at the forefront of particle physics and astrophysics are key to understanding the early evolution of our Universe, its current state and its eventual fate. The Long-Baseline Neutrino Experiment (LBNE) represents an extensively developed plan for a world-class experiment dedicated to addressing these questions. LBNE is conceived around three central components: (1) a new, high-intensity neutrino source generated from a megawatt-class proton accelerator at Fermi National Accelerator Laboratory, (2) a near neutrino detector just downstream of the source, and (3) a massive liquid argon time-projection chamber deployed as a far detector deep underground at the Sanford Underground Research Facility. This facility, located at the site of the former Homestake Mine in Lead, South Dakota, is approximately 1,300 km from the neutrino source at Fermilab -- a distance (baseline) that delivers optimal sensitivity to neutrino charge-parity symmetry violation and mass ordering effects. This ambitious yet cost-effective design incorporates scalability and flexibility and can accommodate a variety of upgrades and contributions. With its exceptional combination of experimental configuration, technical capabilities, and potential for transformative discoveries, LBNE promises to be a vital facility for the field of particle physics worldwide, providing physicists from around the globe with opportunities to collaborate in a twenty to thirty year program of exciting science. In this document we provide a comprehensive overview of LBNE's scientific objectives, its place in the landscape of neutrino physics worldwide, the technologies it will incorporate and the capabilities it will possess."
ANA MARIA REYES,The monument to the children of Villatina: commemorating innocent child victims in the context of lethally stigmatized youth in Colombia,"This article examines the monument for the children of Villatina (2004, Medellín, Colombia) that resulted from the Masacre Villatina v. Colombia Friendly Agreement put forward by the Grupo Interdisciplinario de Derechos Humanos (GIDH) to the Inter-American Commission on Human Rights (IACHR). In 1992, the Colombian police murdered eight youths ranging in age from 8 to 22 years in the Villatina neighborhood of Medellín. After long and difficult negotiations, the GIDH and IACHR brokered a Friendly Agreement (2002) between the victims’ families and the government of Colombia. As a part of the reparations program, the Colombian State committed to install- ing a commemorative monument in a public park in downtown Medellín. While the monument was designed to recognize the dignity and honor of the youthful victims, the author argues that its emphasis on innocence tacitly endorsed the extermination of non-innocent children and young men caught in the vortex of war. Following Judith Butler’s arguments regarding ‘griev- able’ lives in Frames of War: When Is Life Grievable? (2004) and the condi- tion of the human, the author contends that both the process of the Friendly Agreement negotiations and the resulting monument rehearse a hierarchy of humanity that casts some lives, but not all, as grievable."
THOR STEIN,Clinicopathological evaluation of chronic traumatic encephalopathy in players of American football,"IMPORTANCE: Players of American football may be at increased risk of long-term neurological conditions, particularly chronic traumatic encephalopathy (CTE). OBJECTIVE: To determine the neuropathological and clinical features of deceased football players with CTE. DESIGN, SETTING, AND PARTICIPANTS: Case series of 202 football players whose brains were donated for research. Neuropathological evaluations and retrospective telephone clinical assessments (including head trauma history) with informants were performed blinded. Online questionnaires ascertained athletic and military history. EXPOSURES: Participation in American football at any level of play. MAIN OUTCOMES AND MEASURES: Neuropathological diagnoses of neurodegenerative diseases, including CTE, based on defined diagnostic criteria; CTE neuropathological severity (stages I to IV or dichotomized into mild [stages I and II] and severe [stages III and IV]); informant-reported athletic history and, for players who died in 2014 or later, clinical presentation, including behavior, mood, and cognitive symptoms and dementia. RESULTS: Among 202 deceased former football players (median age at death, 66 years [interquartile range, 47-76 years]), CTE was neuropathologically diagnosed in 177 players (87%; median age at death, 67 years [interquartile range, 52-77 years]; mean years of football participation, 15.1 [SD, 5.2]), including 0 of 2 pre–high school, 3 of 14 high school (21%), 48 of 53 college (91%), 9 of 14 semiprofessional (64%), 7 of 8 Canadian Football League (88%), and 110 of 111 National Football League (99%) players. Neuropathological severity of CTE was distributed across the highest level of play, with all 3 former high school players having mild pathology and the majority of former college (27 [56%]), semiprofessional (5 [56%]), and professional (101 [86%]) players having severe pathology. Among 27 participants with mild CTE pathology, 26 (96%) had behavioral or mood symptoms or both, 23 (85%) had cognitive symptoms, and 9 (33%) had signs of dementia. Among 84 participants with severe CTE pathology, 75 (89%) had behavioral or mood symptoms or both, 80 (95%) had cognitive symptoms, and 71 (85%) had signs of dementia. CONCLUSIONS AND RELEVANCE: In a convenience sample of deceased football players who donated their brains for research, a high proportion had neuropathological evidence of CTE, suggesting that CTE may be related to prior participation in football."
THOR STEIN,Bulk brain tissue cell-type deconvolution with bias correction for single-nuclei RNA sequencing data using DeTREM,"BACKGROUND: Quantifying cell-type abundance in bulk tissue RNA-sequencing enables researchers to better understand complex systems. Newer deconvolution methodologies, such as MuSiC, use cell-type signatures derived from single-cell RNA-sequencing (scRNA-seq) data to make these calculations. Single-nuclei RNA-sequencing (snRNA-seq) reference data can be used instead of scRNA-seq data for tissues such as human brain where single-cell data are difficult to obtain, but accuracy suffers due to sequencing differences between the technologies. RESULTS: We propose a modification to MuSiC entitled 'DeTREM' which compensates for sequencing differences between the cell-type signature and bulk RNA-seq datasets in order to better predict cell-type fractions. We show DeTREM to be more accurate than MuSiC in simulated and real human brain bulk RNA-sequencing datasets with various cell-type abundance estimates. We also compare DeTREM to SCDC and CIBERSORTx, two recent deconvolution methods that use scRNA-seq cell-type signatures. We find that they perform well in simulated data but produce less accurate results than DeTREM when used to deconvolute human brain data. CONCLUSION: DeTREM improves the deconvolution accuracy of MuSiC and outperforms other deconvolution methods when applied to snRNA-seq data. DeTREM enables accurate cell-type deconvolution in situations where scRNA-seq data are not available. This modification improves characterization cell-type specific effects in brain tissue and identification of cell-type abundance differences under various conditions."
THOR STEIN,"Concussion, microvascular injury, and early tauopathy in young athletes after impact head injury and an impact concussion mouse model","The mechanisms underpinning concussion, traumatic brain injury, and chronic traumatic encephalopathy, and the relationships between these disorders, are poorly understood. We examined post-mortem brains from teenage athletes in the acute-subacute period after mild closed-head impact injury and found astrocytosis, myelinated axonopathy, microvascular injury, perivascular neuroinflammation, and phosphorylated tau protein pathology. To investigate causal mechanisms, we developed a mouse model of lateral closed-head impact injury that uses momentum transfer to induce traumatic head acceleration. Unanaesthetized mice subjected to unilateral impact exhibited abrupt onset, transient course, and rapid resolution of a concussion-like syndrome characterized by altered arousal, contralateral hemiparesis, truncal ataxia, locomotor and balance impairments, and neurobehavioural deficits. Experimental impact injury was associated with axonopathy, blood–brain barrier disruption, astrocytosis, microgliosis (with activation of triggering receptor expressed on myeloid cells, TREM2), monocyte infiltration, and phosphorylated tauopathy in cerebral cortex ipsilateral and subjacent to impact. Phosphorylated tauopathy was detected in ipsilateral axons by 24 h, bilateral axons and soma by 2 weeks, and distant cortex bilaterally at 5.5 months post-injury. Impact pathologies co-localized with serum albumin extravasation in the brain that was diagnostically detectable in living mice by dynamic contrast-enhanced MRI. These pathologies were also accompanied by early, persistent, and bilateral impairment in axonal conduction velocity in the hippocampus and defective long-term potentiation of synaptic neurotransmission in the medial prefrontal cortex, brain regions distant from acute brain injury. Surprisingly, acute neurobehavioural deficits at the time of injury did not correlate with blood–brain barrier disruption, microgliosis, neuroinflammation, phosphorylated tauopathy, or electrophysiological dysfunction. Furthermore, concussion-like deficits were observed after impact injury, but not after blast exposure under experimental conditions matched for head kinematics. Computational modelling showed that impact injury generated focal point loading on the head and seven-fold greater peak shear stress in the brain compared to blast exposure. Moreover, intracerebral shear stress peaked before onset of gross head motion. By comparison, blast induced distributed force loading on the head and diffuse, lower magnitude shear stress in the brain. We conclude that force loading mechanics at the time of injury shape acute neurobehavioural responses, structural brain damage, and neuropathological sequelae triggered by neurotrauma. These results indicate that closed-head impact injuries, independent of concussive signs, can induce traumatic brain injury as well as early pathologies and functional sequelae associated with chronic traumatic encephalopathy. These results also shed light on the origins of concussion and relationship to traumatic brain injury and its aftermath."
VIJAY K KANABAR,New curriculum on managing projects: Responding to 21st century workforce needs,"Academics in many disciplines are effectively practicing experiential education to engage students using a project-oriented curriculum. The experience gained from working with projects is helpful from a career perspective as well since projects are increasingly viewed as a mechanism to implement organizational strategy and to manage organizational change. Employers today are seeking competent team members and individuals who understand the art and science of leading and managing projects. Business schools can enrich their curriculum with learning outcomes that can address this growing demand from project-oriented organizations for a “project-ready” pool of job applicants. To facilitate course design of a “project-oriented” curriculum, the newly released undergraduate project management curriculum guidelines can be leveraged. In this paper we describe the architecture of the curriculum guidelines and illustrate how business faculty can enhance their courses with project management (PM) principles and concepts."
VIJAY K KANABAR,Communication and leadership skills in the Computer Science and Information Systems curricula: A case study comparison of US and Bulgarian programs,"In this paper we present results from our curriculum research on the behavioral educational topics being in the computer science (CS) and information systems (IS) academic programs in two countries USA and Bulgaria. Specifically, we address learning outcomes as they pertain to IT Project Management. Our research reveals that the two countries approach undergraduate education from different vantage points. The US universities provide a flexible general education curriculum in many academic areas and students have the opportunity to strengthen their soft skills before they enter the workforce. Bulgarian universities provide specialized education in main CS subject areas and the students are technically strong upon graduation. Is there a way to balance out this divergent educational experience so that students get the best of both worlds? Our paper explores this aspect and provides possible solutions."
AMY LIEBERMAN,Semantic processing of adjectives and nouns in American Sign Language: effects of reference ambiguity and word order across development,"When processing spoken language sentences, listeners continuously make and revise predictions about the upcoming linguistic signal. In contrast, during comprehension of American Sign Language (ASL), signers must simultaneously attend to the unfolding linguistic signal and the surrounding scene via the visual modality. This may affect how signers activate potential lexical candidates and allocate visual attention as a sentence unfolds. To determine how signers resolve referential ambiguity during real-time comprehension of ASL adjectives and nouns, we presented deaf adults (n = 18, 19–61 years) and deaf children (n = 20, 4–8 years) with videos of ASL sentences in a visual world paradigm. Sentences had either an adjective-noun (e.g., “SEE YELLOW WHAT? FLOWER”) or a noun-adjective (e.g., “SEE FLOWER WHICH? YELLOW”) structure. The degree of ambiguity in the visual scene was manipulated at the adjective and noun levels (e.g., including one or more yellow items and one or more flowers in the visual array). We investigated effects of ambiguity and word order on target looking at early and late points in the sentence. Analysis revealed that adults and children made anticipatory looks to a target when it could be identified early in the sentence. Further, signers looked more to potential lexical candidates than to unrelated competitors in the early window, and more to matched than unrelated competitors in the late window. Children’s gaze patterns largely aligned with those of adults, although they made fewer anticipatory fixations to the target in the early window and were more susceptible to competitors in the late window. Together, these findings suggest that signers allocate referential attention strategically based on the amount and type of ambiguity at different points in the sentence when processing adjectives and nouns in ASL."
AMY LIEBERMAN,Toddlers' word learning through overhearing: others' attention matters.,"In laboratory settings children are able to learn new words from overheard interactions, yet in naturalistic contexts this is often not the case. We investigated the degree to which joint attention within the overheard interaction facilitates overheard learning. In the study, 20 2-year-olds were tested on novel words they had been exposed to in two different overhearing contexts: one in which both interlocutors were attending to the interaction and one in which one interlocutor was not attending. Participants learned the new words only in the former condition, indicating that they did not learn when joint attention was absent. This finding demonstrates that not all overheard interactions are equally good for word learning; attentive interlocutors are crucial when learning words through overhearing."
AMY LIEBERMAN,Lexical recognition in deaf children learning ASL: activation of semantic and phonological features of signs,"Children learning language efficiently process single words and activate semantic, phonological, and other features of words during recognition. We investigated lexical recognition in deaf children acquiring American Sign Language (ASL) to determine how perceiving language in the visual–spatial modality affects lexical recognition. Twenty native or early‐exposed signing deaf children (ages 4 to 8 years) participated in a visual world eye‐tracking study. Participants were presented with a single ASL sign, target picture, and three competitor pictures that varied in their phonological and semantic relationship to the target. Participants shifted gaze to the target picture shortly after sign offset. Participants showed robust evidence for activation of semantic but not phonological features of signs. However, in their behavioral responses, participants were most susceptible to phonological competitors. Results demonstrated that single word recognition in ASL is largely parallel to spoken language recognition among children who are developing a mature lexicon."
AMY LIEBERMAN,Prediction in a visual language: real-time sentence processing in American Sign Language across development,"Prediction during sign language comprehension may enable signers to integrate linguistic and non-linguistic information within the visual modality. In two eye-tracking experiments, we investigated American Sign language (ASL) semantic prediction in deaf adults and children (aged 4–8 years). Participants viewed ASL sentences in a visual world paradigm in which the sentence-initial verb was either neutral or constrained relative to the sentence-final target noun. Adults and children made anticipatory looks to the target picture before the onset of the target noun in the constrained condition only, showing evidence for semantic prediction. Crucially, signers alternated gaze between the stimulus sign and the target picture only when the sentential object could be predicted from the verb. Signers therefore engage in prediction by optimising visual attention between divided linguistic and referential signals. These patterns suggest that prediction is a modality-independent process, and theoretical implications are discussed."
AMY LIEBERMAN,"The ASL-CDI 2.0: an updated, normed adaptation of the MacArthur Bates Communicative Development Inventory for American Sign Language","Vocabulary is a critical early marker of language development. The MacArthur Bates Communicative Development Inventory has been adapted to dozens of languages, and provides a bird’s-eye view of children’s early vocabularies which can be informative for both research and clinical purposes. We present an update to the American Sign Language Communicative Development Inventory (the ASL-CDI 2.0, https://www.aslcdi.org), a normed assessment of early ASL vocabulary that can be widely administered online by individuals with no formal training in sign language linguistics. The ASL-CDI 2.0 includes receptive and expressive vocabulary, and a Gestures and Phrases section; it also introduces an online interface that presents ASL signs as videos. We validated the ASL-CDI 2.0 with expressive and receptive in-person tasks administered to a subset of participants. The norming sample presented here consists of 120 deaf children (ages 9 to 73 months) with deaf parents. We present an analysis of the measurement properties of the ASL-CDI 2.0. Vocabulary increases with age, as expected. We see an early noun bias that shifts with age, and a lag between receptive and expressive vocabulary. We present these findings with indications for how the ASL-CDI 2.0 may be used in a range of clinical and research settings"
AMY LIEBERMAN,The development and evaluation of a new ASL text comprehension task,"Being able to comprehend a language entails not only mastery of its syntax, lexicon, or phonology, but also the ability to use language to construct meaning, draw inferences, and make connections to world knowledge. However, most available assessments of American Sign Language (ASL) focus on mastery of lower level skills, and as a result little is known about development of higher-order ASL comprehension skills. In this paper, we introduce the American Sign Language Text Comprehension Task (ASL-CMP), a new assessment tool to measure ASL text comprehension ability in deaf children. We first administered the task to a group of deaf children with deaf parents (n = 105, ages 8–18 years) in order to evaluate the reliability and validity of the task, and to develop norms. We found that the ASL-CMP has acceptable levels of internal consistency, difficulty, and discriminability. Next, we administered the task to an additional group of deaf children with hearing parents (n = 251, ages 8–18 years), and found that the ASL-CMP is sensitive to expected patterns: older children have better ASL text comprehension skills, literal questions are generally easier to answer than inferential questions, and children with early exposure to ASL generally outperform those with delayed exposure. We conclude that the ASL-CMP task is reliable and valid and can be used to characterize ASL text comprehension skills in deaf children."
AMY LIEBERMAN,Learning a sign language does not hinder acquisition of a spoken language,"PURPOSE: The purpose of this study is to determine whether and how learning American Sign Language (ASL) is associated with spoken English skills in a sample of ASL-English bilingual deaf and hard of hearing (DHH) children. METHOD: This cross-sectional study of vocabulary size included 56 DHH children between 8 and 60 months of age who were learning both ASL and spoken English and had hearing parents. English and ASL vocabulary were independently assessed via parent report checklists. RESULTS: ASL vocabulary size positively correlated with spoken English vocabulary size. Spoken English vocabulary sizes in the ASL-English bilingual DHH children in the present sample were comparable to those in previous reports of monolingual DHH children who were learning only English. ASL-English bilingual DHH children had total vocabularies (combining ASL and English) that were equivalent to same-age hearing monolingual children. Children with large ASL vocabularies were more likely to have spoken English vocabularies in the average range based on norms for hearing monolingual children. CONCLUSIONS: Contrary to predictions often cited in the literature, acquisition of sign language does not harm spoken vocabulary acquisition. This retrospective, correlational study cannot determine whether there is a causal relationship between sign language and spoken language vocabulary acquisition, but if a causal relationship exists, the evidence here suggests that the effect would be positive. Bilingual DHH children have age-expected vocabularies when considering the entirety of their language skills. We found no evidence to support recommendations that families with DHH children avoid learning sign language. Rather, our findings show that children with early ASL exposure can develop age-appropriate vocabulary skills in both ASL and spoken English."
AMY LIEBERMAN,Exploring joint attention in American sign language: the influence of sign familiarity,
HUI FENG,"Eucalyptusdimers A-C, dimeric phloroglucinol phellandrene meroterpenoids from Eucalyptus robusta","Eucalyptusdimers A–C, three dimeric phellandrene-derived meroterpenoids featuring an unprecedented, fused skeleton between two phellandrene and two acylphloroglucinol subunits, along with one biogenetically related intermediate, (±)-eucalyprobusone A, were isolated from the fruits of Eucalyptus robusta. Their structures and absolute configurations were elucidated using spectroscopic data, X-ray crystallography, and electronic circular dichroism analysis. The isolated meroterpenoids were evaluated for their anti-inflammatory, acetylcholinesterase inhibitory, and protein tyrosine phosphatase 1B inhibitory effects."
HUI FENG,CK2 inhibitor CX-4945 destabilizes NOTCH1 and synergizes with JQ1 against human T-acute lymphoblastic leukemic cells.,"T-cell acute lymphoblastic leukemia (T-ALL) is an aggressive cancer of developing thymocytes, and remains fatal in 20% of pediatric and 50% of adult patients.1,2 Frequent application of multi-agent cytotoxic drugs leads to disease relapse and high toxicities, underscoring the need for targeted therapies. The suppression of aberrant NOTCH1 signaling in T-ALL cells by gamma secretase inhibitors (GSIs) has been met with much enthusiasm; however, the gastrointestinal toxicities and drug resistance of GSIs restrain their clinical applications.3 The proto-oncogene MYC is a transcriptional target of NOTCH1 and a dominant driver of T-ALL pathogenesis.3 Targeting MYC-mediated transcriptional programs through BET bromodomain inhibitor JQ1 exhibits anti-leukemic efficacy in vitro and in vivo.4 However, global repression of transcription is predicted to cause toxicities. Identification of drug(s) synergizing with JQ1 to kill T-ALL cells may enhance the efficacy while reducing toxicities. Protein kinase CK2 is a tetrameric serine-threonine kinase composed of two catalytic (α or α′) and regulatory (β) subunits that can phosphorylate NOTCH1.5 CK2 inhibition by CX-4945, a potent and specific inhibitor in clinical trials for treating breast cancer and multiple myeloma, significantly reduces growth and survival of human T-ALL cells,6 and down-regulates NOTCH1 in lung cancer cells.7 However, it remains unclear whether the cytotoxic effect of CX-4945 on T-ALL cells is associated with repression of NOTCH1 signaling. Here we show that CK2 inhibition by CX-4945 destabilizes NOTCH1 and synergizes with JQ1 to induce apoptosis in human T-ALL cells, implicating an alternative strategy to target NOTCH1 signaling in refractory/relapsed T-ALL."
HUI FENG,Acylphloroglucinols with acetylcholinesterase inhibitory effects from the fruits of Eucalyptus robusta,"Eleven new acylphloroglucinols, including six new formylated phloroglucinol-monoterpene meroterpenoids, eucalyprobusals A-F (1-6), one monomeric acylphloroglucinol, eucalyprobusone B (7), and four dimeric acylphloroglucinols, eucalyprobusones C-F (8-11) were purified from the fruits of Eucalyptus robusta. The establishment of the structures of 1-11 was achieved by a combination of NMR and HRESIMS data analyses, electron circular dichroism (ECD), and single-crystal X-ray diffraction. Compounds 6, 8, and an inseparable mixture of 10 and 11 were found to be potent AChE inhibitors with IC50 values of 3.22 ± 0.36, 3.82 ± 0.22, and 2.55 ± 0.28 μΜ, respectively. Possible interaction sites of 6, 8, 10, and 11 with AChE were investigated by means of molecular docking studies, and the results revealed that AChE residues Asn87, Ser125, Thr83, Tyr133, Tyr124, Tyr337, and Tyr341 played crucial roles in the observed activity of the aforementioned compounds."
HUI FENG,Predicting the epidemic threshold of the susceptible-infected-recovered model,"Researchers have developed several theoretical methods for predicting epidemic thresholds, including the mean-field like (MFL) method, the quenched mean-field (QMF) method and the dynamical message passing (DMP) method. When these methods are applied to predict epidemic threshold they often produce differing results and their relative levels of accuracy are still unknown. We systematically analyze these two issues—relationships among differing results and levels of accuracy—by studying the susceptible-infected-recovered (SIR) model on uncorrelated configuration networks and a group of 56 real-world networks. In uncorrelated configuration networks the MFL and DMP methods yield identical predictions that are larger and more accurate than the prediction generated by the QMF method. As for the 56 real-world networks, the epidemic threshold obtained by the DMP method is more likely to reach the accurate epidemic threshold because it incorporates full network topology information and some dynamical correlations. We find that in most of the networks with positive degree-degree correlations, an eigenvector localized on the high k-core nodes, or a high level of clustering, the epidemic threshold predicted by the MFL method, which uses the degree distribution as the only input information, performs better than the other two methods."
HUI FENG,UFD1 contributes to MYC-mediated leukemia aggressiveness through suppression of the proapoptotic unfolded protein response,"Despite the pivotal role of MYC in tumorigenesis, the mechanisms by which it promotes cancer aggressiveness remain incompletely understood. Here, we show that MYC transcriptionally upregulates the ubiquitin fusion degradation 1 (UFD1) gene in T-cell acute lymphoblastic leukemia (T-ALL). Allelic loss of ufd1 in zebrafish induces tumor cell apoptosis and impairs MYC-driven T-ALL progression but does not affect general health. As the E2 component of an endoplasmic reticulum (ER)-associated degradation (ERAD) complex, UFD1 facilitates the elimination of misfolded/unfolded proteins from the ER. We found that UFD1 inactivation in human T-ALL cells impairs ERAD, exacerbates ER stress, and induces apoptosis. Moreover, we show that UFD1 inactivation promotes the proapoptotic unfolded protein response (UPR) mediated by protein kinase RNA-like ER kinase (PERK). This effect is demonstrated by an upregulation of PERK and its downstream effector C/EBP homologous protein (CHOP), as well as a downregulation of BCL2 and BCLxL. Indeed, CHOP inactivation or BCL2 overexpression is sufficient to rescue tumor cell apoptosis induced by UFD1 knockdown. Together, our studies identify UFD1 as a critical regulator of the ER stress response and a novel contributor to MYC-mediated leukemia aggressiveness, with implications for targeted therapy in T-ALL and likely other MYC-driven cancers."
KAIJA E. SCHILDE,"What goes up, must come down? The asymmetric effects of economic growth and international threat on military spending",
ELAINE O. NSOESIE,Scraping social media photos posted in Kenya and elsewhere to detect and analyze food types,"Monitoring population-level changes in diet could be useful for education and for implementing interventions to improve health. Research has shown that data from social media sources can be used for monitoring dietary behavior. We propose a scrape-by-location methodology to create food image datasets from Instagram posts. We used it to collect 3.56 million images over a period of 20 days in March 2019. We also propose a scrape-by-keywords methodology and used it to scrape ∼30,000 images and their captions of 38 Kenyan food types. We publish two datasets of 104,000 and 8,174 image/caption pairs, respectively. With the first dataset, Kenya104K, we train a Kenyan Food Classifier, called KenyanFC, to distinguish Kenyan food from non-food images posted in Kenya. We used the second dataset, KenyanFood13, to train a classifier KenyanFTR, short for Kenyan Food Type Recognizer, to recognize 13 popular food types in Kenya. The KenyanFTR is a multimodal deep neural network that can identify 13 types of Kenyan foods using both images and their corresponding captions. Experiments show that the average top-1 accuracy of KenyanFC is 99% over 10,400 tested Instagram images and of KenyanFTR is 81% over 8,174 tested data points. Ablation studies show that three of the 13 food types are particularly difficult to categorize based on image content only and that adding analysis of captions to the image analysis yields a classifier that is 9 percent points more accurate than a classifier that relies only on images. Our food trend analysis revealed that cakes and roasted meats were the most popular foods in photographs on Instagram in Kenya in March 2019."
CHARLES CHANG,Intoxication and pitch control in tonal and non-tonal language speakers,"Alcohol intoxication is known to affect pitch variability in non-tonal languages. In this study, intoxication's effects on pitch were examined in tonal and non-tonal language speakers, in both their native language (L1; German, Korean, Mandarin) and nonnative language (L2; English). Intoxication significantly increased pitch variability in the German group (in L1 and L2), but not in the Korean or Mandarin groups (in L1 or L2), although there were individual differences. These results support the view that pitch control is related to the functional load of pitch and is an aspect of speech production that can be advantageously transferred across languages, overriding the expected effects of alcohol."
CHARLES CHANG,"Unity and diversity in Asian American language variation: data from Chinese, Filipino, Korean, and Vietnamese Americans","The present study examined sociophonetic variation in a small sample of Asian Americans in Boston, Massachusetts representing four ethnic groups: Chinese, Filipino, Korean, and Vietnamese. Analyzing these speakers’ English production in tasks eliciting both casual and careful speech, we focused on four linguistic features comprising features observed in Eastern New England and in certain Asian American groups. Three features (R-DELETION, L-VOCALIZATION, L/R-CONFLATION) were coded auditorily and one (LOW BACK RAISING of /ɑ/ to /ɔ/) acoustically. Overall, results showed low use of Eastern New England features (R-DELETION, LOW BACK RAISING), high use of L-VOCALIZATION, and no use of L/R-CONFLATION, but also significant differences in specific patterns of use according to ethnicity and speech style. Ethnicity was a significant predictor of the occurrence of R-DELETION and L- VOCALIZATION, and also a significant predictor of first formant (F1) values in the low back vowels, although no clear vowel merger was found. Careful speech showed lower rates of R-DELETION and L-VOCALIZATION and less overlap of the low back vowels as compared to casual speech. These findings reveal similarities and differences in speech production among ethnically diverse Asian Americans and highlight the need for further investigation of phonetic variation within this community."
CHARLES CHANG,"LEXTALE_CH: A quick, character-based proficiency test for Mandarin Chinese","Research in second language acquisition suggests that objective performance-based assessments may provide more reliable and valid measures of second language proficiency than subjective self-ratings. To measure proficiency in English as a second language, a quick, vocabulary-based test called LexTALE (Lexical Test for Advanced Learners of English) was developed and shown to be able to differentiate between various levels of English proficiency. Following in the line of adaptations of this test for other languages, we created a character-based adaptation for Mandarin Chinese: LEXTALE_CH. In this paper, we discuss the development and validation of LEXTALE_CH in detail. In short, LEXTALE_CH can discriminate between high and low levels of Mandarin proficiency and is sensitive to the significant differences in vocabulary size between native speakers and second language learners of Mandarin; further, it takes only a few minutes to administer and is simple to score, making it a practical tool for low-stakes estimation of Mandarin proficiency."
CHARLES CHANG,On the cognitive basis of contact-induced sound change: vowel merger reversal in Shanghainese,"This study investigates the source and status of a recent sound change in Shanghainese (Wu, Sinitic) that has been attributed to language contact with Mandarin. The change involves two vowels, /e/ and /ɛ/, reported to be merged three decades ago but produced distinctly in contemporary Shanghainese. Results of two production experiments show that speaker age, language mode (monolingual Shanghainese vs. bilingual Shanghainese-Mandarin), and crosslinguistic phonological similarity all influence the production of these vowels. These findings provide evidence for language contact as a linguistic means of merger reversal and are consistent with the view that contact phenomena originate from cross-language interaction within the bilingual mind."
CHARLES CHANG,Bilingual perceptual benefits of experience with a heritage language,"Research on the linguistic knowledge of heritage speakers has been concerned primarily with the advantages conferred by heritage language experience in production, perception, and (re)learning of the heritage language. Meanwhile, second-language speech research has begun to investigate potential benefits of first-language transfer in second-language performance. Bridging these two bodies of work, the current study examined the perceptual benefits of heritage language experience for heritage speakers of Korean in both the heritage language (Korean) and the dominant language (American English). It was hypothesized that, due to their early bilingual experience and the different nature of unreleased stops in Korean and American English, heritage speakers of Korean would show not only native-like perception of Korean unreleased stops, but also better-than-native perception of American English unreleased stops. Results of three perception experiments were consistent with this hypothesis, suggesting that benefits of early heritage language experience can extend well beyond the heritage language."
CHARLES CHANG,Phonetic drift,"This chapter provides an overview of research on the phonetic changes that occur in one’s native language (L1) due to recent experience in another language (L2), a phenomenon known as phonetic drift. Through a survey of empirical findings on segmental and suprasegmental acoustic properties, the chapter examines the features of the L1 that are subject to phonetic drift, the cognitive mechanism(s) behind phonetic drift, and the various factors that influence the likelihood of phonetic drift. In short, virtually all aspects of L1 speech are subject to drift, but different aspects do not drift in the same manner, possibly due to multiple routes of L2 influence coexisting at different levels of L1 phonological structure. In addition to the timescale of these changes, the chapter discusses the relationship between phonetic drift and attrition as well as some of the enduring questions in this area."
CHARLES CHANG,Context effects on second-language learning of tonal contrasts.,"Studies of lexical tone  learning generally focus on monosyllabic contexts, while reports of phonetic learning benefits associated with input variability are based largely on experienced learners. This study trained inexperienced learners on Mandarin tonal contrasts to test two hypotheses regarding the influence of context and variability on tone  learning. The first hypothesis was that increased phonetic variability of tones in disyllabic contexts makes initial tone  learning more challenging in disyllabic than monosyllabic words. The second hypothesis was that the learnability of a given tone varies across contexts due to differences in tonal variability. Results of a word learning experiment supported both hypotheses: tones were acquired less successfully in disyllables than in monosyllables, and the relative difficulty of disyllables was closely related to contextual tonal variability. These results indicate limited relevance of monosyllable-based data on Mandarin learning for the disyllabic majority of the Mandarin lexicon. Furthermore, in the short term, variability can diminish learning; its effects are not necessarily beneficial but dependent on acquisition stage and other learner characteristics. These findings thus highlight the importance of considering contextual variability and the interaction between variability and type of learner in the design, interpretation, and application of research on phonetic learning."
CHARLES CHANG,Language change and linguistic inquiry in a world of multicompetence: Sustained phonetic drift and its implications for behavioral linguistic research,"Linguistic studies focusing on monolinguals have often examined individuals with considerable experience using another language. Results of a methodological review suggest that conflating ostensibly ‘multicompetent’ individuals with monolinguals is still common practice. A year-long longitudinal study of speech production demonstrates why this practice is problematic. Adult native English speakers recently arrived in Korea showed significant changes in their production of English stops and vowels (in terms of voice onset time, fundamental frequency, and formant frequencies) during Korean classes and continued to show altered English production a year later, months after their last Korean class. Consistent with an INCIDENTAL PROCESSING HYPOTHESIS (IPH) concerning the processing of ambient linguistic input, some changes persisted even in speakers who reported limited active use of Korean in their daily life. These patterns thus suggest that the linguistic experience obtained in a foreign language environment induces and then prolongs restructuring of the native language, making the multicompetent native speaker in a foreign language environment unrepresentative of a monolingual in a native language environment. Such restructuring supports the view that one’s native language continues to evolve in adulthood, highlighting the need for researchers to be explicit about a population under study and to accordingly control (and describe) language background in a study sample."
CHARLES CHANG,On the cognitive basis of contact-induced sound change: vowel merger reversal in Shanghainese: online appendices,
CHARLES CHANG,Pitch ability as an aptitude for tone learning,"Tone languages such as Mandarin use voice pitch to signal lexical contrasts, presenting a challenge for second/foreign language (L2) learners whose native languages do not use pitch in this manner. The present study examined components of an aptitude for mastering L2 lexical tone. Native English speakers with no previous tone language experience completed a Mandarin word learning task, as well as tests of pitch ability, musicality, L2 aptitude, and general cognitive ability. Pitch ability measures improved predictions of learning performance beyond musicality, L2 aptitude, and general cognitive ability and also predicted transfer of learning to new talkers. In sum, although certain nontonal measures help predict successful tone learning, the central components of tonal aptitude are pitch-specific perceptual measures."
CHARLES CHANG,Perception of nonnative tonal contrasts by Mandarin-English and English-Mandarin sequential bilinguals,"This study examined the role of acquisition order and crosslinguistic similarity in influencing transfer at the initial stage of perceptually acquiring a tonal third language (L3). Perception of tones in Yoruba and Thai was tested in adult sequential bilinguals representing three different first (L1) and second language (L2) backgrounds: L1 Mandarin-L2 English (MEBs), L1 English-L2 Mandarin (EMBs), and L1 English-L2 intonational/non-tonal (EIBs). MEBs outperformed EMBs and EIBs in discriminating L3 tonal contrasts in both languages, while EMBs showed a small advantage over EIBs on Yoruba. All groups showed better overall discrimination in Thai than Yoruba, but group differences were more robust in Yoruba. MEBs’ and EMBs’ poor discrimination of certain L3 contrasts was further reflected in the L3 tones being perceived as similar to the same Mandarin tone; however, EIBs, with no knowledge of Mandarin, showed many of the same similarity judgments. These findings thus suggest that L1 tonal experience has a particularly facilitative effect in L3 tone perception, but there is also a facilitative effect of L2 tonal experience. Further, crosslinguistic perceptual similarity between L1/L2 and L3 tones, as well as acoustic similarity between different L3 tones, play a significant role at this early stage of L3 tone acquisition."
CHARLES CHANG,"Production of neutral tone in Mandarin by heritage, native, and second language speakers","This study examined the properties of neutral tone (T0) in Mandarin as produced by three groups: native speakers raised in a Mandarin-speaking environment (L1ers), second language learners raised in an English-speaking environment (L2ers), and heritage language speakers (HLers) exposed to Mandarin from birth but currently dominant in English. T0 production was elicited in both obligatory and non-obligatory contexts, acoustically analyzed, and perceptually evaluated by Mandarin L1ers. Acoustic data indicated little difference among groups in pitch contour, but significant differences in duration, especially in the non-obligatory context. Perceptual data revealed relatively low intelligibility of T0 overall, but also a group difference whereby L2ers tended to outperform HLers in the non-obligatory context; nevertheless, L2ers received the lowest goodness ratings, across both contexts. These results thus suggest that phonetic differences between HLers and L2ers are not unidirectional, but instead vary across aspects of the language in accordance with differences in speakers’ linguistic experience."
CHARLES CHANG,Age effects in first language attrition: speech perception by Korean-English bilinguals,"This study investigated how bilinguals’ perception of their first language (L1) differs according to age of reduced contact with L1 after immersion in a second language (L2). Twenty-one L1 Korean-L2 English bilinguals in the United States, ranging in age of reduced contact from 3 to 15 years, and 17 control participants in Korea were tested perceptually on three L1 contrasts differing in similarity to L2 contrasts. Compared to control participants, bilinguals were less accurate on L1-specific contrasts, and their accuracy was significantly correlated with age of reduced contact, an effect most pronounced for the contrast most dissimilar to L2. These findings suggest that the earlier bilinguals are extensively exposed to L2, the less likely they are to perceive L1 sounds accurately. However, this relationship is modulated by crosslinguistic similarity, and a turning point in L2 acquisition and L1 attrition of phonology appears to occur at around age 12."
CHARLES CHANG,The contributions of crosslinguistic influence and individual differences to nonnative speech perception,"Perception of a nonnative language (L2) is known to be affected by crosslinguistic transfer from a listener's native language (L1), but the relative importance of L1 transfer vis-a-vis individual learner differences remains unclear. This study explored the hypothesis that the nature of L1 transfer changes as learners gain experience with the L2, such that individual differences are more influential at earlier stages of learning and L1 transfer is more influential at later stages of learning. To test this hypothesis, novice L2 learners of Korean from diverse L1 backgrounds were examined in a pretest-posttest design with respect to their perceptual acquisition of novel L2 consonant contrasts (the three-way Korean laryngeal contrast among lenis, fortis, and aspirated plosives) and vowel contrasts (/o/-/ʌ/, /u/-/ɨ/). Whereas pretest performance showed little evidence of L1 effects, posttest performance showed significant L1 transfer. Furthermore, pretest performance did not predict posttest performance. These findings support the view that L1 knowledge influences L2 perception dynamically, according to the amount of L2 knowledge available to learners at that time. That is, both individual differences and L1 knowledge play a role in L2 perception, but to different degrees over the course of L2 development."
CHARLES CHANG,Toward an understanding of heritage prosody,"In previous work examining heritage language phonology, heritage speakers have often patterned differently from native speakers and late-onset second language (L2) learners with respect to overall accent and segmentals. The current study extended this line of inquiry to suprasegmentals, comparing the properties of lexical tones produced by heritage, native, and L2 speakers of Mandarin living in the U.S. We hypothesized that heritage speakers would approximate native norms for Mandarin tones more closely than L2 speakers, yet diverge from these norms in one or more ways. We further hypothesized that, due to their unique linguistic experience, heritage speakers would sound the most ambiguous in terms of demographic background. Acoustic data showed that heritage speakers approximated native-like production more closely than L2 speakers with respect to the pitch contour of Tone 3, durational shortening in connected speech, and rates of Tone 3 reduction in non-phrase-final contexts, while showing the highest levels of tonal variability among all groups. Perceptual data indicated that heritage speakers’ tones differed from native and L2 speakers’ in terms of both intelligibility and perceived goodness. Consistent with the variability results, heritage speakers were the most difficult group to classify demographically. Taken together, these findings suggest that, with respect to tone, early heritage language experience can, but does not necessarily, result in a phonological advantage over L2 learners. Further, they add support to the view that heritage speakers are language users distinct from both native and L2 speakers."
CHARLES CHANG,Visualization of metabolic interaction networks in microbial communities using VisANT 5.0,"The complexity of metabolic networks in microbial communities poses an unresolved visualization and interpretation challenge. We address this challenge in the newly expanded version of a software tool for the analysis of biological networks, VisANT 5.0. We focus in particular on facilitating the visual exploration of metabolic interaction between microbes in a community, e.g. as predicted by COMETS (Computation of Microbial Ecosystems in Time and Space), a dynamic stoichiometric modeling framework. Using VisANT's unique metagraph implementation, we show how one can use VisANT 5.0 to explore different time-dependent ecosystem-level metabolic networks. In particular, we analyze the metabolic interaction network between two bacteria previously shown to display an obligate cross-feeding interdependency. In addition, we illustrate how a putative minimal gut microbiome community could be represented in our framework, making it possible to highlight interactions across multiple coexisting species. We envisage that the ""symbiotic layout"" of VisANT can be employed as a general tool for the analysis of metabolism in complex microbial communities as well as heterogeneous human tissues."
CHARLES CHANG,Cultural factors weaken but do not reverse left-to-right spatial biases in numerosity processing: Data from Arabic and English monoliterates and Arabic-English biliterates,"Directional response biases due to a conceptual link between space and number, such as a left-to-right hand bias for increasing numerical magnitude, are known as the SNARC (Spatial-Numerical Association of Response Codes) effect. We investigated how the SNARC effect for numerosities would be influenced by reading-writing direction, task instructions, and ambient visual environment in four literate populations exemplifying opposite reading-writing cultures—namely, Arabic (right-to left script) and English (left-to-right script). Monoliterates and biliterates in Jordan and the U.S. completed a speeded numerosity comparison task to assess the directionality and magnitude of a SNARC effect in their numerosity processing. Monoliterates’ results replicated previously documented effects of reading-writing direction and task instructions: the SNARC effect found in left-to-right readers was weakened in right-to-left readers, and the left-to-right group exhibited a task-dependency effect (SNARC effect in the smaller condition, reverse SNARC effect in the larger condition). Biliterates' results showed an effect of environment: Jordan- and U.S.-based biliterates resembled their monoliterate counterparts living in the same location more than each other. These findings support the proposed Multiple Competing Codes Theory (MCCT), which posits the existence of four distinct spatial-numerical mapping codes (cardinal, ordinal, innate, culture) during numerical processing—each involved at varying levels depending on individual and task factors."
CHARLES CHANG,"Effects of age, sex, context, and lexicality on hyperarticulation of Korean fricatives","Seoul Korean is known for a rare three-way laryngeal contrast among lenis, fortis, and aspirated voiceless stops, which has recently undergone a change in phonetic implementation: whereas older speakers rely more on voice onset time (VOT) to distinguish lenis and aspirated stops, younger speakers rely more on onset fundamental frequency (f 0) in the following vowel. This production difference is reflected in disparate strategies for enhancing the contrast in clear speech, supporting the view that younger and older speakers represent the three laryngeal categories differently in terms of VOT and f 0 targets (Kang & Guion, 2008). In the current study, we used the clear speech paradigm to test for change in the representation of the two-way contrast between fortis (/s*/) and non-fortis (/s/) fricatives. Native Seoul Korean speakers (n = 32), representing two generations and both sexes, were recorded producing the coronal stops and fricatives in different vowel contexts, item types (real vs. nonce words), and speech registers (plain citation vs. clear). We report acoustic data on how the above factors influence production of the fricative contrast and discuss implications for the phonological categorization of non-fortis /s/ as lenis, aspirated, or a hybrid lenis-aspirated category."
CHARLES CHANG,The phonetics of second language learning and bilingualism,"This chapter provides an overview of major theories and findings in the field of second language (L2) phonetics and phonology. Four main conceptual frameworks are discussed and compared: the Perceptual Assimilation Model-L2, the Native Language Magnet Theory, the Automatic Selection Perception Model, and the Speech Learning Model. These frameworks differ in terms of their empirical focus, including the type of learner (e.g., beginner vs. advanced) and target modality (e.g., perception vs. production), and in terms of their theoretical assumptions, such as the basic unit or window of analysis that is relevant (e.g., articulatory gestures, position-specific allophones). Despite the divergences among these theories, three recurring themes emerge from the literature reviewed. First, the learning of a target L2 structure (segment, prosodic pattern, etc.) is influenced by phonetic and/or phonological similarity to structures in the native language (L1). In particular, L1-L2 similarity exists at multiple levels and does not necessarily benefit L2 outcomes. Second, the role played by certain factors, such as acoustic phonetic similarity between close L1 and L2 sounds, changes over the course of learning, such that advanced learners may differ from novice learners with respect to the effect of a specific variable on observed L2 behavior. Third, the connection between L2 perception and production (insofar as the two are hypothesized to be linked) differs significantly from the perception-production links observed in L1 acquisition. In service of elucidating the predictive differences among these theories, this contribution discusses studies that have investigated L2 perception and/or production primarily at a segmental level. In addition to summarizing the areas in which there is broad consensus, the chapter points out a number of questions which remain a source of debate in the field today."
CHARLES CHANG,Perceptual attention as the locus of transfer to nonnative speech perception,"One’s native language (L1) is known to influence the development of a nonnative language (L2) at multiple levels, but the nature of L1 transfer to L2 perception remains unclear. This study explored the hypothesis that transfer effects in perception come from L1-specific processing strategies, which direct attention to phonetic cues according to their estimated relative functional load (RFL). Using target languages that were either familiar (English) or unfamiliar (Korean), perception of unreleased final stops was tested in L1 English listeners and four groups of L2 English learners whose L1s differ in stop phonotactics and the estimated RFL of a crucial cue to unreleased stops (i.e., vowel-to-consonant formant transitions). Results were, overall, consistent with the hypothesis, with L1 Japanese listeners showing the poorest perception, followed by L1 Mandarin, Russian, English, and Korean listeners. Two exceptions occurred with Russian listeners, who underperformed Mandarin listeners in identification of English stops and outperformed English listeners in identification of Korean stops. Taken together, these findings support a cue-centric view of transfer based on perceptual attention over a direct phonotactic view based on structural conformity. However, transfer interacts with prior L2 knowledge, which may result in significantly different perceptual consequences for a familiar and an unfamiliar L2."
CHARLES CHANG,On the cognitive basis of contact-induced sound change: Vowel merger reversal in Shanghainese,"This study investigates the source and status of a recent sound change in Shanghainese (Wu, Sinitic) that has been attributed to language contact with Mandarin. The change involves two vowels, /e/ and /ɛ/, reported to be merged three decades ago but produced distinctly in contemporary Shanghainese. Results of two production experiments show that speaker age, language mode (monolingual Shanghainese vs. bilingual Shanghainese-Mandarin), and crosslinguistic phonological similarity all influence the production of these vowels. These findings provide evidence for language contact as a linguistic means of merger reversal and are consistent with the view that contact phenomena originate from cross-language interaction within the bilingual mind."
CHARLES CHANG,Emotion word development in bilingual children living in majority and minority contexts,"The lexicon of emotion words is fundamental to interpersonal communication. To examine how emotion word acquisition interacts with societal context, the present study investigated emotion word development in three groups of child Korean users aged 4–13 years: those who use Korean primarily outside the home as a majority language (MajKCs) or inside the home as a minority language (MinKCs), and those who use Korean both inside and outside the home (KCs). These groups, along with a group of L1 Korean adults, rated the emotional valence of 61 Korean emotion words varying in frequency, valence, and age of acquisition. Results showed KCs, MajKCs, and MinKCs all converging toward adult-like valence ratings by ages 11–13 years; unlike KCs and MajKCs, however, MinKCs did not show age-graded development and continued to diverge from adults in emotion word knowledge by these later ages. These findings support the view that societal context plays a major role in emotion word development, offering one reason for the intergenerational communication difficulties reported by immigrant families."
CHARLES CHANG,"Toward an understanding of heritage prosody: Acoustic and perceptual properties of tone produced by heritage, native, and second language speakers of Mandarin","In previous work examining heritage language phonology, heritage speakers have often patterned differently from native speakers and late-onset second language (L2) learners with respect to overall accent and segmentals. The current study extended this line of inquiry to suprasegmentals, comparing the properties of lexical tones produced by heritage, native, and L2 speakers of Mandarin living in the U.S. We hypothesized that heritage speakers would approximate native norms for Mandarin tones more closely than L2 speakers, yet diverge from these norms in one or more ways. We further hypothesized that, due to their unique linguistic experience, heritage speakers would sound the most ambiguous in terms of demographic background. Acoustic data showed that heritage speakers approximated native-like production more closely than L2 speakers with respect to the pitch contour of Tone 3, durational shortening in connected speech, and rates of Tone 3 reduction in non-phrase-final contexts, while showing the highest levels of tonal variability among all groups. Perceptual data indicated that heritage speakers’ tones differed from native and L2 speakers’ in terms of both intelligibility and perceived goodness. Consistent with the variability results, heritage speakers were the most difficult group to classify demographically. Taken together, these findings suggest that, with respect to tone, early heritage language experience can, but does not necessarily, result in a phonological advantage over L2 learners. Further, they add support to the view that heritage speakers are language users distinct from both native and L2 speakers."
CHARLES CHANG,COMBREX: A Project to Accelerate the Functional Annotation of Prokaryotic Genomes,COMBREX (http://combrex.bu.edu) is a project to increase the speed of the functional annotation of new bacterial and archaeal genomes. It consists of a database of functional predictions produced by computational biologists and a mechanism for experimental biochemists to bid for the validation of those predictions. Small grants are available to support successful bids.
CHARLES CHANG,"VisANT 3.5: Multi-Scale Network Visualization, Analysis and Inference Based on the Gene Ontology","Despite its wide usage in biological databases and applications, the role of the gene ontology (GO) in network analysis is usually limited to functional annotation of genes or gene sets with auxiliary information on correlations ignored. Here, we report on new capabilities of VisANT—an integrative software platform for the visualization, mining, analysis and modeling of the biological networks—which extend the application of GO in network visualization, analysis and inference. The new VisANT functions can be classified into three categories. (i) Visualization: a new tree-based browser allows visualization of GO hierarchies. GO terms can be easily dropped into the network to group genes annotated under the term, thereby integrating the hierarchical ontology with the network. This facilitates multi-scale visualization and analysis. (ii) Flexible annotation schema: in addition to conventional methods for annotating network nodes with the most specific functional descriptions available, VisANT also provides functions to annotate genes at any customized level of abstraction. (iii) Finding over-represented GO terms and expression-enriched GO modules: two new algorithms have been implemented as VisANT plugins. One detects over-represented GO annotations in any given sub-network and the other finds the GO categories that are enriched in a specified phenotype or perturbed dataset. Both algorithms take account of network topology (i.e. correlations between genes based on various sources of evidence). VisANT is freely available at http://visant.bu.edu."
CHARLES CHANG,"First Sagittarius A* Event Horizon Telescope results. IV. Variability, morphology, and black hole mass","In this paper we quantify the temporal variability and image morphology of the horizon-scale emission from Sgr A*, as observed by the EHT in 2017 April at a wavelength of 1.3 mm. We find that the Sgr A* data exhibit variability that exceeds what can be explained by the uncertainties in the data or by the effects of interstellar scattering. The magnitude of this variability can be a substantial fraction of the correlated flux density, reaching ∼100% on some baselines. Through an exploration of simple geometric source models, we demonstrate that ring-like morphologies provide better fits to the Sgr A* data than do other morphologies with comparable complexity. We develop two strategies for fitting static geometric ring models to the time-variable Sgr A* data; one strategy fits models to short segments of data over which the source is static and averages these independent fits, while the other fits models to the full data set using a parametric model for the structural variability power spectrum around the average source structure. Both geometric modeling and image-domain feature extraction techniques determine the ring diameter to be 51.8 ± 2.3 μas (68% credible intervals), with the ring thickness constrained to have an FWHM between ∼30% and 50% of the ring diameter. To bring the diameter measurements to a common physical scale, we calibrate them using synthetic data generated from GRMHD simulations. This calibration constrains the angular size of the gravitational radius to be 4.8_-0.7^+1.4 μas, which we combine with an independent distance measurement from maser parallaxes to determine the mass of Sgr A* to be 4.0_-0.6^+10^6 M⊙."
CHARLES CHANG,Accounting for multicompetence and restructuring in the study of speech,"Phonetic studies meant to generalize to monolingual speakers of a target language have often examined individuals with considerable experience using another language, such as the immigrant native speaker. This paper presents, first, results from a meta-analysis of the literature, suggesting that conflation of ostensibly bilingual (“multicompetent”) individuals with monolinguals remains common practice and, second, longitudinal data on speech production that demonstrate why this practice is problematic. Adult native English speakers recently arrived in Korea showed significant changes in acoustic properties of their English production during their first weeks of learning Korean (“phonetic drift”) and, furthermore, continued to show altered English production a year later, months after their last Korean class and without extensive use of Korean in daily life. These patterns suggest that the linguistic experience associated with residence in a foreign language environment tends to induce and then prolong phonetic drift of the native language, making the multicompetent native speaker living in a foreign language environment unrepresentative of a monolingual in the native language environment. The speed and persistence of these effects highlight the need for language researchers to be explicit about the population under study and to accordingly control (and describe) language background in a study sample."
CHARLES CHANG,Examining the role of phoneme frequency in first language perceptual attrition,"In this paper, we follow up on previous findings concerning first language (L1) perceptual attrition to examine the role of phoneme frequency in influencing variation across L1 contrasts. We hypothesized that maintenance of L1 Korean contrasts (i.e., resistance to attrition) in L1 Korean-L2 English bilinguals would be correlated with frequency, such that better-maintained contrasts would also be more frequent in the L1. To explore this hypothesis, we collected frequency data on three Korean contrasts (/n/-/l/, /t/-/t*/, /s/-/s*/) and compared these data to perceptual attrition data from a speeded sequence recall task testing the perception and phonological encoding of the target contrasts. Results only partially supported the hypothesis. On the one hand, /n/-/l/, the best-maintained contrast, was the most frequent contrast overall. On the other hand, /n/-/l/ also evinced the greatest frequency asymmetry between the two members of the contrast (meaning that it was the least important to perceive accurately); furthermore, /s/-/s*/, which was less well maintained than /t/-/t*/, was actually more frequent than /t/-/t*/. These results suggest that disparities in perceptual attrition across contrasts cannot be attributed entirely to frequency differences. We discuss the implications of the findings for future research examining frequency effects in L1 perceptual change."
CHARLES CHANG,Exploring the onset of phonetic drift in voice onset time perception,"Recent exposure to a second or foreign language (FL) can influence production and/or perception in the first language (L1), a phenomenon referred to as phonetic drift. The smallest amount of FL exposure shown to effect drift in perception is 1.5 h. The present study examined L1 perception at earlier timepoints of FL exposure, to determine whether the phonetic system is able to resist FL influence at an incipient stage. In a longitudinal pre-test/post-test design, L1 English listeners were exposed to Tagalog under different conditions varying in attention directed to the voice onset time (VOT) plosive contrast in the FL; they then completed an identification task on L1 tokens from VOT continua. In every condition, the likelihood of “voiceless” identifications decreased. This change indicates a shift towards a longer VOT crossover point between “voiced” and “voiceless”, consistent with dissimilatory drift in perception. Listeners in a control condition, however, displayed a similar, albeit less lasting, change in L1 judgments, suggesting that the change arose partly from a task effect. We conclude by discussing directions for future research on phonetic drift in perception."
CHARLES CHANG,"On the auditory identifiability of Asian American identity in speech: the role of listener background, sociolinguistic awareness, and language ideologies","The current study examined the auditory identifiability of Asian American ethnoracial identity, including the role of listener characteristics and ideologies. Results of an identification experiment showed that the overall accuracy of ethnoracial identification on (East and Southeast) Asian talkers was low, but not the lowest among talker groups and not significantly different from accuracy on Black talkers. There were also significant effects of listeners' ethnoracial identity, gender, and linguistic chauvinism (i.e., disfavoring linguistic diversity in the US). In particular, being Asian or a woman was associated with a higher likelihood of accuracy, whereas greater linguistic chauvinism was, to an extent, associated with a lower likelihood of accuracy. Results of a discrimination experiment additionally showed an effect of listeners' awareness of ethnoracially-based language variation: having this awareness was associated with a higher likelihood of accuracy on discrimination trials with one or more Asian talkers. Taken together, these findings converge with previous results showing an effect of the listener's background on ethnoracial perception and further implicate the listener's sociolinguistic awareness and ideologies."
CHARLES CHANG,An individual-differences perspective on variation in heritage Mandarin speakers,"This chapter takes an individual-differences perspective on the dual sound systems of American heritage speakers (HSs) of Mandarin Chinese. Based on detailed socio-demographic data and production data on segmentals and suprasegmentals, we build holistic demographic and phonetic profiles for HSs, as well as native speakers and late learners, to explore how different aspects of their two languages (Mandarin, English) may develop in relation to each other and how individual variation in production may be related to socio-demographic factors. Using multiple factor analysis (MFA), we describe the range of these profiles, identify clusters of variation defined by different socio-demographic factors, and argue that some factors (e.g., age of arrival, language(s) spoken at home) have more predictive power for phonetic profiles than others. Overall, our results suggest a significant, if limited, link between socio-demographic factors and production, but only in Mandarin. We conclude by discussing the advantages and disadvantages of group-based and individual-centered approaches."
CHARLES CHANG,Event Horizon Telescope imaging of the archetypal blazar 3C 279 at an extreme 20 microarcsecond resolution,"3C 279 is an archetypal blazar with a prominent radio jet that show broadband flux density variability across the entire electromagnetic spectrum. We use an ultra-high angular resolution technique – global Very Long Baseline Interferometry (VLBI) at 1.3 mm (230 GHz) – to resolve the innermost jet of 3C 279 in order to study its fine-scale morphology close to the jet base where highly variable γ-ray emission is thought to originate, according to various models. The source was observed during four days in April 2017 with the Event Horizon Telescope at 230 GHz, including the phased Atacama Large Millimeter/submillimeter Array (ALMA), at an angular resolution of ∼20 μas (at a redshift of z = 0.536 this corresponds to ∼0.13 pc  ∼ 1700 Schwarzschild radii with a black hole mass M<jats:sub>BH</jats:sub> = 8 × 10^8 M_⊙). Imaging and model-fitting techniques were applied to the data to parameterize the fine-scale source structure and its variation. We find a multicomponent inner jet morphology with the northernmost component elongated perpendicular to the direction of the jet, as imaged at longer wavelengths. The elongated nuclear structure is consistent on all four observing days and across different imaging methods and model-fitting techniques, and therefore appears robust. Owing to its compactness and brightness, we associate the northern nuclear structure as the VLBI “core”. This morphology can be interpreted as either a broad resolved jet base or a spatially bent jet. We also find significant day-to-day variations in the closure phases, which appear most pronounced on the triangles with the longest baselines. Our analysis shows that this variation is related to a systematic change of the source structure. Two inner jet components move non-radially at apparent speeds of ∼15 c and ∼20 c (∼1.3 and ∼1.7 μas day^−1, respectively), which more strongly supports the scenario of traveling shocks or instabilities in a bent, possibly rotating jet. The observed apparent speeds are also coincident with the 3C 279 large-scale jet kinematics observed at longer (cm) wavelengths, suggesting no significant jet acceleration between the 1.3 mm core and the outer jet. The intrinsic brightness temperature of the jet components are ≲10^10 K, a magnitude or more lower than typical values seen at ≥7 mm wavelengths. The low brightness temperature and morphological complexity suggest that the core region of 3C 279 becomes optically thin at short (mm) wavelengths."
CHARLES CHANG,First M87 Event Horizon Telescope results. II. Array and instrumentation,"The Event Horizon Telescope (EHT) is a very long baseline interferometry (VLBI) array that comprises millimeter- and submillimeter-wavelength telescopes separated by distances comparable to the diameter of the Earth. At a nominal operating wavelength of ~1.3 mm, EHT angular resolution (λ/D) is ~25 μas, which is sufficient to resolve nearby supermassive black hole candidates on spatial and temporal scales that correspond to their event horizons. With this capability, the EHT scientific goals are to probe general relativistic effects in the strong-field regime and to study accretion and relativistic jet formation near the black hole boundary. In this Letter we describe the system design of the EHT, detail the technology and instrumentation that enable observations, and provide measures of its performance. Meeting the EHT science objectives has required several key developments that have facilitated the robust extension of the VLBI technique to EHT observing wavelengths and the production of instrumentation that can be deployed on a heterogeneous array of existing telescopes and facilities. To meet sensitivity requirements, high-bandwidth digital systems were developed that process data at rates of 64 gigabit s−1, exceeding those of currently operating cm-wavelength VLBI arrays by more than an order of magnitude. Associated improvements include the development of phasing systems at array facilities, new receiver installation at several sites, and the deployment of hydrogen maser frequency standards to ensure coherent data capture across the array. These efforts led to the coordination and execution of the first Global EHT observations in 2017 April, and to event-horizon-scale imaging of the supermassive black hole candidate in M87."
CHARLES CHANG,First M87 Event Horizon Telescope results. I. The shadow of the supermassive black hole,"When surrounded by a transparent emission region, black holes are expected to reveal a dark shadow caused by gravitational light bending and photon capture at the event horizon. To image and study this phenomenon, we have assembled the Event Horizon Telescope, a global very long baseline interferometry array observing at a wavelength of 1.3 mm. This allows us to reconstruct event-horizon-scale images of the supermassive black hole candidate in the center of the giant elliptical galaxy M87. We have resolved the central compact radio source as an asymmetric bright emission ring with a diameter of 42 ± 3 μas, which is circular and encompasses a central depression in brightness with a flux ratio gsim10:1. The emission ring is recovered using different calibration and imaging schemes, with its diameter and width remaining stable over four different observations carried out in different days. Overall, the observed image is consistent with expectations for the shadow of a Kerr black hole as predicted by general relativity. The asymmetry in brightness in the ring can be explained in terms of relativistic beaming of the emission from a plasma rotating close to the speed of light around a black hole. We compare our images to an extensive library of ray-traced general-relativistic magnetohydrodynamic simulations of black holes and derive a central mass of M = (6.5 ± 0.7) × 10^9 M ⊙. Our radio-wave observations thus provide powerful evidence for the presence of supermassive black holes in centers of galaxies and as the central engines of active galactic nuclei. They also present a new tool to explore gravity in its most extreme limit and on a mass scale that was so far not accessible."
CHARLES CHANG,The polarized image of a synchrotron-emitting ring of gas orbiting a black hole,"Synchrotron radiation from hot gas near a black hole results in a polarized image. The image polarization is determined by effects including the orientation of the magnetic field in the emitting region, relativistic motion of the gas, strong gravitational lensing by the black hole, and parallel transport in the curved spacetime. We explore these effects using a simple model of an axisymmetric, equatorial accretion disk around a Schwarzschild black hole. By using an approximate expression for the null geodesics derived by Beloborodov and conservation of the Walker–Penrose constant, we provide analytic estimates for the image polarization. We test this model using currently favored general relativistic magnetohydrodynamic simulations of M87*, using ring parameters given by the simulations. For a subset of these with modest Faraday effects, we show that the ring model broadly reproduces the polarimetric image morphology. Our model also predicts the polarization evolution for compact flaring regions, such as those observed from Sgr A* with GRAVITY. With suitably chosen parameters, our simple model can reproduce the EVPA pattern and relative polarized intensity in Event Horizon Telescope images of M87*. Under the physically motivated assumption that the magnetic field trails the fluid velocity, this comparison is consistent with the clockwise rotation inferred from total intensity images."
CHARLES CHANG,First Sagittarius A* Event Horizon Telescope results. I. The shadow of the supermassive black hole in the center of the Milky Way,"We present the first Event Horizon Telescope (EHT) observations of Sagittarius A* (Sgr A*), the Galactic center source associated with a supermassive black hole. These observations were conducted in 2017 using a global interferometric array of eight telescopes operating at a wavelength of λ = 1.3 mm. The EHT data resolve a compact emission region with intrahour variability. A variety of imaging and modeling analyses all support an image that is dominated by a bright, thick ring with a diameter of 51.8 ± 2.3 μas (68% credible interval). The ring has modest azimuthal brightness asymmetry and a comparatively dim interior. Using a large suite of numerical simulations, we demonstrate that the EHT images of Sgr A* are consistent with the expected appearance of a Kerr black hole with mass ∼4 × 106 M ⊙, which is inferred to exist at this location based on previous infrared observations of individual stellar orbits, as well as maser proper-motion studies. Our model comparisons disfavor scenarios where the black hole is viewed at high inclination (i &gt; 50°), as well as nonspinning black holes and those with retrograde accretion disks. Our results provide direct evidence for the presence of a supermassive black hole at the center of the Milky Way, and for the first time we connect the predictions from dynamical measurements of stellar orbits on scales of 103–105 gravitational radii to event-horizon-scale images and variability. Furthermore, a comparison with the EHT results for the supermassive black hole M87* shows consistency with the predictions of general relativity spanning over three orders of magnitude in central mass."
CHARLES CHANG,COMBREX: a project to accelerate the functional annotation of prokaryotic genomes,COMBREX (http://combrex.bu.edu) is a project to increase the speed of the functional annotation of new bacterial and archaeal genomes. It consists of a database of functional predictions produced by computational biologists and a mechanism for experimental biochemists to bid for the validation of those predictions. Small grants are available to support successful bids.
ROBERT REINHART,Electrical stimulation of visual cortex can immediately improve spatial vision,"SUMMARY We can improve human vision by correcting the optics of our lenses [1, 2, 3]. However, after the eye transduces the light, visual cortex has its own limitations that are challenging to correct [4]. Overcoming these limitations has typically involved innovative training regimes that improve vision across many days [5, 6]. In the present study, we wanted to determine whether it is possible to immediately improve the precision of spatial vision with noninvasive direct-current stimulation. Previous work suggested that visual processing could be modulated with such stimulation [7, 8, 9]. However, the short duration and variability of such effects made it seem unlikely that spatial vision could be improved for more than several minutes [7, 10]. Here we show that visual acuity in the parafoveal belt can be immediately improved by delivering noninvasive direct current to visual cortex. Twenty minutes of anodal stimulation improved subjects’ vernier acuity by approximately 15% and increased the amplitude of the earliest visually evoked potentials in lockstep with the behavioral effects. When we reversed the orientation of the electric field, we impaired resolution and reduced the amplitude of visually evoked potentials. Next, we found that anodal stimulation improved acuity enough to be measurable with the relatively coarse Snellen test and that subjects with the poorest acuity benefited the most from stimulation. Finally, we found that stimulation-induced acuity improvements were accompanied by changes in contrast sensitivity at high spatial frequencies."
ROBERT REINHART,Working memory revived in older adults by synchronizing rhythmic brain circuits,"Understanding normal brain aging and developing methods to maintain or improve cognition in older adults are major goals of fundamental and translational neuroscience. Here we show a core feature of cognitive decline—working-memory deficits—emerges from disconnected local and long-range circuits instantiated by theta–gamma phase–amplitude coupling in temporal cortex and theta phase synchronization across frontotemporal cortex. We developed a noninvasive stimulation procedure for modulating long-range theta interactions in adults aged 60–76 years. After 25 min of stimulation, frequency-tuned to individual brain network dynamics, we observed a preferential increase in neural synchronization patterns and the return of sender–receiver relationships of information flow within and between frontotemporal regions. The end result was rapid improvement in working-memory performance that outlasted a 50 min post-stimulation period. The results provide insight into the physiological foundations of age-related cognitive impairment and contribute to groundwork for future non-pharmacological interventions targeting aspects of cognitive decline."
ROBERT REINHART,Disruption and rescue of interareal theta phase coupling and adaptive behavior,"Rescuing executive functions in people with neurological and neuropsychiatric disorders has been a major goal of psychology and neuroscience for decades. Innovative computer-training regimes for executive functions have made tremendous inroads, yet the positive effects of training have not always translated into improved cognitive functioning and often take many days to emerge. In the present study, we asked whether it was possible to immediately change components of executive function by directly manipulating neural activity using a stimulation technology called high-definition transcranial alternating current stimulation (HD-tACS). Twenty minutes of inphase stimulation over medial frontal cortex (MFC) and right lateral prefrontal cortex (lPFC) synchronized theta (∼6 Hz) rhythms between these regions in a frequency and spatially specific manner and rapidly improved adaptive behavior with effects lasting longer than 40 min. In contrast, antiphase stimulation in the same individuals desynchronized MFC-lPFC theta phase coupling and impaired adaptive behavior. Surprisingly, the exogenously driven impairments in performance could be instantly rescued by reversing the phase angle of alternating current. The results suggest executive functions can be rapidly up- or down-regulated by modulating theta phase coupling of distant frontal cortical areas and can contribute to the development of tools for potentially normalizing executive dysfunction in patient populations."
ROBERT REINHART,F211. Finding and fixing attentional dysfunction in schizophrenia,"BACKGROUND Schizophrenia is the most debilitating health problem that exists, and its cognitive impairments are the greatest predictor of disability. Since the earliest clinical descriptions of the illness, abnormalities of attention have been at the core of the cognitive symptoms of schizophrenia. Theories of attentional dysfunction in schizophrenia propose that the deficits arise from either an inability to maintain working memory representations that guide attention, or difficulty focusing lower-level visual attention mechanisms. However, these theoretical accounts neglect the role of long-term memory representations in controlling attention. METHODS To test competing accounts of the etiology of cognitive deficits in schizophrenia, we devised a cued visual search task that allowed us to examine the integrity of the memory mechanisms that control attention and the lower-level mechanisms for focusing attention on visual inputs in patients with schizophrenia and demographically matched controls. In this task, a target object was cued at the beginning of each trial. The task-relevant cue signaled the identity of the target that could appear in the search array presented a second later. Then the target remained the same for three to seven consecutive trials (length of run randomized) before it was changed to a different object. While patients and controls were repeatedly searching for the same target object, we used electrophysiological measurements of brain activity to directly measure how they were focusing attention on the search targets, as well as how they recruited working memory and long-term memory representations to control attention as they searched for the task-relevant targets. In a second experiment, we used a causal manipulation of brain activity to provide converging evidence for our hypotheses regarding the locus of the attentional deficits in schizophrenia and to determine whether it is possible to improve attention in patients. This experiment was a double-blind, sham-controlled, within-subjects design using transcranial direct-current stimulation (tDCS) and established electroencephalographic (EEG) signatures of working memory, long-term memory, and attention. RESULTS Here, we show that the control of perceptual attention is impaired in people with schizophrenia, and that this impairment is driven by an inability to shift attentional control from working memory to long-term memory across practice. Contrary to predictions of the dominant models, this attentional impairment is observed in the face of exuberant neural activity indexing working memory and completely normal activity indexing the focusing of visual attention. Next, we provide converging evidence for the locus of attentional impairments in long-term memory by showing that noninvasive electrical stimulation of medial frontal cortex rectifies long-term memory related neural signatures and normalizes the ability of patients to find targets in complex visual scenes. DISCUSSION The findings challenge existing views of the locus of dysfunction underlying attentional impairments in schizophrenia. Moreover, the results highlight the crucial importance of long-term memory systems in controlling attention and associated abnormalities in the hippocampus and other brain areas in schizophrenia."
ROBERT REINHART,Role of N-methyl-D-aspartate receptors in action-based predictive coding deficits in schizophrenia,"BACKGROUND: Recent theoretical models of schizophrenia posit that dysfunction of the neural mechanisms subserving predictive coding contributes to symptoms and cognitive deficits, and this dysfunction is further posited to result from N-methyl-D-aspartate glutamate receptor (NMDAR) hypofunction. Previously, by examining auditory cortical responses to self-generated speech sounds, we demonstrated that predictive coding during vocalization is disrupted in schizophrenia. To test the hypothesized contribution of NMDAR hypofunction to this disruption, we examined the effects of the NMDAR antagonist, ketamine, on predictive coding during vocalization in healthy volunteers and compared them with the effects of schizophrenia. METHODS: In two separate studies, the N1 component of the event-related potential elicited by speech sounds during vocalization (talk) and passive playback (listen) were compared to assess the degree of N1 suppression during vocalization, a putative measure of auditory predictive coding. In the crossover study, 31 healthy volunteers completed two randomly ordered test days, a saline day and a ketamine day. Event-related potentials during the talk/listen task were obtained before infusion and during infusion on both days, and N1 amplitudes were compared across days. In the case-control study, N1 amplitudes from 34 schizophrenia patients and 33 healthy control volunteers were compared. RESULTS: N1 suppression to self-produced vocalizations was significantly and similarly diminished by ketamine (Cohen’s d = 1.14) and schizophrenia (Cohen’s d = .85). CONCLUSIONS: Disruption of NMDARs causes dysfunction in predictive coding during vocalization in a manner similar to the dysfunction observed in schizophrenia patients, consistent with the theorized contribution of NMDAR hypofunction to predictive coding deficits in schizophrenia."
ROBERT REINHART,Brain-state determines learning improvements after transcranial alternating-current stimulation to frontal cortex,"BACKGROUND Theories of executive control propose that communication between medial frontal cortex (MFC) and lateral prefrontal cortex (lPFC) is critical for learning. 6-Hz phase synchronization may be the mechanism by which neural activity between MFC and lPFC is coordinated into a functional network. Recent evidence suggests that switching from eyes closed to open may induce a change in brain-state reflected by enhanced executive control and related functional connectivity. OBJECTIVE/HYPOTHESIs To examine whether causal manipulation of MFC and lPFC can improve learning according to the brain-state induced by switching from eyes closed to open. METHODS Within-subjects, sham-controlled, double-blind study of 30 healthy subjects, each receiving 6-Hz in-phase high definition transcranial alternating-current stimulation (HD-tACS) applied to MFC and right lPFC prior to performing a time estimation task. RESULTS HD-tACS with eyes open improved learning ability relative to sham, whereas HD-tACS with eyes closed had no significant effect on behavior. CONCLUSION Results suggest a phase-sensitive mechanism in frontal cortex mediates components of learning performance in a state-dependent manner."
ROBERT REINHART,Using transcranial direct-current stimulation (tDCS) to understand cognitive processing,"Noninvasive brain stimulation methods are becoming increasingly common tools in the kit of the cognitive scientist. In particular, transcranial direct-current stimulation (tDCS) is showing great promise as a tool to causally manipulate the brain and understand how information is processed. The popularity of this method of brain stimulation is based on the fact that it is safe, inexpensive, its effects are long lasting, and you can increase the likelihood that neurons will fire near one electrode and decrease the likelihood that neurons will fire near another. However, this method of manipulating the brain to draw causal inferences is not without complication. Because tDCS methods continue to be refined and are not yet standardized, there are reports in the literature that show some striking inconsistencies. Primary among the complications of the technique is that the tDCS method uses two or more electrodes to pass current and all of these electrodes will have effects on the tissue underneath them. In this tutorial, we will share what we have learned about using tDCS to manipulate how the brain perceives, attends, remembers, and responds to information from our environment. Our goal is to provide a starting point for new users of tDCS and spur discussion of the standardization of methods to enhance replicability."
DANIEL R BROOKS,"The Incidence of Varicella and Herpes Zoster in Massachusetts as Measured by the Behavioral Risk Factor Surveillance System (BRFSS) during a Period of Increasing Varicella Vaccine Coverage, 1998–2003","BACKGROUND. The authors sought to monitor the impact of widespread varicella vaccination on the epidemiology of varicella and herpes zoster. While varicella incidence would be expected to decrease, mathematical models predict an initial increase in herpes zoster incidence if re-exposure to varicella protects against reactivation of the varicella zoster virus. METHODS. In 1998–2003, as varicella vaccine uptake increased, incidence of varicella and herpes zoster in Massachusetts was monitored using the random-digit-dial Behavioral Risk Factor Surveillance System. RESULTS. Between 1998 and 2003, varicella incidence declined from 16.5/1,000 to 3.5/1,000 (79%) overall with ≥66% decreases for all age groups except adults (27% decrease). Age-standardized estimates of overall herpes zoster occurrence increased from 2.77/1,000 to 5.25/1,000 (90%) in the period 1999–2003, and the trend in both crude and adjusted rates was highly significant (p < 0.001). Annual age-specific rates were somewhat unstable, but all increased, and the trend was significant for the 25–44 year and 65+ year age groups. CONCLUSION. As varicella vaccine coverage in children increased, the incidence of varicella decreased and the occurrence of herpes zoster increased. If the observed increase in herpes zoster incidence is real, widespread vaccination of children is only one of several possible explanations. Further studies are needed to understand secular trends in herpes zoster before and after use of varicella vaccine in the United States and other countries."
DANIEL R BROOKS,"Cosmology intertwined: a review of the particle physics, astrophysics, and cosmology associated with the cosmological tensions and anomalies",
DANIEL R BROOKS,Heat stress and heat strain among outdoor workers in El Salvador and Nicaragua,"BACKGROUND: There is growing attention on occupational heat stress in Central America, as workers in this region are affected by a unique form of chronic kidney disease. Previous studies have examined wet bulb globe temperatures and estimated metabolic rates to assess heat stress, but there are limited data characterizing heat strain among these workers. OBJECTIVE: The aims were to characterize heat stress and heat strain and examine whether job task, break duration, hydration practices, and kidney function were associated with heat strain. METHODS: We used data from the MesoAmerican Nephropathy Occupational Study, a cohort of 569 outdoor workers in El Salvador and Nicaragua who underwent workplace exposure monitoring, including continuous measurement of core body temperature (Tc), heart rate (HR), physical activity, and wet bulb globe temperature (WBGT), over the course of three days in January 2018 - May 2018. Participants represented five industries: sugarcane, corn, plantain, brickmaking, and construction. RESULTS: Median WBGTs were relatively high (>27 °C) at most sites, particularly when work shifts spanned the afternoon hours (e.g., 29.2 °C among plantain workers). Sugarcane workers, especially cane cutters in both countries and Nicaraguan agrichemical applicators, had the highest estimated metabolic rates (medians: 299-318 kcal/hr). Most workers spent little time on break (<10% of the shift), as determined by physical activity data. Overall, sugarcane workers-particularly those in Nicaragua-experienced the highest Tc and HR values. However, a few workers in other industries reached high Tc (>39 °C) as well. Impaired kidney function (estimated glomerular filtration rate <90 mL/min/1.73 m2) was associated with higher Tc and HR values, even after adjustment. SIGNIFICANCE: This is the largest study to-date examining heat stress and strain among outdoor workers in Central America. Workers at sugar companies regularly experienced Tc > 38°C (76.9% of monitored person-days at Nicaraguan companies; 46.5% at Salvadoran companies). Workers with impaired kidney function had higher measures of Tc and HR. IMPACT STATEMENT: This study examined levels of occupational heat stress and heat strain experienced among outdoor workers in five industries in El Salvador and Nicaragua. We characterized heat stress using wet bulb globe temperatures and estimated metabolic rate and heat strain using core body temperature and heart rate. Sugarcane workers, particularly cane cutters and Nicaraguan agrichemical applicators, performed more strenuous work and experienced greater levels of heat strain. Impaired kidney function was associated with higher heart rates and core body temperatures."
PETER M. BUSTON,De novo transcriptome assembly of the clown anemonefish (Amphiprion percula): a new resource to study the evolution of fish color,"A fundamental question of evolutionary biology is, why are some animals conspicuously colored? This question may be addressed from both a proximate (genetic and ontogenetic) and ultimate (adaptive value and evolutionary origins) perspective, and integrating these perspectives can provide further insights. Over the last few decades we have made great advances in understanding the causes of conspicuous coloration in terrestrial systems, e.g., birds and butterflies, but we still know relatively little about the causes of conspicuous, “poster” coloration in coral reef fishes. Of all coral reef fishes, the clownfish Amphiprion percula, is perhaps the most conspicuously colored, possessing a bright orange body with three iridescent white bars bordered with pitch black. Here, we review what is known about the proximate and ultimate causes of the conspicuous coloration of clownfishes Amphiprion sp.: coloration has a heritable genetic basis; coloration is influenced by development and environment; coloration has multiple plausible signaling functions; there is a phylogenetic component to coloration. Subsequently, to provide new insights into the genetic mechanisms and potential functions of A. percula coloration we (i) generate the first de novo transcriptome for this species, (ii) conduct differential gene expression analyses across different colored epidermal tissues, and (iii) conduct gene ontology (GO) enrichment analyses to characterize function of these differentially expressed genes. BUSCO indicated that transcriptome assembly was successful and many genes were found to be differentially expressed between epidermal tissues of different colors. In orange tissue, relative to white and black, many GO terms associated with muscle were over-represented. In white tissue, relative to orange and black tissue, there were very few over- or under-represented GO terms. In black tissue, relative to orange and white, many GO terms related to immune function were over-represented, supporting the hypothesis that black (melanin) coloration may serve a protective function. Overall, this study presents the assembly of the A. percula transcriptome, and represents a first step in an integrative investigation of the proximate and ultimate causes of conspicuous coloration of this iconic coral reef fish."
PETER M. BUSTON,The next frontier in understanding the evolution of coral reef fish societies,"Research on sociality in marine fishes is a vibrant field that is providing new insights into social evolution more generally. Here, we review the past two decades of research, identifying knowledge gaps and new directions. Two coral reef fishes, with social systems similar to other cooperative breeders, have emerged as models: the clown anemonefish Amphiprion percula and the emerald goby Paragobiodon xanthosoma. In these systems, non-breeders do not forgo their own reproduction to gain indirect genetic benefits. Rather, they do so because they stand to inherit the territory in the future and there are strong ecological and social constraints. The reasons why breeders tolerate non-breeders remain obscure, though it is plausibly a combination of weak kin selection, bet-hedging, and benefits mediated via mutualistic interactions with cnidarian hosts. The latter is particularly interesting, given the parallels with other social animals with mutualistic partners, such as acacia ants. Looking beyond the two model species, our attention is turning to species with more complex social organization, such as the damselfish Dascyllus aruanus. Here, variable group stability, conflict intensity, and reproductive skew provide opportunities to test theories of social evolution that have only been tested in a few taxa. New methods like social network analysis are enabling us to uncover more subtle effects of ecology on social interactions. More recently, comparative methods have yielded insights into the correlates of interspecific variation in sociality in the genera to which our model species belong. Phylogenetically controlled contrasts within the genus Gobiodon, have revealed the role of ecology, life history traits, and their interaction in sociality: smaller bodied species are more social than larger bodied species, which are only social on large corals. As climate change affects coral reefs, there is a pressing need to understand the many ways in which environmental disturbance influences these unique social systems. In sum, coral reef fishes have enabled us to test the robustness of current theories of social evolution in new taxa and environments, and they have generated new insights into social evolution that are applicable to a wider variety of taxa."
PETER M. BUSTON,Genetic relatedness in social groups of the emerald coral goby Paragobiodon xanthosoma creates potential for weak kin selection,"Animals forming social groups that include breeders and nonbreeders present evolutionary paradoxes; why do breeders tolerate nonbreeders? And why do nonbreeders tolerate their situation? Both paradoxes are often explained with kin selection. Kin selection is, however, assumed to play little or no role in social group formation of marine organisms with dispersive larval phases. Yet, in some marine organisms, recent evidence suggests small-scale patterns of relatedness, meaning that this assumption must always be tested. Here, we investigated the genetic relatedness of social groups of the emerald coral goby, Paragobiodon xanthosoma. We genotyped 73 individuals from 16 groups in Kimbe Bay, Papua New Guinea, at 20 microsatellite loci and estimated pairwise relatedness among all individuals. We found that estimated pairwise relatedness among individuals within groups was significantly higher than the pairwise relatedness among individuals from the same reef, and pairwise relatedness among individuals from the same reef was significantly higher than the pairwise relatedness among individuals from different reefs. This spatial signature suggests that there may be very limited dispersal in this species. The slightly positive relatedness within groups creates the potential for weak kin selection, which may help to resolve the paradox of why breeders tolerate subordinates in P. xanthosoma. The other paradox, why nonbreeders tolerate their situation, is better explained by alternative hypotheses such as territory inheritance, and ecological and social constraints. We show that even in marine animals with dispersive larval phases, kin selection needs to be considered to explain the evolution of complex social groups."
PETER M. BUSTON,"Reproduction, early development, and larval rearing strategies for two sponge-dwelling neon gobies, Elacatinus lori and E.colini","A major goal of the aquaculture industry is to reduce collection pressure on wild populations by developing captive breeding techniques for marine ornamental species, particularly coral reef fishes. The objective of this study was to develop a rearing protocol for two recently described species of neon gobies that are endemic to the Mesoamerican Barrier Reef: 1) Elacatinus lori; and 2) Elacatinus colini. First, the current study describes the reproductive behavior and larval development of both species. Second, it evaluates the effects of different rotifer and Artemia densities on the survival and growth of E. lori and E. colini larvae. Third, it compares the survival and growth of E. colini larvae fed wild plankton to those fed a combination of rotifers and Artemia. Once acclimated, pairs of E. lori began spawning in 53.2 ± 12.4 d (mean ± sd), while pairs of E. colini took only 12.2 ± 10.3 d. E. lori produced more embryos per clutch (1009 ± 477) than E. colini (168 ± 83). E. lori larvae hatched 8.18 ± 0.4 days after initial observation with a notochord length of 3.67 ± 0.2 mm. In comparison, E. colini larvae hatched 6.8 ± 0.4 days after initial observation with a notochord length of 3.51 ± 2.3 mm. Both species settled as early as 28 days post hatch at 9–9.5 mm standard length, following the fusion of the pelvic fins to form a pelvic disc. During rotifer density trials, from 0 to 6 days post hatch, there was no significant difference in survival or standard length between treatments fed 10, 15 or 20 rotifers ml^− 1 for either species. During Artemia density trials, from 6 to 14 days post hatch, control treatments fed solely on 15 rotifers ml^− 1 had significantly higher survival than treatments that were fed rotifers in combination with 3, 6 or 9 Artemia ml^− 1. Finally, E. colini larvae that were fed wild plankton had significantly higher survival and growth than those fed with a combination of 15 rotifers ml^− 1 and 3 Artemia ml^− 1. The results of this study suggest that Artemia nauplii are not a suitable prey for E. lori or E. colini larvae. Our results demonstrate the feasibility of rearing E. lori and E. colini to settlement, and suggest that 10–20 rotifers ml^− 1 and wild plankton provide a viable starting point for optimizing the survival and growth of Elacatinus spp. larvae."
PETER M. BUSTON,Strategic growth in social vertebrates,"Individual differences in growth and size of vertebrates often represent adaptive, plastic responses to contrasts in ecological conditions. Recent studies show that vertebrates can also modify their growth and size in an adaptive fashion in response to fine-grain changes in social conditions (which we refer to as strategic growth). Here, we review experimental evidence for strategic growth in social vertebrates. We describe a set of conditions under which strategic growth commonly occurs, and highlight potential examples of convergent evolution of strategic growth across the tree of life. This synthesis has implications for the way we think about organismal growth and size, because it underscores that the size of individuals can often be fine-tuned to their social environment."
PETER M. BUSTON,Offspring sex preferences among patrilineal and matrilineal Mosuo in Southwest China revealed by differences in parity progression,"Son preference predominates in China, yet there are patterned exceptions to this rule. In this paper, we test whether lineality (patrilineal versus matrilineal inheritance and descent) is associated with son versus daughter preference among the ethnic Mosuo (Na) of Southwest China. Our results show (i) an increased probability of continued fertility among matrilineal women after having a son compared with a daughter and (ii) an increased probability of continued fertility among patrilineal women after having a daughter compared with a son. These results are consistent with son preference among patrilineal Mosuo and more muted daughter preference among the matrilineal Mosuo. Furthermore, we show (iii) the lowest probability of continued fertility at parity 2 once women have one daughter and one son across both systems, suggesting that preferences for at least one of each sex exist alongside preferences for the lineal sex. The Mosuo are the only known small-scale society in which two kinship systems distinguish sub-groups with many otherwise shared cultural characteristics. We discuss why this, in conjunction with differences in subsistence, may shed light on the evolutionary underpinnings of offspring sex preferences."
PETER M. BUSTON,Vertebrate growth plasticity in response to variation in a mutualistic interaction,"Vertebrate growth can be phenotypically plastic in response to predator-prey and competitive interactions. It is unknown however, if it can be plastic in response to mutualistic interactions. Here we investigate plasticity of vertebrate growth in response to variation in mutualistic interactions, using clown anemonefish and their anemone hosts. In the wild, there is a positive correlation between the size of the fish and the size of the anemone, but the cause of this correlation is unknown. Plausible hypotheses are that fish exhibit growth plasticity in response to variation in food or space provided by the host. In the lab, we pair individuals with real anemones of various sizes and show that fish on larger anemones grow faster than fish on smaller anemones. By feeding the fish a constant food ration, we exclude variation in food availability as a cause. By pairing juveniles with artificial anemones of various sizes, we exclude variation in space availability as a single cause. We argue that variation in space availability in conjunction with host cues cause the variability in fish growth. By adjusting their growth, anemonefish likely maximize their reproductive value given their anemone context. More generally, we demonstrate vertebrate growth plasticity in response to variation in mutualistic interactions."
PETER M. BUSTON,Cognitive processes underlying human mate choice: the relationship between self-perception and mate preference in Western society,"This study tested two hypotheses concerning the cognitive processes underlying human mate choice in Western society: (i) mate preference is conditional in that the selectivity of individuals' mate preference is based on their perception of themselves as long-term partners, and (ii) the decision rule governing such conditional mate preference is based on translating perception of oneself on a given attribute into a comparable selectivity of preference for the same attribute in a mate. Both hypotheses were supported. A two-part questionnaire was completed by 978 heterosexual residents of Ithaca, New York, aged 18-24; they first rated the importance they placed on 10 attributes in a long-term partner and then rated their perception of themselves on those same attributes. Both women and men who rated themselves highly were significantly more selective in their mate preference. When the 10 attributes were grouped into four evolutionarily relevant categories (indicative of wealth and status, family commitment, physical appearance, and sexual fidelity), the greatest amount of variation in the selectivity of mate preference in each category was explained by self-perception in the same category of attributes. We conclude that, in Western society, humans use neither an ""opposites-attract"" nor a ""reproductive-potentials-attract"" decision rule in their choice of long-term partners but rather a ""likes-attract"" rule based on a preference for partners who are similar to themselves across a number of characteristics."
PETER M. BUSTON,Heritability of dispersal-related larval traits in the clown anemonefish Amphiprion percula,"A major goal of marine ecology is to identify the drivers of variation in larval dispersal. Larval traits are emerging as an important potential source of variation in dispersal outcomes, but little is known about how the evolution of these traits might shape dispersal patterns. Here, we consider the potential for adaptive evolution in two possibly dispersal-related traits by quantifying the heritability of larval size and swimming speed in the clown anemonefish (Amphiprion percula). Using a laboratory population of wild-caught A. percula, we measured the size and swimming speed of larvae from 24 half-sibling families. Phenotypic variance was partitioned into genetic and environmental components using a linear mixed-effects model. Importantly, by including half-siblings in the breeding design, we ensured that our estimates of genetic variance do not include nonheritable effects shared by clutches of full-siblings, which could lead to significant overestimates of heritability. We find unequivocal evidence for the heritability of larval body size (estimated between 0.21 and 0.34) and equivocal evidence for the heritability of swimming speed (between 0.05 and 0.19 depending on the choice of prior). From a methodological perspective, this work demonstrates the importance of evaluating sensitivity to prior distribution in Bayesian analysis. From a biological perspective, it advances our understanding of potential dispersal-related larval traits by quantifying the extent to which they can be inherited and thus have the potential for adaptive evolution."
PETER M. BUSTON,Description of surface transport in the region of the Belizean Barrier Reef based on observations and alternative high-resolution models,"The gains from implementing high-resolution versus less costly low-resolution models to describe coastal circulation are not always clear, often lacking statistical evaluation. Here we construct a hierarchy of ocean–atmosphere models operating at multiple scales within a 1 × 1° domain of the Belizean Barrier Reef (BBR). The various components of the atmosphere–ocean models are evaluated with in situ observations of surface drifters, wind and sea surface temperature. First, we compare the dispersion and velocity of 55 surface drifters released in the field in summer 2013 to the dispersion and velocity of simulated drifters under alternative model configurations. Increasing the resolution of the ocean model (from 1/12° to 1/100°, from 1 day to 1 h) and atmosphere model forcing (from 1/2° to 1/100°, from 6 h to 1 h), and incorporating tidal forcing incrementally reduces discrepancy between simulated and observed velocities and dispersion. Next, in trying to understand why the high-resolution models improve prediction, we find that resolving both the diurnal sea-breeze and semi-diurnal tides is key to improving the Lagrangian statistics and transport predictions along the BBR. Notably, the model with the highest ocean–atmosphere resolution and with tidal forcing generates a higher number of looping trajectories and sub-mesoscale coherent structures that are otherwise unresolved. Finally, simulations conducted with this model from June to August of 2013 show an intensification of the velocity fields throughout the summer and reveal a mesoscale anticyclonic circulation around Glovers Reef, and sub-mesoscale cyclonic eddies formed in the vicinity of Columbus Island. This study provides a general framework to assess the best surface transport prediction from alternative ocean–atmosphere models using metrics derived from high frequency drifters’ data and meteorological stations."
PETER M. BUSTON,"Patterns, causes, and consequences of marine larval dispersal","Quantifying the probability of larval exchange among marine populations is key to predicting local population dynamics and optimizing networks of marine protected areas. The pattern of connectivity among populations can be described by the measurement of a dispersal kernel. However, a statistically robust, empirical dispersal kernel has been lacking for any marine species. Here, we use genetic parentage analysis to quantify a dispersal kernel for the reef fish Elacatinus lori, demonstrating that dispersal declines exponentially with distance. The spatial scale of dispersal is an order of magnitude less than previous estimates—the median dispersal distance is just 1.7 km and no dispersal events exceed 16.4 km despite intensive sampling out to 30 km from source. Overlaid on this strong pattern is subtle spatial variation, but neither pelagic larval duration nor direction is associated with the probability of successful dispersal. Given the strong relationship between distance and dispersal, we show that distance-driven logistic models have strong power to predict dispersal probabilities. Moreover, connectivity matrices generated from these models are congruent with empirical estimates of spatial genetic structure, suggesting that the pattern of dispersal we uncovered reflects long-term patterns of gene flow. These results challenge assumptions regarding the spatial scale and presumed predictors of marine population connectivity. We conclude that if marine reserve networks aim to connect whole communities of fishes and conserve biodiversity broadly, then reserves that are close in space (<10 km) will accommodate those members of the community that are short-distance dispersers."
CHUNYU LIU,Genome-Wide Association Study for Subclinical Atherosclerosis in Major Arterial Territories in the NHLBI's Framingham Heart Study,"INTRODUCTION: Subclinical atherosclerosis (SCA) measures in multiple arterial beds are heritable phenotypes that are associated with increased incidence of cardiovascular disease. We conducted a genome-wide association study (GWAS) for SCA measurements in the community-based Framingham Heart Study. METHODS: Over 100,000 single nucleotide polymorphisms (SNPs) were genotyped (Human 100K GeneChip, Affymetrix) in 1345 subjects from 310 families. We calculated sex-specific age-adjusted and multivariable-adjusted residuals in subjects tested for quantitative SCA phenotypes, including ankle-brachial index, coronary artery calcification and abdominal aortic calcification using multi-detector computed tomography, and carotid intimal medial thickness (IMT) using carotid ultrasonography. We evaluated associations of these phenotypes with 70,987 autosomal SNPs with minor allele frequency ≥ 0.10, call rate ≥ 80%, and Hardy-Weinberg p-value ≥ 0.001 in samples ranging from 673 to 984 subjects, using linear regression with generalized estimating equations (GEE) methodology and family-based association testing (FBAT). Variance components LOD scores were also calculated. RESULTS. There was no association result meeting criteria for genome-wide significance, but our methods identified 11 SNPs with p < 10-5 by GEE and five SNPs with p < 10-5 by FBAT for multivariable-adjusted phenotypes. Among the associated variants were SNPs in or near genes that may be considered candidates for further study, such as rs1376877 (GEE p < 0.000001, located in ABI2) for maximum internal carotid artery IMT and rs4814615 (FBAT p = 0.000003, located in PCSK2) for maximum common carotid artery IMT. Modest significant associations were noted with various SCA phenotypes for variants in previously reported atherosclerosis candidate genes, including NOS3 and ESR1. Associations were also noted of a region on chromosome 9p21 with CAC phenotypes that confirm associations with coronary heart disease and CAC in two recently reported genome-wide association studies. In linkage analyses, several regions of genome-wide linkage were noted, confirming previously reported linkage of internal carotid artery IMT on chromosome 12. All GEE, FBAT and linkage results are provided as an open-access results resource at. CONCLUSION: The results from this GWAS generate hypotheses regarding several SNPs that may be associated with SCA phenotypes in multiple arterial beds. Given the number of tests conducted, subsequent independent replication in a staged approach is essential to identify genetic variants that may be implicated in atherosclerosis."
CHUNYU LIU,The Framingham Heart Study 100K SNP Genome-Wide Association Study Resource: Overview of 17 Phenotype Working Group Reports,"BACKGROUND: The Framingham Heart Study (FHS), founded in 1948 to examine the epidemiology of cardiovascular disease, is among the most comprehensively characterized multi-generational studies in the world. Many collected phenotypes have substantial genetic contributors; yet most genetic determinants remain to be identified. Using single nucleotide polymorphisms (SNPs) from a 100K genome-wide scan, we examine the associations of common polymorphisms with phenotypic variation in this community-based cohort and provide a full-disclosure, web-based resource of results for future replication studies. METHODS: Adult participants (n = 1345) of the largest 310 pedigrees in the FHS, many biologically related, were genotyped with the 100K Affymetrix GeneChip. These genotypes were used to assess their contribution to 987 phenotypes collected in FHS over 56 years of follow up, including: cardiovascular risk factors and biomarkers; subclinical and clinical cardiovascular disease; cancer and longevity traits; and traits in pulmonary, sleep, neurology, renal, and bone domains. We conducted genome-wide variance components linkage and population-based and family-based association tests. RESULTS: The participants were white of European descent and from the FHS Original and Offspring Cohorts (examination 1 Offspring mean age 32 ± 9 years, 54% women). This overview summarizes the methods, selected findings and limitations of the results presented in the accompanying series of 17 manuscripts. The presented association results are based on 70,897 autosomal SNPs meeting the following criteria: minor allele frequency ≥ 10%, genotype call rate ≥ 80%, Hardy-Weinberg equilibrium p-value ≥ 0.001, and satisfying Mendelian consistency. Linkage analyses are based on 11,200 SNPs and short-tandem repeats. Results of phenotype-genotype linkages and associations for all autosomal SNPs are posted on the NCBI dbGaP website at. CONCLUSION: We have created a full-disclosure resource of results, posted on the dbGaP website, from a genome-wide association study in the FHS. Because we used three analytical approaches to examine the association and linkage of 987 phenotypes with thousands of SNPs, our results must be considered hypothesis-generating and need to be replicated. Results from the FHS 100K project with NCBI web posting provides a resource for investigators to identify high priority findings for replication."
CHUNYU LIU,Genome-Wide Association with Diabetes-Related Traits in the Framingham Heart Study,"BACKGROUND: Susceptibility to type 2 diabetes may be conferred by genetic variants having modest effects on risk. Genome-wide fixed marker arrays offer a novel approach to detect these variants. METHODS: We used the Affymetrix 100K SNP array in 1,087 Framingham Offspring Study family members to examine genetic associations with three diabetes-related quantitative glucose traits (fasting plasma glucose (FPG), hemoglobin A1c, 28-yr time-averaged FPG (tFPG)), three insulin traits (fasting insulin, HOMA-insulin resistance, and 0–120 min insulin sensitivity index); and with risk for diabetes. We used additive generalized estimating equations (GEE) and family-based association test (FBAT) models to test associations of SNP genotypes with sex-age-age2-adjusted residual trait values, and Cox survival models to test incident diabetes. RESULTS: We found 415 SNPs associated (at p < 0.001) with at least one of the six quantitative traits in GEE, 242 in FBAT (18 overlapped with GEE for 639 non-overlapping SNPs), and 128 associated with incident diabetes (31 overlapped with the 639) giving 736 non-overlapping SNPs. Of these 736 SNPs, 439 were within 60 kb of a known gene. Additionally, 53 SNPs (of which 42 had r2 < 0.80 with each other) had p < 0.01 for incident diabetes AND (all 3 glucose traits OR all 3 insulin traits, OR 2 glucose traits and 2 insulin traits); of these, 36 overlapped with the 736 other SNPs. Of 100K SNPs, one (rs7100927) was in moderate LD (r2 = 0.50) with TCF7L2 (rs7903146), and was associated with risk of diabetes (Cox p-value 0.007, additive hazard ratio for diabetes = 1.56) and with tFPG (GEE p-value 0.03). There were no common (MAF > 1%) 100K SNPs in LD (r2 > 0.05) with ABCC8 A1369S (rs757110), KCNJ11 E23K (rs5219), or SNPs in CAPN10 or HNFa. PPARG P12A (rs1801282) was not significantly associated with diabetes or related traits. CONCLUSION: Framingham 100K SNP data is a resource for association tests of known and novel genes with diabetes and related traits posted at. Framingham 100K data replicate the TCF7L2 association with diabetes."
CHUNYU LIU,The Framingham Heart Study 100K SNP Genome-Wide Association Study Resource: Overview of 17 Phenotype Working Group Reports,"BACKGROUND: The Framingham Heart Study (FHS), founded in 1948 to examine the epidemiology of cardiovascular disease, is among the most comprehensively characterized multi-generational studies in the world. Many collected phenotypes have substantial genetic contributors; yet most genetic determinants remain to be identified. Using single nucleotide polymorphisms (SNPs) from a 100K genome-wide scan, we examine the associations of common polymorphisms with phenotypic variation in this community-based cohort and provide a full-disclosure, web-based resource of results for future replication studies. METHODS: Adult participants (n = 1345) of the largest 310 pedigrees in the FHS, many biologically related, were genotyped with the 100K Affymetrix GeneChip. These genotypes were used to assess their contribution to 987 phenotypes collected in FHS over 56 years of follow up, including: cardiovascular risk factors and biomarkers; subclinical and clinical cardiovascular disease; cancer and longevity traits; and traits in pulmonary, sleep, neurology, renal, and bone domains. We conducted genome-wide variance components linkage and population-based and family-based association tests. RESULTS: The participants were white of European descent and from the FHS Original and Offspring Cohorts (examination 1 Offspring mean age 32 ± 9 years, 54% women). This overview summarizes the methods, selected findings and limitations of the results presented in the accompanying series of 17 manuscripts. The presented association results are based on 70,897 autosomal SNPs meeting the following criteria: minor allele frequency ≥ 10%, genotype call rate ≥ 80%, Hardy-Weinberg equilibrium p-value ≥ 0.001, and satisfying Mendelian consistency. Linkage analyses are based on 11,200 SNPs and short-tandem repeats. Results of phenotype-genotype linkages and associations for all autosomal SNPs are posted on the NCBI dbGaP website at. CONCLUSION: We have created a full-disclosure resource of results, posted on the dbGaP website, from a genome-wide association study in the FHS. Because we used three analytical approaches to examine the association and linkage of 987 phenotypes with thousands of SNPs, our results must be considered hypothesis-generating and need to be replicated. Results from the FHS 100K project with NCBI web posting provides a resource for investigators to identify high priority findings for replication."
CHUNYU LIU,Comparisons of Case-Selection Approaches Based on Allele Sharing and/or Disease Severity Index: Application to the GAW14 Simulated Data,"For mapping complex disease traits, linkage studies are often followed by a case-control association strategy in order to identify disease-associated genes/single-nucleotide polymorphisms (SNPs). Substantial efforts are required in selecting the most informative cases from a large collection of affected individuals in order to maximize the power of the study, while taking into consideration study cost. In this article, we applied and extended three case-selection strategies that use allele-sharing information method for families with multiple affected offspring to select most informative cases using additional information on disease severity. Our results revealed that most significant associations, as measured by the lowest p-values, were obtained from a strategy that selected a case with the most allele sharing with other affected sibs from linked families (""linked-best""), despite reduction in sample size resulting from discarding unlinked families. Moreover, information on disease severity appears to be useful to improve the ability to detect associations between markers and disease loci."
CHUNYU LIU,Genome-wide association study for subclinical atherosclerosis in major arterial territories in the NHLBI's Framingham Heart Study,"INTRODUCTION:Subclinical atherosclerosis (SCA) measures in multiple arterial beds are heritable phenotypes that are associated with increased incidence of cardiovascular disease. We conducted a genome-wide association study (GWAS) for SCA measurements in the community-based Framingham Heart Study.METHODS:Over 100,000 single nucleotide polymorphisms (SNPs) were genotyped (Human 100K GeneChip, Affymetrix) in 1345 subjects from 310 families. We calculated sex-specific age-adjusted and multivariable-adjusted residuals in subjects tested for quantitative SCA phenotypes, including ankle-brachial index, coronary artery calcification and abdominal aortic calcification using multi-detector computed tomography, and carotid intimal medial thickness (IMT) using carotid ultrasonography. We evaluated associations of these phenotypes with 70,987 autosomal SNPs with minor allele frequency [greater than or equal to] 0.10, call rate [greater than or equal to] 80%, and Hardy-Weinberg p-value [greater than or equal to] 0.001 in samples ranging from 673 to 984 subjects, using linear regression with generalized estimating equations (GEE) methodology and family-based association testing (FBAT). Variance components LOD scores were also calculated.RESULTS:There was no association result meeting criteria for genome-wide significance, but our methods identified 11 SNPs with p < 10-5 by GEE and five SNPs with p < 10-5 by FBAT for multivariable-adjusted phenotypes. Among the associated variants were SNPs in or near genes that may be considered candidates for further study, such as rs1376877 (GEE p < 0.000001, located in ABI2) for maximum internal carotid artery IMT and rs4814615 (FBAT p = 0.000003, located in PCSK2) for maximum common carotid artery IMT. Modest significant associations were noted with various SCA phenotypes for variants in previously reported atherosclerosis candidate genes, including NOS3 and ESR1. Associations were also noted of a region on chromosome 9p21 with CAC phenotypes that confirm associations with coronary heart disease and CAC in two recently reported genome-wide association studies. In linkage analyses, several regions of genome-wide linkage were noted, confirming previously reported linkage of internal carotid artery IMT on chromosome 12. All GEE, FBAT and linkage results are provided as an open-access results resource at http://www.ncbi.nlm.nih.gov/projects/gap/cgi-bin/study.cgi?id=phs000007.CONCLUSION:The results from this GWAS generate hypotheses regarding several SNPs that may be associated with SCA phenotypes in multiple arterial beds. Given the number of tests conducted, subsequent independent replication in a staged approach is essential to identify genetic variants that may be implicated in atherosclerosis."
ANDREW ROBICHAUD,"Capitalist Pigs: Pigs, Pork, and Power in America. By J. L. Anderson",
JACOB BOR,"Trends in the burden of HIV mortality after roll-out of antiretroviral therapy in KwaZulu-Natal, South Africa: an observational community cohort study","BACKGROUND: Antiretroviral therapy (ART) substantially decreases morbidity and mortality in people living with HIV. In this study, we describe population-level trends in the adult life expectancy and trends in the residual burden of HIV mortality after the roll-out of a public sector ART programme in KwaZulu-Natal, South Africa, one of the populations with the most severe HIV epidemics in the world. METHODS AND FINDINGS: Data come from the Africa Centre Demographic Information System (ACDIS), an observational community cohort study in the uMkhanyakude district in northern KwaZulu-Natal, South Africa. We used non-parametric survival analysis methods to estimate gains in the population-wide life expectancy at age 15 years since the introduction of ART, and the shortfall of the population-wide adult life expectancy compared with that of the HIV-negative population (ie, the life expectancy defi cit). Life expectancy gains and defi cits were further disaggregated by age and cause of death with demographic decomposition methods. FINDINGS: Covering the calendar years 2001 through to 2014, we obtained information on 93 903 adults who jointly contribute 535 42 8 person-years of observation to the analyses and 9992 deaths. Since the roll-out of ART in 2004, adult life expectancy increased by 15·2 years for men (95% CI 12·4–17·8) and 17·2 years for women (14·5–20·2). Reductions in pulmonary tuberculosis and HIV-related mortality account for 79·7% of the total life expectancy gains in men (8·4 adult life-years), and 90·7% in women (12·8 adult life-years). For men, 9·5% is the result of a decline in external injuries. By 2014, the life expectancy defi cit had decreased to 1·2 years for men (–2·9 to 5·8) and to 5·3 years for women (2·6–7·8). In 2011–14, pulmonary tuberculosis and HIV were responsible for 84·9% of the life expectancy deficit in men and 80·8% in women. INTERPRETATION: The burden of HIV on adult mortality in this population is rapidly shrinking, but remains large for women, despite their better engagement with HIV-care services. Gains in adult life-years lived as well as the present life expectancy defi cit are almost exclusively due to differences in mortality attributed to HIV and pulmonary tuberculosis."
JACOB BOR,Imputing HIV treatment start dates from routine laboratory data in South Africa: a validation study.,"BACKGROUND: Poor clinical record keeping hinders health systems monitoring and patient care in many low resource settings. We develop and validate a novel method to impute dates of antiretroviral treatment (ART) initiation from routine laboratory data in South Africa's public sector HIV program. This method will enable monitoring of the national ART program using real-time laboratory data, avoiding the error potential of chart review. METHODS: We developed an algorithm to impute ART start dates based on the date of a patient's ""ART workup"", i.e. the laboratory tests used to determine treatment readiness in national guidelines, and the time from ART workup to initiation based on clinical protocols (21 days). To validate the algorithm, we analyzed data from two large clinical HIV cohorts: Hlabisa HIV Treatment and Care Programme in rural KwaZulu-Natal; and Right to Care Cohort in urban Gauteng. Both cohorts contain known ART initiation dates and laboratory results imported directly from the National Health Laboratory Service. We assessed median time from ART workup to ART initiation and calculated sensitivity (SE), specificity (SP), positive predictive value (PPV), and negative predictive value (NPV) of our imputed start date vs. the true start date within a 6 month window. Heterogeneity was assessed across individual clinics and over time. RESULTS: We analyzed data from over 80,000 HIV-positive adults. Among patients who had a workup and initiated ART, median time to initiation was 16 days (IQR 7,31) in Hlabisa and 21 (IQR 8,43) in RTC cohort. Among patients with known ART start dates, SE of the imputed start date was 83% in Hlabisa and 88% in RTC, indicating this method accurately predicts ART start dates for about 85% of all ART initiators. In Hlabisa, PPV was 95%, indicating that for patients with a lab workup, true start dates were predicted with high accuracy. SP (100%) and NPV (92%) were also very high. CONCLUSIONS: Routine laboratory data can be used to infer ART initiation dates in South Africa's public sector. Where care is provided based on protocols, laboratory data can be used to monitor health systems performance and improve accuracy and completeness of clinical records."
JACOB BOR,Effect of eliminating CD4-count thresholds on HIV treatment initiation in South Africa: An empirical modeling study,"BACKGROUND: The World Health Organization recommends initiating antiretroviral therapy (ART) regardless of CD4 count. We assessed the effect of ART eligibility on treatment uptake and simulated the impact of WHO’s recommendations in South Africa. METHODS: We conducted an empirical analysis of cohort data using a regression discontinuity design, and then used this model for policy simulation. We enrolled all patients (n = 19,279) diagnosed with HIV between August 2011 and December 2013 in the Hlabisa HIV Treatment and Care Programme in rural South Africa. Patients were ART-eligible with CD4<350 cells/mm3 or Stage III/IV illness. We estimated: (1) distribution of first CD4 counts in 2013; (2) probability of initiating ART ≤6 months of HIV diagnosis under existing criteria at each CD4 count; (3) probability of initiating ART by CD4 count if thresholds were eliminated; and (4) number of expected new initiators if South Africa eliminates thresholds. FINDINGS: In 2013, 38.9% of patients diagnosed had a CD4 count ≥500. 8.0% of these patients initiated even without eligible CD4 counts. If CD4 criteria were eliminated, we project that an additional 19.2% of patients with CD4 ≥500 would initiate ART; 72.8% would not initiate ART despite being eligible. Eliminating CD4 criteria would increase the number starting ART by 26.7%. If these numbers hold nationally, this would represent an additional 164,000 initiators per year, a 5.2% increase in patients receiving ART and 5.3% increase in programme costs. CONCLUSIONS: Removing CD4 criteria alone will modestly increase timely uptake of ART. However, our results suggest the majority of newly-eligible patients will not initiate. Improved testing, linkage, and initiation procedures are needed to achieve 90-90-90 targets."
JACOB BOR,Has the phasing out of stavudine in accordance with changes in WHO guidelines led to a decrease in single-drug substitutions in first-line antiretroviral therapy for HIV in sub-Saharan Africa?,"OBJECTIVE: We assessed the relationship between phasing out stavudine in first-line antiretroviral therapy (ART) in accordance with WHO 2010 policy and single-drug substitutions (SDS) (substituting the nucleoside reverse transcriptase inhibitor in first-line ART) in sub-Saharan Africa. DESIGN: Prospective cohort analysis (International epidemiological Databases to Evaluate AIDS-Multiregional) including ART-naive, HIV-infected patients aged at least 16 years, initiating ART between January 2005 and December 2012. Before April 2010 (July 2007 in Zambia) national guidelines called for patients to initiate stavudine-based or zidovudine-based regimen, whereas thereafter tenofovir or zidovudine replaced stavudine in first-line ART. METHODS: We evaluated the frequency of stavudine use and SDS by calendar year 2004-2014. Competing risk regression was used to assess the association between nucleoside reverse transcriptase inhibitor use and SDS in the first 24 months on ART. RESULTS: In all, 33 441 (8.9%; 95% confience interval 8.7-8.9%) SDS occurred among 377 656 patients in the first 24 months on ART, close to 40% of which were amongst patients on stavudine. The decrease in SDS corresponded with the phasing out of stavudine. Competing risks regression models showed that patients on tenofovir were 20-95% less likely to require a SDS than patients on stavudine, whereas patients on zidovudine had a 75-85% decrease in the hazards of SDS when compared to stavudine. CONCLUSION: The decline in SDS in the first 24 months on treatment appears to be associated with phasing out stavudine for zidovudine or tenofovir in first-line ART in our study. Further efforts to decrease the cost of tenofovir and zidovudine for use in this setting is warranted to substitute all patients still receiving stavudine."
DARREN ROBLYER,Performance assessment of diffuse optical spectroscopic imaging instruments in a 2-year multicenter breast cancer,"We present a framework for characterizing the performance of an experimental imaging technology, diffuse optical spectroscopic imaging (DOSI), in a 2-year multicenter American College of Radiology Imaging Network (ACRIN) breast cancer study (ACRIN-6691). DOSI instruments combine broadband frequency-domain photon migration with time-independent near-infrared (650 to 1000 nm) spectroscopy to measure tissue absorption and reduced scattering spectra and tissue hemoglobin, water, and lipid composition. The goal of ACRIN-6691 was to test the effectiveness of optically derived imaging endpoints in predicting the final pathologic response of neoadjuvant chemotherapy (NAC). Sixty patients were enrolled over a 2-year period at participating sites and received multiple DOSI scans prior to and during 3- to 6-month NAC. The impact of three sources of error on accuracy and precision, including different operators, instruments, and calibration standards, was evaluated using a broadband reflectance standard and two different solid tissue-simulating optical phantoms. Instruments showed <0.0010  mm−1 (10.3%) and 0.06  mm−1 (4.7%) deviation in broadband absorption and reduced scattering, respectively, over the 2-year duration of ACRIN-6691. These variations establish a useful performance criterion for assessing instrument stability. The proposed procedures and tests are not limited to DOSI; rather, they are intended to provide methods to characterize performance of any instrument used in translational optical imaging."
DARREN ROBLYER,Spatial frequency domain imaging for monitoring immune-mediated chemotherapy treatment response and resistance in a murine breast cancer model,"Spatial Frequency Domain Imaging (SFDI) can provide longitudinal, label-free, and widefield hemodynamic and scattering measurements of murine tumors in vivo. Our previous work has shown that the reduced scattering coefficient (μ's) at 800 nm, as well as the wavelength dependence of scattering, both have prognostic value in tracking apoptosis and proliferation during treatment with anti-cancer therapies. However, there is limited work in validating these optical biomarkers in clinically relevant tumor models that manifest specific treatment resistance mechanisms that mimic the clinical setting. It was recently demonstrated that metronomic dosing of cyclophosphamide induces a strong anti-tumor immune response and tumor volume reduction in the E0771 murine breast cancer model. This immune activation mechanism can be blocked with an IFNAR-1 antibody, leading to treatment resistance. Here we present a longitudinal study utilizing SFDI to monitor this paired responsive-resistant model for up to 30 days of drug treatment. Mice receiving the immune modulatory metronomic cyclophosphamide schedule had a significant increase in tumor optical scattering compared to mice receiving cyclophosphamide in combination with the IFNAR-1 antibody (9% increase vs 10% decrease on day 5 of treatment, p < 0.001). The magnitude of these differences increased throughout the duration of treatment. Additionally, scattering changes on day 4 of treatment could discriminate responsive versus resistant tumors with an accuracy of 78%, while tumor volume had an accuracy of only 52%. These results validate optical scattering as a promising prognostic biomarker that can discriminate between treatment responsive and resistant tumor models."
DARREN ROBLYER,Compressive remodeling alters fluid transport properties of collagen networks - implications for tumor growth,"Biomechanical alterations to the tumor microenvironment include accumulation of solid stresses, extracellular matrix (ECM) stiffening and increased fluid pressure in both interstitial and peri-tumoral spaces. The relationship between interstitial fluid pressurization and ECM remodeling in vascularized tumors is well characterized, while earlier biomechanical changes occurring during avascular tumor growth within the peri-tumoral ECM remain poorly understood. Type I collagen, the primary fibrous ECM constituent, bears load in tension while it buckles under compression. We hypothesized that tumor-generated compressive forces cause collagen remodeling via densification which in turn creates a barrier to convective fluid transport and may play a role in tumor progression and malignancy. To better understand this process, we characterized the structure-function relationship of collagen networks under compression both experimentally and computationally. Here we show that growth of epithelial cancers induces compressive remodeling of the ECM, documented in the literature as a TACS-2 phenotype, which represents a localized densification and tangential alignment of peri-tumoral collagen. Such compressive remodeling is caused by the unique features of collagen network mechanics, such as fiber buckling and cross-link rupture, and reduces the overall hydraulic permeability of the matrix."
DARREN ROBLYER,Fluorescence lifetime imaging microscopy (FLIM) reveals spatial-metabolic changes in 3D breast cancer spheroids,"Cancer cells are mechanically sensitive to physical properties of the microenvironment, which can affect downstream signaling to promote malignancy, in part through the modulation of metabolic pathways. Fluorescence Lifetime Imaging Microscopy (FLIM) can be used to measure the fluorescence lifetime of endogenous fluorophores, such as the metabolic co-factors NAD(P)H and FAD, in live samples. We used multiphoton FLIM to investigate the changes in cellular metabolism of 3D breast spheroids derived from MCF-10A and MD-MB-231 cell lines embedded in collagen with varying densities (1 vs. 4 mg/ml) over time (Day 0 vs. Day 3). MCF-10A spheroids demonstrated spatial gradients, with the cells closest to the spheroid edge exhibiting FLIM changes consistent with a shift towards oxidative phosphorylation (OXPHOS) while the spheroid core had changes consistent with a shift towards glycolysis. The MDA-MB-231 spheroids had a large shift consistent with increased OXPHOS with a more pronounced change at the higher collagen concentration. The MDA-MB-231 spheroids invaded into the collagen gel over time and cells that traveled the farthest had the largest changes consistent with a shift towards OXPHOS. Overall, these results suggest that the cells in contact with the extracellular matrix (ECM) and those that migrated the farthest had changes consistent with a metabolic shift towards OXPHOS. More generally, these results demonstrate the ability of multiphoton FLIM to characterize how spheroids metabolism and spatial metabolic gradients are modified by physical properties of the 3D ECM."
TYLER PERRACHIONE,Speaker recognition across languages,"Listeners identify voices more accurately in their native language than an unknown, foreign language, in a phenomenon known as the language-familiarity effect in talker identification. This effect has been reliably observed for a wide range of different language pairings and using a variety of different methodologies, including voice line-ups, talker identification training, and talker discrimination. What do listeners know about their native language that helps them recognize voices more accurately? Do listeners gain access to this knowledge when they learn a second language? Is linguistic competence necessary, or can mere exposure to a foreign language help listeners identify voices more accurately? In this chapter, I review the more than three decades of research on the language-familiarity effect in talker identification with an emphasis on how attention to this phenomenon can inform not only better psychological and neural models of memory for voices, but also better models of speech processing."
TYLER PERRACHIONE,Learning to identify emotional voices,"Recognizing people by the sound of their voice is an important social skill. What listeners hear as a talker's “voice” is a highly variable signal, the acoustic features of which can change dramatically depending on situational factors such as a talker's emotional state when speaking or the linguistic content of an utterance. A challenge for listeners in talker identification is to maintain perceptual constancy of talker identity across different situations. We investigated listeners’ ability to learn to identify voices from emotional speech and generalize their knowledge of talker identity to new emotional contexts. Listeners learned to identify voices from utterances spoken with neutral, angry, or fearful vocal affects and were then tested on their ability to identify those voices from both trained and untrained affects. Listeners learned talker identity equally well regardless of which emotion was expressed during training. However, in all cases, changing the vocal affect of the speech at test resulted in a significant decrement in talker identification accuracy. These results elucidate how emotional variability impacts social auditory perception: The phonetic changes to speech resulting from the vocal expression of emotion can obscure the correspondence between speech acoustics and talker identity expected by listeners."
TYLER PERRACHIONE,Shared neuroanatomical substrates of impaired phonological working memory across reading disability and autism,"BACKGROUND: Individuals with reading disability or individuals with autism spectrum disorder (ASD) are characterized, respectively, by their difficulties in reading or social communication, but both groups often have impaired phonological working memory (PWM). It is not known whether the impaired PWM reflects distinct or shared neuroanatomical abnormalities in these two diagnostic groups. METHODS: White-matter structural connectivity via diffusion weighted imaging was examined in sixty-four children, ages 5-17 years, with reading disability, ASD, or typical development (TD), who were matched in age, gender, intelligence, and diffusion data quality. RESULTS: Children with reading disability and children with ASD exhibited reduced PWM compared to children with TD. The two diagnostic groups showed altered white-matter microstructure in the temporo-parietal portion of the left arcuate fasciculus (AF) and in the temporo-occipital portion of the right inferior longitudinal fasciculus (ILF), as indexed by reduced fractional anisotropy and increased radial diffusivity. Moreover, the structural integrity of the right ILF was positively correlated with PWM ability in the two diagnostic groups, but not in the TD group. CONCLUSIONS: These findings suggest that impaired PWM is transdiagnostically associated with shared neuroanatomical abnormalities in ASD and reading disability. Microstructural characteristics in left AF and right ILF may play important roles in the development of PWM. The right ILF may support a compensatory mechanism for children with impaired PWM."
TYLER PERRACHIONE,Altered engagement of the speech motor network is associated with reduced phonological working memory in autism,"Nonword repetition, a common clinical measure of phonological working memory, involves component processes of speech perception, working memory, and speech production. Autistic children often show behavioral challenges in nonword repetition, as do many individuals with communication disorders. It is unknown which subprocesses of phonological working memory are vulnerable in autistic individuals, and whether the same brain processes underlie the transdiagnostic difficulty with nonword repetition. We used functional magnetic resonance imaging (fMRI) to investigate the brain bases for nonword repetition challenges in autism. We compared activation during nonword repetition in functional brain networks subserving speech perception, working memory, and speech production between neurotypical and autistic children. Autistic children performed worse than neurotypical children on nonword repetition and had reduced activation in response to increasing phonological working memory load in the supplementary motor area. Multivoxel pattern analysis within the speech production network classified shorter vs longer nonword-repetition trials less accurately for autistic than neurotypical children. These speech production motor-specific differences were not observed in a group of children with reading disability who had similarly reduced nonword repetition behavior. These findings suggest that atypical function in speech production brain regions may contribute to nonword repetition difficulties in autism."
TYLER PERRACHIONE,Pitch contour perception test (PCPT),"A computer-based assessment in PsychoPy to ascertain aptitude for lexical tone learning. The zip archive includes stimulus files, stimulus-presentation scripts, methods and procedure descriptions, and an annotated bibliography. See Wong & Perrachione (2007) in Applied Psycholinguistics for the original description of this test."
TYLER PERRACHIONE,Noninvasive neurostimulation of left ventral motor cortex enhances sensorimotor adaptation in speech production,"Sensorimotor adaptation¬—enduring changes to motor commands due to sensory feedback—allows speakers to match their articulations to intended speech acoustics. How the brain integrates auditory feedback to modify speech motor commands and what limits the degree of these modifications remain unknown. Here, we investigated the role of speech motor cortex in modifying stored speech motor plans. In a within-subjects design, participants underwent separate sessions of sham and anodal transcranial direct current stimulation (tDCS) over speech motor cortex while speaking and receiving altered auditory feedback of the first formant. Anodal tDCS increased the rate of sensorimotor adaptation for feedback perturbation. Computational modeling of our results using the Directions Into Velocities of Articulators (DIVA) framework of speech production suggested that tDCS primarily affected behavior by increasing the feedforward learning rate. This study demonstrates how focal noninvasive neurostimulation can enhance the integration of auditory feedback into speech motor plans."
TYLER PERRACHIONE,Representation of semantic typicality in brain activation in healthy adults and individuals with aphasia: a multi-voxel pattern analysis,"This study aimed to investigate brain regions that show different activation patterns between semantically typical and atypical items in both healthy adults and individuals with aphasia (PWA). Eighteen neurologically healthy adults and twenty-one PWA participated in an fMRI semantic feature verification task that included typical and atypical stimuli from five different semantic categories. A whole-brain searchlight multi-voxel pattern analysis (MVPA) was conducted to classify brain activation patterns between typical and atypical conditions in each participant group separately. Behavioral responses were faster and more accurate for typical vs. atypical items across both groups. The searchlight MVPA identified two significant clusters in healthy adults: left middle occipital gyrus and right calcarine cortex, but no significant clusters were found in PWA. A follow-up analysis in PWA revealed a significant association between neural classification of semantic typicality in the left middle occipital gyrus and reaction times in the fMRI task. When the typicality effect was examined for each semantic category at the univariate level, significance was identified in the visual cortex for fruits in both groups of participants. These findings suggest that semantic typicality was modulated in the visual cortex in healthy individuals, but to a lesser extent in the same region in PWA."
TYLER PERRACHIONE,Time and information in perceptual adaptation to speech,"Perceptual adaptation to a talker enables listeners to efficiently resolve the many-to-many mapping between variable speech acoustics and abstract linguistic representations. However, models of speech perception have not delved into the variety or the quantity of information necessary for successful adaptation, nor how adaptation unfolds over time. In three experiments using speeded classification of spoken words, we explored how the quantity (duration), quality (phonetic detail), and temporal continuity of talker-specific context contribute to facilitating perceptual adaptation to speech. In single- and mixed-talker conditions, listeners identified phonetically-confusable target words in isolation or preceded by carrier phrases of varying lengths and phonetic content, spoken by the same talker as the target word. Word identification was always slower in mixed-talker conditions than single-talker ones. However, interference from talker variability decreased as the duration of preceding speech increased but was not affected by the amount of preceding talker-specific phonetic information. Furthermore, efficiency gains from adaptation depended on temporal continuity between preceding speech and the target word. These results suggest that perceptual adaptation to speech may be understood via models of auditory streaming, where perceptual continuity of an auditory object (e.g., a talker) facilitates allocation of attentional resources, resulting in more efficient perceptual processing."
TYLER PERRACHIONE,Sensorimotor adaptation to auditory perturbation of speech is facilitated by noninvasive brain stimulation,"Repeated exposure to disparity between the motor plan and auditory feedback during speech production results in a proportionate change in the motor system’s response called auditory-motor adaptation. Artificially raising F1 in auditory feedback results in a concomitant decrease in F1 during speech production. Transcranial direct current stimulation (tDCS) can be used to alter neuronal excitability in focal areas of the brain. The present experiment explored the effect of noninvasive brain stimulation applied to the speech premotor cortex on the timing and magnitude of adaptation responses to artificially raised F1 in auditory feedback. Participants (N = 18) completed a speaking task in which they read target words aloud. Participants' speech was processed to raise F1 by 30% and played back to them over headphones in real time. A within-subjects design compared acoustics of participants’ speech while receiving anodal (active) tDCS stimulation versus sham (control) stimulation. Participants' speech showed an increasing magnitude of adaptation of F1 over time during anodal stimulation compared to sham. These results indicate that tDCS can affect behavioral response during auditory-motor adaptation, which may have translational implications for sensorimotor training in speech disorders."
EVE MANZ,Designing for home-based science learning: infrastructuring within new openings and constraints,"We describe efforts to use blurred home-school boundaries in the COVID-19 pandemic to co-design learning activities that provide new opportunities for teachers, students, and families to engage with science practices together. This work aims to support the intellectual and cultural resources of home and family life during this pandemic and beyond in ways that draw from and repurpose existing infrastructures. We share our design evolution, including commitments, ongoing tensions, and responses to constraints"
EVE MANZ,Characterizing pedagogical decisions in sense-making conversations motivated by scientific uncertainty,
EVE MANZ,Examining elementary teachers’ puzzles: a cross-disciplinary analysis,"We present a cross-disciplinary analysis of the puzzles and tensions elementary teachers experience as they conduct classroom discussion. We describe two teachers’ framings and sense-making about the puzzle of how (much) to steer discussion in light of instructional goals, considering similarities and differences across teachers and disciplines. This work is part of a project to understand how elementary teachers learn to conduct classroom discussions in ways that support deep disciplinary learning and seek to disrupt settled expectations of disciplines, children, and teaching (Bang, Warren, Rosebery, & Medin, 2012). We assume that systems of oppression permeate teaching and learning, for example, through curriculum structures, how subject matter is constituted, and privileged ways of speaking and acting (Bang et al, 2012; Esmonde & Booker, 2016). This poster shares how we have sought to understand the puzzles and tensions that elementary teachers experience as they conduct classroom discussion. We focus on puzzles because they provide windows into teacher sense-making and they may reveal opportunities to work with teachers around their own concerns at the intersection of disciplines, classroom discourse, and power. When teachers frame and try to make sense of puzzles and tensions, they draw upon practices, curriculum materials, and categories for labeling students (Hall & Horn, 2012) that inevitably reflect the dominant ideologies of society, school disciplines, and disciplinary knowing (Louie, 2020). We are interested in understanding how teachers' puzzles and tensions might be similar and different across school disciplines. While elementary teachers typically work with one group of children across content areas, researchers have tended to approach studying and supporting teachers’ practice from the perspective of a particular discipline (e.g., mathematics). We seek to understand how the puzzles and tensions that emerge for teachers might be shaped by school disciplines, and how they can serve to make visible the contradictions and dominant ideologies of larger systems."
EVE MANZ,Unpacking dimensions of evidentiary knowledge and reasoning in the teaching and learning of science,
EVE MANZ,Designing for and analyzing productive uncertainty in science investigations,
EVE MANZ,Interlocking models as sites of modeling practice and conceptual innovation,"A central goal of both professional and classroom-based scientific communities is building and testing explanatory models of the natural world. The process of modeling a complex phenomenon often requires working across representational systems of differing scales, modalities, and purposes. When put into contact, entities across multiple representational systems can become related or “interlock.” This paper describes how students drew from multiple representational systems to construct “interlocking models” and how reasoning with interlocking models supported meaningful practice and conceptual innovation. We present the design and findings from the implementation of a fifth-grade investigation into the conservation of matter. We describe the process of how contradictions between representational systems surfaced and led to interlocking models. Our findings suggest that students can recognize and take up interlocking models that provide a purpose for students to critique and refine their understanding."
ROBERT M JOSEPH,First M87 Event Horizon Telescope results. III. Data processing and calibration,"We present the calibration and reduction of Event Horizon Telescope (EHT) 1.3 mm radio wavelength observations of the supermassive black hole candidate at the center of the radio galaxy M87 and the quasar 3C 279, taken during the 2017 April 5–11 observing campaign. These global very long baseline interferometric observations include for the first time the highly sensitive Atacama Large Millimeter/submillimeter Array (ALMA); reaching an angular resolution of 25 μas, with characteristic sensitivity limits of ~1 mJy on baselines to ALMA and ~10 mJy on other baselines. The observations present challenges for existing data processing tools, arising from the rapid atmospheric phase fluctuations, wide recording bandwidth, and highly heterogeneous array. In response, we developed three independent pipelines for phase calibration and fringe detection, each tailored to the specific needs of the EHT. The final data products include calibrated total intensity amplitude and phase information. They are validated through a series of quality assurance tests that show consistency across pipelines and set limits on baseline systematic errors of 2% in amplitude and 1° in phase. The M87 data reveal the presence of two nulls in correlated flux density at ~3.4 and ~8.3 Gλ and temporal evolution in closure quantities, indicating intrinsic variability of compact structure on a timescale of days, or several light-crossing times for a few billion solar-mass black hole. These measurements provide the first opportunity to image horizon-scale structure in M87."
ROBERT M JOSEPH,First M87 Event Horizon Telescope results. V. Physical origin of the asymmetric ring,"The Event Horizon Telescope (EHT) has mapped the central compact radio source of the elliptical galaxy M87 at 1.3 mm with unprecedented angular resolution. Here we consider the physical implications of the asymmetric ring seen in the 2017 EHT data. To this end, we construct a large library of models based on general relativistic magnetohydrodynamic (GRMHD) simulations and synthetic images produced by general relativistic ray tracing. We compare the observed visibilities with this library and confirm that the asymmetric ring is consistent with earlier predictions of strong gravitational lensing of synchrotron emission from a hot plasma orbiting near the black hole event horizon. The ring radius and ring asymmetry depend on black hole mass and spin, respectively, and both are therefore expected to be stable when observed in future EHT campaigns. Overall, the observed image is consistent with expectations for the shadow of a spinning Kerr black hole as predicted by general relativity. If the black hole spin and M87's large scale jet are aligned, then the black hole spin vector is pointed away from Earth. Models in our library of non-spinning black holes are inconsistent with the observations as they do not produce sufficiently powerful jets. At the same time, in those models that produce a sufficiently powerful jet, the latter is powered by extraction of black hole spin energy through mechanisms akin to the Blandford-Znajek process. We briefly consider alternatives to a black hole for the central compact object. Analysis of existing EHT polarization data and data taken simultaneously at other wavelengths will soon enable new tests of the GRMHD models, as will future EHT campaigns at 230 and 345 GHz."
ROBERT M JOSEPH,First M87 Event Horizon Telescope results. VI. The shadow and mass of the central black hole,"We present measurements of the properties of the central radio source in M87 using Event Horizon Telescope data obtained during the 2017 campaign. We develop and fit geometric crescent models (asymmetric rings with interior brightness depressions) using two independent sampling algorithms that consider distinct representations of the visibility data. We show that the crescent family of models is statistically preferred over other comparably complex geometric models that we explore. We calibrate the geometric model parameters using general relativistic magnetohydrodynamic (GRMHD) models of the emission region and estimate physical properties of the source. We further fit images generated from GRMHD models directly to the data. We compare the derived emission region and black hole parameters from these analyses with those recovered from reconstructed images. There is a remarkable consistency among all methods and data sets. We find that >50% of the total flux at arcsecond scales comes from near the horizon, and that the emission is dramatically suppressed interior to this region by a factor >10, providing direct evidence of the predicted shadow of a black hole. Across all methods, we measure a crescent diameter of 42 ± 3 μas and constrain its fractional width to be <0.5. Associating the crescent feature with the emission surrounding the black hole shadow, we infer an angular gravitational radius of GM/Dc^2 = 3.8 ± 0.4 μas. Folding in a distance measurement of {16.8}_{-0.7}^{+0.8}{Mpc} gives a black hole mass of M = 6.5 ± 0.2{| }_{stat} ± 0.7{| }_{sys} × {10}^{9} {M}_{odot }. This measurement from lensed emission near the event horizon is consistent with the presence of a central Kerr black hole, as predicted by the general theory of relativity."
ROBERT M JOSEPH,"Bostonia: v. 13, no. 1-10",
ROBERT M JOSEPH,Analysis of existing mathematics textbooks for use in secondary schools.,
ROBERT M JOSEPH,"New and improved demonstrations, each illustrating a single scientific paper",
ROBERT M JOSEPH,What America means to sixth grade children.,
ROBERT M JOSEPH,"Bostonia: v. 17, no. 1-9",
ROBERT M JOSEPH,"BMQ : Boston medical quarterly: v. 8, no. 1-4",
ROBERT M JOSEPH,"BMQ : Boston medical quarterly: v. 2, no. 1-4",
ROBERT M JOSEPH,Awake mouse imaging: from two-photon microscopy to blood oxygen level-dependent functional magnetic resonance imaging,"BACKGROUND: Functional magnetic resonance imaging (fMRI) in awake behaving mice is well positioned to bridge the detailed cellular-level view of brain activity, which has become available owing to recent advances in microscopic optical imaging and genetics, to the macroscopic scale of human noninvasive observables. However, though microscopic (e.g., two-photon imaging) studies in behaving mice have become a reality in many laboratories, awake mouse fMRI remains a challenge. Owing to variability in behavior among animals, performing all types of measurements within the same subject is highly desirable and can lead to higher scientific rigor. METHODS: We demonstrated blood oxygenation level-dependent fMRI in awake mice implanted with long-term cranial windows that allowed optical access for microscopic imaging modalities and optogenetic stimulation. We started with two-photon imaging of single-vessel diameter changes (n = 1). Next, we implemented intrinsic optical imaging of blood oxygenation and flow combined with laser speckle imaging of blood flow obtaining a mesoscopic picture of the hemodynamic response (n = 16). Then we obtained corresponding blood oxygenation level-dependent fMRI data (n = 5). All measurements could be performed in the same mice in response to identical sensory and optogenetic stimuli. RESULTS: The cranial window did not deteriorate the quality of fMRI and allowed alternation between imaging modalities in each subject. CONCLUSIONS: This report provides a proof of feasibility for multiscale imaging approaches in awake mice. In the future, this protocol could be extended to include complex cognitive behaviors translatable to humans, such as sensory discrimination or attention."
ROBERT M JOSEPH,"Bostonia: v. 44, no. 2, 4",
ROBERT M JOSEPH,"Bostonia: v. 6, no. 1-10",
ROBERT M JOSEPH,"Scope: v. 1, no. 1-8",
ROBERT M JOSEPH,First Sagittarius A* Event Horizon Telescope results. V. Testing astrophysical models of the galactic center black hole,"In this paper we provide a first physical interpretation for the Event Horizon Telescope's (EHT) 2017 observations of Sgr A*. Our main approach is to compare resolved EHT data at 230 GHz and unresolved non-EHT observations from radio to X-ray wavelengths to predictions from a library of models based on time-dependent general relativistic magnetohydrodynamics simulations, including aligned, tilted, and stellar-wind-fed simulations; radiative transfer is performed assuming both thermal and nonthermal electron distribution functions. We test the models against 11 constraints drawn from EHT 230 GHz data and observations at 86 GHz, 2.2 μm, and in the X-ray. All models fail at least one constraint. Light-curve variability provides a particularly severe constraint, failing nearly all strongly magnetized (magnetically arrested disk (MAD)) models and a large fraction of weakly magnetized models. A number of models fail only the variability constraints. We identify a promising cluster of these models, which are MAD and have inclination i ≤ 30°. They have accretion rate (5.2–9.5) × 10−9 M ⊙ yr−1, bolometric luminosity (6.8–9.2) × 1035 erg s−1, and outflow power (1.3–4.8) × 1038 erg s−1. We also find that all models with i ≥ 70° fail at least two constraints, as do all models with equal ion and electron temperature; exploratory, nonthermal model sets tend to have higher 2.2 μm flux density; and the population of cold electrons is limited by X-ray constraints due to the risk of bremsstrahlung overproduction. Finally, we discuss physical and numerical limitations of the models, highlighting the possible importance of kinetic effects and duration of the simulations."
ROBERT M JOSEPH,First M87 Event Horizon Telescope results. VII. Polarization of the ring,"In 2017 April, the Event Horizon Telescope (EHT) observed the near-horizon region around the supermassive black hole at the core of the M87 galaxy. These 1.3 mm wavelength observations revealed a compact asymmetric ring-like source morphology. This structure originates from synchrotron emission produced by relativistic plasma located in the immediate vicinity of the black hole. Here we present the corresponding linear-polarimetric EHT images of the center of M87. We find that only a part of the ring is significantly polarized. The resolved fractional linear polarization has a maximum located in the southwest part of the ring, where it rises to the level of ∼15%. The polarization position angles are arranged in a nearly azimuthal pattern. We perform quantitative measurements of relevant polarimetric properties of the compact emission and find evidence for the temporal evolution of the polarized source structure over one week of EHT observations. The details of the polarimetric data reduction and calibration methodology are provided. We carry out the data analysis using multiple independent imaging and modeling techniques, each of which is validated against a suite of synthetic data sets. The gross polarimetric structure and its apparent evolution with time are insensitive to the method used to reconstruct the image. These polarimetric images carry information about the structure of the magnetic fields responsible for the synchrotron emission. Their physical interpretation is discussed in an accompanying publication."
ROBERT M JOSEPH,First M87 Event Horizon Telescope results. VIII. Magnetic field structure near The Event Horizon,"Event Horizon Telescope (EHT) observations at 230 GHz have now imaged polarized emission around the supermassive black hole in M87 on event-horizon scales. This polarized synchrotron radiation probes the structure of magnetic fields and the plasma properties near the black hole. Here we compare the resolved polarization structure observed by the EHT, along with simultaneous unresolved observations with the Atacama Large Millimeter/submillimeter Array, to expectations from theoretical models. The low fractional linear polarization in the resolved image suggests that the polarization is scrambled on scales smaller than the EHT beam, which we attribute to Faraday rotation internal to the emission region. We estimate the average density n_e ∼ 10^4–7 cm^−3, magnetic field strength B ∼ 1–30 G, and electron temperature T_e ∼ (1–12) × 10^10 K of the radiating plasma in a simple one-zone emission model. We show that the net azimuthal linear polarization pattern may result from organized, poloidal magnetic fields in the emission region. In a quantitative comparison with a large library of simulated polarimetric images from general relativistic magnetohydrodynamic (GRMHD) simulations, we identify a subset of physical models that can explain critical features of the polarimetric EHT observations while producing a relativistic jet of sufficient power. The consistent GRMHD models are all of magnetically arrested accretion disks, where near-horizon magnetic fields are dynamically important. We use the models to infer a mass accretion rate onto the black hole in M87 of (3–20) × 10^−4 M ⊙ yr^−1."
ROBERT M JOSEPH,Resolving the inner parsec of the blazar J1924–2914 with the event horizon telescope,"The blazar J1924–2914 is a primary Event Horizon Telescope (EHT) calibrator for the Galactic center’s black hole Sagittarius A*. Here we present the first total and linearly polarized intensity images of this source obtained with the unprecedented 20 μas resolution of the EHT. J1924–2914 is a very compact flat-spectrum radio source with strong optical variability and polarization. In April 2017 the source was observed quasi-simultaneously with the EHT (April 5–11), the Global Millimeter VLBI Array (April 3), and the Very Long Baseline Array (April 28), giving a novel view of the source at four observing frequencies, 230, 86, 8.7, and 2.3 GHz. These observations probe jet properties from the subparsec to 100 pc scales. We combine the multifrequency images of J1924–2914 to study the source morphology. We find that the jet exhibits a characteristic bending, with a gradual clockwise rotation of the jet projected position angle of about 90° between 2.3 and 230 GHz. Linearly polarized intensity images of J1924–2914 with the extremely fine resolution of the EHT provide evidence for ordered toroidal magnetic fields in the blazar compact core."
ROBERT M JOSEPH,Imaging X-ray polarimetry explorer: prelaunch,"Launched on 2021 December 9, the Imaging X-ray Polarimetry Explorer (IXPE) is a NASA Small Explorer Mission in collaboration with the Italian Space Agency (ASI). The mission will open a new window of investigation—imaging x-ray polarimetry. The observatory features three identical telescopes, each consisting of a mirror module assembly with a polarization-sensitive imaging x-ray detector at the focus. A coilable boom, deployed on orbit, provides the necessary 4-m focal length. The observatory utilizes a three-axis-stabilized spacecraft, which provides services such as power, attitude determination and control, commanding, and telemetry to the ground. During its 2-year baseline mission, IXPE will conduct precise polarimetry for samples of multiple categories of x-ray sources, with follow-on observations of selected targets."
ROBERT M JOSEPH,"Bostonia: v. 10, no. 1-10",
ROBERT M JOSEPH,Genetic Analysis Workshop 15: Gene Expression Analysis and Approaches to Detecting Multiple Functional Loci,
ROBERT M JOSEPH,"Bostonia: v. 9, no. 1-10",
ROBERT M JOSEPH,A universal power-law prescription for variability from synthetic images of black hole accretion flows,"We present a framework for characterizing the spatiotemporal power spectrum of the variability expected from the horizon-scale emission structure around supermassive black holes, and we apply this framework to a library of general relativistic magnetohydrodynamic (GRMHD) simulations and associated general relativistic ray-traced images relevant for Event Horizon Telescope (EHT) observations of Sgr A*. We find that the variability power spectrum is generically a red-noise process in both the temporal and spatial dimensions, with the peak in power occurring on the longest timescales and largest spatial scales. When both the time-averaged source structure and the spatially integrated light-curve variability are removed, the residual power spectrum exhibits a universal broken power-law behavior. On small spatial frequencies, the residual power spectrum rises as the square of the spatial frequency and is proportional to the variance in the centroid of emission. Beyond some peak in variability power, the residual power spectrum falls as that of the time-averaged source structure, which is similar across simulations; this behavior can be naturally explained if the variability arises from a multiplicative random field that has a steeper high-frequency power-law index than that of the time-averaged source structure. We briefly explore the ability of power spectral variability studies to constrain physical parameters relevant for the GRMHD simulations, which can be scaled to provide predictions for black holes in a range of systems in the optically thin regime. We present specific expectations for the behavior of the M87* and Sgr A* accretion flows as observed by the EHT."
ROBERT M JOSEPH,Millimeter light curves of Sagittarius A* observed during the 2017 Event Horizon Telescope campaign,"The Event Horizon Telescope (EHT) observed the compact radio source, Sagittarius A* (Sgr A*), in the Galactic Center on 2017 April 5–11 in the 1.3 mm wavelength band. At the same time, interferometric array data from the Atacama Large Millimeter/submillimeter Array and the Submillimeter Array were collected, providing Sgr A* light curves simultaneous with the EHT observations. These data sets, complementing the EHT very long baseline interferometry, are characterized by a cadence and signal-to-noise ratio previously unattainable for Sgr A* at millimeter wavelengths, and they allow for the investigation of source variability on timescales as short as a minute. While most of the light curves correspond to a low variability state of Sgr A*, the April 11 observations follow an X-ray flare and exhibit strongly enhanced variability. All of the light curves are consistent with a red-noise process, with a power spectral density (PSD) slope measured to be between −2 and −3 on timescales between 1 minute and several hours. Our results indicate a steepening of the PSD slope for timescales shorter than 0.3 hr. The spectral energy distribution is flat at 220 GHz, and there are no time lags between the 213 and 229 GHz frequency bands, suggesting low optical depth for the event horizon scale source. We characterize Sgr A*’s variability, highlighting the different behavior observed just after the X-ray flare, and use Gaussian process modeling to extract a decorrelation timescale and a PSD slope. We also investigate the systematic calibration uncertainties by analyzing data from independent data reduction pipelines."
ROBERT M JOSEPH,Selective dynamical imaging of interferometric data,"Recent developments in very long baseline interferometry (VLBI) have made it possible for the Event Horizon Telescope (EHT) to resolve the innermost accretion flows of the largest supermassive black holes on the sky. The sparse nature of the EHT’s (u, v)-coverage presents a challenge when attempting to resolve highly time-variable sources. We demonstrate that the changing (u, v)-coverage of the EHT can contain regions of time over the course of a single observation that facilitate dynamical imaging. These optimal time regions typically have projected baseline distributions that are approximately angularly isotropic and radially homogeneous. We derive a metric of coverage quality based on baseline isotropy and density that is capable of ranking array configurations by their ability to produce accurate dynamical reconstructions. We compare this metric to existing metrics in the literature and investigate their utility by performing dynamical reconstructions on synthetic data from simulated EHT observations of sources with simple orbital variability. We then use these results to make recommendations for imaging the 2017 EHT Sgr A* data set."
ROBERT M JOSEPH,"Response Monitoring, Repetitive Behaviour and Anterior Cingulate Abnormalities in Autism Spectrum Disorders (ASD)","Autism spectrum disorders (ASD) are characterized by inflexible and repetitive behaviour. Response monitoring involves evaluating the consequences of behaviour and making adjustments to optimize outcomes. Deficiencies in this function, and abnormalities in the anterior cingulate cortex (ACC) on which it relies, have been reported as contributing factors to autistic disorders. We investigated whether ACC structure and function during response monitoring were associated with repetitive behaviour in ASD. We compared ACC activation to correct and erroneous antisaccades using rapid presentation event-related functional MRI in 14 control and ten ASD participants. Because response monitoring is the product of coordinated activity in ACC networks, we also examined the microstructural integrity of the white matter (WM) underlying this brain region using diffusion tensor imaging (DTI) measures of fractional anisotropy (FA) in 12 control and 12 adult ASD participants. ACC activation and FA were examined in relation to Autism Diagnostic Interview-Revised ratings of restricted and repetitive behaviour. Relative to controls, ASD participants: (i) made more antisaccade errors and responded more quickly on correct trials; (ii) showed reduced discrimination between error and correct responses in rostral ACC (rACC), which was primarily due to (iii) abnormally increased activation on correct trials and (iv) showed reduced FA in WM underlying ACC. Finally, in ASD (v) increased activation on correct trials and reduced FA in rACC WM were related to higher ratings of repetitive behaviour. These findings demonstrate functional and structural abnormalities of the ACC in ASD that may contribute to repetitive behaviour. rACC activity following errors is thought to reflect affective appraisal of the error. Thus, the hyperactive rACC response to correct trials can be interpreted as a misleading affective signal that something is awry, which may trigger repetitive attempts at correction. Another possible consequence of reduced affective discrimination between error and correct responses is that it might interfere with the reinforcement of responses that optimize outcomes. Furthermore, dysconnection of the ACC, as suggested by reduced FA, to regions involved in behavioural control might impair on-line modulations of response speed to optimize performance (i.e. speed-accuracy trade-off) and increase error likelihood. These findings suggest that in ASD, structural and functional abnormalities of the ACC compromise response monitoring and thereby contribute to behaviour that is rigid and repetitive rather than flexible and responsive to contingencies. Illuminating the mechanisms and clinical significance of abnormal response monitoring in ASD represents a fruitful avenue for further research."
ROBERT M JOSEPH,"Forty-Three Loci Associated with Plasma Lipoprotein Size, Concentration, and Cholesterol Content in Genome-Wide Analysis","While conventional LDL-C, HDL-C, and triglyceride measurements reflect aggregate properties of plasma lipoprotein fractions, NMR-based measurements more accurately reflect lipoprotein particle concentrations according to class (LDL, HDL, and VLDL) and particle size (small, medium, and large). The concentrations of these lipoprotein sub-fractions may be related to risk of cardiovascular disease and related metabolic disorders. We performed a genome-wide association study of 17 lipoprotein measures determined by NMR together with LDL-C, HDL-C, triglycerides, ApoA1, and ApoB in 17,296 women from the Women's Genome Health Study (WGHS). Among 36 loci with genome-wide significance (P<5×10−8) in primary and secondary analysis, ten (PCCB/STAG1 (3q22.3), GMPR/MYLIP (6p22.3), BTNL2 (6p21.32), KLF14 (7q32.2), 8p23.1, JMJD1C (10q21.3), SBF2 (11p15.4), 12q23.2, CCDC92/DNAH10/ZNF664 (12q24.31.B), and WIPI1 (17q24.2)) have not been reported in prior genome-wide association studies for plasma lipid concentration. Associations with mean lipoprotein particle size but not cholesterol content were found for LDL at four loci (7q11.23, LPL (8p21.3), 12q24.31.B, and LIPG (18q21.1)) and for HDL at one locus (GCKR (2p23.3)). In addition, genetic determinants of total IDL and total VLDL concentration were found at many loci, most strongly at LIPC (15q22.1) and APOC-APOE complex (19q13.32), respectively. Associations at seven more loci previously known for effects on conventional plasma lipid measures reveal additional genetic influences on lipoprotein profiles and bring the total number of loci to 43. Thus, genome-wide associations identified novel loci involved with lipoprotein metabolism—including loci that affect the NMR-based measures of concentration or size of LDL, HDL, and VLDL particles—all characteristics of lipoprotein profiles that may impact disease risk but are not available by conventional assay. Author Summary Genome-wide association studies (GWAS) of plasma lipoprotein fractions hold great promise for understanding lipid metabolism and its central role in cardiovascular disease and related disorders. Conventional assays for lipoprotein status determine total cholesterol content of low- or high-density lipoprotein particles (LDL-C or HDL-C, respectively) or total plasma triglyceride content (as an estimate of very-low density lipoprotein particle concentration [VLDL]). All three measures have been targets for recent GWAS. However, a more precise target for GWAS of lipoprotein metabolism would be the concentration of the individual lipoprotein particles according to class (LDL, HDL, VLDL) and size (small, medium, and large), all of which can be measured by NMR-based methods. In a population of 17,296 women of European ancestry from the Women's Genome Health Study, we have performed a GWAS for 22 lipoprotein measures derived from NMR-based and conventional assays. We find 43 genetic loci involved in lipoprotein metabolism, including 10 novel loci. The results offer a clearer picture of common genetic influences on lipoprotein metabolism than available previously, including genetic effects on the distribution of LDL, HDL, and VLDL particle size, as well as on IDL and VLDL particle concentration, neither of which can be assessed by conventional measures."
ROBERT M JOSEPH,First Sagittarius A* Event Horizon Telescope results. VI. Testing the black hole metric,"Astrophysical black holes are expected to be described by the Kerr metric. This is the only stationary, vacuum, axisymmetric metric, without electromagnetic charge, that satisfies Einstein’s equations and does not have pathologies outside of the event horizon. We present new constraints on potential deviations from the Kerr prediction based on 2017 EHT observations of Sagittarius A* (Sgr A*). We calibrate the relationship between the geometrically defined black hole shadow and the observed size of the ring-like images using a library that includes both Kerr and non-Kerr simulations. We use the exquisite prior constraints on the mass-to-distance ratio for Sgr A* to show that the observed image size is within ∼10% of the Kerr predictions. We use these bounds to constrain metrics that are parametrically different from Kerr, as well as the charges of several known spacetimes. To consider alternatives to the presence of an event horizon, we explore the possibility that Sgr A* is a compact object with a surface that either absorbs and thermally reemits incident radiation or partially reflects it. Using the observed image size and the broadband spectrum of Sgr A*, we conclude that a thermal surface can be ruled out and a fully reflective one is unlikely. We compare our results to the broader landscape of gravitational tests. Together with the bounds found for stellar-mass black holes and the M87 black hole, our observations provide further support that the external spacetimes of all black holes are described by the Kerr metric, independent of their mass."
ROBERT M JOSEPH,Polarimetric properties of Event Horizon Telescope targets from ALMA,"We present the results from a full polarization study carried out with the Atacama Large Millimeter/submillimeter Array (ALMA) during the first Very Long Baseline Interferometry (VLBI) campaign, which was conducted in 2017 April in the λ3 mm and λ1.3 mm bands, in concert with the Global mm-VLBI Array (GMVA) and the Event Horizon Telescope (EHT), respectively. We determine the polarization and Faraday properties of all VLBI targets, including Sgr A*, M87, and a dozen radio-loud active galactic nuclei (AGNs), in the two bands at several epochs in a time window of 10 days. We detect high linear polarization fractions (2%–15%) and large rotation measures (RM &gt; 103.3–105.5 rad m−2), confirming the trends of previous AGN studies at millimeter wavelengths. We find that blazars are more strongly polarized than other AGNs in the sample, while exhibiting (on average) order-of-magnitude lower RM values, consistent with the AGN viewing angle unification scheme. For Sgr A* we report a mean RM of (−4.2 ± 0.3) × 105 rad m−2 at 1.3 mm, consistent with measurements over the past decade and, for the first time, an RM of (–2.1 ± 0.1) × 105 rad m−2 at 3 mm, suggesting that about half of the Faraday rotation at 1.3 mm may occur between the 3 mm photosphere and the 1.3 mm source. We also report the first unambiguous measurement of RM toward the M87 nucleus at millimeter wavelengths, which undergoes significant changes in magnitude and sign reversals on a one year timescale, spanning the range from −1.2 to 0.3 × 105 rad m−2 at 3 mm and −4.1 to 1.5 × 105 rad m−2 at 1.3 mm. Given this time variability, we argue that, unlike the case of Sgr A*, the RM in M87 does not provide an accurate estimate of the mass accretion rate onto the black hole. We put forward a two-component model, comprised of a variable compact region and a static extended region, that can simultaneously explain the polarimetric properties observed by both the EHT (on horizon scales) and ALMA (which observes the combined emission from both components). These measurements provide critical constraints for the calibration, analysis, and interpretation of simultaneously obtained VLBI data with the EHT and GMVA."
ROBERT M JOSEPH,"First Sagittarius A* Event Horizon Telescope results. IV. Variability, morphology, and black hole mass","In this paper we quantify the temporal variability and image morphology of the horizon-scale emission from Sgr A*, as observed by the EHT in 2017 April at a wavelength of 1.3 mm. We find that the Sgr A* data exhibit variability that exceeds what can be explained by the uncertainties in the data or by the effects of interstellar scattering. The magnitude of this variability can be a substantial fraction of the correlated flux density, reaching ∼100% on some baselines. Through an exploration of simple geometric source models, we demonstrate that ring-like morphologies provide better fits to the Sgr A* data than do other morphologies with comparable complexity. We develop two strategies for fitting static geometric ring models to the time-variable Sgr A* data; one strategy fits models to short segments of data over which the source is static and averages these independent fits, while the other fits models to the full data set using a parametric model for the structural variability power spectrum around the average source structure. Both geometric modeling and image-domain feature extraction techniques determine the ring diameter to be 51.8 ± 2.3 μas (68% credible intervals), with the ring thickness constrained to have an FWHM between ∼30% and 50% of the ring diameter. To bring the diameter measurements to a common physical scale, we calibrate them using synthetic data generated from GRMHD simulations. This calibration constrains the angular size of the gravitational radius to be 4.8_-0.7^+1.4 μas, which we combine with an independent distance measurement from maser parallaxes to determine the mass of Sgr A* to be 4.0_-0.6^+10^6 M⊙."
ROBERT M JOSEPH,"Cosmology intertwined: a review of the particle physics, astrophysics, and cosmology associated with the cosmological tensions and anomalies",
ROBERT M JOSEPH,An experimental study of word learning in minimally verbal children and adolescents with autism spectrum disorder,"BACKGROUND AND AIMS: When children hear a novel word, they tend to associate it with a novel rather than a familiar object. The ability to map a novel word to its corresponding referent is thought to depend, at least in part, on language-learning strategies, such as mutual exclusivity and lexical contrast. Although the importance of word learning strategies has been broadly investigated in typically developing children as well as younger children with autism spectrum disorder, who are usually language delayed, there is a paucity of research on such strategies and their role in language learning in school-age children and adolescents with autism spectrum disorder who have failed to develop fluent speech. In this study, we examined the ability of minimally verbal children and adolescents with autism spectrum disorder to learn and retain novel words in an experimental task, as well as the cognitive, language, and social correlates of these abilities. We were primarily interested in the characteristics that differentiated between three subgroups of participants: those unable to use word learning strategies, particularly mutual exclusivity, to learn novel words; those able to learn novel words over several exposure trials but not able retain them; and those able to retain the words they learned. METHODS: Participants were 29 minimally verbal individuals with autism spectrum disorder from 5 to 17 years of age. Participants completed a computerized touchscreen novel-word-learning procedure followed by assessments of immediate retention and of delayed retention, two hours later. Participants were grouped according to whether they passed/failed at least 7 of 8 (binomial p < .035) novel word learning trials and 7 of 8 immediate or delayed retention trials, and were compared on measures of nonverbal IQ, receptive and expressive vocabulary, phonological processing, joint attention and symptom severity. RESULTS: Of 29 participants, 14 failed both learning and immediate retention, 8 passed learning but failed immediate retention, and 7 passed both learning and immediate retention. Group performance was highly similar for delayed retention. Language level, particularly expressive vocabulary, differentiated between participants who did and did not succeed in retention, even while controlling for differences in nonverbal IQ. CONCLUSIONS: The ability of minimally verbal school-age children and adolescents with autism spectrum disorder to identify the referents of novel words was associated with nonverbal cognitive abilities. Retention of words was associated with concurrent expressive language abilities. Implications Our findings of associations between the retention of novel words acquired in a lab-based experimental task and concurrent language ability warrants further investigation with larger samples and longitudinal research designs, which may support the incorporation of contrastive word learning strategies into language learning interventions for severely language-impaired individuals with autism spectrum disorder."
ROBERT M JOSEPH,"First Sagittarius A* Event Horizon Telescope results. II. EHT and multiwavelength observations, data processing, and calibration","We present Event Horizon Telescope (EHT) 1.3 mm measurements of the radio source located at the position of the supermassive black hole Sagittarius A* (Sgr A*), collected during the 2017 April 5–11 campaign. The observations were carried out with eight facilities at six locations across the globe. Novel calibration methods are employed to account for Sgr A*'s flux variability. The majority of the 1.3 mm emission arises from horizon scales, where intrinsic structural source variability is detected on timescales of minutes to hours. The effects of interstellar scattering on the image and its variability are found to be subdominant to intrinsic source structure. The calibrated visibility amplitudes, particularly the locations of the visibility minima, are broadly consistent with a blurred ring with a diameter of ∼50 μas, as determined in later works in this series. Contemporaneous multiwavelength monitoring of Sgr A* was performed at 22, 43, and 86 GHz and at near-infrared and X-ray wavelengths. Several X-ray flares from Sgr A* are detected by Chandra, one at low significance jointly with Swift on 2017 April 7 and the other at higher significance jointly with NuSTAR on 2017 April 11. The brighter April 11 flare is not observed simultaneously by the EHT but is followed by a significant increase in millimeter flux variability immediately after the X-ray outburst, indicating a likely connection in the emission physics near the event horizon. We compare Sgr A*’s broadband flux during the EHT campaign to its historical spectral energy distribution and find that both the quiescent emission and flare emission are consistent with its long-term behavior."
ROBERT M JOSEPH,"Research update: recent progress on 2D materials beyond graphene: from ripples, defects, intercalation, and valley dynamics to straintronics and power dissipation","The field of two-dimensional (2D) materials has witnessed several significant advancements in a short period of time. There have been extensive research efforts dedicated to this field and an expanding community of researchers built around the same. The focus of this review article is on the most recent milestones in several aspects of 2D materials with emphasis on transition metal dichalcogenides, such as improved synthesis and property engineering, approaching this from both experimental and theoretical viewpoints. There is also an attempt at highlighting some emerging material properties that are of interest and use of these 2D materials in several electronic applications."
ROBERT M JOSEPH,Broadband multi-wavelength properties of M87 during the 2017 Event Horizon Telescope campaign,"In 2017, the Event Horizon Telescope (EHT) Collaboration succeeded in capturing the first direct image of the center of the M87 galaxy. The asymmetric ring morphology and size are consistent with theoretical expectations for a weakly accreting supermassive black hole of mass ∼6.5 × 109 M ⊙. The EHTC also partnered with several international facilities in space and on the ground, to arrange an extensive, quasi-simultaneous multi-wavelength campaign. This Letter presents the results and analysis of this campaign, as well as the multi-wavelength data as a legacy data repository. We captured M87 in a historically low state, and the core flux dominates over HST-1 at high energies, making it possible to combine core flux constraints with the more spatially precise very long baseline interferometry data. We present the most complete simultaneous multi-wavelength spectrum of the active nucleus to date, and discuss the complexity and caveats of combining data from different spatial scales into one broadband spectrum. We apply two heuristic, isotropic leptonic single-zone models to provide insight into the basic source properties, but conclude that a structured jet is necessary to explain M87’s spectrum. We can exclude that the simultaneous γ-ray emission is produced via inverse Compton emission in the same region producing the EHT mm-band emission, and further conclude that the γ-rays can only be produced in the inner jets (inward of HST-1) if there are strongly particle-dominated regions. Direct synchrotron emission from accelerated protons and secondaries cannot yet be excluded."
ROBERT M JOSEPH,Event Horizon Telescope imaging of the archetypal blazar 3C 279 at an extreme 20 microarcsecond resolution,"3C 279 is an archetypal blazar with a prominent radio jet that show broadband flux density variability across the entire electromagnetic spectrum. We use an ultra-high angular resolution technique – global Very Long Baseline Interferometry (VLBI) at 1.3 mm (230 GHz) – to resolve the innermost jet of 3C 279 in order to study its fine-scale morphology close to the jet base where highly variable γ-ray emission is thought to originate, according to various models. The source was observed during four days in April 2017 with the Event Horizon Telescope at 230 GHz, including the phased Atacama Large Millimeter/submillimeter Array (ALMA), at an angular resolution of ∼20 μas (at a redshift of z = 0.536 this corresponds to ∼0.13 pc  ∼ 1700 Schwarzschild radii with a black hole mass M<jats:sub>BH</jats:sub> = 8 × 10^8 M_⊙). Imaging and model-fitting techniques were applied to the data to parameterize the fine-scale source structure and its variation. We find a multicomponent inner jet morphology with the northernmost component elongated perpendicular to the direction of the jet, as imaged at longer wavelengths. The elongated nuclear structure is consistent on all four observing days and across different imaging methods and model-fitting techniques, and therefore appears robust. Owing to its compactness and brightness, we associate the northern nuclear structure as the VLBI “core”. This morphology can be interpreted as either a broad resolved jet base or a spatially bent jet. We also find significant day-to-day variations in the closure phases, which appear most pronounced on the triangles with the longest baselines. Our analysis shows that this variation is related to a systematic change of the source structure. Two inner jet components move non-radially at apparent speeds of ∼15 c and ∼20 c (∼1.3 and ∼1.7 μas day^−1, respectively), which more strongly supports the scenario of traveling shocks or instabilities in a bent, possibly rotating jet. The observed apparent speeds are also coincident with the 3C 279 large-scale jet kinematics observed at longer (cm) wavelengths, suggesting no significant jet acceleration between the 1.3 mm core and the outer jet. The intrinsic brightness temperature of the jet components are ≲10^10 K, a magnitude or more lower than typical values seen at ≥7 mm wavelengths. The low brightness temperature and morphological complexity suggest that the core region of 3C 279 becomes optically thin at short (mm) wavelengths."
ROBERT M JOSEPH,First M87 Event Horizon Telescope results. II. Array and instrumentation,"The Event Horizon Telescope (EHT) is a very long baseline interferometry (VLBI) array that comprises millimeter- and submillimeter-wavelength telescopes separated by distances comparable to the diameter of the Earth. At a nominal operating wavelength of ~1.3 mm, EHT angular resolution (λ/D) is ~25 μas, which is sufficient to resolve nearby supermassive black hole candidates on spatial and temporal scales that correspond to their event horizons. With this capability, the EHT scientific goals are to probe general relativistic effects in the strong-field regime and to study accretion and relativistic jet formation near the black hole boundary. In this Letter we describe the system design of the EHT, detail the technology and instrumentation that enable observations, and provide measures of its performance. Meeting the EHT science objectives has required several key developments that have facilitated the robust extension of the VLBI technique to EHT observing wavelengths and the production of instrumentation that can be deployed on a heterogeneous array of existing telescopes and facilities. To meet sensitivity requirements, high-bandwidth digital systems were developed that process data at rates of 64 gigabit s−1, exceeding those of currently operating cm-wavelength VLBI arrays by more than an order of magnitude. Associated improvements include the development of phasing systems at array facilities, new receiver installation at several sites, and the deployment of hydrogen maser frequency standards to ensure coherent data capture across the array. These efforts led to the coordination and execution of the first Global EHT observations in 2017 April, and to event-horizon-scale imaging of the supermassive black hole candidate in M87."
ROBERT M JOSEPH,First M87 Event Horizon Telescope results. I. The shadow of the supermassive black hole,"When surrounded by a transparent emission region, black holes are expected to reveal a dark shadow caused by gravitational light bending and photon capture at the event horizon. To image and study this phenomenon, we have assembled the Event Horizon Telescope, a global very long baseline interferometry array observing at a wavelength of 1.3 mm. This allows us to reconstruct event-horizon-scale images of the supermassive black hole candidate in the center of the giant elliptical galaxy M87. We have resolved the central compact radio source as an asymmetric bright emission ring with a diameter of 42 ± 3 μas, which is circular and encompasses a central depression in brightness with a flux ratio gsim10:1. The emission ring is recovered using different calibration and imaging schemes, with its diameter and width remaining stable over four different observations carried out in different days. Overall, the observed image is consistent with expectations for the shadow of a Kerr black hole as predicted by general relativity. The asymmetry in brightness in the ring can be explained in terms of relativistic beaming of the emission from a plasma rotating close to the speed of light around a black hole. We compare our images to an extensive library of ray-traced general-relativistic magnetohydrodynamic simulations of black holes and derive a central mass of M = (6.5 ± 0.7) × 10^9 M ⊙. Our radio-wave observations thus provide powerful evidence for the presence of supermassive black holes in centers of galaxies and as the central engines of active galactic nuclei. They also present a new tool to explore gravity in its most extreme limit and on a mass scale that was so far not accessible."
ROBERT M JOSEPH,"Bostonia: v. 5, no. 1-10",
ROBERT M JOSEPH,First Sagittarius A* Event Horizon Telescope results. III. Imaging of the Galactic center supermassive black hole,"We present the first event-horizon-scale images and spatiotemporal analysis of Sgr A* taken with the Event Horizon Telescope in 2017 April at a wavelength of 1.3 mm. Imaging of Sgr A* has been conducted through surveys over a wide range of imaging assumptions using the classical CLEAN algorithm, regularized maximum likelihood methods, and a Bayesian posterior sampling method. Different prescriptions have been used to account for scattering effects by the interstellar medium toward the Galactic center. Mitigation of the rapid intraday variability that characterizes Sgr A* has been carried out through the addition of a “variability noise budget” in the observed visibilities, facilitating the reconstruction of static full-track images. Our static reconstructions of Sgr A* can be clustered into four representative morphologies that correspond to ring images with three different azimuthal brightness distributions and a small cluster that contains diverse nonring morphologies. Based on our extensive analysis of the effects of sparse (u, v)-coverage, source variability, and interstellar scattering, as well as studies of simulated visibility data, we conclude that the Event Horizon Telescope Sgr A* data show compelling evidence for an image that is dominated by a bright ring of emission with a ring diameter of ∼50 μas, consistent with the expected “shadow” of a 4 × 106 M⊙ black hole in the Galactic center located at a distance of 8 kpc."
ROBERT M JOSEPH,Characterizing and mitigating intraday variability: reconstructing source structure in accreting black holes with mm-VLBI,"The extraordinary physical resolution afforded by the Event Horizon Telescope has opened a window onto the astrophysical phenomena unfolding on horizon scales in two known black holes, M87* and Sgr A*. However, with this leap in resolution has come a new set of practical complications. Sgr A* exhibits intraday variability that violates the assumptions underlying Earth aperture synthesis, limiting traditional image reconstruction methods to short timescales and data sets with very sparse (u, v) coverage. We present a new set of tools to detect and mitigate this variability. We develop a data-driven, model-agnostic procedure to detect and characterize the spatial structure of intraday variability. This method is calibrated against a large set of mock data sets, producing an empirical estimator of the spatial power spectrum of the brightness fluctuations. We present a novel Bayesian noise modeling algorithm that simultaneously reconstructs an average image and statistical measure of the fluctuations about it using a parameterized form for the excess variance in the complex visibilities not otherwise explained by the statistical errors. These methods are validated using a variety of simulated data, including general relativistic magnetohydrodynamic simulations appropriate for Sgr A* and M87*. We find that the reconstructed source structure and variability are robust to changes in the underlying image model. We apply these methods to the 2017 EHT observations of M87*, finding evidence for variability across the EHT observing campaign. The variability mitigation strategies presented are widely applicable to very long baseline interferometry observations of variable sources generally, for which they provide a data-informed averaging procedure and natural characterization of inter-epoch image consistency."
ROBERT M JOSEPH,A genome-wide association study reveals variants in ARL15 that influence adiponectin levels,"The adipocyte-derived protein adiponectin is highly heritable and inversely associated with risk of type 2 diabetes mellitus (T2D) and coronary heart disease (CHD). We meta-analyzed 3 genome-wide association studies for circulating adiponectin levels (n = 8,531) and sought validation of the lead single nucleotide polymorphisms (SNPs) in 5 additional cohorts (n = 6,202). Five SNPs were genome-wide significant in their relationship with adiponectin (P≤5×10−8). We then tested whether these 5 SNPs were associated with risk of T2D and CHD using a Bonferroni-corrected threshold of P≤0.011 to declare statistical significance for these disease associations. SNPs at the adiponectin-encoding ADIPOQ locus demonstrated the strongest associations with adiponectin levels (P-combined = 9.2×10−19 for lead SNP, rs266717, n = 14,733). A novel variant in the ARL15 (ADP-ribosylation factor-like 15) gene was associated with lower circulating levels of adiponectin (rs4311394-G, P-combined = 2.9×10−8, n = 14,733). This same risk allele at ARL15 was also associated with a higher risk of CHD (odds ratio [OR] = 1.12, P = 8.5×10−6, n = 22,421) more nominally, an increased risk of T2D (OR = 1.11, P = 3.2×10−3, n = 10,128), and several metabolic traits. Expression studies in humans indicated that ARL15 is well-expressed in skeletal muscle. These findings identify a novel protein, ARL15, which influences circulating adiponectin levels and may impact upon CHD risk. Author Summary Through a meta-analysis of genome-wide association studies of 14,733 individuals, we identified common base-pair variants in the genome which influence circulating adiponectin levels. Since adiponectin is an adipocyte-derived circulating protein which has been inversely associated with risk of obesity-related diseases such as type 2 diabetes (T2D) and coronary heart disease (CHD), we next sought to understand if the identified variants influencing adiponectin levels also influence risk of T2D, CHD, and several metabolic traits. In addition to confirming that variation at the ADIPOQ locus influences adiponectin levels, our analyses point to a variant in the ARL15 (ADP-ribosylation factor-like 15) locus which decreases adiponectin levels and increases risk of CHD and T2D. Further, this same variant was associated with increased fasting insulin levels and glycated hemoglobin. While the function of ARL15 is not known, we provide insight into the tissue specificity of ARL15 expression. These results thus provide novel insights into the physiology of the adiponectin pathway and obesity-related diseases."
ROBERT M JOSEPH,The polarized image of a synchrotron-emitting ring of gas orbiting a black hole,"Synchrotron radiation from hot gas near a black hole results in a polarized image. The image polarization is determined by effects including the orientation of the magnetic field in the emitting region, relativistic motion of the gas, strong gravitational lensing by the black hole, and parallel transport in the curved spacetime. We explore these effects using a simple model of an axisymmetric, equatorial accretion disk around a Schwarzschild black hole. By using an approximate expression for the null geodesics derived by Beloborodov and conservation of the Walker–Penrose constant, we provide analytic estimates for the image polarization. We test this model using currently favored general relativistic magnetohydrodynamic simulations of M87*, using ring parameters given by the simulations. For a subset of these with modest Faraday effects, we show that the ring model broadly reproduces the polarimetric image morphology. Our model also predicts the polarization evolution for compact flaring regions, such as those observed from Sgr A* with GRAVITY. With suitably chosen parameters, our simple model can reproduce the EVPA pattern and relative polarized intensity in Event Horizon Telescope images of M87*. Under the physically motivated assumption that the magnetic field trails the fluid velocity, this comparison is consistent with the clockwise rotation inferred from total intensity images."
ROBERT M JOSEPH,"BMQ : Boston medical quarterly: v. 10, no. 1-4",
ROBERT M JOSEPH,First Sagittarius A* Event Horizon Telescope results. I. The shadow of the supermassive black hole in the center of the Milky Way,"We present the first Event Horizon Telescope (EHT) observations of Sagittarius A* (Sgr A*), the Galactic center source associated with a supermassive black hole. These observations were conducted in 2017 using a global interferometric array of eight telescopes operating at a wavelength of λ = 1.3 mm. The EHT data resolve a compact emission region with intrahour variability. A variety of imaging and modeling analyses all support an image that is dominated by a bright, thick ring with a diameter of 51.8 ± 2.3 μas (68% credible interval). The ring has modest azimuthal brightness asymmetry and a comparatively dim interior. Using a large suite of numerical simulations, we demonstrate that the EHT images of Sgr A* are consistent with the expected appearance of a Kerr black hole with mass ∼4 × 106 M ⊙, which is inferred to exist at this location based on previous infrared observations of individual stellar orbits, as well as maser proper-motion studies. Our model comparisons disfavor scenarios where the black hole is viewed at high inclination (i &gt; 50°), as well as nonspinning black holes and those with retrograde accretion disks. Our results provide direct evidence for the presence of a supermassive black hole at the center of the Milky Way, and for the first time we connect the predictions from dynamical measurements of stellar orbits on scales of 103–105 gravitational radii to event-horizon-scale images and variability. Furthermore, a comparison with the EHT results for the supermassive black hole M87* shows consistency with the predictions of general relativity spanning over three orders of magnitude in central mass."
SRIKANTH GOPALAN,Co-infiltration of nickel and mixed conducting Gd0.1Ce0.9O2−δ and La0.6Sr0.3Ni0.15Cr0.85O3−δ phases in Ni-YSZ anodes for improved stability and performance,
SRIKANTH GOPALAN,Effect of anodic current density on the spreading of infiltrated nickel nanoparticles in nickel-yttria stabilized zirconia cermet anodes,
SRIKANTH GOPALAN,"Chromium poisoning effects on performance of (La, Sr) MnO3-based cathode in anode-supported solid oxide fuel cells","Chromium (Cr) vapor species from chromia-forming alloy interconnects are known to cause cathode performance degradation in solid oxide fuel cells (SOFCs). To understand the impact of Cr-poisoning on cathode performance, it is important to determine its effects on different cathode polarization losses. In this study, anode-supported SOFCs, with a (La,Sr)MnO3 (LSM) + yttria-stabilized zirconia (YSZ) cathode active layer and a LSM cathode current collector layer were fabricated. At 800°C, cells were electrochemically tested in direct contact with Crofer22H meshes, under different cathode atmospheres (dry air or humidified air) and current conditions (open-circuit or galvanostatic). Significant performance degradation was observed when cell was tested under galvanostatic condition (0.5 A/cm2), which was not the case under open-circuit condition. Humidity was found to accelerate the performance degradation. By curve-fitting the experimentally measured current-voltage traces to a polarization model, the effects of Cr-poisoning on different cathodic polarization losses were estimated. It is found that, under normal operating conditions, increase of activation polarization dominates the cathode performance degradation. Microstructures of the cathodes were characterized and Cr-containing deposits were identified. Higher concentrations of Cr-containing deposits were found at the cathode/electrolyte interface and the amounts directly correlated with the cell performance degradations."
SRIKANTH GOPALAN,Quantifying percolated triple phase boundary density and its effects on anodic polarization in Ni-infiltrated Ni/YSZ SOFC snodes,"Increasing the density of percolated triple phase boundaries (TPBs) by infiltrating nanoscale electrocatalysts can improve the performance of solid oxide fuel cell (SOFC) anodes. However, the complex microstructure of these infiltrated nanocatalysts creates challenges in quantifying their role in anode performance improvements. In this research, scanning electron microscopy of fractured cross-sections of a Ni-nanocatalyst infiltrated anodic symmetric cell along with three-dimensional (3-D) reconstruction of the same anode have been used to quantify the changes in percolated TPB densities due to infiltration. This change in percolated TPB density has been compared to the improvement in anode activation polarization resistance measured by electrochemical impedance spectroscopy (EIS). It was found that increased TPB densities only partially accounted for the measured performance improvement. Distribution of relaxation times (DRT) analyses showed that a reduction in the time constants of the catalytic processes in the anode also play a role, suggesting that the added nanoscale percolated TPB boundaries are more electrochemically active as compared to the cermet TPB boundaries."
HAO XING,Radner equilibrium and systems of quadratic BSDEs with discontinuous generators,"Motivated by an equilibrium problem, we establish the existence of a solution for a family of Markovian backward stochastic differential equations with quadratic nonlinearity and discontinuity in Z. Using unique continuation and backward uniqueness, we show that the set of discontinuity has measure zero. In a continuous-time stochastic model of an endowment economy, we prove the existence of an incomplete Radner equilibrium with nondegenerate endogenous volatility."
HAO XING,Dynamic discrete choice under rational inattention,"We adopt the posterior-based approach to study dynamic discrete choice problems under rational inattention. We provide necessary and sufficient conditions to characterize the solution for the additive class of uniformly posterior-separable cost functions. We propose an efficient algorithm to solve these conditions and apply our model to explain phenomena such as status quo bias, confirmation bias, and belief polarization. A key condition for our approach to work is the concavity of the difference between the generalized entropy of the current posterior and the discounted generalized entropy of the prior beliefs about the future states."
HAO XING,"Abstract, classic, and explicit turnpikes","Portfolio turnpikes state that, as the investment horizon increases, optimal portfolios for generic utilities converge to those of isoelastic utilities. This paper proves three kinds of turn- pikes. In a general semimartingale setting, the abstract turnpike states that optimal final payoffs and portfolios converge under their myopic probabilities. In diffusion models with several assets and a single state variable, the classic turnpike demonstrates that optimal portfolios converge un- der the physical probability; meanwhile the explicit turnpike identifies the limit of finite-horizon optimal portfolios as a long-run myopic portfolio defined in terms of the solution of an ergodic HJB equation."
HAO XING,Robust portfolios and weak incentives in long-run investments,"When the planning horizon is long, and the safe asset grows indefinitely, isoelastic portfolios are nearly optimal for investors who are close to isoelastic for high wealth, and not too risk averse for low wealth. We prove this result in a general arbitrage-free, frictionless, semimartingale model. As a consequence, optimal portfolios are robust to the perturbations in preferences induced by common option compensation schemes, and such incentives are weaker when their horizon is longer. Robust option incentives are possible, but require several, arbitrarily large exercise prices, and are not always convex."
HAO XING,Systemic risk and spatiotemporal dynamics of the US housing market,"Housing markets play a crucial role in economies and the collapse of a real-estate bubble usually destabilizes the financial system and causes economic recessions. We investigate the systemic risk and spatiotemporal dynamics of the US housing market (1975–2011) at the state level based on the Random Matrix Theory (RMT). We identify richer economic information in the largest eigenvalues deviating from RMT predictions for the housing market than for stock markets and find that the component signs of the eigenvectors contain either geographical information or the extent of differences in house price growth rates or both. By looking at the evolution of different quantities such as eigenvalues and eigenvectors, we find that the US housing market experienced six different regimes, which is consistent with the evolution of state clusters identified by the box clustering algorithm and the consensus clustering algorithm on the partial correlation matrices. We find that dramatic increases in the systemic risk are usually accompanied by regime shifts, which provide a means of early detection of housing bubbles."
HAO XING,Firm dynamics depend on cash and capital,"We study how costly financing and bankruptcy interact with a firm's cash and capital to determine optimal investment, payout, issuance, and default. The dynamic model connects disperse strands of the empirical literature, and we find support in the data for novel non-linearities: (1) equity issuance scaled by capital is declining and convex in capital and (2) payout scaled by capital is concave in capital. Accounting for these predictions in prior studies increases explanatory power and alters results. We prove uniqueness of the model solution by proving a comparison theorem for discontinuous viscosity solutions."
HAO XING,Heterogeneous learning in product markets,"We study how the combination of market structure and the asymmetries in learn- ing technologies affects trade in a product market. In this market, a new product of unknown quality is introduced to challenge an existing product of known quality. We show that market efficiency is achieved both under monopoly and competition if buyers are symmetric in the amount of information they generate when they consume the new product. If buyers are instead asymmetric, only a monopolistic market in which the seller of the old product also sells the new one is efficient. We identify inefficiency as a learning externality that consumption of the new product by one buyer generates for the other buyers. The equilibrium inefficiency has two essential features: (i) efficiency for the top learners, that is, the threshold for starting to serve the best learners (i.e., to enter into a beta phase) remains the efficient one; and (ii) nonmonotonicity, that is, distortions are not monotone in the extent of the asymmetry. Finally, we explore our results’ robustness under different assumptions about the ability to price discriminate."
HAO XING,Robustness and dynamic sentiment,"Errors in survey expectations display waves of pessimism and optimism and significant sluggishness. This paper develops a novel theoretical framework of time-varying beliefs capturing these empirical characteristics. The dynamic beliefs arise endogenously due to agents’ attitude toward alternative models. Decision-maker’s distorted beliefs generate countercyclical risk aversion, procyclical portfolio weights, countercyclical equilibrium asset returns, and excess volatility. A calibrated version of our model is shown to match salient features in equity markets.
 Errors in survey expectations display waves of pessimism and optimism and significant sluggishness. This paper develops a novel theoretical framework of time-varying beliefs capturing these empirical facts. In our model, the dynamic beliefs arise endogenously due to agents’ attitude toward alternative models. Decision-maker’s distorted beliefs generate countercyclical risk aversion, procyclical portfolio weights, countercyclical equilibrium asset returns, and excess volatility. A calibrated version of our model is shown to match salient features in equity markets.
 "
HAO XING,Paired yeast one-hybrid assays to detect DNA-binding cooperativity and antagonism across transcription factors,"Cooperativity and antagonism between transcription factors (TFs) can drastically modify their binding to regulatory DNA elements. While mapping these relationships between TFs is important for understanding their context-specific functions, existing approaches either rely on DNA binding motif predictions, interrogate one TF at a time, or study individual TFs in parallel. Here, we introduce paired yeast one-hybrid (pY1H) assays to detect cooperativity and antagonism across hundreds of TF-pairs at DNA regions of interest. We provide evidence that a wide variety of TFs are subject to modulation by other TFs in a DNA region-specific manner. We also demonstrate that TF-TF relationships are often affected by alternative isoform usage and identify cooperativity and antagonism between human TFs and viral proteins from human papillomaviruses, Epstein-Barr virus, and other viruses. Altogether, pY1H assays provide a broadly applicable framework to study how different functional relationships affect protein occupancy at regulatory DNA regions."
MAXWELL PALMER,2020 Menino Survey of Mayors: policing and protests,"The 2020 Menino Survey of Mayors represents the seventh nationally representative survey of American mayors and is based on interviews with 130 sitting mayors from 38 states. The 2020 Survey explores mayoral views on COVID-19 recovery, policing and protests, parks and greenspace, and the 2020 Census. The third set of findings, released in January 2021, explores mayors’ recognition of racial inequality, their roles during protests in their communities, and how they hope to reform their police departments. The 2020 Survey continues with the support of Citi and The Rockefeller Foundation."
MAXWELL PALMER,2020 Menino Survey of Mayors: Urban parks and the public realm: equity & access in post-COVID cities,
MAXWELL PALMER,Land of the freeholder: how property rights make local voting rights,"A large body of research documents the dominance of homeowners in local politics. There has been little scholarship, however, on the role that voting institutions have played in empowering homeowners from the inception of the United States; indeed, most accounts describe property qualifications for voting and officeholding as largely fading from view by the mid-1800s. Combining a novel analysis of state constitutions and constitutional conventions with data on state statutes, this article explores the emergence of property qualifications for voting, with a particular emphasis on their role in local politics. We find that, counter most historical narratives, property requirements persisted well into the 20th century, with almost 90 percent of property requirements restricting voting and officeholding at the local level. Most centered on local bond referenda, school districts, and land use — suggesting that homeowner citizens were granted particular political control over local taxation and public services. These requirements were largely clustered in the American South and West — emerging alongside Jim Crow laws and mass availability of federal public lands — and were not eliminated until the Supreme Court took action in 1969 and 1970. This article illuminates the important role that voting institutions played in linking homeownership with American democratic citizenship, especially at the local level."
MAXWELL PALMER,"As the Trump administration retreats on climate change, US cities are moving forward",
MAXWELL PALMER,2018 Menino Survey of Mayors,"The 2018 Menino Survey of Mayors represents the fifth scientifically rigorous and nationally representative survey of American mayors released by the Boston University Initiatives on Cities and supported by Citi Community Development and The Rockefeller Foundation. The Survey, based on interviews with 110 sitting mayors conducted in 2018, reveals mayoral views on economic development—including corporate recruitment, financial incentives, the sharing economy, and social mobility—as well as public health, housing, and intergovernmental relations."
MAXWELL PALMER,Do mayors run for higher office? New evidence on progressive ambition,"The mayor’s office potentially offers a launchpad for statewide and national political ambitions. We know relatively little, however, about how frequently mayors actually run for higher office, and which mayors choose to do so. This article combines longitudinal data on the career paths of the mayors of 200 big cities with new survey and interview data to investigate these questions. While we find that individual and city traits—especially gender—have some predictive power, the overwhelming story is that relatively few mayors—just under one-fifth—ever seek higher office. We suggest that ideological, institutional, and electoral factors all help to explain why so few mayors exhibit progressive ambition."
MAXWELL PALMER,Mayoral views on housing production: do planning goals match reality?,"Mayoral Views on Housing Production: Do Planning Goals Match Reality? evaluates mayoral priorities relative to actual need. Based on our analysis, even the most ambitious mayors are not prioritizing sufficient development necessary to meet the demand for housing and to address the affordability crisis. The authors recommend reforming local zoning codes and reducing regulatory barriers to the construction of multifamily housing to help address this shortfall."
MAXWELL PALMER,"2022 Menino Survey of Mayors: economic opportunity, poverty & well-being","The 2022 Menino Survey of Mayors represents the ninth nationally representative survey of American mayors and is based on interviews with 118 sitting mayors from 38 states. The 2022 Survey explores mayoral views on climate and energy, poverty and rising costs of living, and health and safety. The second and final set of findings, released in April 2023, analyzes mayors’ views on key economic challenges – including poverty and the rising cost of living – and tools they can use at the local level. It also investigates what mayors perceive to be the main public health and public safety challenges in their communities. The 2022 Survey continues with the support of The Rockefeller Foundation."
MAXWELL PALMER,Mayoral views on racism and discrimination,"This report, which draws on data from the 2017 Menino Survey of Mayors, explores how mayors of medium-sized and large cities understand race, discrimination and equity in their communities and on a national level. The report cites three key findings: 1) Mayors believe that the four groups most discriminated against in their cities and across the country are immigrants, transgender individuals, black people and Muslims. In relation to these group and others, mayors perceive far more discrimination in the country as a whole than in their own communities. 2) Mayors believe that access to public services is significantly better for white people than for people of color, except for subsidized housing. More than half of all mayors report that white people have better access to jobs, educational opportunities, housing and healthcare, and are treated better by police and the courts. 3) While mayors see disparities in access to services, they overwhelmingly believe that the quality of services is largely equal across different groups of people, except for educational services, which they think is worse for people of color. The report also highlights several successful initiatives that cities, including Anaheim, Boston, Louisville and New Orleans, have undertaken in combating discrimination."
MAXWELL PALMER,City learning: evidence of policy information diffusion from a survey of U.S. mayors,"Most studies of policy diffusion attempt to infer the processes through which policies spread by observing outputs (policy adoptions). We approach these issues from the other direction by directly analyzing a key policymaking input—information about others’ policies. Moreover, we do so by investigating policy diffusion in cities rather than states. Using a survey of U.S. mayors, more specifically, mayors’ own lists of cities they look to for ideas, we find evidence that distance, similarity, and capacity all influence the likelihood of a policy maker looking to a particular jurisdiction for policy information. We also consider whether these traits are complements or substitutes and provide some evidence for the latter. Specifically, we find that, at times, mayors eschew similarity and distance to look to highly respected “high capacity” cities but that there is no tradeoff between distance and similarity."
MAXWELL PALMER,Who participates in local government? Evidence from meeting minutes,"Scholars and policymakers have highlighted institutions that enable community participation as a potential buffer against existing political inequalities. Yet these venues may bias policy discussions in favor of an unrepresentative group of individuals. To explore who participates, we compile a novel data set by coding thousands of instances of citizens speaking at planning and zoning board meetings concerning housing development. We match individuals to a voter file to investigate local political participation in housing and development policy. We find that individuals who are older, male, longtime residents, voters in local elections, and homeowners are significantly more likely to participate in these meetings. These individuals overwhelmingly (and to a much greater degree than the general public) oppose new housing construction. These participatory inequalities have important policy implications and may be contributing to rising housing costs."
MAXWELL PALMER,Divided government and significant legislation: A History of Congress from 1789 to 2010,"This article presents and analyzes the most comprehensive database to date of significant acts of Congress—from 1789 to 2010—to test whether divided party control of government affects the number of important acts Congress passes. We find that unified control corresponds with one additional significant act passed per Congress in the nineteenth century and four additional such acts in the twentieth century. However, party control of government cannot explain the broad historical trends in the rate at which Congress passes significant legislation. Nixon in 1969 was far more successful with a Democratic Congress than was McKinley in 1897 with a Republican one."
MAXWELL PALMER,2022 Menino Survey of Mayors: mayors and the climate crisis,"The 2022 Menino Survey of Mayors represents the ninth nationally representative survey of American mayors and is based on interviews with 118 sitting mayors from 38 states. The 2022 Survey explores mayoral views on climate and energy, poverty and rising costs of living, and health and safety. The first set of findings, released in January 2023, delves into mayors’ current views on local climate action, focusing on their beliefs about the underlying issues and threats, their sense of the tools they have at their disposal, and their enthusiasm for using them. The 2022 Survey continues with the support of The Rockefeller Foundation."
MAXWELL PALMER,2019 Menino Survey of Mayors,"The 2019 Menino Survey of Mayors represents the sixth nationally representative survey of American mayors and is based on interviews with 119 sitting mayors from 38 states. The 2019 Survey explores mayoral views on issues ranging from infrastructure and transportation priorities — including mobility and public safety — to the changing nature of work. The 2019 Survey also provides the first in-depth examination of mayors’ reactions to and expectations for the Opportunity Zones program, a significant new federal initiative to stimulate urban development. The 2019 Survey continues with the support of Citi Community Development and The Rockefeller Foundation."
MAXWELL PALMER,2021 Menino Survey of Mayors: Building back better,"The 2021 Menino Survey of Mayors represents the eighth nationally representative survey of American mayors and is based on interviews with 126 sitting mayors from 39 states. The 2021 Survey explores mayoral views on COVID-19 recovery, equity and small business, closing the racial wealth gap, and housing and homelessness. The first set of findings, released in November 2021, delves into the challenges mayors are facing in light of the ongoing pandemic—and the extent to which massive support from the federal government has helped to fill the gap."
MAXWELL PALMER,2017 Menino Survey of Mayors,"The 2017 Menino Survey of Mayors represents the fourth scientifically rigorous and nationally representative survey of American mayors released by the Boston University Initiatives on Cities. The Menino Survey, based on interviews with 115 sitting mayors conducted in 2017, provides insight into mayoral priorities, policy views and relationships with their key partners, including other levels of government. Researchers spoke with mayors about a range of topics including affordable housing, climate change, city-to-city networks, and data-driven decision-making."
MAXWELL PALMER,Counting the city: mayoral views on the 2020 Census,"As the 2020 Census concludes at the end of September, a large majority of the mayors of America’s major cities are extremely concerned that their cities’ populations will be undercounted. According to Boston University’s 2020 Menino Survey of Mayors – the only national representative survey of American mayors – 82% of local leaders are “very” or “somewhat concerned” about undercounting their cities’ populations; only 6% of mayors were “not concerned at all.” While there is a small partisan difference in level of concern (19% of Republican mayors are “not concerned at all” compared to 4% of Democratic mayors), nearly two-thirds of Republican mayors are somewhat or very concerned that their populations will be undercounted."
MAXWELL PALMER,2021 Menino Survey of Mayors: Closing the racial wealth gap,"The 2021 Menino Survey of Mayors represents the eighth nationally representative survey of American mayors and is based on interviews with 126 sitting mayors from 39 states. The 2021 Survey explores mayoral views on COVID-19 recovery, equity and small business, closing the racial wealth gap, and housing and homelessness. The third and final set of findings, released in March 2022, explores how mayors are approaching the racial wealth gap in their cities."
MAXWELL PALMER,COVID-19 housing policy,"Federal government response to housing challenges created by COVID-19 has been limited, leaving state and local governments to create a patchwork of solutions. State and local governments have been forced to provide eviction and foreclosure protections and relief from rent, mortgages, and property taxes as federal government support falls well short of current housing needs. In this report, the authors analyze state and local pandemic housing policy across all 50 states and 118 cities."
MAXWELL PALMER,2020 Menino Survey of Mayors: COVID-19 recovery and the future of cities,"The 2020 Menino Survey of Mayors details insights and perspectives shared by a representative sample of 130 mayors leading U.S. cities with populations of more than 75,000 residents. This year’s Survey explores mayoral views on COVID-19 recovery and implications, policing and protests, parks and greenspace, and the 2020 Census. This report focuses on the COVD-19 related findings and outlines mayors’ responses to the global pandemic, perceptions of its impact, and expectations for the future of their cities. The 2020 Survey continues with the support of Citi and The Rockefeller Foundation."
MAXWELL PALMER,'Descended from immigrants and revolutionists': how family immigration history shapes representation in Congress,"Does recent immigrant lineage influence the legislative behavior of members of Congress on immigration policy? We examine the relationship between the immigrant background of legislators (i.e., their generational distance from immigration) and legislative behavior, focusing on roll-call votes for landmark immigration legislation and congressional speech on the floor. Legislators more proximate to the immigrant experience tend to support more permissive immigration legislation. Legislators with recent immigration backgrounds also speak more often about immigration in Congress, though the size of immigrant constituencies in their districts accounts for a larger share of this effect. A regression discontinuity design on close elections, which addresses selection bias concerns and holds district composition constant, confirms that legislators with recent immigrant backgrounds tend to support pro-immigration legislation. Finally, we demonstrate how a common immigrant identity can break down along narrower ethnic lines in cases where restrictive legislation targets specific places of origin. Our findings illustrate the important role of immigrant identity in legislative behavior and help illuminate the legislative dynamics of present-day immigration policy."
MAXWELL PALMER,A partisan solution to partisan Gerrymandering: the define–combine procedure,"Redistricting reformers have proposed many solutions to the problem of partisan gerrymandering, but they all require either bipartisan consensus or the agreement of both parties on the legitimacy of a neutral third party to resolve disputes. In this paper, we propose a new method for drawing district maps, the Define–Combine Procedure, that substantially reduces partisan gerrymandering without requiring a neutral third party or bipartisan agreement. One party defines a map of $2N$ equal-population contiguous districts. Then the second party combines pairs of contiguous districts to create the final map of N districts. Using real-world geographic and electoral data, we employ simulations and map-drawing algorithms to show that this procedure dramatically reduces the advantage conferred to the party controlling the redistricting process and leads to less-biased maps without requiring cooperation or non-partisan actors."
MAXWELL PALMER,2023 Menino Survey of Mayors: building for a Green Future: Cities and the IRA,"The 2023 Menino Survey of Mayors represents the tenth nationally representative survey of American mayors and is based on interviews with 118 sitting mayors from 39 states. The 2023 Survey explores mayoral views on Inflation Reduction Act (IRA) implementation and issues ranging from clean energy and permitting, to public messaging, to capacity challenges, to government accountability and control. The first set of findings, Building for a Green Future: Cities & the IRA, released in March 2024, details mayors’ initial experiences with the Inflation Reduction Act (IRA) and identifies key challenges at the local level to realizing the law’s potential."
MAXWELL PALMER,2023 Menino Survey: Mayoral Accountability and Control,"The 2023 Menino Survey of Mayors represents the tenth nationally representative survey of American mayors and is based on interviews with 118 sitting mayors from 39 states. The 2023 Survey explores mayoral views on Inflation Reduction Act (IRA) implementation and issues ranging from clean energy and permitting, to public messaging, to capacity challenges, to government accountability and control. The second set of findings, Mayoral Accountability and Control, released in April 2024, examines how mayors view their control and accountability over a variety of elements of local government, and how these perceptions have changed in recent years."
CATHARINE WANG,"Awareness, interest, and preferences of primary care providers in using point-of-care cancer screening technology","Well-developed point-of-care (POC) cancer screening tools have the potential to provide better cancer care to patients in both developed and developing countries. However, new medical technology will not be adopted by medical providers unless it addresses a population’s existing needs and end-users’ preferences. The goals of our study were to assess primary care providers’ level of awareness, interest, and preferences in using POC cancer screening technology in their practice and to provide guidelines to biomedical engineers for future POC technology development. A total of 350 primary care providers completed a one-time self-administered online survey, which took approximately 10 minutes to complete. A $50 Amazon gift card was given as an honorarium for the first 100 respondents to encourage participation. The description of POC cancer screening technology was provided in the beginning of the survey to ensure all participants had a basic understanding of what constitutes POC technology. More than half of the participants (57%) stated that they heard of the term “POC technology” for the first time when they took the survey. However, almost all of the participants (97%) stated they were either “very interested” (68%) or “somewhat interested” (29%) in using POC cancer screening technology in their practice. Demographic characteristics such as the length of being in the practice of medicine, the percentage of patients on Medicaid, and the average number of patients per day were not shown to be associated with the level of interest in using POC. These data show that there is a great interest in POC cancer screening technology utilization among this population of primary care providers and vast room for future investigations to further understand the interest and preferences in using POC cancer technology in practice. Ensuring that the benefits of new technology outweigh the costs will maximize the likelihood it will be used by medical providers and patients."
CATHARINE WANG,Consumer use and response to online third-party raw DNA interpretation services,
CATHARINE WANG,Causal Beliefs about Obesity and Associated Health Behaviors: Results from a Population-Based Survey,"BACKGROUND. Several genetic variants are associated with obesity risk. Promoting the notion of genes as a cause for obesity may increase genetically deterministic beliefs and decrease motivation to engage in healthy lifestyle behaviors. Little is known about whether causal beliefs about obesity are associated with lifestyle behaviors. Study objectives were as follows: 1) to document the prevalence of various causal beliefs about obesity (i.e., genes versus lifestyle behaviors), and 2) to determine the association between obesity causal beliefs and self-reported dietary and physical activity behaviors. METHODS. The study data were drawn from the 2007 Health Information National Trends Survey (HINTS). A total of 3,534 individuals were included in the present study. RESULTS. Overall, 72% of respondents endorsed the belief that lifestyle behaviors have 'a lot' to do with causing obesity, whereas 19% indicated that inheritance has 'a lot' to do with causing obesity. Multinomial logistic regression analyses indicated that the belief that obesity is inherited was associated with lower reported levels of physical activity (OR = 0.87, 95% CI: 0.77-0.99) and fruit and vegetable consumption (OR = 0.87, 95% CI: 0.76-0.99). In contrast, the belief that obesity is caused by lifestyle behaviors was associated with greater reported levels of physical activity (OR = 1.29, 95% CI: 1.03-1.62), but was not associated with fruit and vegetable intake (OR = 1.07, 95% CI: 0.90-1.28). CONCLUSIONS. Causal beliefs about obesity are associated with some lifestyle behaviors. Additional research is needed to determine whether promoting awareness of the genetic determinants of obesity will decrease the extent to which individuals will engage in the lifestyle behaviors essential to healthy weight management."
JENNIFER J SCHLEZINGER,Direct Assessment of Cumulative Aryl Hydrocarbon Receptor Agonist Activity in Sera from Experimentally Exposed Mice and Environmentally Exposed Humans,"BACKGROUND. Aryl hydrocarbon receptor (AhR) ligands adversely affect many biological processes. However, assessment of the significance of human exposures is hampered by an incomplete understanding of how complex mixtures affect AhR activation/inactivation. OBJECTIVES. These studies used biological readouts to provide a broader context for estimating human risk than that obtained with serum extraction and gas chromatography/mass spectroscopy (GC/MS)-based assays alone. METHODS. AhR agonist activity was quantified in sera from dioxin-treated mice, commercial human sources, and polychlorinated biphenyl (PCB)-exposed Faroe Islanders using an AhR-driven reporter cell line. To validate relationships between serum AhR agonist levels and biological outcomes, AhR agonist activity in mouse sera correlated with toxic end points. AhR agonist activity in unmanipulated (""neat"") human sera was compared with these biologically relevant doses and with GC/MS-assayed PCB levels. RESULTS. Mouse serum AhR agonist activity correlated with injected dioxin dose, thymic atrophy, and heptomegaly, validating the use of neat serum to assess AhR agonist activity. AhR agonist activity in sera from Faroe Islanders varied widely, was associated with the frequency of recent pilot whale dinners, but did not correlate with levels of PCBs quantified by GC/MS. Surprisingly, significant ""baseline"" AhR activity was found in commercial human sera. CONCLUSIONS. An AhR reporter assay revealed cumulative levels of AhR activation potential in neat serum, whereas extraction may preclude detection of important non-dioxin-like biological activity. Significant levels of AhR agonist activity in commercial sera and in Faroe Islander sera, compared with that from experimentally exposed mice, suggest human exposures that are biologically relevant in both populations."
JENNIFER J SCHLEZINGER,Generalized concentration addition predicts joint effects of aryl hydrocarbon receptor agonists with partial agonists and competitive antagonists,"BACKGROUND. Predicting the expected outcome of a combination exposure is critical to risk assessment. The toxic equivalency factor (TEF) approach used for analyzing joint effects of dioxin-like chemicals is a special case of the method of concentration addition. However, the TEF method assumes that individual agents are full aryl hydrocarbon receptor (AhR) agonists with parallel dose-response curves, whereas many mixtures include partial agonists. OBJECTIVES. We assessed the ability of generalized concentration addition (GCA) to predict effects of combinations of full AhR agonists with partial agonists or competitive antagonists. METHODS. We measured activation of AhR-dependent gene expression in H1G1.1c3 cells after application of binary combinations of AhR ligands. A full agonist (2,3,7,8-tetrachlorodibenzo-p-dioxin or 2,3,7,8-tetrachlorodibenzofuran) was combined with either a full agonist (3,3',4,4',5-pentachlorobiphenyl), a partial agonist (2,3,3',4,4'-pentachlorobiphenyl or galangin), or an antagonist (3,3'-diindolylmethane). Combination effects were modeled by the TEF and GCA approaches, and goodness of fit of the modeled response surface to the experimental data was assessed using a nonparametric statistical test. RESULTS. The GCA and TEF models fit the experimental data equally well for a mixture of two full agonists. In all other cases, GCA fit the experimental data significantly better than the TEF model. CONCLUSIONS. The TEF model overpredicts effects of AhR ligands at the highest concentration combinations. At lower concentrations, the difference between GCA and TEF approaches depends on the efficacy of the partial agonist. GCA represents a more accurate definition of additivity for mixtures that include partial agonist or competitive antagonist ligands."
JENNIFER J SCHLEZINGER,Aryl hydrocarbon receptor (AhR) agonists suppress Interleukin-6 expression by bone marrow stromal cells: an immunotoxicology study,"BACKGROUND: Bone marrow stromal cells produce cytokines required for the normal growth and development of all eight hematopoietic cell lineages. Aberrant cytokine production by stromal cells contributes to blood cell dyscrasias. Consequently, factors that alter stromal cell cytokine production may significantly compromise the development of normal blood cells. We have shown that environmental chemicals, such as aromatic hydrocarbon receptor (AhR) agonists, suppress B lymphopoiesis by modulating bone marrow stromal cell function. Here, we extend these studies to evaluate the potential for two prototypic AhR agonists, 7,12-dimethylbenz [a]anthracene (DMBA) and 2,3,7,8-tetrachlorodibenzo-p-dioxin (TCDD), to alter stromal cell cytokine responses. METHODS: Bone marrow stromal cells were treated with AhR agonists and bacterial lipopolysaccharide (LPS) to mimic innate inflammatory cytokine responses and to study the effects of AhR ligands on those responses. Steady state cytokine RNA levels were screened by RNAse protection assays (RPA) and quantified by real-time PCR. Cytokine (IL-6) protein production was measured by ELISA. NF-κB EMSAs were used to study IL-6 transcriptional regulation. RESULTS: RPAs indicated that AhR+ bone marrow stromal cells consistently up-regulated genes encoding IL-6 and LIF in response to LPS, presumably through activation of Toll-like receptor 4. Pre-treatment with low doses of DMBA or TCDD selectively abrogated IL-6 gene induction but had no effect on LIF mRNA. Real-time-PCR indicated a significant inhibition of IL-6 mRNA by AhR ligands within 1 hour of LPS challenge which was reflected in a profound down-regulation of IL-6 protein induction, with DMBA and TCDD suppressing IL-6 levels as much as 65% and 88%, respectively. This potent inhibitory effect persisted for at least 72 hours. EMSAs measuring NF-κB binding to IL-6 promoter sequences, an event known to induce IL-6 transcription, indicated a significant decrease in the LPS-mediated induction of DNA-binding RelA/p50 and c-Rel/p50 heterodimers in the presence of DMBA. CONCLUSIONS: Common environmental AhR agonists can suppress the response to bacterial lipopolysaccharide, a model for innate inflammatory responses, through down-regulation of IL-6, a cytokine critical to the growth of several hematopoietic cell subsets, including early B cells. This suppression occurs at least at the level of IL-6 gene transcription and may be regulated by NF-κB."
DANIEL ERKER,"Contact, co-variation, and sociolinguistic salience: what Mister Rogers knows about language change","This study asks whether and how the features that define a language variety co-vary within the communities and speakers said to be representative of it. Of particular interest is the relationship between multiple variables in a setting known to promote contact-induced language change. The central idea that emerges here is that less salient linguistic variables are more likely to co-vary, that is, to be uniformly influenced by the contact setting, than are variables of higher salience. This claim is supported by an analysis of five variables in the speech of four Spanish-speaking adults, two of whom have lived their entire lives in the contact setting and two who are recent arrivals to it. The variables are (1) filled pauses, (2) the presence vs. absence of subject pronouns, (3) subject pronoun position (i.e., pre- vs. post-verbal), (4) general subject position (the pre- or post-verbal position of non-pronominal subjects, e.g. lexical NPs, clauses, etc.), and (5) coda /s/ weakening, examined in terms of rates of deletion as well two acoustic parameters. It is only with respect to the last of these features, which is highly salient sociolinguistically, that strong regionally delineated continuity in the Spanish of the U.S. born speakers is clearly observed. The four lower salience features have shifted in parallel, increasing in similarity to the use of analogous features in English. These results indicate that in a setting characterized by language contact, the fate of socio-linguistic variables is mediated by salience. Low salience features are more susceptible to the influence of the contact setting and are more likely to be uniformly reshaped by it. High salience features, in contrast, are differentiated by speakers’ greater awareness of their social signaling potential and are more likely to unfold along autonomous and individuated trajectories."
DANIEL ERKER,Some acoustic and articulatory correlates of phrasal stress in Spanish,"All spoken languages show rhythmic patterns. Recent work with a number of different languages (English, Japanese, Mandarin Chinese, and French) suggests that metrically (hierarchically) assigned stress levels of the utterance show strong correlations with the amount of jaw displacement, and corresponding F1 values. This paper examines some articulatory and acoustic correlates of Spanish rhythm; specifically, we ask if there is a correlation between phrasal stress values metrically assigned to each syllable and acoustic/articulatory values. We used video recordings of three Salvadoran Spanish speakers to measure maximum jaw displacement, mean F0, mean intensity, mean duration, and mid-vowel F1 for each vowel in two Spanish sentences. The results show strong correlations between stress and duration, and between stress and F1, but weak correlations between stress and both mean vowel intensity and maximum jaw displacement. We also found weak correlations between jaw displacement and both mean vowel intensity and F1."
ARUNIMA KRISHNA,"Missing voices: examining how misinformation-susceptible individuals from underrepresented communities engage, perceive, and combat science misinformation","This study examines how misinformation-susceptible individuals from historically excluded and marginalized communities engage with science topics (e.g., climate change, vaccines, and health/wellness) and interpret misinformation and corrective intervention strategies. Two focus groups reveal that most participants are highly distrustful of authority figures, celebrity endorsements, and fact-checking strategies to combat misinformation. As one of the first studies to explore underrepresented community members’ experiences with science misinformation, findings reveal structural and institutional power dynamics that impede access to accurate information and indicate how missing voices must be included in the efforts at media and information literacy initiatives."
JONATHAN APPAVOO,EbbRT: a customizable operating system for cloud applications,"Efficient use of hardware requires operating system components be customized to the application workload. Our general purpose operating systems are ill-suited for this task. We present Genesis, a new operating system that enables per-application customizations for cloud applications. Genesis achieves this through a novel heterogeneous distributed structure, a partitioned object model, and an event-driven execution environment. This paper describes the design and prototype implementation of Genesis, and evaluates its ability to improve the performance of common cloud applications. The evaluation of the Genesis prototype demonstrates memcached, run within a VM, can outperform memcached run on an unvirtualized Linux. The prototype evaluation also demonstrates an 14% performance improvement of a V8 JavaScript engine benchmark, and a node.js webserver that achieves a 50% reduction in 99th percentile latency compared to it run on Linux."
JONATHAN APPAVOO,Dynamic pricing for efficient workload colocation,"Pricing models for virtualized (cloud) resources are meant to reflect the operational costs and profit margins for providers to deliver specific resources or services to customers subject to an underlying Service Level Agreements (SLAs). While the operational costs incurred by cloud providers are dynamic they vary over time, depending on factors such as energy cost, cooling strategies, and overall utilization the pricing models extended to customers are typically fixed they are static over time and independent of aggregate demand. This disconnect between the cost incurred by a provider and the price paid by a customer results in an inefficient marketplace. In particular, it does not provide incentives for customers to express workload scheduling flexibilities that may benefit them as well as cloud providers. In this paper, we propose a new dynamic pricing model that aims to address this marketplace inefficiency by giving customers the opportunity and incentive to take advantage of any tolerances they may have regarding the scheduling of their workloads. We present the architecture and algorithmic blueprints of a framework for workload colocation, which provides customers with the ability to formally express workload scheduling flexibilities using Directed Acyclic Graphs (DAGs), optimizes the use of cloud resources to collocate clients’ workloads, and utilizes Shapley valuation to rationally and thus fairly in a game-theoretic sense attribute costs to customer workloads. In a thorough experimental evaluation we show the practical utility of our dynamic pricing mechanism and the efficacy of the resulting marketplace in terms of cost savings."
JONATHAN APPAVOO,Total order broadcast for fault tolerant exascale systems,"In the process of designing a new fault tolerant run-time for future exascale systems, we discovered that a total order broadcast would be necessary. That is, nodes of a supercomputer should be able to broadcast messages to other nodes even in the face of failures. All messages should be seen in the same order at all nodes. While this is a well studied problem in distributed systems, few researchers have looked at how to perform total order broadcasts at large scales for data availability. Our experience implementing a published total order broadcast algorithm showed poor scalability at tens of nodes. In this paper we present a novel algorithm for total order broadcast which scales logarithmically in the number of processes and is not delayed by most process failures. While we are motivated by the needs of our run-time we believe this primitive is of general applicability. Total order broadcasts are used often in datacenter environments and as HPC developers begins to address fault tolerance at the application level we believe they will need similar primitives."
JONATHAN APPAVOO,SEUSS: rapid serverless deployment using environment snapshots,"Modern FaaS systems perform well in the case of repeat executions when function working sets stay small. However, these platforms are less effective when applied to more complex, large-scale and dynamic workloads. In this paper, we introduce SEUSS (serverless execution via unikernel snapshot stacks), a new system-level approach for rapidly deploying serverless functions. Through our approach, we demonstrate orders of magnitude improvements in function start times and cacheability, which improves common re-execution paths while also unlocking previously-unsupported large-scale bursty workloads."
JONATHAN APPAVOO,MultiLibOS: an OS architecture for cloud computing,"Cloud computing is resulting in fundamental changes to computing infrastructure, yet these changes have not resulted in corresponding changes to operating systems. In this paper we discuss some key changes we see in the computing infrastructure and applications of IaaS systems. We argue that these changes enable and demand a very different model of operating system. We then describe the MulitLibOS architecture we are exploring and how it helps exploit the scale and elasticity of integrated systems while still allowing for legacy software run on traditional OSes."
JONATHAN APPAVOO,Scalable elastic systems architecture,"Cloud computing has spurred the exploration and exploitation of elastic access to large scales of computing. To date the predominate building blocks by which elasticity has been exploited are applications and operating systems that are built around traditional computing infrastructure and programming models that are in-elastic or at best coarsely elastic. What would happen if application themselves could express and exploit elasticity in a fine grain fashion and this elasticity could be efficiently mapped to the scale and elasticity offered by modern cloud hardware systems? Would economic and market models that exploit elasticity pervade even the lowest levels? And would this enable greater efficiency both globally and individually? Would novel approaches to traditional problems such as quality of service arise? Would new applications be enabled both technically and economically? How to construct scalable and elastic software is an open challenge. Our work explores a systematic method for constructing and deploying such software. Building on several years of prior research, we will develop and evaluate a new cloud computing systems software architecture that addresses both scalability and elasticity. We explore a combination of a novel programming model and alternative operating systems structure. The goal of the architecture is to enable applications that inherently can scale up or down to react to changes in demand. We hypothesize that enabling such fine-grain elastic applications will open up new avenues for exploring both supply and demand elasticity across a broad range of research areas such as economic models, optimization, mechanism design, software engineering, networking and others."
JONATHAN APPAVOO,Transistor scaled HPC application performance,"We propose a radically new, biologically inspired, model of extreme scale computer on which ap- plication performance automatically scales with the transistor count even in the face of component failures. Today high performance computers are massively parallel systems composed of potentially hundreds of thousands of traditional processor cores, formed from trillions of transistors, consuming megawatts of power. Unfortunately, increasing the number of cores in a system, unlike increasing clock frequencies, does not automatically translate to application level improvements. No general auto-parallelization techniques or tools exist for HPC systems. To obtain application improvements, HPC application programmers must manually cope with the challenge of multicore programming and the significant drop in reliability associated with the sheer number of transistors. Drawing on biological inspiration, the basic premise behind this work is that computation can be dramatically accelerated by integrating a very large-scale, system-wide, predictive associative memory into the operation of the computer. The memory effectively turns computation into a form of pattern recognition and prediction whose result can be used to avoid significant fractions of computation. To be effective the expectation is that the memory will require billions of concurrent devices akin to biological cortical systems, where each device implements a small amount of storage, computation and localized communication. As typified by the recent announcement of the Lyric GP5 Probability Processor, very efficient scalable hardware for pattern recognition and prediction are on the horizon. One class of such devices, called neuromorphic, was pioneered by Carver Mead in the 80’s to provide a path for breaking the power, scaling, and reliability barriers associated with standard digital VLSI tech- nology. Recent neuromorphic research examples include work at Stanford, MIT, and the DARPA Sponsored SyNAPSE Project. These devices operate transistors as unclocked analog devices orga- nized to implement pattern recognition and prediction several orders of magnitude more efficiently than functionally equivalent digital counterparts. Abstractly, the devices can be used to implement modern machine learning or statistical inference. When exposed to data as a time-varying signal, the devices learn and store patterns in the data at multiple time scales and constantly provide predictions about what the signal will do in the future. This kind of function can be seen as a form of predictive associative memory. In this paper we describe our model and initial plans for exploring it."
JONATHAN APPAVOO,Unikernels: the next stage of Linux’s dominance,"Unikernels have demonstrated enormous advantages over Linux in many important domains, causing some to propose that the days of Linux's dominance may be coming to an end. On the contrary, we believe that unikernels' advantages represent the next natural evolution for Linux, as it can adopt the best ideas from the unikernel approach and, along with its battle-tested codebase and large open source community, continue to dominate. In this paper, we posit that an upstreamable unikernel target is achievable from the Linux kernel, and, through an early Linux unikernel prototype, demonstrate that some simple changes can bring dramatic performance advantages."
JONATHAN APPAVOO,Why elasticity matters,"In this paper we proposed a new research agenda focused on elasticity. We argued that elasticity is an important area of research and hypothesized that research in this area will lead to more efficient systems with less hoarding, new applications that exploit massive cloud resources elastically, and system software and libraries that will simplify the task of developing elastic applications. We discussed some of our thoughts on a top-to-bottom cloud-scale system focused on elasticity. We argued that such a system will require: 1) a HW/IaaS layer that can quickly reallocated resources to different applications, 2) an event driven model where resource demand flows from the high level layers as transparently as possible to the lowest level of the system, and 3) a model of modularity that allows layers to be overridden as necessary and provides applications with a component model that enables the base elasticity to be exploited by new and advanced applications."
JONATHAN APPAVOO,EbbRT: Elastic Building Block Runtime - case studies,"We present a new systems runtime, EbbRT, for cloud hosted applications. EbbRT takes a different approach to the role operating systems play in cloud computing. It supports stitching application functionality across nodes running commodity OSs and nodes running specialized application specific software that only execute what is necessary to accelerate core functions of the application. In doing so, it allows tradeoffs between efficiency, developer productivity, and exploitation of elasticity and scale. EbbRT, as a software model, is a framework for constructing applications as collections of standard application software and Elastic Building Blocks (Ebbs). Elastic Building Blocks are components that encapsulate runtime software objects and are implemented to exploit the raw access, scale and elasticity of IaaS resources to accelerate critical application functionality. This paper presents the EbbRT architecture, our prototype and experimental evaluation of the prototype under three different application scenarios."
JONATHAN APPAVOO,EbbRT: a framework for building per-application library operating systems,"Efficient use of high speed hardware requires operating system components be customized to the application work- load. Our general purpose operating systems are ill-suited for this task. We present EbbRT, a framework for constructing per-application library operating systems for cloud applications. The primary objective of EbbRT is to enable high-performance in a tractable and maintainable fashion. This paper describes the design and implementation of EbbRT, and evaluates its ability to improve the performance of common cloud applications. The evaluation of the EbbRT prototype demonstrates memcached, run within a VM, can outperform memcached run on an unvirtualized Linux. The prototype evaluation also demonstrates an 14% performance improvement of a V8 JavaScript engine benchmark, and a node.js webserver that achieves a 50% reduction in 99th percentile latency compared to it run on Linux."
JONATHAN APPAVOO,EbbRT: Elastic Building Block Runtime - overview,"EbbRT provides a lightweight runtime that enables the construction of reusable, low-level system software which can integrate with existing, general purpose systems. It achieves this by providing a library that can be linked into a process on an existing OS, and as a small library OS that can be booted directly on an IaaS node."
JONATHAN APPAVOO,Programmable smart machines,"In this paper we conjecture that a system can be constructed that exploits the general ability to learn through the counting, correlating, and memorizing of occurrences of events to fast-forward a programmable computer. In particular, we propose a signal based interpretation of a computer's execution that can be used to implement a form of system state memoization using a predictive associative memory. Such an approach may some day lead to a system that can utilize both traditional logic and neuromorphic or other biologically inspired mechanisms to be both programmable and smart."
JONATHAN APPAVOO,Slowing down for performance and energy: an OS-centric study in network driven workloads,"This paper studies three fundamental aspects of an OS that impact the performance and energy efficiency of network processing: 1) batching, 2) processor energy settings, and 3) the logic and instructions of the OS networking paths. A network device’s interrupt delay feature is used to induce batching and processor frequency is manipulated to control the speed of instruction execution. A baremetal library OS is used to explore OS path specialization. This study shows how careful use of batching and interrupt delay results in 2X energy and performance improvements across different workloads. Surprisingly, we find polling can be made energy efficient and can result in gains up to 11X over baseline Linux. We developed a methodology and a set of tools to collect system data in order to understand how energy is impacted at a fine-grained granularity. This paper identifies a number of other novel findings that have implications in OS design for networked applications and suggests a path forward to consider energy as a focal point of systems research."
JONATHAN APPAVOO,The virtual block interface: a flexible alternative to the conventional virtual memory framework,"Computers continue to diversify with respect to system designs, emerging memory technologies, and application memory demands. Unfortunately, continually adapting the conventional virtual memory framework to each possible system configuration is challenging, and often results in performance loss or requires non-trivial workarounds. To address these challenges, we propose a new virtual memory framework, the Virtual Block Interface (VBI). We design VBI based on the key idea that delegating memory management duties to hardware can reduce the overheads and software complexity associated with virtual memory. VBI introduces a set of variable-sized virtual blocks (VBs) to applications. Each VB is a contiguous region of the globally-visible VBI address space, and an application can allocate each semantically meaningful unit of information (e.g., a data structure) in a separate VB. VBI decouples access protection from memory allocation and address translation. While the OS controls which programs have access to which VBs, dedicated hardware in the memory controller manages the physical memory allocation and address translation of the VBs. This approach enables several architectural optimizations to (1) efficiently and flexibly cater to different and increasingly diverse system configurations, and (2) eliminate key inefficiencies of conventional virtual memory. We demonstrate the benefits of VBI with two important use cases: (1) reducing the overheads of address translation (for both native execution and virtual machine environments), as VBI reduces the number of translation requests and associated memory accesses; and (2) two heterogeneous main memory architectures, where VBI increases the effectiveness of managing fast memory regions. For both cases, VBI significantly improves performance over conventional virtual memory."
JONATHAN APPAVOO,Towards general-purpose neural network computing,
FRANCESCA SETA,Vascular smooth muscle Sirtuin-1 protects against aortic dissection during Angiotensin II-induced hypertension,"BACKGROUND: Sirtuin-1 (SirT1), a nicotinamide adenine dinucleotide(+)-dependent deacetylase, is a key enzyme in the cellular response to metabolic, inflammatory, and oxidative stresses; however, the role of endogenous SirT1 in the vasculature has not been fully elucidated. Our goal was to evaluate the role of vascular smooth muscle SirT1 in the physiological response of the aortic wall to angiotensin II, a potent hypertrophic, oxidant, and inflammatory stimulus. METHODS AND RESULTS: Mice lacking SirT1 in vascular smooth muscle (ie, smooth muscle SirT1 knockout) had drastically high mortality (70%) caused by aortic dissection after angiotensin II infusion (1 mg/kg per day) but not after an equipotent dose of norepinephrine, despite comparable blood pressure increases. Smooth muscle SirT1 knockout mice did not show any abnormal aortic morphology or blood pressure compared with wild-type littermates. Nonetheless, in response to angiotensin II, aortas from smooth muscle SirT1 knockout mice had severely disorganized elastic lamellae with frequent elastin breaks, increased oxidant production, and aortic stiffness compared with angiotensin II-treated wild-type mice. Matrix metalloproteinase expression and activity were increased in the aortas of angiotensin II-treated smooth muscle SirT1 knockout mice and were prevented in mice overexpressing SirT1 in vascular smooth muscle or with use of the oxidant scavenger tempol. CONCLUSIONS: Endogenous SirT1 in aortic smooth muscle is required to maintain the structural integrity of the aortic wall in response to oxidant and inflammatory stimuli, at least in part, by suppressing oxidant-induced matrix metalloproteinase activity. SirT1 activators could potentially be a novel therapeutic approach to prevent aortic dissection and rupture in patients at risk, such as those with hypertension or genetic disorders, such as Marfan's syndrome."
FRANCESCA SETA,BCL11B regulates arterial stiffness and related target organ damage,"RATIONALE: BCL11B (B-cell leukemia 11b) is a transcription factor known as an essential regulator of T lymphocytes and neuronal development during embryogenesis. A genome-wide association study showed that a gene desert region downstream of BCL11B, known to function as a BCL11B enhancer, harbors single nucleotide polymorphisms associated with increased arterial stiffness. However, a role for BCL11B in the adult cardiovascular system is unknown. OBJECTIVE: Based on these human findings, we sought to examine the relation between BCL11B and arterial function. METHODS AND RESULTS: Here we report that BCL11B is expressed in the vascular smooth muscle where it regulates vascular stiffness. RNA sequencing of aortas from wild-type and Bcl11b null mice (BSMKO) identified the cGMP (cyclic guanosine monophosphate)-cGMP-dependent protein kinase G (PKG) as the most significant differentially regulated signaling pathway in BSMKO compared with wild-type mice. BSMKO aortas showed decreased levels of PKG1, increased levels of Ca++-calmodulin-dependent serine/threonine phosphatase calcineurin (PP2B) and decreased levels of their common phosphorylation target, phosphorylated vasodilator-stimulated phosphoprotein (pVASPS239), a regulator of cytoskelatal actin rearrangements. Decreased pVASPS239 in BSMKO aortas was associated with increased actin polymerization (filamentous/globular actin ratio). Functionally, aortic force, stress, wall tension, and stiffness, measured ex vivo in organ baths, were increased in BSMKO aortas, and BSMKO mice had increased pulse wave velocity, the in vivo index of arterial stiffness. Despite having no effect on blood pressure or microalbuminuria, increased arterial stiffness in BSMKO mice was associated with increased incidence of cerebral microbleeds compared with age-matched wild-type littermates. CONCLUSIONS: We have identified vascular smooth muscle BCL11B as a crucial regulator of aortic smooth muscle function and a potential therapeutic target for vascular stiffness."
FRANCESCA SETA,MicroRNA-203 mimics age-related aortic smooth muscle dysfunction of cytoskeletal pathways,"Increased aortic stiffness is a biomarker for subsequent adverse cardiovascular events. We have previously reported that vascular smooth muscle Src-dependent cytoskeletal remodelling, which contributes to aortic plasticity, is impaired with ageing. Here, we use a multi-scale approach to determine the molecular mechanisms behind defective Src-dependent signalling in an aged C57BL/6 male mouse model. Increased aortic stiffness, as measured in vivo by pulse wave velocity, was found to have a comparable time course to that in humans. Bioinformatic analyses predicted several miRs to regulate Src-dependent cytoskeletal remodelling. qRT-PCR was used to determine the relative levels of predicted miRs in aortas and, notably, the expression of miR-203 increased almost twofold in aged aorta. Increased miR-203 expression was associated with a decrease in both mRNA and protein expression of Src, caveolin-1 and paxillin in aged aorta. Probing with phospho-specific antibodies confirmed that overexpression of miR-203 significantly attenuated Src and extracellular signal regulated kinase (ERK) signalling, which we have previously found to regulate vascular smooth muscle stiffness. In addition, transfection of miR-203 into aortic tissue from young mice increased phenylephrine-induced aortic stiffness ex vivo, mimicking the aged phenotype. Upstream of miR-203, we found that DNA methyltransferases (DNMT) 1, 3a, and 3b are also significantly decreased in the aged mouse aorta and that DNMT inhibition significantly increases miR-203 expression. Thus, the age-induced increase in miR-203 may be caused by epigenetic promoter hypomethylation in the aorta. These findings indicate that miR-203 promotes a re-programming of Src/ERK signalling pathways in vascular smooth muscle, impairing the regulation of stiffness in aged aorta."
MADISON CONDON,Limits to asset manager adaptation,"In Our Lives in Their Portfolios, Brett Christophers provides an account of the rise of ‘asset manager society’ – a world in which the infrastructures of public life are converted from public to private ownership. Here I use Christophers’ analysis to comment on growing calls for asset manager investment in climate adaptation. The asset manager business model requires ever-escalating returns, a poor fit with the now unavoidable losses that climate change promises to bring."
ALEXANDER SUSHKOV,Floquet-engineered quantum state manipulation in a noisy qubit,"Adiabatic evolution is a common strategy for manipulating quantum states and has been employed in diverse fields such as quantum simulation, computation and annealing. However, adiabatic evolution is inherently slow and therefore susceptible to decoherence. Existing methods for speeding up adiabatic evolution require complex many-body operators or are difficult to construct for multi-level systems. Using the tools of Floquet engineering, we design a scheme for high-fidelity quantum state manipulation, utilizing only the interactions available in the original Hamiltonian. We apply this approach to a qubit and experimentally demonstrate its performance with the electronic spin of a Nitrogen-vacancy center in diamond. Our Floquet-engineered protocol achieves state preparation fidelity of $0.994 \pm 0.004$, on the same level as the conventional fast-forward protocol, but is more robust to external noise acting on the qubit. Floquet engineering provides a powerful platform for high-fidelity quantum state manipulation in complex and noisy quantum systems."
SAHAR SHARIFZADEH,Structural and excited-state properties of oligoacene crystals from first principles,"Molecular crystals are a prototypical class of van der Waals (vdW) bound organic materials with excited state properties relevant for optoelectronics applications. Predicting the structure and excited state properties of molecular crystals presents a challenge for electronic structure theory, as standard approximations to density functional theory (DFT) do not capture long range vdW dispersion interactions and do not yield excited state properties. In this work, we use a combination of DFT including vdW forces) using both non local correlation functionals and pair wise correction methods (together with many body perturbation theory (MBPT) to study the geometry and excited states, respectively, of the entire series of oligoacene crystals, from benzene to hexacene. We find that vdW methods can predict lattice constants within 1 percent of the experimental measurements, on par with the previously reported accuracy of pairwise approximations for the same systems. We further find that excitation energies are sensitive to geometry, but if optimized geometries are used MBPT can yield excited state properties within a few tenths of an eV from experiment. We elucidate trends in MBPT computed charged and neutral excitation energies across the acene series and discuss the role of common approximations used in MBPT."
SAHAR SHARIFZADEH,Interplay of broken symmetry and delocalized excitations in the insulating state of 1T-TaS,
SAHAR SHARIFZADEH,"Broken symmetry optical transitions in (6,5) single-walled carbon nanotubes containing sp3 defects revealed by first-principles theory","We present a first-principles many-body perturbation theory study of nitrophenyl-doped (6,5) single-walled nanotubes (SWCNTs) to understand how sp3 doping impacts the excitonic properties. sp3-doped SWCNTs are promising as a class of optoelectronic materials with bright tunable photoluminescence, long spin coherence, and single-photon emission (SPE), motivating the study of spin excitations. We predict that the dopant results in a single unpaired spin localized around the defect site, which induces multiple low-energy excitonic peaks. By comparing optical absorption and photoluminescence from experiment and theory, we identify the transitions responsible for the red-shifted, defect-induced E11* peak, which has demonstrated SPE for some dopants; the presence of this state is due to both the symmetry-breaking associated with the defect and the presence of the defect-induced in-gap state. Furthermore, we find an asymmetry between the contribution of the two spin channels, suggesting that this system has potential for spin-selective optical transitions."
SAHAR SHARIFZADEH,Excitation protocols for nonlinear phononics in bismuth and antimony,
STEFANO MONTI,Abstract 803: Targeting β-catenin/CBP signaling in OSCC,"OBJECTIVES: Oral squamous cell carcinoma (OSCC) is an aggressive malignancy characterized by molecular heterogeneity and locoregional spread associated with high morbidity. Aggressive cancers are thought to arise from populations of cancer initiating cells (CICs) that exhibit the properties of stem cells and drive tumor development, recurrence and resistance to therapy. The transcriptional regulator, β-catenin, has been implicated in OSCC CICs. Nuclear β-catenin has been shown to recruit the chromatin remodeling CREB binding protein (CBP) to drive expression of proliferation and survival genes, as well as genes that maintain stem-like phenotypes. We hypothesized that targeting β-catenin-CBP interaction will inhibit CICs in oral tumors and restore an epithelial phenotype. METHODS: To test tumor aggressive potential of OSCC CICs, we used zebrafish as a model system. We isolated CD44+CD24hiCD29hi cells fom aggressive HSC-3 OSCC cells by FACS and assayed their ability to drive tumor growth and metastases in zebrafish compared to unsorted and CD44+CD24lowCD29low cells. In addition, we examined the role of the β-catenin/CBP axis in the aggressive phenotype of these cells. We also assessed whether the β-catenin/CBP axis affected CICs in tumors from immune competent HPV+ mice. RESULTS: Zebrafish injected with subpopulation of cells co-expressing CD44+CD24hiCD2hi primitive cell surface markers drove rapid tumor growth and metastases, followed by unsorted and sorted CD44+CD24lowCD29low. Treatment of CD44+CD24hiCD29hi cells with a small molecule inhibitor of the β-catenin-CBP interaction, ICG-001, interfered with tumor growth and metastases in zebrafish. Further, ICG-001 inhibited tumor growth in immunocompetent HPV+ murine model. On a cellular level, ICG-001 promoted membrane localization of β-catenin, enhanced E-cadherin adhesion and restored epithelial phenotype. Significantly, ICG-001 gene signatures tracked with reduced overall patient survival in the cancer genome atlas, TCGA. Conclusion: Our studies indicate that the β-catenin/CBP axis promotes OSCC CICs and that ICG-001 may be an effective therapeutic agent for this malignancy."
STEFANO MONTI,Inhibition of Ubc13-mediated ubiquitination by GPS2 regulates multiple stages of B cell development,"Non-proteolytic ubiquitin signaling mediated by Lys63 ubiquitin chains plays a critical role in multiple pathways that are key to the development and activation of immune cells. Our previous work indicates that GPS2 (G-protein Pathway Suppressor 2) is a multifunctional protein regulating TNF signaling and lipid metabolism in the adipose tissue through modulation of Lys63 ubiquitination events. However, the full extent of GPS2-mediated regulation of ubiquitination and the underlying molecular mechanisms are unknown. Here, we report that GPS2 is required for restricting the activation of TLR and BCR signaling pathways and the AKT/FOXO1 pathway in immune cells based on direct inhibition of Ubc13 enzymatic activity. Relevance of this regulatory strategy is confirmed in vivo by B cell-targeted deletion of GPS2, resulting in developmental defects at multiple stages of B cell differentiation. Together, these findings reveal that GPS2 genomic and non-genomic functions are critical for the development and cellular homeostasis of B cells."
ESTHER BULLITT,Giardia Cyst Wall Protein 1 Is a Lectin That Binds to Curled Fibrils of the GalNAc Homopolymer,"The infectious and diagnostic stage of Giardia lamblia (also known as G. intestinalis or G. duodenalis) is the cyst. The Giardia cyst wall contains fibrils of a unique β-1,3-linked N-acetylgalactosamine (GalNAc) homopolymer and at least three cyst wall proteins (CWPs) composed of Leu-rich repeats (CWPLRR) and a C-terminal conserved Cys-rich region (CWPCRR). Our goals were to dissect the structure of the cyst wall and determine how it is disrupted during excystation. The intact Giardia cyst wall is thin (~400 nm), easily fractured by sonication, and impermeable to small molecules. Curled fibrils of the GalNAc homopolymer are restricted to a narrow plane and are coated with linear arrays of oval-shaped protein complex. In contrast, cyst walls of Giardia treated with hot alkali to deproteinate fibrils of the GalNAc homopolymer are thick (~1.2 µm), resistant to sonication, and permeable. The deproteinated GalNAc homopolymer, which forms a loose lattice of curled fibrils, is bound by native CWP1 and CWP2, as well as by maltose-binding protein (MBP)-fusions containing the full-length CWP1 or CWP1LRR. In contrast, neither MBP alone nor MBP fused to CWP1CRR bind to the GalNAc homopolymer. Recombinant CWP1 binds to the GalNAc homopolymer within secretory vesicles of Giardia encysting in vitro. Fibrils of the GalNAc homopolymer are exposed during excystation or by treatment of heat-killed cysts with chymotrypsin, while deproteinated fibrils of the GalNAc homopolymer are degraded by extracts of Giardia cysts but not trophozoites. These results show the Leu-rich repeat domain of CWP1 is a lectin that binds to curled fibrils of the GalNAc homopolymer. During excystation, host and Giardia proteases appear to degrade bound CWPs, exposing fibrils of the GalNAc homopolymer that are digested by a stage-specific glycohydrolase. Author SummaryWhile the walls of plants and fungi contain numerous sugar homopolymers (cellulose, chitin, and β-1,3-glucans) and dozens of proteins, the cyst wall of Giardia is relatively simple. The Giardia wall contains a unique homopolymer of β-1,3-linked N-acetylgalactosamine (GalNAc) and at least three cyst wall proteins (CWPs), each of which is composed of Leu-rich repeats and a C-terminal Cys-rich region. The three major discoveries here are: 1) Fibrils of the GalNAc homopolymer are curled and form a lattice that is compressed into a narrow plane by bound protein in intact cyst walls. 2) Leu-rich repeats of CWP1 form a novel lectin domain that is specific for fibrils of the GalNAc homopolymer, which can be isolated by methods used to deproteinate fungal walls. 3) A cyst-specific glycohydrolase is able to degrade deproteinated fibrils of the GalNAc homopolymer. We incorporate these findings into a new curled fiber and lectin model of the intact Giardia cyst wall and a protease and glycohydrolase model of excystation."
ESTHER BULLITT,"Evidence for a ""Wattle and Daub"" Model of the Cyst Wall of Entamoeba","The cyst wall of Entamoeba invadens (Ei), a model for the human pathogen Entamoeba histolytica, is composed of fibrils of chitin and three chitin-binding lectins called Jacob, Jessie3, and chitinase. Here we show chitin, which was detected with wheat germ agglutinin, is made in secretory vesicles prior to its deposition on the surface of encysting Ei. Jacob lectins, which have tandemly arrayed chitin-binding domains (CBDs), and chitinase, which has an N-terminal CBD, were each made early during encystation. These results are consistent with their hypothesized roles in cross-linking chitin fibrils (Jacob lectins) and remodeling the cyst wall (chitinase). Jessie3 lectins likely form the mortar or daub of the cyst wall, because 1) Jessie lectins were made late during encystation; 2) the addition to Jessie lectins to the cyst wall correlated with a marked decrease in the permeability of cysts to nucleic acid stains (DAPI) and actin-binding heptapeptide (phalloidin); and 3) recombinant Jessie lectins, expressed as a maltose-binding proteins in the periplasm of Escherichia coli, caused transformed bacteria to agglutinate in suspension and form a hard pellet that did not dissociate after centrifugation. Jessie3 appeared as linear forms and rosettes by negative staining of secreted recombinant proteins. These findings provide evidence for a ""wattle and daub"" model of the Entamoeba cyst wall, where the wattle or sticks (chitin fibrils likely cross-linked by Jacob lectins) is constructed prior to the addition of the mortar or daub (Jessie3 lectins). Author SummaryParasitic protists, which are spread by the fecal-oral route, have cyst walls that resist environmental insults (e.g. desiccation, stomach acids, bile, etc.). Entamoeba histolytica, the cause of amebic dysentery and liver abscess, is the only protist characterized to date that has chitin in its cyst wall. We have previously characterized Entamoeba chitin synthases, chitinases, and multivalent chitin-binding lectins called Jacob. Here we present evidence that the Entamoeba Jessie3 lectin contributes to the mortar or daub, which makes the cyst wall impenetrable to small molecules. First, the Jessie3 lectin was made after chitin and Jacob lectins had already been deposited onto the surface of encysting Entamoeba. Second, cysts became impenetrable to small molecules at the same time that Jessie3 was deposited into the wall. Third, recombinant Jessie3 lectins self-aggregated and caused transfected bacteria to agglutinate. These results suggest a ""wattle and daub"" model of the Ei cyst wall, where the wattle or sticks (chitin fibrils likely cross-linked by Jacob lectins) is constructed prior to the addition of the mortar or daub (Jessie3 lectins)."
ESTHER BULLITT,Crystal structure of the P Pilus rod subunit PapA,"P pili are important adhesive fibres involved in kidney infection by uropathogenic Escherichia coli strains. P pili are assembled by the conserved chaperone-usher pathway, which involves the PapD chaperone and the PapC usher. During pilus assembly, subunits are incorporated into the growing fiber via the donor-strand exchange (DSE) mechanism, whereby the chaperone's G1 β-strand that complements the incomplete immunoglobulin-fold of each subunit is displaced by the N-terminal extension (Nte) of an incoming subunit. P pili comprise a helical rod, a tip fibrillum, and an adhesin at the distal end. PapA is the rod subunit and is assembled into a superhelical right-handed structure. Here, we have solved the structure of a ternary complex of PapD bound to PapA through donor-strand complementation, itself bound to another PapA subunit through DSE. This structure provides insight into the structural basis of the DSE reaction involving this important pilus subunit. Using gel filtration chromatography and electron microscopy on a number of PapA Nte mutants, we establish that PapA differs in its mode of assembly compared with other Pap subunits, involving a much larger Nte that encompasses not only the DSE region of the Nte but also the region N-terminal to it. Author Summary. Bacterial adhesion to a host is a crucial step that determines the onset of bacterial infection. It is mediated through recognition of a receptor on the host cell surface by a protein called an adhesin displayed on the surface of the bacterium. Many adhesins are displayed at the tip of specialized organelles called pili, some of which are assembled by the ubiquitous chaperone-usher pathway. In this pathway, each pilus subunit is assisted in folding by a chaperone. The resulting chaperone-subunit complex is targeted to a pore located in the outer membrane, called the usher, that serves as assembly platform. There, pilus subunits dissociate from the chaperone and polymerize, resulting in a surface organelle, the pilus, that protrudes out of the usher. Here, we have determined the structure of the major subunit of the P pilus, PapA. The P pilus, produced in uropathogenic Escherichia coli, displays the adhesin PapG responsible for targeting the bacterium to the kidney epithelium. We have determined the structure of PapA either bound to its cognate chaperone, PapD, or bound to another PapA subunit. These structures provide a view of PapA before and after its assembly in the pilus and shed light on the mechanism of PapA assembly."
MARGARET TYLER,Shared neuroanatomical substrates of impaired phonological working memory across reading disability and autism,"BACKGROUND: Individuals with reading disability or individuals with autism spectrum disorder (ASD) are characterized, respectively, by their difficulties in reading or social communication, but both groups often have impaired phonological working memory (PWM). It is not known whether the impaired PWM reflects distinct or shared neuroanatomical abnormalities in these two diagnostic groups. METHODS: White-matter structural connectivity via diffusion weighted imaging was examined in sixty-four children, ages 5-17 years, with reading disability, ASD, or typical development (TD), who were matched in age, gender, intelligence, and diffusion data quality. RESULTS: Children with reading disability and children with ASD exhibited reduced PWM compared to children with TD. The two diagnostic groups showed altered white-matter microstructure in the temporo-parietal portion of the left arcuate fasciculus (AF) and in the temporo-occipital portion of the right inferior longitudinal fasciculus (ILF), as indexed by reduced fractional anisotropy and increased radial diffusivity. Moreover, the structural integrity of the right ILF was positively correlated with PWM ability in the two diagnostic groups, but not in the TD group. CONCLUSIONS: These findings suggest that impaired PWM is transdiagnostically associated with shared neuroanatomical abnormalities in ASD and reading disability. Microstructural characteristics in left AF and right ILF may play important roles in the development of PWM. The right ILF may support a compensatory mechanism for children with impaired PWM."
MARGARET TYLER,Altered engagement of the speech motor network is associated with reduced phonological working memory in autism,"Nonword repetition, a common clinical measure of phonological working memory, involves component processes of speech perception, working memory, and speech production. Autistic children often show behavioral challenges in nonword repetition, as do many individuals with communication disorders. It is unknown which subprocesses of phonological working memory are vulnerable in autistic individuals, and whether the same brain processes underlie the transdiagnostic difficulty with nonword repetition. We used functional magnetic resonance imaging (fMRI) to investigate the brain bases for nonword repetition challenges in autism. We compared activation during nonword repetition in functional brain networks subserving speech perception, working memory, and speech production between neurotypical and autistic children. Autistic children performed worse than neurotypical children on nonword repetition and had reduced activation in response to increasing phonological working memory load in the supplementary motor area. Multivoxel pattern analysis within the speech production network classified shorter vs longer nonword-repetition trials less accurately for autistic than neurotypical children. These speech production motor-specific differences were not observed in a group of children with reading disability who had similarly reduced nonword repetition behavior. These findings suggest that atypical function in speech production brain regions may contribute to nonword repetition difficulties in autism."
QIONG YANG,The Framingham Heart Study 100K SNP Genome-Wide Association Study Resource: Overview of 17 Phenotype Working Group Reports,"BACKGROUND: The Framingham Heart Study (FHS), founded in 1948 to examine the epidemiology of cardiovascular disease, is among the most comprehensively characterized multi-generational studies in the world. Many collected phenotypes have substantial genetic contributors; yet most genetic determinants remain to be identified. Using single nucleotide polymorphisms (SNPs) from a 100K genome-wide scan, we examine the associations of common polymorphisms with phenotypic variation in this community-based cohort and provide a full-disclosure, web-based resource of results for future replication studies. METHODS: Adult participants (n = 1345) of the largest 310 pedigrees in the FHS, many biologically related, were genotyped with the 100K Affymetrix GeneChip. These genotypes were used to assess their contribution to 987 phenotypes collected in FHS over 56 years of follow up, including: cardiovascular risk factors and biomarkers; subclinical and clinical cardiovascular disease; cancer and longevity traits; and traits in pulmonary, sleep, neurology, renal, and bone domains. We conducted genome-wide variance components linkage and population-based and family-based association tests. RESULTS: The participants were white of European descent and from the FHS Original and Offspring Cohorts (examination 1 Offspring mean age 32 ± 9 years, 54% women). This overview summarizes the methods, selected findings and limitations of the results presented in the accompanying series of 17 manuscripts. The presented association results are based on 70,897 autosomal SNPs meeting the following criteria: minor allele frequency ≥ 10%, genotype call rate ≥ 80%, Hardy-Weinberg equilibrium p-value ≥ 0.001, and satisfying Mendelian consistency. Linkage analyses are based on 11,200 SNPs and short-tandem repeats. Results of phenotype-genotype linkages and associations for all autosomal SNPs are posted on the NCBI dbGaP website at. CONCLUSION: We have created a full-disclosure resource of results, posted on the dbGaP website, from a genome-wide association study in the FHS. Because we used three analytical approaches to examine the association and linkage of 987 phenotypes with thousands of SNPs, our results must be considered hypothesis-generating and need to be replicated. Results from the FHS 100K project with NCBI web posting provides a resource for investigators to identify high priority findings for replication."
QIONG YANG,Genome-Wide Association Study for Renal Traits in the Framingham Heart and Atherosclerosis Risk in Communities Studies,"BACKGROUND: The Framingham Heart Study (FHS) recently obtained initial results from the first genome-wide association scan for renal traits. The study of 70,987 single nucleotide polymorphisms (SNPs) in 1,010 FHS participants provides a list of SNPs showing the strongest associations with renal traits which need to be verified in independent study samples. METHODS: Sixteen SNPs were selected for replication based on the most promising associations with chronic kidney disease (CKD), estimated glomerular filtration rate (eGFR), and serum cystatin C in FHS. These SNPs were genotyped in 15,747 participants of the Atherosclerosis in Communities (ARIC) Study and evaluated for association using multivariable adjusted regression analyses. Primary outcomes in ARIC were CKD and eGFR. Secondary prospective analyses were conducted for association with kidney disease progression using multivariable adjusted Cox proportional hazards regression. The definition of the outcomes, all covariates, and the use of an additive genetic model was consistent with the original analyses in FHS. RESULTS: The intronic SNP rs6495446 in the gene MTHFS was significantly associated with CKD among white ARIC participants at visit 4: the odds ratio per each C allele was 1.24 (95% CI 1.09–1.41, p = 0.001). Borderline significant associations of rs6495446 were observed with CKD at study visit 1 (p = 0.024), eGFR at study visits 1 (p = 0.073) and 4 (lower mean eGFR per C allele by 0.6 ml/min/1.73 m2, p = 0.043) and kidney disease progression (hazard ratio 1.13 per each C allele, 95% CI 1.00–1.26, p = 0.041). Another SNP, rs3779748 in EYA1, was significantly associated with CKD at ARIC visit 1 (odds ratio per each T allele 1.22, p = 0.01), but only with eGFR and cystatin C in FHS. CONCLUSION: This genome-wide association study provides unbiased information implicating MTHFS as a candidate gene for kidney disease. Our findings highlight the importance of replication to identify common SNPs associated with renal traits."
QIONG YANG,Genome-Wide Association and Linkage Analyses of Hemostatic Factors and Hematological Phenotypes in the Framingham Heart Study,"BACKGROUND: Increased circulating levels of hemostatic factors as well as anemia have been associated with increased risk of cardiovascular disease (CVD). Known associations between hemostatic factors and sequence variants at genes encoding these factors explain only a small proportion of total phenotypic variation. We sought to confirm known putative loci and identify novel loci that may influence either trait in genome-wide association and linkage analyses using the Affymetrix GeneChip 100K single nucleotide polymorphism (SNP) set. METHODS: Plasma levels of circulating hemostatic factors (fibrinogen, factor VII, plasminogen activator inhibitor-1, von Willebrand factor, tissue plasminogen activator, D-dimer) and hematological phenotypes (platelet aggregation, viscosity, hemoglobin, red blood cell count, mean corpuscular volume, mean corpuscular hemoglobin concentration) were obtained in approximately 1000 Framingham Heart Study (FHS) participants from 310 families. Population-based association analyses using the generalized estimating equations (GEE), family-based association test (FBAT), and multipoint variance components linkage analyses were performed on the multivariable adjusted residuals of hemostatic and hematological phenotypes. RESULTS: In association analysis, the lowest GEE p-value for hemostatic factors was p = 4.5*10-16 for factor VII at SNP rs561241, a variant located near the F7 gene and in complete linkage disequilibrium (LD) (r2 = 1) with the Arg353Gln F7 SNP previously shown to account for 9% of total phenotypic variance. The lowest GEE p-value for hematological phenotypes was 7*10-8 at SNP rs2412522 on chromosome 4 for mean corpuscular hemoglobin concentration. We presented top 25 most significant GEE results with p-values in the range of 10-6 to 10-5 for hemostatic or hematological phenotypes. In relating 100K SNPs to known candidate genes, we identified two SNPs (rs1582055, rs4897475) in erythrocyte membrane protein band 4.1-like 2 (EPB41L2) associated with hematological phenotypes (GEE p < 10-3). In linkage analyses, the highest linkage LOD score for hemostatic factors was 3.3 for factor VII on chromosome 10 around 15 Mb, and for hematological phenotypes, LOD 3.4 for hemoglobin on chromosome 4 around 55 Mb. All GEE and FBAT association and variance components linkage results can be found at CONCLUSION: Using genome-wide association methodology, we have successfully identified a SNP in complete LD with a sequence variant previously shown to be strongly associated with factor VII, providing proof of principle for this approach. Further study of additional strongly associated SNPs and linked regions may identify novel variants that influence the inter-individual variability in hemostatic factors and hematological phenotypes."
QIONG YANG,A Genome-Wide Association for Kidney Function and Endocrine-Related Traits in the NHLBI's Framingham Heart Study,"BACKGROUND: Glomerular filtration rate (GFR) and urinary albumin excretion (UAE) are markers of kidney function that are known to be heritable. Many endocrine conditions have strong familial components. We tested for association between the Affymetrix GeneChip Human Mapping 100K single nucleotide polymorphism (SNP) set and measures of kidney function and endocrine traits. METHODS: Genotype information on the Affymetrix GeneChip Human Mapping 100K SNP set was available on 1345 participants. Serum creatinine and cystatin-C (cysC; n = 981) were measured at the seventh examination cycle (1998–2001); GFR (n = 1010) was estimated via the Modification of Diet in Renal Disease (MDRD) equation; UAE was measured on spot urine samples during the sixth examination cycle (1995–1998) and was indexed to urinary creatinine (n = 822). Thyroid stimulating hormone (TSH) was measured at the third and fourth examination cycles (1981–1984; 1984–1987) and mean value of the measurements were used (n = 810). Age-sex-adjusted and multivariable-adjusted residuals for these measurements were used in association with genotype data using generalized estimating equations (GEE) and family-based association tests (FBAT) models. We presented the results for association tests using additive allele model. We evaluated associations with 70,987 SNPs on autosomes with minor allele frequencies of at least 0.10, Hardy-Weinberg Equilibrium p-value ≥ 0.001, and call rates of at least 80%. RESULTS: The top SNPs associated with these traits using the GEE method were rs2839235 with GFR (p-value 1.6*10-05), rs1158167 with cysC (p-value 8.5*10-09), rs1712790 with UAE (p-value 1.9*10-06), and rs6977660 with TSH (p-value 3.7*10-06), respectively. The top SNPs associated with these traits using the FBAT method were rs6434804 with GFR(p-value 2.4*10-5), rs563754 with cysC (p-value 4.7*10-5), rs1243400 with UAE (p-value 4.8*10-6), and rs4128956 with TSH (p-value 3.6*10-5), respectively. Detailed association test results can be found at . Four SNPs in or near the CST3 gene were highly associated with cysC levels (p-value 8.5*10-09 to 0.007). CONCLUSION: Kidney function traits and TSH are associated with SNPs on the Affymetrix GeneChip Human Mapping 100K SNP set. These data will serve as a valuable resource for replication as more SNPs associated with kidney function and endocrine traits are identified."
QIONG YANG,Power and Type I Error Rate of False Discovery Rate Approaches in Genome-Wide Association Studies,"In genome-wide genetic studies with a large number of markers, balancing the type I error rate and power is a challenging issue. Recently proposed false discovery rate (FDR) approaches are promising solutions to this problem. Using the 100 simulated datasets of a genome-wide marker map spaced about 3 cM and phenotypes from the Genetic Analysis Workshop 14, we studied the type I error rate and power of Storey's FDR approach, and compared it to the traditional Bonferroni procedure. We confirmed that Storey's FDR approach had a strong control of FDR. We found that Storey's FDR approach only provided weak control of family-wise error rate (FWER). For these simulated datasets, Storey's FDR approach only had slightly higher power than the Bonferroni procedure. In conclusion, Storey's FDR approach is more powerful than the Bonferroni procedure if strong control of FDR or weak control of FWER is desired. Storey's FDR approach has little power advantage over the Bonferroni procedure if there is low linkage disequilibrium among the markers. Further evaluation of the type I error rate and power of the FDR approaches for higher linkage disequilibrium and for haplotype analyses is warranted."
QIONG YANG,The Framingham Heart Study 100K SNP Genome-Wide Association Study Resource: Overview of 17 Phenotype Working Group Reports,"BACKGROUND: The Framingham Heart Study (FHS), founded in 1948 to examine the epidemiology of cardiovascular disease, is among the most comprehensively characterized multi-generational studies in the world. Many collected phenotypes have substantial genetic contributors; yet most genetic determinants remain to be identified. Using single nucleotide polymorphisms (SNPs) from a 100K genome-wide scan, we examine the associations of common polymorphisms with phenotypic variation in this community-based cohort and provide a full-disclosure, web-based resource of results for future replication studies. METHODS: Adult participants (n = 1345) of the largest 310 pedigrees in the FHS, many biologically related, were genotyped with the 100K Affymetrix GeneChip. These genotypes were used to assess their contribution to 987 phenotypes collected in FHS over 56 years of follow up, including: cardiovascular risk factors and biomarkers; subclinical and clinical cardiovascular disease; cancer and longevity traits; and traits in pulmonary, sleep, neurology, renal, and bone domains. We conducted genome-wide variance components linkage and population-based and family-based association tests. RESULTS: The participants were white of European descent and from the FHS Original and Offspring Cohorts (examination 1 Offspring mean age 32 ± 9 years, 54% women). This overview summarizes the methods, selected findings and limitations of the results presented in the accompanying series of 17 manuscripts. The presented association results are based on 70,897 autosomal SNPs meeting the following criteria: minor allele frequency ≥ 10%, genotype call rate ≥ 80%, Hardy-Weinberg equilibrium p-value ≥ 0.001, and satisfying Mendelian consistency. Linkage analyses are based on 11,200 SNPs and short-tandem repeats. Results of phenotype-genotype linkages and associations for all autosomal SNPs are posted on the NCBI dbGaP website at. CONCLUSION: We have created a full-disclosure resource of results, posted on the dbGaP website, from a genome-wide association study in the FHS. Because we used three analytical approaches to examine the association and linkage of 987 phenotypes with thousands of SNPs, our results must be considered hypothesis-generating and need to be replicated. Results from the FHS 100K project with NCBI web posting provides a resource for investigators to identify high priority findings for replication."
QIONG YANG,A Three-Stage Approach for Genome-Wide Association Studies with Family Data for Quantitative Traits,"BACKGROUND. Genome-wide association (GWA) studies that use population-based association approaches may identify spurious associations in the presence of population admixture. In this paper, we propose a novel three-stage approach that is computationally efficient and robust to population admixture and more powerful than the family-based association test (FBAT) for GWA studies with family data. We propose a three-stage approach for GWA studies with family data. The first stage is to perform linear regression ignoring phenotypic correlations among family members. SNPs with a first stage p-value below a liberal cut-off (e.g. 0.1) are then analyzed in the second stage that employs a linear mixed effects (LME) model that accounts for within family correlations. Next, SNPs that reach genome-wide significance (e.g. 10-6 for 34,625 genotyped SNPs in this paper) are analyzed in the third stage using FBAT, with correction of multiple testing only for SNPs that enter the third stage. Simulations are performed to evaluate type I error and power of the proposed method compared to LME adjusting for 10 principal components (PC) of the genotype data. We also apply the three-stage approach to the GWA analyses of uric acid in Framingham Heart Study's SNP Health Association Resource (SHARe) project. RESULTS. Our simulations show that whether or not population admixture is present, the three-stage approach has no inflated type I error. In terms of power, using LME adjusting PC is only slightly more powerful than the three-stage approach. When applied to the GWA analyses of uric acid in the SHARe project of FHS, the three-stage approach successfully identified and confirmed three SNPs previously reported as genome-wide significant signals. CONCLUSIONS. For GWA analyses of quantitative traits with family data, our three-stage approach provides another appealing solution to population admixture, in addition to LME adjusting for genetic PC."
QIONG YANG,"Genome-wide association studies of serum magnesium, potassium, and sodium concentrations identify six loci influencing serum magnesium levels","Magnesium, potassium, and sodium, cations commonly measured in serum, are involved in many physiological processes including energy metabolism, nerve and muscle function, signal transduction, and fluid and blood pressure regulation. To evaluate the contribution of common genetic variation to normal physiologic variation in serum concentrations of these cations, we conducted genome-wide association studies of serum magnesium, potassium, and sodium concentrations using ∼2.5 million genotyped and imputed common single nucleotide polymorphisms (SNPs) in 15,366 participants of European descent from the international CHARGE Consortium. Study-specific results were combined using fixed-effects inverse-variance weighted meta-analysis. SNPs demonstrating genome-wide significant (p<5×10−8) or suggestive associations (p<4×10−7) were evaluated for replication in an additional 8,463 subjects of European descent. The association of common variants at six genomic regions (in or near MUC1, ATP2B1, DCDC5, TRPM6, SHROOM3, and MDS1) with serum magnesium levels was genome-wide significant when meta-analyzed with the replication dataset. All initially significant SNPs from the CHARGE Consortium showed nominal association with clinically defined hypomagnesemia, two showed association with kidney function, two with bone mineral density, and one of these also associated with fasting glucose levels. Common variants in CNNM2, a magnesium transporter studied only in model systems to date, as well as in CNNM3 and CNNM4, were also associated with magnesium concentrations in this study. We observed no associations with serum sodium or potassium levels exceeding p<4×10−7. Follow-up studies of newly implicated genomic loci may provide additional insights into the regulation and homeostasis of human serum magnesium levels. Author Summary Magnesium, potassium, and sodium are involved in important physiological processes. To better understand how common genetic variation may contribute to inter-individual differences in serum concentrations of these electrolytes, we evaluated single nucleotide polymorphisms (SNPs) across the genome in association with serum magnesium, potassium, and sodium levels in 15,366 participants of European descent from the CHARGE Consortium. We then verified the associations in an additional 8,463 study participants. Six different genomic regions contain variants that are reproducibly associated with serum magnesium levels, and only one of the regions had been previously known to influence serum magnesium concentrations in humans. The identified SNPs also show association with clinically defined hypomagnesemia, and some of them with traits that have been linked to serum magnesium levels, including kidney function, fasting glucose, and bone mineral density. We further provide evidence for a physiological role of magnesium transporters in humans which have previously only been studied in model systems. None of the SNPs evaluated in our study are significantly associated with serum levels of sodium or potassium. Additional studies are needed to investigate the underlying molecular mechanisms in order to help us understand the contribution of these newly identified regions to magnesium homeostasis."
QIONG YANG,Genetic Analysis Workshop 15: Gene Expression Analysis and Approaches to Detecting Multiple Functional Loci,
QIONG YANG,Joint Modeling of Linkage and Association Using Affected Sib-Pair Data,"There has been a growing interest in developing strategies for identifying single-nucleotide polymorphisms (SNPs) that explain a linkage signal by joint modeling of linkage and association. We compare several existing methods and propose a new method called the homozygote sharing transmission-disequilibrium test (HSTDT) to detect linkage and association or to identify SNPs explaining the linkage signal on chromosome 6 for rheumatoid arthritis using 100 replicates of the Genetic Analysis Workshop (GAW) 15 simulated affected sib-pair data. Existing methods considered included the family-based tests of association implemented in FBAT, a transmission-disequilibrium test, a conditional logistic regression approach, a likelihood-based approach implemented in LAMP, and the homozygote sharing test (HST). We compared the type I error rates and power for tests classified into three categories according to their null hypotheses: 1) no association in the presence of linkage (i.e., a SNP explains none of the linkage evidence), 2) no linkage adjusting for the association (i.e., a SNP explains all linkage evidence), and 3) no linkage and no association. For testing association in the presence of linkage, we found similar power among all tests except for the homozygote sharing test that had lower power. When testing linkage adjusting for association, similar power was observed between LAMP and HST, but lower power for the conditional logistic regression method. When testing linkage or association, the conditional logistic regression method was more powerful than FBAT."
QIONG YANG,Two-Stage Approach for Identifying Single-Nucleotide Polymorphisms Associated with Rheumatoid Arthritis Using Random Forests and Bayesian Networks,"We used the simulated data set from Genetic Analysis Workshop 15 Problem 3 to assess a two-stage approach for identifying single-nucleotide polymorphisms (SNPs) associated with rheumatoid arthritis (RA). In the first stage, we used random forests (RF) to screen large amounts of genetic data using the variable importance measure, which takes into account SNP interaction effects as well as main effects without requiring model specification. We used the simulated 9187 SNPs mimicking a 10 K SNP chip, along with covariates DR (the simulated DRB1 gentoype), smoking, and sex as input to the RF analyses with a training set consisting of 750 unrelated RA cases and 750 controls. We used an iterative RF screening procedure to identify a smaller set of variables for further analysis. In the second stage, we used the software program CaMML for producing Bayesian networks, and developed complex etiologic models for RA risk using the variables identified by our RF screening procedure. We evaluated the performance of this method using independent test data sets for up to 100 replicates."
QIONG YANG,Description of the Framingham Heart Study Data for Genetic Analysis Workshop 13,
QIONG YANG,Handling Linkage Disequilibrium in Linkage Analysis Using Dense Single-Nucleotide Polymorphisms,"The presence of linkage disequilibrium violates the underlying assumption of linkage equilibrium in most traditional multipoint linkage approaches. Studies have shown that such violation leads to bias in qualitative trait linkage analysis when parental genotypes are unavailable. Appropriate handling of marker linkage disequilibrium can avoid such false positive evidence. Using the rheumatoid arthritis simulated data from Genetic Analysis Workshop 15, we examined and compared the following three approaches to handle linkage disequilibrium among dense markers in both qualitative and quantitative trait linkage analyses: a simple algorithm; SNPLINK, methods for marker selection; and MERLIN-LD, a method for modeling linkage disequilibrium by creating marker clusters. In analysis ignoring linkage disequilibrium between markers, we observed LOD score inflation only in the affected sib-pair linkage analysis without parental genotypes; no such inflation was present in the quantitative trait locus linkage analysis with severity as our phenotype with or without parental genotypes. Using methods to model or adjust for linkage disequilibrium, we found a substantial reduction of inflation of LOD score in affected sib-pair linkage analysis. Greater LOD score reduction was observed by decreasing the amount of tolerable linkage disequilibrium among markers selected or marker clusters using MERLIN-LD; the latter approach showed most reduction. SNPLINK performed better with selected markers based on the D' measure of linkage disequilibrium as opposed to the r2 measure and outperformed the simple algorithm. Our findings reiterate the necessity of properly handling dense markers in linkage analysis, especially when parental genotypes are unavailable."
QIONG YANG,Genetic Analyses of Longitudinal Phenotype Data: A Comparison of Univariate Methods and a Multivariate Approach,"BACKGROUND. We explored three approaches to heritability and linkage analyses of longitudinal total cholesterol levels (CHOL) in the Genetic Analysis Workshop 13 simulated data without knowing the answers. The first two were univariate approaches and used 1) baseline measure at exam one or 2) summary measures such as mean and slope from multiple exams. The third method was a multivariate approach that directly models multiple measurements on a subject. A variance components model (SOLAR) was employed in the univariate approaches. A mixed regression model with polynomials was employed in the multivariate approach and implemented in SAS/IML. RESULTS. Using the baseline measure at exam 1, we detected all baseline or slope genes contributing a substantial amount (0.08) of variance (LOD > 3). Compared to the baseline measure, the mean measures yielded slightly higher LOD at the slope genes, and a lower LOD at the baseline genes. The slope measure produced a somewhat lower LOD for the slope gene than did the mean measure. Descriptive information on the pattern of changes in gene effects with age was estimated for three linked loci by the third approach. CONCLUSION. We found simple univariate methods may be effective to detect genes affecting longitudinal phenotypes but may not fully reveal temporal trends in gene effects. The relative efficiency of the univariate methods to detect genes depends heavily on the underlying model. Compared with the univariate approaches, the multivariate approach provided more information on temporal trends in gene effects at the cost of more complicated modelling and more intense computations."
QIONG YANG,CDKN1C/p57kip2 Is a candidate tumor suppressor gene in human breast cancer,"BACKGROUND. CDKN1C (also known as p57KIP2) is a cyclin-dependent kinase inhibitor previously implicated in several types of human cancer. Its family members (CDKN1A/p21CIP1 and B/p27KIP1) have been implicated in breast cancer, but information about CDKN1C's role is limited. We hypothesized that decreased CDKN1C may be involved in human breast carcinogenesis in vivo. METHODS. We determined rates of allele imbalance or loss of heterozygosity (AI/LOH) in CDKN1C, using an intronic polymorphism, and in the surrounding 11p15.5 region in 82 breast cancers. We examined the CDKN1C mRNA level in 10 cancers using quantitative real-time PCR (qPCR), and the CDKN1C protein level in 20 cancers using immunohistochemistry (IHC). All samples were obtained using laser microdissection. Data were analyzed using standard statistical tests. RESULTS. AI/LOH at 11p15.5 occurred in 28/73 (38%) informative cancers, but CDKN1C itself underwent AI/LOH in only 3/16 (19%) cancers (p = ns). In contrast, CDKN1C mRNA levels were reduced in 9/10 (90%) cancers (p < 0.0001), ranging from 2–60% of paired normal epithelium. Similarly, CDKN1C protein staining was seen in 19/20 (95%) cases' normal epithelium but in only 7/14 (50%) cases' CIS (p < 0.004) and 5/18 (28%) cases' IC (p < 0.00003). The reduction appears primarily due to loss of CDKN1C expression from myoepithelial layer cells, which stained intensely in 17/20 (85%) normal lobules, but in 0/14 (0%) CIS (p < 0.00001). In contrast, luminal cells displayed less intense, focal staining fairly consistently across histologies. Decreased CDKN1C was not clearly associated with tumor grade, histology, ER, PR or HER2 status. CONCLUSION. CDKN1C is expressed in normal epithelium of most breast cancer cases, mainly in the myothepithelial layer. This expression decreases, at both the mRNA and protein level, in the large majority of breast cancers, and does not appear to be mediated by AI/LOH at the gene. Thus, CDKN1C may be a breast cancer tumor suppressor."
CAROLYN HODGES-SIMEON,Can listeners assess men's self-reported health from their voice?,"Men's voices may provide cues to overall condition; however, little research has assessed whether health status is reliably associated with perceivable voice parameters. In Study 1, we investigated whether listeners could classify voices belonging to men with either relatively lower or higher self-reported health. Participants rated voices for speaker health, disease likelihood, illness frequency, and symptom severity, as well as attractiveness (women only) and dominance (men only). Listeners' were mostly unable to judge the health of male speakers from their voices; however, men rated the voices of men with better self-reported health as sounding more dominant. In Study 2, we tested whether men's vocal parameters (fundamental frequency mean and variation, apparent vocal tract length, and harmonics-to-noise ratio) and aspects of their self-reported health predicted listeners' health and disease resistance ratings of those voices. Speakers' fundamental frequency (𝑓ₒ) negatively predicted ratings of health. However, speakers' self-reported health did not predict ratings of health made by listeners. In Study 3, we investigated whether separately manipulating two sexually dimorphic vocal parameters—𝑓ₒ and apparent vocal tract length (VTL)—affected listeners' health ratings. Listeners rated men's voices with lower 𝑓ₒ (but not VTL) as healthier, supporting findings from Study 2. Women rated voices with lower 𝑓ₒ and VTL as more attractive, and men rated them as more dominant. Thus, while both VTL and 𝑓ₒ affect dominance and attractiveness judgments, only 𝑓ₒ appears to affect health judgments. Results of the above studies suggest that, although listeners assign higher health ratings to speakers with more masculine 𝑓ₒ, these ratings may not be accurate at tracking speakers' self-rated health."
ANDREW BELL,Crafting spaces for good water governance in Pakistan,
ANDREW BELL,A workbook of stories and selected exercises for boys of sixth grade interests and second grade reading ability,
ANDREW BELL,"Archaeologists and American foreign relations in a World of Empire, 1879-1945","This dissertation explores how, between 1879 and 1945, American archaeologists contributed to the expansion of the U.S. state’s presence overseas and in the western territories; how they legitimated, propagated, and amplified imperial projects across the globe; and how they spurred broader American investments in the world and antiquity. It follows archaeologists out of museums and lecture halls and into the field, where their research demanded the cultivation of local elites for access to sites; organization of indigenous peoples, local peasants, and migrant workers into labor regimes; enlistment of diplomatic aid to secure possession of finds; and collaboration with the Departments of War and the Interior to institute policies of protection and surveillance. Whether they operated in Mediterranean states within the political orbit of Europe’s Great Powers, the colonial-territorial American Southwest, United Fruit enclaves in Guatemala, British-controlled Palestine, or occupied Japan—American archaeologists considered disputed and less-than sovereign spaces the most bountiful fields for harvesting artifacts. Contested antiquities—which no group or nation bore singular possession—then followed archaeologists back to the United States, where Americans staked their own claims to them, using these remnants of the past to understand themselves as heirs to collective—Western, settler, pan-American, Judeo-Christian, or world—heritages. Chapter one sets the stage by revealing how government agents, namely consuls, once spearheaded American contributions to archaeological research. Chapter two examines the Archaeological Institute of America’s first projects—conducting a major excavation and establishing a field school—in the Ottoman Empire and Greece, two ostensibly sovereign nations, and the appeal of Western civilization. Chapter three explores the relationship between archaeologists and settler-colonialism in New Mexico prior to statehood. Chapter four connects archaeological work at the Maya site of Quiriguá to the informal-imperial projects and pan-American ideas that structured U.S.-Central American relations. Chapter five details the complex interactions between American archaeologists, British authorities, Jewish settlers, and local Arabs in the Palestine Mandate. Chapter six explores the height of American archaeologists’ collaboration with the U.S. government—serving as advisors in the Second World War—and the development of the world heritage idea amid the “war without mercy” in the Pacific."
ANDREW BELL,The role of incentive-based instruments and social equity in conservation conflict interventions,"Conflicts between biodiversity conservation and other human activities are multifaceted. Understanding farmer preferences for various conflict mitigation strategies is therefore critical. We developed a novel interactive game around farmer land management decisions across 18 villages in Gabon to examine responses to three elephant conflict mitigation options: use of elephant deterrent methods, flat-rate subsidy, and agglomeration payments rewarding coordinated action for setting land aside for elephants. We found that all three policies significantly reduced participants’ inclinations to engage in lethal control. Use of deterrents and agglomeration payments were also more likely to reduce decisions to kill elephants in situations where levels of social equity were higher. Only the two monetary incentives increased farmers’ predisposition to provide habitats for elephants, suggesting that incentive-based instruments were conducive to pro-conservation behavior; different subsidy levels did not affect responses. Likewise, neither participants’ socioeconomic characteristics nor their real-life experiences of crop damage by elephants affected game decisions. Killing behavior in the games was 64% lower in villages influenced by protected areas than in villages surrounded by logging concessions, highlighting the need to address conservation conflicts beyond protected areas. Our study shows the importance of addressing underlying social conflicts, specifically equity attitudes, prior to, or alongside addressing material losses."
ANDREW BELL,Causal language and strength of inference in academic and media articles shared in social media (CLAIMS): a systematic review,"BACKGROUND: The pathway from evidence generation to consumption contains many steps which can lead to overstatement or misinformation. The proliferation of internet-based health news may encourage selection of media and academic research articles that overstate strength of causal inference. We investigated the state of causal inference in health research as it appears at the end of the pathway, at the point of social media consumption. METHODS: We screened the NewsWhip Insights database for the most shared media articles on Facebook and Twitter reporting about peer-reviewed academic studies associating an exposure with a health outcome in 2015, extracting the 50 most-shared academic articles and media articles covering them. We designed and utilized a review tool to systematically assess and summarize studies’ strength of causal inference, including generalizability, potential confounders, and methods used. These were then compared with the strength of causal language used to describe results in both academic and media articles. Two randomly assigned independent reviewers and one arbitrating reviewer from a pool of 21 reviewers assessed each article. RESULTS: We accepted the most shared 64 media articles pertaining to 50 academic articles for review, representing 68% of Facebook and 45% of Twitter shares in 2015. Thirty-four percent of academic studies and 48% of media articles used language that reviewers considered too strong for their strength of causal inference. Seventy percent of academic studies were considered low or very low strength of inference, with only 6% considered high or very high strength of causal inference. The most severe issues with academic studies’ causal inference were reported to be omitted confounding variables and generalizability. Fifty-eight percent of media articles were found to have inaccurately reported the question, results, intervention, or population of the academic study. CONCLUSIONS: We find a large disparity between the strength of language as presented to the research consumer and the underlying strength of causal inference among the studies most widely shared on social media. However, because this sample was designed to be representative of the articles selected and shared on social media, it is unlikely to be representative of all academic and media work. More research is needed to determine how academic institutions, media organizations, and social network sharing patterns impact causal inference and language as received by the research consumer."
ANDREW BELL,How to keep it adequate: a protocol for ensuring validity in agent-based simulation,
ANDREW BELL,Smart subsidies for sustainable soils: Evidence from a randomized controlled trial in southern Malawi,"Conventional agricultural practices – especially conventional tillage – are a major driver of soil erosion globally. While soil may not frequently considered a vulnerable natural resource, the erosion and degradation of soils poses a serious threat to food production and the production of numerous otherin situ andex situ ecosystem services. This study provides some of the first evidence on the effectiveness of a payments for ecosystem services (PES) program to encourage the adoption of soil conservation practices, specifically conservation agriculture (CA). Through minimized soil disturbance, permanent soil cover, and diversified crop mix, CA is believed to enhance soil fertility and rehabilitate soil structure, with the resulting preservation of ecosystem service flows. By providing calibrated financial incentives, we demonstrate that it is possible to substantially increase the extent and intensity of CA adoption. What is more, we show that a novel incentive mechanisms that leverages social networks for the consolidation of fragmented land may be more effective at bringing more land under conservation objectives, even if some of the additional land does not officially fall under the purview of the PES program. We also demonstrate that some of the supposed weaknesses hindering the adoption of CA – lower yields in the short-run and higher expenditures on weed control – were not necessarily obstacles in our study area, perhaps suggesting that the provision of subsidies need not continue into perpetuity, but may only be needed to overcome short-term transition costs."
ANDREW BELL,Migration theory in climate mobility research,"The purpose of this article is to explore how migration theory is invoked in empirical studies of climate-related migration, and to provide suggestions for engagement with theory in the emerging field of climate mobility. Theory is critical for understanding processes we observe in social-ecological systems because it points to a specific locus of attention for research, shapes research questions, guides quantitative model development, influences what researchers find, and ultimately informs policies and programs. Research into climate mobility has grown out of early studies on environmental migration, and has often developed in isolation from broader theoretical developments in the migration research community. As such, there is a risk that the work may be inadequately informed by the rich corpus of theory that has contributed to our understanding of who migrates; why they migrate; the types of mobility they employ; what sustains migration streams; and why they choose certain destinations over others. On the other hand, there are ways in which climate and broader environment migration research is enriching the conceptual frameworks being employed to understand migration, particularly forced migration. This paper draws on a review of 75 empirical studies and modeling efforts conducted by researchers from a diversity of disciplines, covering various regions, and using a variety of data sources and methods to assess how they used theory in their research. The goal is to suggest ways forward for engagement with migration theory in this large and growing research domain."
ANDREW BELL,Experimental evidence on the impact of payments and property rights on forest user decisions,"Clearing forests for swidden agriculture, despite providing food to millions of farmers in the tropics, can be a major driver of deforestation. Payments for ecosystem services schemes can help stop swidden agriculture-induced forest loss by rewarding forest users for maintaining forests. Clear and secure property rights are a key prerequisite for the success of these payment schemes. In this study, we use a novel iterative and dynamic game in Madagascar and Kenya to examine farmer responses to individual and communal rights to forestlands, with and without financial incentives, in the context of swidden agricultural landscapes. We find that farmer pro conservation behaviour, defined by the propensity to keep forests or fallows on their lands, as well as the effects of land tenure and conservation incentive treatments on such behaviour, differ across the two contexts. The average percentages of land left forest/fallow in the game are 65 and 35% in Kenya and Madagascar, respectively. Individual ownership significantly improves decisions to preserve forests or leave land fallow in Madagascar but has no significant effect in Kenya. Also, the effect of the individual tenure treatment varies across education and wealth levels in Madagascar. Subsidy increases farmers' willingness to support conservation interests in both countries, but its effect is four times greater in Kenya. We find no interaction effects of the two treatments in either country. We conclude that the effectiveness of financial incentives for conservation and tenure reform in preserving forestland vary significantly across contexts. We show how interactive games can help develop a more targeted and practical approach to environmental policy."
ANDREW BELL,"Experimental evidence for conservation conflict interventions: The importance of financial payments, community trust and equity attitudes","1. Conflicts between the objectives of agricultural production and conservation are becoming increasingly complex. Of vital importance to the success of conflict in-terventions is a detailed understanding of how stakeholders react to management interventions as well as the influence of interacting social and political factors. 2. Across Europe, goose populations have increased considerably, leading to widespread impacts on agriculture and significant conflicts between different stakeholder groups. We used a novel experimental game to understand farmer preferences regarding the design of goose conflict interventions in Scotland. We specifically examined how three alternative interventions (government financial support for scaring activities, subsidies and agglomeration payments that include bonus payments for adoption by neighbouring farms) affect farmer propensity to support goose conservation interests through reduced shooting and the provision of sacrificial crops. We also examined the links between within-game behaviour and real-life attributes and attitudes of farmers. 3. We found that all three interventions were conducive to pro-conservation behaviour in the games. The effects of all three interventions were stronger among farmers who had higher trust towards other community members. Agglomeration payments led to increased provision of sacrificial crops among farmers with negative attitudes towards the current allocation of goose finances in Scotland. Farmers with more positive attitudes towards wildlife tourism were more likely to provide more sacrificial crops, and less likely to shoot in the games. 4. Farmers' real-life traits had a statistically significant but marginal impact on the effectiveness of financial payments, such as the number of geese being shot on their own lands, remoteness and crop damage by geese. 5. These game results provide evidence for the potential of innovative financial instruments in conflict management and their interactions with social factors such as community trust, equity attitude and real-life shooting levels. Our study high-lights the importance of socio-political elements in fostering mutually beneficial outcomes in conservation conflicts in addition to addressing material losses to wildlife. We also show how games can help in addressing conservation conflicts in a wide range of settings."
ANDREW BELL,"The L 98-59 system: three transiting, terrestrial-size planets orbiting a nearby M dwarf","We report the Transiting Exoplanet Survey Satellite (TESS) discovery of three terrestrial-size planets transiting L 98-59 (TOI-175, TIC 307210830)—a bright M dwarf at a distance of 10.6 pc. Using the Gaia-measured distance and broadband photometry, we find that the host star is an M3 dwarf. Combined with the TESS transits from three sectors, the corresponding stellar parameters yield planet radii ranging from 0.8 R ⊕ to 1.6 R ⊕. All three planets have short orbital periods, ranging from 2.25 to 7.45 days with the outer pair just wide of a 2:1 period resonance. Diagnostic tests produced by the TESS Data Validation Report and the vetting package DAVE rule out common false-positive sources. These analyses, along with dedicated follow-up and the multiplicity of the system, lend confidence that the observed signals are caused by planets transiting L 98-59 and are not associated with other sources in the field. The L 98-59 system is interesting for a number of reasons: the host star is bright (V = 11.7 mag, K = 7.1 mag) and the planets are prime targets for further follow-up observations including precision radial-velocity mass measurements and future transit spectroscopy with the James Webb Space Telescope; the near-resonant configuration makes the system a laboratory to study planetary system dynamical evolution; and three planets of relatively similar size in the same system present an opportunity to study terrestrial planets where other variables (age, metallicity, etc.) can be held constant. L 98-59 will be observed in four more TESS sectors, which will provide a wealth of information on the three currently known planets and have the potential to reveal additional planets in the system."
WILSON WONG,Genetic variation and gene expression across multiple tissues and developmental stages in a nonhuman primate,"By analyzing multitissue gene expression and genome-wide genetic variation data in samples from a vervet monkey pedigree, we generated a transcriptome resource and produced the first catalog of expression quantitative trait loci (eQTLs) in a nonhuman primate model. This catalog contains more genome-wide significant eQTLs per sample than comparable human resources and identifies sex- and age-related expression patterns. Findings include a master regulatory locus that likely has a role in immune function and a locus regulating hippocampal long noncoding RNAs (lncRNAs), whose expression correlates with hippocampal volume. This resource will facilitate genetic investigation of quantitative traits, including brain and behavioral phenotypes relevant to neuropsychiatric disorders."
WILSON WONG,Engineering clinically-approved drug gated CAR circuits,"[Chimeric antigen receptor (CAR) T cell immunotherapy has the potential to revolutionize cancer medicine. However, excessive CAR activation, lack of tumor-specific surface markers, and antigen escape have limited the safety and efficacy of CAR T cell therapy. A multi-antigen targeting CAR system that is regulated by safe, clinically-approved pharmaceutical agents is urgently needed, yet only a few simple systems have been developed, and even fewer have been evaluated for efficacy in vivo. Here, we present NASCAR (NS3 ASsociated CAR), a collection of induc-ible ON and OFF switch CAR circuits engineered with a NS3 protease domain deriving from the Hepatitis C Virus (HCV). We establish their ability to regulate CAR activity using multiple FDA-approved antiviral protease inhibitors, including grazoprevir (GZV), both in vitro and in a xenograft tumor model. In addition, we have engineered several dual-gated NASCAR circuits, consisting of an AND logic gate CAR, universal ON-OFF CAR, and a switchboard CAR. These engineered receptors enhance control over T cell activity and tumor-targeting specificity. Together, our com-prehensive set of multiplex drug-gated CAR circuits represent a dynamic, tunable, and clinically-ready set of modules for enhancing the safety of CAR T cell therapy.]"
WILSON WONG,Head & Neck Optical Diagnostics: Vision of the Future of Surgery,Review paper and Proceedings of the Inaugural Meeting of the Head and Neck Optical Diagnostics Society (HNODS) on March 14th 2009 at University College London. The aim of our research must be to provide breakthrough translational research which can be applied clinically in the immediate rather than the near future. We are fortunate that this is indeed a possibility and may fundamentally change current clinical and surgical practice to improve our patients' lives.
WILSON WONG,The prevalence of sleep disturbances in adolescents and the link to mental health disorders,"There is a large body of research showing that sleep disorders are becoming more prevalent, especially in developing children in the United States. The negative effects of sleep disorders are well researched in adults. One such negative effect is the connection between sleep disorders and mental health disorders. Though this connection is well researched in adults, less is known about the connection between sleep disorders and mental health in developing children. The primary purpose of this paper is to review existing literature on the negative effects of sleep disorders, the causes of sleep disorders in children, and how sleep disorders may affect the mental well-being of developing teenagers in their time of vulnerability."
WILSON WONG,Clinically-driven design of synthetic gene regulatory programs in human cells,"Synthetic biology seeks to enable the rational design of regulatory molecules and circuits to reprogram cellular behavior. The application of this approach to human cells could lead to powerful gene and cell-based therapies that provide transformative ways to combat complex diseases. To date, however, synthetic genetic circuits are challenging to implement in clinically-relevant cell types and their components often present translational incompatibilities, greatly limiting the feasibility, efficacy and safety of this approach. Here, using a clinically-driven design process, we developed a toolkit of programmable synthetic transcription regulators that feature a compact human protein-based design, enable precise genome-orthogonal regulation, and can be modulated by FDA-approved small molecules. We demonstrate the toolkit by engineering therapeutic human immune cells with genetic programs that enable titratable production of immunotherapeutics, drug-regulated control of tumor killing in vivo and in 3D spheroid models, and the first multi-channel synthetic switch for independent control of immunotherapeutic genes. Our work establishes a powerful platform for engineering custom gene expression programs in mammalian cells with the potential to accelerate clinical translation of synthetic systems."
EDWARD DOWNES,"Unit organization of the topic Unity, coherence and emphasis in sentence construction",
ANNA A HENCHMAN,Tallow candles and meaty air in Bleak House,"In Charles Dickens’s Bleak House there is a strange (and disgusting) pattern of characters feeling that they can ‘taste’ the air, and that that air tastes either meaty or greasy. Esther notices that snuffing ‘two great office candles in tin candlesticks’ at Mrs Jellyby’s ‘made the room taste strongly of hot tallow’, the mutton or beef fat out of which inexpensive candles were made. In Bleak House, candles retain their sheepy atmospheres and release them into the surrounding air when consumed. Mrs Jellyby’s home and Mr Vholes’s office are just two places in which Dickens suggests that the process of turning organic animal bodies into urban commodities (candles, parchment, wigs) has not quite been completed. Candles and parchment are part animal, part object, and they constantly threaten to revert back into their animal forms. The commodification of animal bodies occurs primarily in the city, where parts of formerly living bodies are manufactured into things. Filled with the smell of burning chops or a spontaneously combusted human, Dickens’s greasier atmospheres contain animal matter suspended in the air that the characters smell, taste, and touch. Once we realize that the apparent smell of chops and candles is, in fact, Krook’s body, this act of taking the air becomes a form of cannibalism that is at least as unsettling as Michael Pollan’s recent account of cows being fed cow parts in factory farms. Drawing on this insight and on Allen MacDuffie’s analyses of energy systems in Bleak House, this article focuses on instances in which Dickens defamiliarizes the human consumption of energy by having his characters unintentionally ingest animal particles. Studying Dickens’s treatment of animal fat suspended in air adds a new dimension to recent work on systems of energy expenditure and exchange in an age of industrial capitalism."
ANNA A HENCHMAN,"Charles Darwin’s final book on earthworms, 1881","This article focuses on the publication of Darwin’s final book (1881) in the context of Darwin’s larger attempts to resist the habitual anthropocentrism of human beings. It begins with Darwin’s discussion of animal cognition and the senses of worms. It concludes with his emphasis on the significant effects worm digestion has on the landscape and the fertility of the earth. The article links Darwin’s Worms Edwin Abbott’s 1884 novella Flatland, arguing that both texts are engaged in dismantling human perceptions that stem from possessing a highly visual brain, and that both throw doubt on the belief that a single objective world exists independent of particular observers."
BRIAN KULIS,Piecewise linear regression via a difference of convex functions,"We present a new piecewise linear regression methodology that utilizes fitting a difference of convex functions (DC functions) to the data. These are functions f that may be represented as the difference 𝜙_1- 𝜙_2 for a choice of convex functions 𝜙_1,𝜙_2. The method proceeds by estimating piecewise-liner convex functions, in a manner similar to max-affine regression, whose difference approximates the data. The choice of the function is regularised by a new seminorm over the class of DC functions that controls the 𝓁_∞ Lipschitz constant of the estimate. The resulting methodology can be efficiently implemented via Quadratic programming even in high dimensions, and is shown to have close to minimax statistical risk. We empirically validate the method, showing it to be practically implementable, and to have comparable performance to existing egression/classification methods on real-world datasets."
BRIAN KULIS,Deep divergence learning,"Classical linear metric learning methods have recently been extended along two distinct lines: deep metric learning methods for learning embeddings of the data using neural networks, and Bregman divergence learning approaches for extending learning Euclidean distances to more general divergence measures such as divergences over distributions. In this paper, we introduce deep Bregman divergences, which are based on learning and parameterizing functional Bregman divergences using neural networks, and which unify and extend these existing lines of work. We show in particular how deep metric learning formulations, kernel metric learning, Mahalanobis metric learning, and moment-matching functions for comparing distributions arise as special cases of these divergences in the symmetric setting. We then describe a deep learning framework for learning general functional Bregman divergences, and show in experiments that this method yields superior performance on benchmark datasets as compared to existing deep metric learning approaches. We also discuss novel applications, including a semi-supervised distributional clustering problem, and a new loss function for unsupervised data generation."
BRIAN KULIS,Metadata-aware end-to-end keyword spotting,
BRIAN KULIS,Tiny-CRNN: streaming wakeword detection in a low footprint setting,
BRIAN KULIS,ALBADross: active learning based anomaly diagnosis for production HPC systems,
BRIAN KULIS,Latency control for keyword spotting,
BRIAN KULIS,Substitutional neural image compression,
BRIAN KULIS,Convolutional neural network denoising of focused ion beam micrographs,"Most research on deep learning algorithms for image denoising has focused on signal-independent additive noise. Focused ion beam (FIB) microscopy with direct secondary electron detection has an unusual Neyman Type A (compound Poisson) measurement model, and sample damage poses fundamental challenges in obtaining training data. Model-based estimation is difficult and ineffective because of the nonconvexity of the negative log likelihood. In this paper, we develop deep learning-based denoising methods for FIB micrographs using synthetic training data generated from natural images. To the best of our knowledge, this is the first attempt in the literature to solve this problem with deep learning. Our results show that the proposed methods slightly outperform a total variation-regularized model-based method that requires time-resolved measurements that are not conventionally available. Improvements over methods using conventional measurements and less accurate noise modeling are dramatic - around 10 dB in peak signal-to-noise ratio."
BRIAN KULIS,Joint bilateral learning for real-time universal photorealistic style transfer,"Photorealistic style transfer is the task of transferring the artistic style of an image onto a content target, producing a result that is plausibly taken with a camera. Recent approaches, based on deep neural networks, produce impressive results but are either too slow to run at practical resolutions, or still contain objectionable artifacts. We propose a new end-to-end model for photorealistic style transfer that is both fast and inherently generates photorealistic results. The core of our approach is a feed-forward neural network that learns local edge-aware a ne transforms that automatically obey the photorealism constraint. When trained on a diverse set of images and a variety of styles, our model can robustly apply style transfer to an arbitrary pair of input images. Compared to the state of the art, our method produces visually superior results and is three orders of magnitude faster, enabling real- time performance at 4K on a mobile phone. We validate our method with ablation and user studies."
BRIAN KULIS,An audio-based wakeword-independent verification system,"We propose an audio-based wakeword-independent verification model to determine whether a wakeword spotting model correctly woke and should respond or incorrectly woke and should not respond. Our model works on any wakeword-initiated audio, independent of the wakeword by operating only on the audio surrounding the wakeword, yielding a wakeword agnostic model. This model is based on two key assumptions: that audio surrounding the wakeword is informative to determine if the user intended to wake the device and that this audio is independent of the wakeword itself. We show experimentally that on wakewords not included in the training set, our model trained without examples or knowledge of the wakeword is able to achieve verification performance comparable to models trained on 5,000 to 10,000 annotated examples of the new wakeword."
BRIAN KULIS,Building a robust word-level wakeword verification network,
BRIAN KULIS,Deep metric learning to rank,"We propose a novel deep metric learning method by revisiting the learning to rank approach. Our method, named FastAP, optimizes the rank-based Average Precision measure, using an approximation derived from distance quantization. FastAP has a low complexity compared to existing methods, and is tailored for stochastic gradient descent. To fully exploit the benefits of the ranking formulation, we also propose a new minibatch sampling scheme, as well as a simple heuristic to enable large-batch training. On three few-shot image retrieval datasets, FastAP consistently outperforms competing methods, which often involve complex optimization heuristics or costly model ensembles."
BRIAN KULIS,Supervised metric learning to rank for retrieval via contextual similarity optimization,
BRIAN KULIS,Faster algorithms for learning convex functions,
BRIAN KULIS,Faster algorithms for learning convex functions,
BRIAN KULIS,Learning to approximate a Bregman divergence,"Bregman divergences generalize measures such as the squared Euclidean distance and the KL divergence, and arise throughout many areas of machine learning. In this paper, we focus on the problem of approximating an arbitrary Bregman divergence from supervision, and we provide a well-principled approach to analyzing such approximations. We develop a formulation and algorithm for learning arbitrary Bregman divergences based on approximating their underlying convex generating function via a piecewise linear function. We provide theoretical approximation bounds using our parameterization and show that the generalization error Op(m^-1/2) for metric learning using our framework matches the known generalization error in the strictly less general Mahalanobis metric learning setting. We further demonstrate empirically that our method performs well in comparison to existing metric learning methods, particularly for clustering and ranking problems."
ROY GRUNDMANN,Labour in a single shot: critical perspectives on Antje Ehmann and Harun Farocki's global video project,"This collection of essays offers a critical assessment of Labour in a Single Shot, a groundbreaking documentary video workshop. From 2011 to 2014, curator Antje Ehmann and film- and videomaker Harun Farocki produced an art project of truly global proportions. They travelled to fifteen cities around the world to conduct workshops inspired by cinema history’s first film, Workers Leaving the Lumière Factory, shot in 1895 by the Lumière brothers in France. While the workshop videos are in colour and the camera was not required to remain static, Ehmann and Farocki’s students were tasked with honouring the original Lumière film’s basic parameters of theme and style. The fascinating result is a collection of more than 550 short videos that have appeared in international exhibitions and on an open-access website, offering the widest possible audience the opportunity to ponder contemporary labour in multiple contexts around the world."
ROY GRUNDMANN,Editors' Introduction,
MEGAN MACGARVIE,Does removing gatekeepers democratize the diffusion of knowledge? Evidence from COVID-19 preprints,"Online platforms such as preprint servers have become an increasingly important way to disseminate new knowledge prior to peer review. In contrast to peer-reviewed research, preprints have no barriers to publication and no quality certification. Removing barriers to publication has the potential to democratize access to knowledge. However, the considerable uncertainty about the quality of unpublished research could lead audiences to assess preprints based on observable aspects of the preprint such as country of origin of the authors. This study explores how readers allocated attention across preprints in a context of great urgency (the initial months of the COVID-19 pandemic). We find that, after controlling carefully for article quality, preprints with authors from Chinese institutions receive less attention, and preprints with authors from US institutions receive more attention than preprints with authors from the rest of the world during the early months of the pandemic. In an exploration of potential mechanisms driving the observed effects, we find that Chinese authors are less likely to be promoted by self-organizing screening mechanisms that drive attention to preprints, such as twitter endorsements, and the response to endorsement does not close the attention gap. The results suggest that biases may persist or even be exacerbated on platforms designed to promote unfettered access to early research findings in a context of high urgency and uncertainty."
JUSTIN WHITE,Effect of Spatial Resolution on Cluster Detection: A Simulation Study,"BACKGROUND. Aggregation of spatial data is intended to protect privacy, but some effects of aggregation on spatial methods have not yet been quantified. METHODS. We generated 3,000 spatial data sets and evaluated power of detection at 12 different levels of aggregation using the spatial scan statistic implemented in SaTScan v6.0. RESULTS. Power to detect clusters decreased from nearly 100% when using exact locations to roughly 40% at the coarsest level of spatial resolution. CONCLUSION. Aggregation has the potential for obfuscation."
JUSTIN WHITE,Radial velocity prospects current and future: A white paper report prepared by the Study Analysis Group 8 for the Exoplanet Program Analysis Group (ExoPAG),"In this white paper report, we present an assessment of the current capabilities and the future potential of the precise radial velocity (PRV) method to advance the NASA goal to “search for planetary bodies and Earth-like planets in orbit around other stars.” (U.S. National Space Policy, June 28, 2010). PRVs complement other exoplanet detection methods, for example offering a direct path to obtaining the bulk density and thus the structure and composition of transiting exoplanets."
JUSTIN WHITE,The long-baseline neutrino experiment: exploring fundamental symmetries of the universe,"The preponderance of matter over antimatter in the early Universe, the dynamics of the supernova bursts that produced the heavy elements necessary for life and whether protons eventually decay --- these mysteries at the forefront of particle physics and astrophysics are key to understanding the early evolution of our Universe, its current state and its eventual fate. The Long-Baseline Neutrino Experiment (LBNE) represents an extensively developed plan for a world-class experiment dedicated to addressing these questions. LBNE is conceived around three central components: (1) a new, high-intensity neutrino source generated from a megawatt-class proton accelerator at Fermi National Accelerator Laboratory, (2) a near neutrino detector just downstream of the source, and (3) a massive liquid argon time-projection chamber deployed as a far detector deep underground at the Sanford Underground Research Facility. This facility, located at the site of the former Homestake Mine in Lead, South Dakota, is approximately 1,300 km from the neutrino source at Fermilab -- a distance (baseline) that delivers optimal sensitivity to neutrino charge-parity symmetry violation and mass ordering effects. This ambitious yet cost-effective design incorporates scalability and flexibility and can accommodate a variety of upgrades and contributions. With its exceptional combination of experimental configuration, technical capabilities, and potential for transformative discoveries, LBNE promises to be a vital facility for the field of particle physics worldwide, providing physicists from around the globe with opportunities to collaborate in a twenty to thirty year program of exciting science. In this document we provide a comprehensive overview of LBNE's scientific objectives, its place in the landscape of neutrino physics worldwide, the technologies it will incorporate and the capabilities it will possess."
ALINA ENE,Parallel algorithm for non-monotone DR-submodular maximization,"In this work, we give a new parallel algorithm for the problem of maximizing a non-monotone diminishing returns submodular function subject to a cardinality constraint. For any desired accuracy 𝜖, our algorithm achieves a 1/e − 𝜖 approximation using O(log n log(1/𝜖 )/𝜖^3) parallel rounds of function evaluations. The approximation guarantee nearly matches the best approximation guarantee known for the problem in the sequential setting and the number of parallel rounds is nearly-optimal for any constant 𝜖. Previous algorithms achieve worse approximation guarantees using Ω (log^2 n) parallel rounds. Our experimental evaluation suggests that our algorithm obtains solutions whose objective value nearly matches the value obtained by the state of the art sequential algorithms, and it outperforms previous parallel algorithms in number of parallel rounds, iterations, and solution quality."
ANDREW FITZPATRICK,Scintillation light detection in the 6-m drift-length ProtoDUNE Dual Phase liquid argon TPC,"DUNE is a dual-site experiment for long-baseline neutrino oscillation studies, neutrino astrophysics and nucleon decay searches. ProtoDUNE Dual Phase (DP) is a 6  ×  6  ×  6 m 3 liquid argon time-projection-chamber (LArTPC) that recorded cosmic-muon data at the CERN Neutrino Platform in 2019-2020 as a prototype of the DUNE Far Detector. Charged particles propagating through the LArTPC produce ionization and scintillation light. The scintillation light signal in these detectors can provide the trigger for non-beam events. In addition, it adds precise timing capabilities and improves the calorimetry measurements. In ProtoDUNE-DP, scintillation and electroluminescence light produced by cosmic muons in the LArTPC is collected by photomultiplier tubes placed up to 7 m away from the ionizing track. In this paper, the ProtoDUNE-DP photon detection system performance is evaluated with a particular focus on the different wavelength shifters, such as PEN and TPB, and the use of Xe-doped LAr, considering its future use in giant LArTPCs. The scintillation light production and propagation processes are analyzed and a comparison of simulation to data is performed, improving understanding of the liquid argon properties."
ANDREW FITZPATRICK,Prospects for beyond the standard model physics searches at the deep underground neutrino experiment: DUNE collaboration,"The Deep Underground Neutrino Experiment (DUNE) will be a powerful tool for a variety of physics topics. The high-intensity proton beams provide a large neutrino flux, sampled by a near detector system consisting of a combination of capable precision detectors, and by the massive far detector system located deep underground. This configuration sets up DUNE as a machine for discovery, as it enables opportunities not only to perform precision neutrino measurements that may uncover deviations from the present three-flavor mixing paradigm, but also to discover new particles and unveil new interactions and symmetries beyond those predicted in the Standard Model (SM). Of the many potential beyond the Standard Model (BSM) topics DUNE will probe, this paper presents a selection of studies quantifying DUNE's sensitivities to sterile neutrino mixing, heavy neutral leptons, non-standard interactions, CPT symmetry violation, Lorentz invariance violation, neutrino trident production, dark matter from both beam induced and cosmogenic sources, baryon number violation, and other new physics topics that complement those at high-energy colliders and significantly extend the present reach."
ANDREW FITZPATRICK,Identification and reconstruction of low-energy electrons in the ProtoDUNE-SP detector,
CHEN YANG,Estimation of leaf area index and its sunlit portion from DSCOVR EPIC data: theoretical basis,"This paper presents the theoretical basis of the algorithm designed for the generation of leaf area index and diurnal course of its sunlit portion from NASA's Earth Polychromatic Imaging Camera (EPIC) onboard NOAA's Deep Space Climate Observatory (DSCOVR). The Look-up-Table (LUT) approach implemented in the MODIS operational LAI/FPAR algorithm is adopted. The LUT, which is the heart of the approach, has been significantly modified. First, its parameterization incorporates the canopy hot spot phenomenon and recent advances in the theory of canopy spectral invariants. This allows more accurate decoupling of the structural and radiometric components of the measured Bidirectional Reflectance Factor (BRF), improves scaling properties of the LUT and consequently simplifies adjustments of the algorithm for data spatial resolution and spectral band compositions. Second, the stochastic radiative transfer equations are used to generate the LUT for all biome types. The equations naturally account for radiative effects of the three-dimensional canopy structure on the BRF and allow for an accurate discrimination between sunlit and shaded leaf areas. Third, the LUT entries are measurable, i.e., they can be independently derived from both below canopy measurements of the transmitted and above canopy measurements of reflected radiation fields. This feature makes possible direct validation of the LUT, facilitates identification of its deficiencies and development of refinements. Analyses of field data on canopy structure and leaf optics collected at 18 sites in the Hyytiälä forest in southern boreal zone in Finland and hyperspectral images acquired by the EO-1 Hyperion sensor support the theoretical basis."
CHEN YANG,Prototyping of LAI and FPAR retrievals from MODIS multi-angle implementation of atmospheric correction (MAIAC) data,"Leaf area index (LAI) and fraction of photosynthetically active radiation (FPAR) absorbed by vegetation are key variables in many global models of climate, hydrology, biogeochemistry, and ecology. These parameters are being operationally produced from Terra and Aqua MODIS bidirectional reflectance factor (BRF) data. The MODIS science team has developed, and plans to release, a new version of the BRF product using the multi-angle implementation of atmospheric correction (MAIAC) algorithm from Terra and Aqua MODIS observations. This paper presents analyses of LAI and FPAR retrievals generated with the MODIS LAI/FPAR operational algorithm using Terra MAIAC BRF data. Direct application of the operational algorithm to MAIAC BRF resulted in an underestimation of the MODIS Collection 6 (C6) LAI standard product by up to 10%. The difference was attributed to the disagreement between MAIAC and MODIS BRFs over the vegetation by −2% to +8% in the red spectral band, suggesting different accuracies in the BRF products. The operational LAI/FPAR algorithm was adjusted for uncertainties in the MAIAC BRF data. Its performance evaluated on a limited set of MAIAC BRF data from North and South America suggests an increase in spatial coverage of the best quality, high-precision LAI retrievals of up to 10%. Overall MAIAC LAI and FPAR are consistent with the standard C6 MODIS LAI/FPAR. The increase in spatial coverage of the best quality LAI retrievals resulted in a better agreement of MAIAC LAI with field data compared to the C6 LAI product, with the RMSE decreasing from 0.80 LAI units (C6) down to 0.67 (MAIAC) and the R2 increasing from 0.69 to 0.80. The slope (intercept) of the satellite-derived vs. field-measured LAI regression line has changed from 0.89 (0.39) to 0.97 (0.25)."
CHEN YANG,Implications of whole-disc DSCOVR EPIC spectral observations for estimating Earth's spectral reflectivity based on low-earth-orbiting and geostationary observations,"Earth’s reflectivity is among the key parameters of climate research. National Aeronautics and Space Administration (NASA)’s Earth Polychromatic Imaging Camera (EPIC) onboard National Oceanic and Atmospheric Administration (NOAA)’s Deep Space Climate Observatory (DSCOVR) spacecraft provides spectral reflectance of the entire sunlit Earth in the near backscattering direction every 65 to 110 min. Unlike EPIC, sensors onboard the Earth Orbiting Satellites (EOS) sample reflectance over swaths at a specific local solar time (LST) or over a fixed area. Such intrinsic sampling limits result in an apparent Earth’s reflectivity. We generated spectral reflectance over sampling areas using EPIC data. The difference between the EPIC and EOS estimates is an uncertainty in Earth’s reflectivity. We developed an Earth Reflector Type Index (ERTI) to discriminate between major Earth atmosphere components: clouds, cloud-free ocean, bare and vegetated land. Temporal variations in Earth’s reflectivity are mostly determined by clouds. The sampling area of EOS sensors may not be sufficient to represent cloud variability, resulting in biased estimates. Taking EPIC reflectivity as a reference, low-earth-orbiting-measurements at the sensor-specific LST tend to overestimate EPIC values by 0.8% to 8%. Biases in geostationary orbiting approximations due to a limited sampling area are between −0.7% and 12%. Analyses of ERTI-based Earth component reflectivity indicate that the disagreement between EPIC and EOS estimates depends on the sampling area, observation time and vary between −10% and 23%."
CHEN YANG,Understanding cellular internalization pathways of silicon nanowires,"BACKGROUND: Understanding how cells interact with nanomaterials is important for rational design of nanomaterials for nanomedicine and transforming them for clinical applications. Particularly, the mechanism for one-dimensional (1D) nanomaterials with high aspect ratios still remains unclear. RESULTS: In this work, we present amine-functionalized silicon nanowires (SiNW-NH2) entering CHO-β cells via a physical membrane wrapping mechanism. By utilizing optical microscopy, transmission electron microscopy, and confocal fluorescence microscopy, we successfully visualized the key steps of internalization of SiNW-NH2 into cells. CONCLUSION: Our results provide insight into the interaction between 1D nanomaterials and confirm that these materials can be used for understanding membrane mechanics through physical stress exerted on the membrane."
CHEN YANG,Generating global products of LAI and FPAR from SNPP-VIIRS data: theoretical background and implementation,"Leaf area index (LAI) and fraction of photosynthetically active radiation (FPAR) absorbed by vegetation have been successfully generated from the Moderate Resolution Imaging Spectroradiometer (MODIS) data since early 2000. As the Visible Infrared Imaging Radiometer Suite (VIIRS) instrument onboard, the Suomi National Polar-orbiting Partnership (SNPP) has inherited the scientific role of MODIS, and the development of a continuous, consistent, and well-characterized VIIRS LAI/FPAR data set is critical to continue the MODIS time series. In this paper, we build the radiative transfer-based VIIRS-specific lookup tables by achieving minimal difference with the MODIS data set and maximal spatial coverage of retrievals from the main algorithm. The theory of spectral invariants provides the configurable physical parameters, i.e., single scattering albedos (SSAs) that are optimized for VIIRS-specific characteristics. The effort finds a set of smaller red-band SSA and larger near-infraredband SSA for VIIRS compared with the MODIS heritage. The VIIRS LAI/FPAR is evaluated through comparisons with one year of MODIS product in terms of both spatial and temporal patterns. Further validation efforts are still necessary to ensure the product quality. Current results, however, imbue confidence in the VIIRS data set and suggest that the efforts described here meet the goal of achieving the operationally consistent multisensor LAI/FPAR data sets. Moreover, the strategies of parametric adjustment and LAI/FPAR evaluation applied to SNPP-VIIRS can also be employed to the subsequent Joint Polar Satellite System VIIRS or other instruments."
CHEN YANG,Management services and small business.,
CHEN YANG,Evaluation of MODIS LAI/FPAR product Collection 6. Part 2: Validation and intercomparison,"The aim of this paper is to assess the latest version of the MODIS LAI/FPAR product (MOD15A2H), namely Collection 6 (C6). We comprehensively evaluate this product through three approaches: validation with field measurements, intercomparison with other LAI/FPAR products and comparison with climate variables. Comparisons between ground measurements and C6, as well as C5 LAI/FPAR indicate: (1) MODIS LAI is closer to true LAI than effective LAI; (2) the C6 product is considerably better than C5 with RMSE decreasing from 0.80 down to 0.66; (3) both C5 and C6 products overestimate FPAR over sparsely-vegetated areas. Intercomparisons with three existing global LAI/FPAR products (GLASS, CYCLOPES and GEOV1) are carried out at site, continental and global scales. MODIS and GLASS (CYCLOPES and GEOV1) agree better with each other. This is expected because the surface reflectances, from which these products were derived, were obtained from the same instrument. Considering all biome types, the RMSE of LAI (FPAR) derived from any two products ranges between 0.36 (0.05) and 0.56 (0.09). Temporal comparisons over seven sites for the 2001–2004 period indicate that all products properly capture the seasonality in different biomes, except evergreen broadleaf forests, where infrequent observations due to cloud contamination induce unrealistic variations. Thirteen years of C6 LAI, temperature and precipitation time series data are used to assess the degree of correspondence between their variations. The statistically-significant associations between C6 LAI and climate variables indicate that C6 LAI has the potential to provide reliable biophysical information about the land surface when diagnosing climate-driven vegetation responses."
CHEN YANG,Use of graphene as protection film in biological environments,"Corrosion of metal in biomedical devices could cause serious health problems to patients. Currently ceramics coating materials used in metal implants can reduce corrosion to some extent with limitations. Here we proposed graphene as a biocompatible protective film for metal potentially for biomedical application. We confirmed graphene effectively inhibits Cu surface from corrosion in different biological aqueous environments. Results from cell viability tests suggested that graphene greatly eliminates the toxicity of Cu by inhibiting corrosion and reducing the concentration of Cu(2+) ions produced. We demonstrated that additional thiol derivatives assembled on graphene coated Cu surface can prominently enhance durability of sole graphene protection limited by the defects in graphene film. We also demonstrated that graphene coating reduced the immune response to metal in a clinical setting for the first time through the lymphocyte transformation test. Finally, an animal experiment showed the effective protection of graphene to Cu under in vivo condition. Our results open up the potential for using graphene coating to protect metal surface in biomedical application."
CHEN YANG,Highly sensitive transient absorption imaging of graphene and graphene oxide in living cells and circulating blood,We report a transient absorption (TA) imaging method for fast visualization and quantitative layer analysis of graphene and GO. Forward and backward imaging of graphene on various substrates under ambient condition was imaged with a speed of 2 μs per pixel. The TA intensity linearly increased with the layer number of graphene. Real-time TA imaging of GO in vitro with capability of quantitative analysis of intracellular concentration and ex vivo in circulating blood were demonstrated. These results suggest that TA microscopy is a valid tool for the study of graphene based materials.
CHEN YANG,Far-field imaging of non-fluorescent species with sub-diffraction resolution,"Super-resolution optical microscopy is opening a new window to unveil the unseen details on the nanoscopic scale. Current far-field super-resolution techniques rely on fluorescence as the read-out1-5. Here, we demonstrate a scheme for breaking the diffraction limit in far-field imaging of non-fluorescent species by using spatially controlled saturation of electronic absorption. Our method is based on a pump-probe process where a modulated pump field perturbs the charge-carrier density in a sample, thus modulating the transmission of a probe field. A doughnut shape laser beam is then added to transiently saturate the electronic transition in the periphery of the focal volume, thus the induced modulation in the sequential probe pulse only occurs at the focal center. By raster scanning the three collinearly aligned beams, high-speed sub-diffraction-limited imaging of graphite nano-platelets was performed. This technique potentially enables super-resolution imaging of nano-materials and non-fluorescent chromophores, which may remain out of reach for fluorescence-based methods."
CHEN YANG,Analyses of impact of needle surface properties on estimation of needle absorption spectrum: case study with coniferous needle and shoot samples,"Leaf scattering spectrum is the key optical variable that conveys information about leaf absorbing constituents from remote sensing. It cannot be directly measured from space because the radiation scattered from leaves is affected by the 3D canopy structure. In addition, some radiation is specularly reflected at the surface of leaves. This portion of reflected radiation is partly polarized, does not interact with pigments inside the leaf and therefore contains no information about its interior. Very little empirical data are available on the spectral and angular scattering properties of leaf surfaces. Whereas canopy-structure effects are well understood, the impact of the leaf surface reflectance on estimation of leaf absorption spectra remains uncertain. This paper presents empirical and theoretical analyses of angular, spectral, and polarimetric measurements of light reflected by needles and shoots ofPinus koraiensisandPicea koraiensisspecies. Our results suggest that ignoring the leaf surface reflected radiation can result in an inaccurate estimation of the leaf absorption spectrum. Polarization measurements may be useful to account for leaf surface effects because radiation reflected from the leaf surface is partly polarized, whereas that from the leaf interior is not."
CHEN YANG,Development and validation of a prognostic risk score system for COVID-19 inpatients: a multi-center retrospective study in China,"Coronavirus disease 2019 (COVID-19) has become a worldwide pandemic. Hospitalized patients of COVID-19 suffer from a high mortality rate, motivating the development of convenient and practical methods that allow clinicians to promptly identify high-risk patients. Here, we have developed a risk score using clinical data from 1479 inpatients admitted to Tongji Hospital, Wuhan, China (development cohort) and externally validated with data from two other centers: 141 inpatients from Jinyintan Hospital, Wuhan, China (validation cohort 1) and 432 inpatients from The Third People's Hospital of Shenzhen, Shenzhen, China (validation cohort 2). The risk score is based on three biomarkers that are readily available in routine blood samples and can easily be translated into a probability of death. The risk score can predict the mortality of individual patients more than 12 d in advance with more than 90% accuracy across all cohorts. Moreover, the Kaplan-Meier score shows that patients can be clearly differentiated upon admission as low, intermediate, or high risk, with an area under the curve (AUC) score of 0.9551. In summary, a simple risk score has been validated to predict death in patients infected with severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2); it has also been validated in independent cohorts."
CHEN YANG,Improving the characterization of ex vivo human brain optical properties using high numerical aperture optical coherence tomography by spatially constraining the confocal parameters,"SIGNIFICANCE: The optical properties of biological samples provide information about the structural characteristics of the tissue and any changes arising from pathological conditions. Optical coherence tomography (OCT) has proven to be capable of extracting tissue's optical properties using a model that combines the exponential decay due to tissue scattering and the axial point spread function that arises from the confocal nature of the detection system, particularly for higher numerical aperture (NA) measurements. A weakness in estimating the optical properties is the inter-parameter cross-talk between tissue scattering and the confocal parameters defined by the Rayleigh range and the focus depth. AIM: In this study, we develop a systematic method to improve the characterization of optical properties with high-NA OCT. APPROACH: We developed a method that spatially parameterizes the confocal parameters in a previously established model for estimating the optical properties from the depth profiles of high-NA OCT. RESULTS: The proposed parametrization model was first evaluated on a set of intralipid phantoms and then validated using a low-NA objective in which cross-talk from the confocal parameters is negligible. We then utilize our spatially parameterized model to characterize optical property changes introduced by a tissue index matching process using a simple immersion agent, 2,2'-thiodiethonal. CONCLUSIONS: Our approach improves the confidence of parameter estimation by reducing the degrees of freedom in the non-linear fitting model."
CHEN YANG,Finding MNEMON: reviving memories of node embeddings,
CHEN YANG,A non-canonical Notch complex regulates adherens junctions and vascular barrier function,"The vascular barrier that separates blood from tissues is actively regulated by the endothelium and is essential for transport, inflammation, and haemostasis1. Haemodynamic shear stress plays a critical role in maintaining endothelial barrier function2, but how this occurs remains unknown. Here we use an engineered organotypic model of perfused microvessels to show that activation of the transmembrane receptor NOTCH1 directly regulates vascular barrier function through a non-canonical, transcription-independent signalling mechanism that drives assembly of adherens junctions, and confirm these findings in mouse models. Shear stress triggers DLL4-dependent proteolytic activation of NOTCH1 to expose the transmembrane domain of NOTCH1. This domain mediates establishment of the endothelial barrier; expression of the transmembrane domain of NOTCH1 is sufficient to rescue defects in barrier function induced by knockout of NOTCH1. The transmembrane domain restores barrier function by catalysing the formation of a receptor complex in the plasma membrane consisting of vascular endothelial cadherin, the transmembrane protein tyrosine phosphatase LAR, and the RAC1 guanidine-exchange factor TRIO. This complex activates RAC1 to drive assembly of adherens junctions and establish barrier function. Canonical transcriptional signalling via Notch is highly conserved in metazoans and is required for many processes in vascular development, including arterial–venous differentiation3, angiogenesis4 and remodelling5. We establish the existence of a non-canonical cortical NOTCH1 signalling pathway that regulates vascular barrier function, and thus provide a mechanism by which a single receptor might link transcriptional programs with adhesive and cytoskeletal remodelling."
CHEN YANG,Plasmon-enhanced stimulated Raman scattering microscopy with single-molecule detection sensitivity,"Stimulated Raman scattering (SRS) microscopy allows for high-speed label-free chemical imaging of biomedical systems. The imaging sensitivity of SRS microscopy is limited to ~10 mM for endogenous biomolecules. Electronic pre-resonant SRS allows detection of sub-micromolar chromophores. However, label-free SRS detection of single biomolecules having extremely small Raman cross-sections (~10-30 cm2 sr-1) remains unreachable. Here, we demonstrate plasmon-enhanced stimulated Raman scattering (PESRS) microscopy with single-molecule detection sensitivity. Incorporating pico-Joule laser excitation, background subtraction, and a denoising algorithm, we obtain robust single-pixel SRS spectra exhibiting single-molecule events, verified by using two isotopologues of adenine and further confirmed by digital blinking and bleaching in the temporal domain. To demonstrate the capability of PESRS for biological applications, we utilize PESRS to map adenine released from bacteria due to starvation stress. PESRS microscopy holds the promise for ultrasensitive detection and rapid mapping of molecular events in chemical and biomedical systems."
CHEN YANG,Neuroimaging markers for studying Gulf-War illness: single-subject level analytical method based on machine learning,"Gulf War illness (GWI) refers to the multitude of chronic health symptoms, spanning from fatigue, musculoskeletal pain, and neurological complaints to respiratory, gastrointestinal, and dermatologic symptoms experienced by about 250,000 GW veterans who served in the 1991 Gulf War (GW). Longitudinal studies showed that the severity of these symptoms often remain unchanged even years after the GW, and these veterans with GWI continue to have poorer general health and increased chronic medical conditions than their non-deployed counterparts. For better management and treatment of this condition, there is an urgent need for developing objective biomarkers that can help with simple and accurate diagnosis of GWI. In this study, we applied multiple neuroimaging techniques, including T1-weighted magnetic resonance imaging (T1W-MRI), diffusion tensor imaging (DTI), and novel neurite density imaging (NDI) to perform both a group-level statistical comparison and a single-subject level machine learning (ML) analysis to identify diagnostic imaging features of GWI. Our results supported NDI as the most sensitive in defining GWI characteristics. In particular, our classifier trained with white matter NDI features achieved an accuracy of 90% and F-score of 0.941 for classifying GWI cases from controls after the cross-validation. These results are consistent with our previous study which suggests that NDI measures are sensitive to the microstructural and macrostructural changes in the brain of veterans with GWI, which can be valuable for designing better diagnosis method and treatment efficacy studies."
CHEN YANG,Extreme suppression of antiferromagnetic order and critical scaling in a two-dimensional random quantum magnet,"Sr_2CuTeO_6 is a square-lattice Néel antiferromagnet with superexchange between first-neighbor S=1/2 Cu spins mediated by plaquette centered Te ions. Substituting Te by W, the affected impurity plaquettes have predominantly second-neighbor interactions, thus causing local magnetic frustration. Here we report a study of Sr_2CuTe_1-xW_xO_6 using neutron diffraction and μSR techniques, showing that the Néel order vanishes already at x=0.025±0.005. We explain this extreme order suppression using a two-dimensional Heisenberg spin model, demonstrating that a W-type impurity induces a deformation of the order parameter that decays with distance as 1/r^2 at temperature T=0. The associated logarithmic singularity leads to loss of order for any x>0. Order for small x>0 and T>0 is induced by weak interplane couplings. In the nonmagnetic phase of Sr_2CuTe_1-x W_x O_6, the μSR relaxation rate exhibits quantum critical scaling with a large dynamic exponent, z≈3, consistent with a random-singlet state."
CHEN YANG,Structural and functional investigation of the trabecular outflow pathway,"Primary open-angle glaucoma (POAG) is a leading cause of blindness in the world. A primary risk factor for POAG is elevated intraocular pressure (IOP), caused by increased aqueous humor outflow resistance. Currently, lowering the IOP is the only effective way of treating glaucoma; however, the cause of increased outflow resistance remains unclear. This thesis will present a series of studies which investigated structures of the trabecular outflow pathway, including Schlemm’s canal endothelium, juxtacanalicular tissue, and trabecular beams, and their roles in regulating aqueous outflow resistance. The studies were conducted in both human and animal models using ex vivo ocular perfusion as well as in vitro microfluidic systems. In the first study, we investigated the effects of Y27632, a derivative of Rho-kinase inhibitor that is being developed as next generation glaucoma drug with unclear IOP lowering mechanism, on aqueous humor outflow dynamics and associated morphological changes in normal human eyes and laser-induced ocular hypertensive monkey eyes. In the second study, we developed and validated a novel three-dimensional microfluidic system using lymphatic microvascular endothelial cells. The microfluidic system can be used to study Schlemm’s canal endothelial cell dynamics and aqueous humor transport mechanism in the future. In the last study, we characterized the morphological structure, distribution, and thickness of the endothelial glycocalyx in the aqueous humor outflow pathway of human and bovine eyes. Together these studies will help define new directions for therapy that will help control IOP and preserve vision throughout a normal life span."
CHEN YANG,High-performance communication infrastructure design on FPGA-centric clusters,"FPGA-Centric Clusters (FCCs) with the FPGAs directly linked through their Multi-Gigabit Transceivers (MGTs) have a proven advantage over other commodity architectures for communication bound applications. To date, however, communication infrastructure for such clusters has generally only taken one of two simple approaches: nearest-neighbor-only, which is fast but of limited utility, and processor-based, which is general but slow. The overall problem addressed in this dissertation is the architecture, design, and implementation of communication networks for FCCs. These network designs should take advantage of the decades of design experience in networks for High-Performance Computing (HPC) clusters, but should also account for, and take advantage of, unique characteristics of FCCs, in particular, the configurability of the FPGAs themselves. This dissertation has seven parts. We begin with in-depth implementations of two model applications, Directional Dark Matter (DM) Detection, and Molecular Dynamics (MD). These implementations expose the necessary characteristics of FCC networks from physical through application layers. The second is the systematic exploration of communication microarchitecture for FCCs, as has been done previously for HPC clusters and for Networks on Chips (NoCs) on both FPGAs and ASICs. One outcome of this part is to find the properties of FCCs that substantially influence the router design space. Another outcome is to create a selection of candidate routers and generalize it so that it is parameterized by routing algorithm, arbitration policy, number of virtual channels (VCs), and other parameters. The third part is to use the proposed application-aware framework to evaluate the resulting design space with respect to a number of common communication patterns and packet sizes. The results from this part enable two sets of designs. One is the selection of an optimal router for a given resource budget that accounts for all the workloads. The other is to take advantage of FPGA reconfigurability to select the optimal router accounting for both resource budget and a particular workload. The fourth part is to evaluate the advantages of this approach of adapting the router design to the application. We find that the optimality of the router design varies significantly with workloads. We observe that compared with the router configuration with the best average performance, application-aware router selection can lead to substantial improvement in performance or reduction in resources required. The fifth part is application-specific optimizations in which we develop several modules and functional units that can provide specific optimizations for certain types of communication workloads depending on the application it going to serve. The sixth part explores topology emulation, e.g., when a three-dimensional network is used in the computation of an application that is logically two dimensional. We propose a generalized fold-and-cut mechanism that both preserves the locality in logical mapping, while also making use of the extra links provided by our 3D-torus fixture. The seventh part is a table-based static-scheduled router for applications with a static or persistent communication pattern. The router supports various cases, including unicast, multicast, and reduction. By making routing decisions a priori, we can bring better load-balance to network links and reduce congestion."
CHEN YANG,A Three-Stage Approach for Genome-Wide Association Studies with Family Data for Quantitative Traits,"BACKGROUND. Genome-wide association (GWA) studies that use population-based association approaches may identify spurious associations in the presence of population admixture. In this paper, we propose a novel three-stage approach that is computationally efficient and robust to population admixture and more powerful than the family-based association test (FBAT) for GWA studies with family data. We propose a three-stage approach for GWA studies with family data. The first stage is to perform linear regression ignoring phenotypic correlations among family members. SNPs with a first stage p-value below a liberal cut-off (e.g. 0.1) are then analyzed in the second stage that employs a linear mixed effects (LME) model that accounts for within family correlations. Next, SNPs that reach genome-wide significance (e.g. 10-6 for 34,625 genotyped SNPs in this paper) are analyzed in the third stage using FBAT, with correction of multiple testing only for SNPs that enter the third stage. Simulations are performed to evaluate type I error and power of the proposed method compared to LME adjusting for 10 principal components (PC) of the genotype data. We also apply the three-stage approach to the GWA analyses of uric acid in Framingham Heart Study's SNP Health Association Resource (SHARe) project. RESULTS. Our simulations show that whether or not population admixture is present, the three-stage approach has no inflated type I error. In terms of power, using LME adjusting PC is only slightly more powerful than the three-stage approach. When applied to the GWA analyses of uric acid in the SHARe project of FHS, the three-stage approach successfully identified and confirmed three SNPs previously reported as genome-wide significant signals. CONCLUSIONS. For GWA analyses of quantitative traits with family data, our three-stage approach provides another appealing solution to population admixture, in addition to LME adjusting for genetic PC."
CHEN YANG,"Genome-wide association studies of serum magnesium, potassium, and sodium concentrations identify six loci influencing serum magnesium levels","Magnesium, potassium, and sodium, cations commonly measured in serum, are involved in many physiological processes including energy metabolism, nerve and muscle function, signal transduction, and fluid and blood pressure regulation. To evaluate the contribution of common genetic variation to normal physiologic variation in serum concentrations of these cations, we conducted genome-wide association studies of serum magnesium, potassium, and sodium concentrations using ∼2.5 million genotyped and imputed common single nucleotide polymorphisms (SNPs) in 15,366 participants of European descent from the international CHARGE Consortium. Study-specific results were combined using fixed-effects inverse-variance weighted meta-analysis. SNPs demonstrating genome-wide significant (p<5×10−8) or suggestive associations (p<4×10−7) were evaluated for replication in an additional 8,463 subjects of European descent. The association of common variants at six genomic regions (in or near MUC1, ATP2B1, DCDC5, TRPM6, SHROOM3, and MDS1) with serum magnesium levels was genome-wide significant when meta-analyzed with the replication dataset. All initially significant SNPs from the CHARGE Consortium showed nominal association with clinically defined hypomagnesemia, two showed association with kidney function, two with bone mineral density, and one of these also associated with fasting glucose levels. Common variants in CNNM2, a magnesium transporter studied only in model systems to date, as well as in CNNM3 and CNNM4, were also associated with magnesium concentrations in this study. We observed no associations with serum sodium or potassium levels exceeding p<4×10−7. Follow-up studies of newly implicated genomic loci may provide additional insights into the regulation and homeostasis of human serum magnesium levels. Author Summary Magnesium, potassium, and sodium are involved in important physiological processes. To better understand how common genetic variation may contribute to inter-individual differences in serum concentrations of these electrolytes, we evaluated single nucleotide polymorphisms (SNPs) across the genome in association with serum magnesium, potassium, and sodium levels in 15,366 participants of European descent from the CHARGE Consortium. We then verified the associations in an additional 8,463 study participants. Six different genomic regions contain variants that are reproducibly associated with serum magnesium levels, and only one of the regions had been previously known to influence serum magnesium concentrations in humans. The identified SNPs also show association with clinically defined hypomagnesemia, and some of them with traits that have been linked to serum magnesium levels, including kidney function, fasting glucose, and bone mineral density. We further provide evidence for a physiological role of magnesium transporters in humans which have previously only been studied in model systems. None of the SNPs evaluated in our study are significantly associated with serum levels of sodium or potassium. Additional studies are needed to investigate the underlying molecular mechanisms in order to help us understand the contribution of these newly identified regions to magnesium homeostasis."
CHEN YANG,Joint Modeling of Linkage and Association Using Affected Sib-Pair Data,"There has been a growing interest in developing strategies for identifying single-nucleotide polymorphisms (SNPs) that explain a linkage signal by joint modeling of linkage and association. We compare several existing methods and propose a new method called the homozygote sharing transmission-disequilibrium test (HSTDT) to detect linkage and association or to identify SNPs explaining the linkage signal on chromosome 6 for rheumatoid arthritis using 100 replicates of the Genetic Analysis Workshop (GAW) 15 simulated affected sib-pair data. Existing methods considered included the family-based tests of association implemented in FBAT, a transmission-disequilibrium test, a conditional logistic regression approach, a likelihood-based approach implemented in LAMP, and the homozygote sharing test (HST). We compared the type I error rates and power for tests classified into three categories according to their null hypotheses: 1) no association in the presence of linkage (i.e., a SNP explains none of the linkage evidence), 2) no linkage adjusting for the association (i.e., a SNP explains all linkage evidence), and 3) no linkage and no association. For testing association in the presence of linkage, we found similar power among all tests except for the homozygote sharing test that had lower power. When testing linkage adjusting for association, similar power was observed between LAMP and HST, but lower power for the conditional logistic regression method. When testing linkage or association, the conditional logistic regression method was more powerful than FBAT."
CHEN YANG,Evaluation of MODIS LAI/FPAR product Collection 6. Part 1: consistency and improvements,"As the latest version of Moderate Resolution Imaging Spectroradiometer (MODIS) Leaf Area Index (LAI) and Fraction of Photosynthetically Active Radiation (FPAR) products, Collection 6 (C6) has been distributed since August 2015. This collection is evaluated in this two-part series with the goal of assessing product accuracy, uncertainty and consistency with the previous version. In this first paper, we compare C6 (MOD15A2H) with Collection 5 (C5) to check for consistency and discuss the scale effects associated with changing spatial resolution between the two collections and benefits from improvements to algorithm inputs. Compared with C5, C6 benefits from two improved inputs: (1) L2G–lite surface reflectance at 500 m resolution in place of reflectance at 1 km resolution; and (2) new multi-year land-cover product at 500 m resolution in place of the 1 km static land-cover product. Global and seasonal comparison between C5 and C6 indicates good continuity and consistency for all biome types. Moreover, inter-annual LAI anomalies at the regional scale from C5 and C6 agree well. The proportion of main radiative transfer algorithm retrievals in C6 increased slightly in most biome types, notably including a 17% improvement in evergreen broadleaf forests. With same biome input, the mean RMSE of LAI and FPAR between C5 and C6 at global scale are 0.29 and 0.091, respectively, but biome type disagreement worsens the consistency (LAI: 0.39, FPAR: 0.102). By quantifying the impact of input changes, we find that the improvements of both land-cover and reflectance products improve LAI/FPAR products. Moreover, we find that spatial scale effects due to a resolution change from 1 km to 500 m do not cause any significant differences."
CHEN YANG,Spectral and Spatial Dependence of Diffuse Optical Signals in Response to Peripheral Nerve Stimulation,"Using non-invasive, near-infrared spectroscopy we have previously reported optical signals measured at or around peripheral nerves in response to their stimulation. Such optical signals featured amplitudes on the order of 0.1% and peaked about 100 ms after peripheral nerve stimulation in human subjects. Here, we report a study of the spatial and spectral dependence of the optical signals induced by stimulation of the human median and sural nerves, and observe that these optical signals are: (1) unlikely due to either dilation or constriction of blood vessels, (2) not associated with capillary bed hemoglobin, (3) likely due to blood vessel(s) displacement, and (4) unlikely due to fiber-skin optical coupling effects. We conclude that the most probable origin of the optical response to peripheral nerve stimulation is from displacement of blood vessels within the optically probed volume, as a result of muscle twitch in adjacent areas."
CHEN YANG,Multiple Independent Loci at Chromosome 15q25.1 Affect Smoking Quantity: a Meta-Analysis and Comparison with Lung Cancer and COPD,"Recently, genetic association findings for nicotine dependence, smoking behavior, and smoking-related diseases converged to implicate the chromosome 15q25.1 region, which includes the CHRNA5-CHRNA3-CHRNB4 cholinergic nicotinic receptor subunit genes. In particular, association with the nonsynonymous CHRNA5 SNP rs16969968 and correlates has been replicated in several independent studies. Extensive genotyping of this region has suggested additional statistically distinct signals for nicotine dependence, tagged by rs578776 and rs588765. One goal of the Consortium for the Genetic Analysis of Smoking Phenotypes (CGASP) is to elucidate the associations among these markers and dichotomous smoking quantity (heavy versus light smoking), lung cancer, and chronic obstructive pulmonary disease (COPD). We performed a meta-analysis across 34 datasets of European-ancestry subjects, including 38,617 smokers who were assessed for cigarettes-per-day, 7,700 lung cancer cases and 5,914 lung-cancer-free controls (all smokers), and 2,614 COPD cases and 3,568 COPD-free controls (all smokers). We demonstrate statistically independent associations of rs16969968 and rs588765 with smoking (mutually adjusted p-values<10−35 and >10−8 respectively). Because the risk alleles at these loci are negatively correlated, their association with smoking is stronger in the joint model than when each SNP is analyzed alone. Rs578776 also demonstrates association with smoking after adjustment for rs16969968 (p<10−6). In models adjusting for cigarettes-per-day, we confirm the association between rs16969968 and lung cancer (p<10−20) and observe a nominally significant association with COPD (p = 0.01); the other loci are not significantly associated with either lung cancer or COPD after adjusting for rs16969968. This study provides strong evidence that multiple statistically distinct loci in this region affect smoking behavior. This study is also the first report of association between rs588765 (and correlates) and smoking that achieves genome-wide significance; these SNPs have previously been associated with mRNA levels of CHRNA5 in brain and lung tissue. Author Summary Nicotine binds to cholinergic nicotinic receptors, which are composed of a variety of subunits. Genetic studies for smoking behavior and smoking-related diseases have implicated a genomic region that encodes the alpha5, alpha3, and beta4 subunits. We examined genetic data across this region for over 38,000 smokers, a subset of which had been assessed for lung cancer or chronic obstructive pulmonary disease. We demonstrate strong evidence that there are at least two statistically independent loci in this region that affect risk for heavy smoking. One of these loci represents a change in the protein structure of the alpha5 subunit. This work is also the first to report strong evidence of association between smoking and a group of genetic variants that are of biological interest because of their links to expression of the alpha5 cholinergic nicotinic receptor subunit gene. These advances in understanding the genetic influences on smoking behavior are important because of the profound public health burdens caused by smoking and nicotine addiction."
CHEN YANG,"“Go eat a bat, Chang!”: on the emergence of sinophobic behavior on web communities in the face of COVID-19","The outbreak of the COVID-19 pandemic has changed our lives in unprecedented ways. In the face of the projected catastrophic consequences, most countries have enacted social distancing measures in an attempt to limit the spread of the virus. Under these conditions, the Web has become an indispensable medium for information acquisition, communication, and entertainment. At the same time, unfortunately, the Web is being exploited for the dissemination of potentially harmful and disturbing content, such as the spread of conspiracy theories and hateful speech towards specific ethnic groups, in particular towards Chinese people and people of Asian descent since COVID-19 is believed to have originated from China. In this paper, we make a first attempt to study the emergence of Sinophobic behavior on the Web during the outbreak of the COVID-19 pandemic. We collect two large datasets from Twitter and 4chan’s Politically Incorrect board (/pol/) over a time period of approximately five months and analyze them to investigate whether there is a rise or important differences with regard to the dissemination of Sinophobic content. We find that COVID-19 indeed drives the rise of Sinophobia on the Web and that the dissemination of Sinophobic content is a cross-platform phenomenon: it exists on fringe Web communities like /pol/, and to a lesser extent on mainstream ones like Twitter. Using word embeddings over time, we characterize the evolution of Sinophobic slurs on both Twitter and /pol/. Finally, we find interesting differences in the context in which words related to Chinese people are used on the Web before and after the COVID-19 outbreak: on Twitter we observe a shift towards blaming China for the situation, while on /pol/ we find a shift towards using more (and new) Sinophobic slurs."
CHEN YANG,"Cosmology intertwined: a review of the particle physics, astrophysics, and cosmology associated with the cosmological tensions and anomalies",
CHEN YANG,Myosin IIA-mediated forces regulate multicellular integrity during vascular sprouting,"Angiogenic sprouting is a critical process involved in vascular network formation within tissues. During sprouting, tip cells and ensuing stalk cells migrate collectively into the extracellular matrix while preserving cell-cell junctions, forming patent structures that support blood flow. Although several signaling pathways have been identified as controlling sprouting, it remains unclear to what extent this process is mechanoregulated. To address this question, we investigated the role of cellular contractility in sprout morphogenesis, using a biomimetic model of angiogenesis. Three-dimensional maps of mechanical deformations generated by sprouts revealed that mainly leader cells, not stalk cells, exert contractile forces on the surrounding matrix. Surprisingly, inhibiting cellular contractility with blebbistatin did not affect the extent of cellular invasion but resulted in cell-cell dissociation primarily between tip and stalk cells. Closer examination of cell-cell junctions revealed that blebbistatin impaired adherens-junction organization, particularly between tip and stalk cells. Using CRISPR/Cas9-mediated gene editing, we further identified NMIIA as the major isoform responsible for regulating multicellularity and cell contractility during sprouting. Together, these studies reveal a critical role for NMIIA-mediated contractile forces in maintaining multicellularity during sprouting and highlight the central role of forces in regulating cell-cell adhesions during collective motility."
CHEN YANG,Genomic insights of body plan transitions from bilateral to pentameral symmetry in echinoderms,"Echinoderms are an exceptional group of bilaterians that develop pentameral adult symmetry from a bilaterally symmetric larva. However, the genetic basis in evolution and development of this unique transformation remains to be clarified. Here we report newly sequenced genomes, developmental transcriptomes, and proteomes of diverse echinoderms including the green sea urchin (L. variegatus), a sea cucumber (A. japonicus), and with particular emphasis on a sister group of the earliest-diverged echinoderms, the feather star (A. japonica). We learned that the last common ancestor of echinoderms retained a well-organized Hox cluster reminiscent of the hemichordate, and had gene sets involved in endoskeleton development. Further, unlike in other animal groups, the most conserved developmental stages were not at the body plan establishing phase, and genes normally involved in bilaterality appear to function in pentameric axis development. These results enhance our understanding of the divergence of protostomes and deuterostomes almost 500 Mya."
CHEN YANG,Derivedness index for estimating degree of phenotypic evolution of embryos: a study of comparative transcriptomic analyses of chordates and echinoderms,"Species retaining ancestral features, such as species called living fossils, are often regarded as less derived than their sister groups, but such discussions are usually based on qualitative enumeration of conserved traits. This approach creates a major barrier, especially when quantifying the degree of phenotypic evolution or degree of derivedness, since it focuses only on commonly shared traits, and newly acquired or lost traits are often overlooked. To provide a potential solution to this problem, especially for inter-species comparison of gene expression profiles, we propose a new method named ""derivedness index"" to quantify the degree of derivedness. In contrast to the conservation-based approach, which deals with expressions of commonly shared genes among species being compared, the derivedness index also considers those that were potentially lost or duplicated during evolution. By applying our method, we found that the gene expression profiles of penta-radial phases in echinoderm tended to be more highly derived than those of the bilateral phase. However, our results suggest that echinoderms may not have experienced much larger modifications to their developmental systems than chordates, at least at the transcriptomic level. In vertebrates, we found that the mid-embryonic and organogenesis stages were generally less derived than the earlier or later stages, indicating that the conserved phylotypic period is also less derived. We also found genes that potentially explain less derivedness, such as Hox genes. Finally, we highlight technical concerns that may influence the measured transcriptomic derivedness, such as read depth and library preparation protocols, for further improvement of our method through future studies. We anticipate that this index will serve as a quantitative guide in the search for constrained developmental phases or processes."
CHEN YANG,A multimodal spatio-temporal GCN model with enhancements for isolated sign recognition,"We propose a multimodal network using skeletons and handshapes as input to recognize individual signs and detect their boundaries in American Sign Language (ASL) videos. Our method integrates a spatio-temporal Graph Convolutional Network (GCN) architecture to estimate human skeleton keypoints; it uses a late-fusion approach for both forward and backward processing of video streams. Our (core) method is designed for the extraction---and analysis of features from---ASL videos, to enhance accuracy and efficiency of recognition of individual signs. A Gating module based on per-channel multi-layer convolutions is employed to evaluate significant frames for recognition of isolated signs. Additionally, an auxiliary multimodal branch network, integrated with a transformer, is designed to estimate the linguistic start and end frames of an isolated sign within a video clip. We evaluated performance of our approach on multiple datasets that include isolated, citation-form signs and signs pre-segmented from continuous signing based on linguistic annotations of start and end points of signs within sentences. We have achieved very promising results when using both types of sign videos combined for training, with overall sign recognition accuracy of 80.8% Top-1 and 95.2% Top-5 for citation-form signs, and 80.4% Top-1 and 93.0% Top-5 for signs pre-segmented from continuous signing."
CHEN YANG,Search for astrophysical electron antineutrinos in Super-Kamiokande with 0.01% gadolinium-loaded water,"We report the first search result for the flux of astrophysical electron antineutrinos for energies 𝒪(10) MeV in the gadolinium-loaded Super-Kamiokande (SK) detector. In 2020 June, gadolinium was introduced to the ultrapure water of the SK detector in order to detect neutrons more efficiently. In this new experimental phase, SK-Gd, we can search for electron antineutrinos via inverse beta decay with efficient background rejection thanks to the high efficiency of the neutron tagging technique. In this paper, we report the result for the initial stage of SK-Gd, during 2020 August 26, and 2022 June 1 with a 22.5 × 552 kton · day exposure at 0.01% Gd mass concentration. No significant excess over the expected background in the observed events is found for the neutrino energies below 31.3 MeV. Thus, the flux upper limits are placed at the 90% confidence level. The limits and sensitivities are already comparable with the previous SK result with pure water (22.5 × 2970 kton · day) owing to the enhanced neutron tagging. Operation with Gd increased to 0.03% started in 2022 June."
CHEN YANG,Measurement of the cosmogenic neutron yield in Super-Kamiokande with gadolinium loaded water,
CHEN YANG,Scintillation light detection in the 6-m drift-length ProtoDUNE Dual Phase liquid argon TPC,"DUNE is a dual-site experiment for long-baseline neutrino oscillation studies, neutrino astrophysics and nucleon decay searches. ProtoDUNE Dual Phase (DP) is a 6  ×  6  ×  6 m 3 liquid argon time-projection-chamber (LArTPC) that recorded cosmic-muon data at the CERN Neutrino Platform in 2019-2020 as a prototype of the DUNE Far Detector. Charged particles propagating through the LArTPC produce ionization and scintillation light. The scintillation light signal in these detectors can provide the trigger for non-beam events. In addition, it adds precise timing capabilities and improves the calorimetry measurements. In ProtoDUNE-DP, scintillation and electroluminescence light produced by cosmic muons in the LArTPC is collected by photomultiplier tubes placed up to 7 m away from the ionizing track. In this paper, the ProtoDUNE-DP photon detection system performance is evaluated with a particular focus on the different wavelength shifters, such as PEN and TPB, and the use of Xe-doped LAr, considering its future use in giant LArTPCs. The scintillation light production and propagation processes are analyzed and a comparison of simulation to data is performed, improving understanding of the liquid argon properties."
CHEN YANG,Prospects for beyond the standard model physics searches at the deep underground neutrino experiment: DUNE collaboration,"The Deep Underground Neutrino Experiment (DUNE) will be a powerful tool for a variety of physics topics. The high-intensity proton beams provide a large neutrino flux, sampled by a near detector system consisting of a combination of capable precision detectors, and by the massive far detector system located deep underground. This configuration sets up DUNE as a machine for discovery, as it enables opportunities not only to perform precision neutrino measurements that may uncover deviations from the present three-flavor mixing paradigm, but also to discover new particles and unveil new interactions and symmetries beyond those predicted in the Standard Model (SM). Of the many potential beyond the Standard Model (BSM) topics DUNE will probe, this paper presents a selection of studies quantifying DUNE's sensitivities to sterile neutrino mixing, heavy neutral leptons, non-standard interactions, CPT symmetry violation, Lorentz invariance violation, neutrino trident production, dark matter from both beam induced and cosmogenic sources, baryon number violation, and other new physics topics that complement those at high-energy colliders and significantly extend the present reach."
CHEN YANG,Identification and reconstruction of low-energy electrons in the ProtoDUNE-SP detector,
AARON B BEELER,Multidimensional reaction screening for photochemical transformations as a tool for discovering new chemotypes,"We have developed an automated photochemical microfluidics platform that integrates a 1 kW high-pressure Hg vapor lamp and allows for analytical pulse flow or preparative continuous flow reactions. Herein, we will discuss the use of this platform toward the discovery of new chemotypes through multidimensional reaction screening. We will highlight the ability to discretely control wavelengths with optical filters, allowing for control of reaction outcomes."
AARON B BEELER,Fine-tuning of macrophage activation using synthetic rocaglate derivatives.,"Drug-resistant bacteria represent a significant global threat. Given the dearth of new antibiotics, host-directed therapies (HDTs) are especially desirable. As IFN-gamma (IFNγ) plays a central role in host resistance to intracellular bacteria, including Mycobacterium tuberculosis, we searched for small molecules to augment the IFNγ response in macrophages. Using an interferon-inducible nuclear protein Ipr1 as a biomarker of macrophage activation, we performed a high-throughput screen and identified molecules that synergized with low concentration of IFNγ. Several active compounds belonged to the flavagline (rocaglate) family. In primary macrophages a subset of rocaglates 1) synergized with low concentrations of IFNγ in stimulating expression of a subset of IFN-inducible genes, including a key regulator of the IFNγ network, Irf1; 2) suppressed the expression of inducible nitric oxide synthase and type I IFN and 3) induced autophagy. These compounds may represent a basis for macrophage-directed therapies that fine-tune macrophage effector functions to combat intracellular pathogens and reduce inflammatory tissue damage. These therapies would be especially relevant to fighting drug-resistant pathogens, where improving host immunity may prove to be the ultimate resource."
AARON B BEELER,Development of a potent and selective HDAC8 inhibitor,"A novel, isoform-selective inhibitor of histone deacetylase 8 (HDAC8) has been discovered by the repurposing of a diverse compound collection. Medicinal chemistry optimization led to the identification of a highly potent (0.8 nM) and selective inhibitor of HDAC8."
AARON B BEELER,A photochemical flow reactor for large scale syntheses of aglain and rocaglate natural product analogues,"Herein, we report the development of continuous flow photoreactors for large scale ESIPT-mediated [3+2]-photocycloaddition of 2-(p-methoxyphenyl)-3-hydroxyflavone and cinnamate-derived dipolarophiles. These reactors can be efficiently numbered up to increase throughput two orders of magnitude greater than the corresponding batch reactions."
AARON B BEELER,Remodelling of the natural product fumagillol employing a reaction discovery approach,"In the search for new biologically active molecules, diversity-oriented synthetic strategies break through the limitation of traditional library synthesis by sampling new chemical space. Many natural products can be regarded as intriguing starting points for diversity-oriented synthesis, wherein stereochemically rich core structures may be reorganized into chemotypes that are distinctly different from the parent structure. Ideally, to be suited to library applications, such transformations should be general and involve few steps. With this objective in mind, the highly oxygenated natural product fumagillol has been successfully remodelled in several ways using a reaction-discovery-based approach. In reactions with amines, excellent regiocontrol in a bis-epoxide opening/cyclization sequence can be obtained by size-dependent interaction of an appropriate catalyst with the parent molecule, forming either perhydroisoindole or perhydroisoquinoline products. Perhydroisoindoles can be further remodelled by cascade processes to afford either morpholinone or bridged 4,1-benzoxazepine-containing structures."
AARON B BEELER,Synthesis of neocannabinoids using controlled friedel-crafts reactions,"A one-step transformation to produce 8,9-dihydrocannabidiol (H2CBD) and related ""neocannabinoids"" via controlled Friedel-Crafts reactions is reported. Experimental and computational studies probing the mechanism of neocannabinoid synthesis from cyclic allylic alcohol and substituted resorcinol reaction partners provide understanding of the kinetic and thermodynamic factors driving regioselectivity for the reaction. Herein, we present the reaction scope for neocannabinoid synthesis including the production of both normal and abnormal isomers under both kinetic and thermodynamic control. Discovery and optimization of this one-step protocol between various allylic alcohols and resorcinol derivatives are discussed and supported with density functional theory calculations."
AARON B BEELER,Channeling macrophage polarization by rocaglates increases macrophage resistance to Mycobacterium tuberculosis,"Macrophages contribute to host immunity and tissue homeostasis via alternative activation programs. M1-like macrophages control intracellular bacterial pathogens and tumor progression. In contrast, M2-like macrophages shape reparative microenvironments that can be conducive for pathogen survival or tumor growth. An imbalance of these macrophages phenotypes may perpetuate sites of chronic unresolved inflammation, such as infectious granulomas and solid tumors. We have found that plant-derived and synthetic rocaglates sensitize macrophages to low concentrations of the M1-inducing cytokine IFN-gamma and inhibit their responsiveness to IL-4, a prototypical activator of the M2-like phenotype. Treatment of primary macrophages with rocaglates enhanced phagosome-lysosome fusion and control of intracellular mycobacteria. Thus, rocaglates represent a novel class of immunomodulators that can direct macrophage polarization toward the M1-like phenotype in complex microenvironments associated with hypofunction of type 1 and/or hyperactivation of type 2 immunity, e.g., chronic bacterial infections, allergies, and, possibly, certain tumors."
ANGELA HO,Human APOER2 isoforms have differential cleavage events and synaptic properties,"Human APOER2 is a type I transmembrane protein with a large extracellular domain (ECD) and a short cytoplasmic tail. APOER2-ECD contains several ligand binding domains (LBD) that are organized into exons with aligning phase junctions, which allows for in-frame exon cassette splicing events. We have identified 25 human APOER2 isoforms from cerebral cortex using gene-specific APOER2 primers, where the majority are exon-skipping events within the N-terminal LBD regions in comparison to 6 identified in the heart. APOER2 undergoes proteolytic cleavage in response to ligand binding that releases a C-terminal fragment (CTF) and transcriptionally active intracellular domain (ICD). We therefore tested whether the diversity of human brain-specific APOER2 variants affects APOER2 cleavage. We found exclusion of different ligand binding repeats from splicing generated different amounts of CTFs compared to full-length APOER2 (APOER2-FL). Specifically, APOER2 isoforms lacking exons 5-8 (Δex5-8) and lacking exons 4-6 (Δex4-6) generated the highest and lowest amounts of CTF generation respectively in response to APOE peptide compared to APOER2-FL. The differential CTF generation of APOER2 Δex5-8 and Δex4-6 coincides with the proteolytic release of the ICD which mediates transcriptional activation facilitated by the Mint1 adaptor protein. Functionally, we demonstrated loss of mouse Apoer2 decreased miniature event frequency in excitatory synapses suggesting that Apoer2 is required for spontaneous neurotransmitter release in mature neurons. Lentiviral rescue with human APOER2-FL or Δex4-6 isoform in Apoer2 knockout neurons fully restored the miniature event frequency but not Δex5-8 isoform. These results suggest that human APOER2 isoforms have differential cleavage events and synaptic properties."
ANGELA HO,CLASP2 links Reelin to the cytoskeleton during neocortical development,"INTRODUCTION The complex architecture of the brain requires precise control over the timing of neurogenesis, neuron migration, and differentiation. These three developmental processes are exquisitely controlled during the expansion of the mammalian neocortex. The six morphologically distinct layers of the neocortex form in an “inside-out” pattern with early-born neurons forming deeper layers and later-born neurons migrating past them to form superficial layers of the cortical plate (Rakic, 1974). The Reelin signaling pathway plays a crucial role in cortical lamination. Reelin is a secreted glycoprotein that exerts its function by binding to the lipoprotein receptors ApoER2 and VLDLR and inducing tyrosine phosphorylation of the intracellular adaptor protein Disabled (Dab1) (Howell et al., 2000, Bock and Herz, 2003). Phosphorylated Dab1 then recruits downstream signaling molecules to promote cytoskeletal changes necessary for neuronal migration, final positioning, and morphology (D’Arcangelo, 2005). Mutations of Reelin, the dual ApoER2/VLDLR receptor, or Dab1 lead to an inversion of the normal inside-out pattern of cortex development (D’Arcangelo et al., 1995, Howell et al., 1997, Trommsdorff et al., 1999). In addition, a number of mutations in cytoskeletal-encoded genes produce deficits in neuron migration and cortical lamination phenotypically similar to Reelin mutants, firmly establishing a mechanistic and developmentally critical connection between Reelin and the cytoskeleton. For example, human mutations in lissencephaly-1, doublecortin, and tubulin, integral components of the microtubule cytoskeleton, cause severe cortical lamination defects with later-born neurons failing to migrate past previously born neurons (Reiner et al., 1993, Gleeson et al., 1998, Romaniello et al., 2015). The culmination of these genetic studies indicates that several signaling pathways, including the Reelin pathway, converge on downstream cytoskeletal proteins to affect proper neuronal migration and brain development. However, the molecular effectors of these pathways have not been fully characterized. CLASPs (cytoplasmic linker associated proteins) belong to a heterogeneous family of plus-end tracking proteins (+TIPs) that specifically accumulate at the growth cone. This localization strategically places them in a position to control neurite growth, directionality, and the crosstalk between microtubules and the actin cytoskeleton (Akhmanova and Hoogenraad, 2005, Basu and Chang, 2007, Akhmanova and Steinmetz, 2008). Previous evidence showed that CLASPs accumulate asymmetrically toward the leading edge of migrating fibroblasts, indicating a role for CLASPs in cell polarity and movement (Akhmanova et al., 2001, Wittmann and Waterman-Storer, 2005). We found that CLASP2 protein levels steadily increase throughout neuronal development and are specifically enriched at the growth cones of extending neurites. In particular, short-hairpin RNA (shRNA)-mediated knockdown of CLASP2 in primary mouse neurons decreases neurite length, whereas overexpression of human CLASP2 causes the formation of multiple axons, enhanced dendritic branching, and Golgi condensation (Beffert et al., 2012). These results implicate a role for CLASP2 in neuronal morphogenesis and polarization; however, the function of CLASP2 during brain development is unknown. Here we demonstrate that CLASP2 is a modifier of the Reelin signaling pathway during cortical development. In vivo knockdown experiments demonstrate that CLASP2 plays significant roles in neural precursor proliferation, neuronal migration, and morphogenesis. In addition, we show that GSK3β-mediated phosphorylation of CLASP2 controls its binding to the Reelin adaptor protein Dab1, a required molecular step governing CLASP2’s regulatory effects on neuron morphology and movement. RESULTS CLASP2 Expression Is Functionally Associated with the Reelin Signaling Pathway To identify novel genes downstream of Reelin signaling, we examined the expression of mRNA transcripts by microarray between adult brain cortices from mice deficient in either Reelin, the double ApoER2/VLDLR receptor mutant, or Dab1 and compared Affymetrix gene expression profiles against age-matched, wild-type mice. Importantly, each of these mutant mouse models present a similar phenotype that includes severe neuronal migration defects (D’Arcangelo et al., 1995, Howell et al., 1997, Trommsdorff et al., 1999). We defined a large network of genes perturbed above a threshold of 1.5-fold in response to deficient Reelin signaling, identifying 832 upregulated and 628 downregulated genes that were common to all three mouse models (Figure 1A). Ingenuity Pathway Analysis revealed a network of genes that is functionally related to cytoskeleton organization, microtubule dynamics, neurogenesis, and migration of cells (Figure 1B). Of the few cytoskeletal candidate genes identified, CLASP2 was the only microtubule +TIP. Specifically, CLASP2 mRNA expression was increased in all three Reelin mutant phenotypes, while CLASP1 mRNA expression remained unchanged (Figure 1B). Consistent with the microarray data, CLASP2 protein levels were ∼2.8-fold higher in Dab1 knockout mice (Figure 1C). These findings suggest that Reelin signaling controls CLASP2 expression and establishes the first molecular link between a plus-end, microtubule binding protein downstream of extracellular Reelin signaling."
ANGELA HO,ApoER2: functional tuning through splicing,"Alternative splicing occurs in over 95% of protein-coding genes and contributes to the diversity of the human proteome. Apolipoprotein E receptor 2 (apoER2) is a critical modulator of neuronal development and synaptic plasticity in the brain and is enriched in cassette exon splicing events, in which functional exons are excluded from the final transcript. These alternative splicing events affect apoER2 function, as individual apoER2 exons tend to encode distinct protein functional domains. Although several apoER2 splice variants have been characterized, much work remains to understand how apoER2 splicing events modulate distinct apoER2 activities, including ligand binding specificity, synapse formation and plasticity. Additionally, little is known about how apoER2 splicing events are regulated. Often, alternative splicing events are regulated through the combinatorial action of RNA-binding proteins and other epigenetic mechanisms, however, the regulatory pathways corresponding to each specific exon are unknown in most cases. In this mini-review, we describe the structure of apoER2, highlight the unique functions of known isoforms, discuss what is currently known about the regulation of apoER2 splicing by RNA-binding proteins and pose new questions that will further our understanding of apoER2 splicing complexity."
ANGELA HO,"Single molecule, long-read Apoer2 sequencing identifies conserved and species-specific splicing patterns","Apolipoprotein E receptor 2 (Apoer2) is a synaptic receptor in the brain that binds disease-relevant ligand Apolipoprotein E (Apoe) and is highly alternatively spliced. We examined alternative splicing (AS) of conserved Apoer2 exons across vertebrate species and identified gain of exons in mammals encoding functional domains such as the cytoplasmic and furin inserts, and loss of an exon in primates encoding the eighth LDLa repeat, likely altering receptor surface levels and ligand-binding specificity. We utilized single molecule, long-read RNA sequencing to profile full-length Apoer2 isoforms and identified 68 and 48 unique full-length Apoer2 transcripts in the mouse and human cerebral cortex, respectively. Furthermore, we identified two exons encoding protein functional domains, the third EGF-precursor like repeat and glycosylation domain, that are tandemly skipped specifically in mouse. Our study provides new insight into Apoer2 isoform complexity in the vertebrate brain and highlights species-specific differences in splicing decisions that support functional diversity."
ANGELA HO,Inactivation of presenilins causes pre-synaptic impairment prior to post-synaptic dysfunction,"Synaptic dysfunction is widely thought to be a pathogenic precursor to neurodegeneration in Alzheimer’s disease (AD), and the extent of synaptic loss provides the best correlate for the severity of dementia in AD patients. Presenilins 1 and 2 are the major causative genes of early‐onset familial AD. Conditional inactivation of presenilins in the adult cerebral cortex results in synaptic dysfunction and memory impairment, followed by age‐dependent neurodegeneration. To characterize further the consequence of presenilin inactivation in the synapse, we evaluated the temporal development of pre‐synaptic and post‐synaptic deficits in the Schaeffer‐collateral pathway of presenilin conditional double knockout (PS cDKO) mice prior to onset of neurodegeneration. Following presenilin inactivation at 4 weeks, synaptic facilitation and probability of neurotransmitter release are impaired in PS cDKO mice at 5 weeks of age, whereas post‐synaptic NMDA receptor (NMDAR)‐mediated responses are normal at 5 weeks but impaired at 6 weeks of age. Long‐term potentiation induced by theta burst stimulation is also reduced in PS cDKO mice at 6 weeks of age. These results show that loss of presenilins results in pre‐synaptic deficits in short‐term plasticity and probability of neurotransmitter release prior to post‐synaptic NMDAR dysfunction, raising the possibility that presenilins may regulate post‐synaptic NMDAR function in part via a trans‐synaptic mechanism."
ANGELA HO,A rare autism-associated MINT2/APBA2 mutation disrupts neurexin trafficking and synaptic function,"MINT2/APBA2 is a synaptic adaptor protein involved in excitatory synaptic transmission. Several nonsynonymous coding variants in MINT2 have been identified in autism spectrum disorders (ASDs); however, these rare variants have not been examined functionally and the pathogenic mechanisms are unknown. Here, we examined the synaptic effects of rat Mint2 N723S mutation (equivalent to autism-linked human MINT2 N722S mutation) which targets a conserved asparagine residue in the second PDZ domain of Mint2 that binds to neurexin-1α (Nrxn1α), a presynaptic cell-adhesion protein implicated in ASDs. We show the N723S mutation impairs Nrxn1α stabilization and trafficking to the membrane while binding to Nrxn1α remains unaffected. Using time-lapse imaging in primary mouse neurons, we found that the N723S mutant had more immobile puncta at neuronal processes compared to Mint2 wild type. We therefore, reasoned that the N723S mutant may alter the co-transport of Nrxn1α at axonal processes to presynaptic terminals. Indeed, we found the N723S mutation affected Nrxn1α localization at presynaptic terminals which correlated with a decrease in Nrxn-mediated synaptogenesis and miniature event frequency in excitatory synapses. Together, our data reveal Mint2 N723S leads to neuronal dysfunction, in part due to alterations in Nrxn1α surface trafficking and synaptic function of Mint2."
ANGELA HO,FOXR1 regulates stress response pathways and is necessary for proper brain development,"The forkhead box (Fox) family of transcription factors are highly conserved and play essential roles in a wide range of cellular and developmental processes. We report an individual with severe neurological symptoms including postnatal microcephaly, progressive brain atrophy and global developmental delay associated with a de novo missense variant (M280L) in the FOXR1 gene. At the protein level, M280L impaired FOXR1 expression and induced a nuclear aggregate phenotype due to protein misfolding and proteolysis. RNAseq and pathway analysis showed that FOXR1 acts as a transcriptional activator and repressor with central roles in heat shock response, chaperone cofactor-dependent protein refolding and cellular response to stress pathways. Indeed, FOXR1 expression is increased in response to cellular stress, a process in which it directly controls HSPA6, HSPA1A and DHRS2 transcripts. The M280L mutant compromises FOXR1's ability to respond to stress, in part due to impaired regulation of downstream target genes that are involved in the stress response pathway. Quantitative PCR of mouse embryo tissues show Foxr1 expression in the embryonic brain. Using CRISPR/Cas9 gene editing, we found that deletion of mouse Foxr1 leads to a severe survival deficit while surviving newborn Foxr1 knockout mice have reduced body weight. Further examination of newborn Foxr1 knockout brains revealed a decrease in cortical thickness and enlarged ventricles compared to littermate wild-type mice, suggesting that loss of Foxr1 leads to atypical brain development. Combined, these results suggest FOXR1 plays a role in cellular stress response pathways and is necessary for normal brain development."
RUTH PARIS,Locating infant and early childhood mental health at the heart of social work,"Infant and early childhood mental health (IECMH)—an interdisciplinary field dedicated to advancing understanding of early relationships, socioemotional development, and cultural and contextual influences on caregiving—offers essential tools for social workers to support the well-being of infants, toddlers, preschoolers, and their families. Even though social worker Selma Fraiberg was a founder of the field, and social workers are central to the work of assessment and intervention with young children and their caregivers in many settings, few schools of social work offer training in IECMH, and few social workers are familiar with its core principles, scholarship, and intervention approaches. In this article, faculty members from four U.S. social work programs address the vital role of IECMH in social work training, research, and practice as well as issue a call to the field to recover and renew commitment to a practice perspective and knowledge base with roots in social work. Twenty-five years ago, Social Work published a similar call, but the request has gone largely unheeded. The authors examine the changing landscape and argue that it is more important and timelier than ever for social workers to learn and integrate the relationship-based approach to promotion, prevention, intervention, and treatment offered by IECMH."
GIANLUCA STRINGHINI,On the origins of memes by means of fringe web communities,"Internet memes are increasingly used to sway and manipulate public opinion. This prompts the need to study their propagation, evolution, and influence across the Web. In this paper, we detect and measure the propagation of memes across multiple Web communities, using a processing pipeline based on perceptual hashing and clustering techniques, and a dataset of 160M images from 2.6B posts gathered from Twitter, Reddit, 4chan's Politically Incorrect board (/pol/), and Gab, over the course of 13 months. We group the images posted on fringe Web communities (/pol/, Gab, and The_Donald subreddit) into clusters, annotate them using meme metadata obtained from Know Your Meme, and also map images from mainstream communities (Twitter and Reddit) to the clusters. Our analysis provides an assessment of the popularity and diversity of memes in the context of each community, showing, e.g., that racist memes are extremely common in fringe Web communities. We also find a substantial number of politics-related memes on both mainstream and fringe Web communities, supporting media reports that memes might be used to enhance or harm politicians. Finally, we use Hawkes processes to model the interplay between Web communities and quantify their reciprocal influence, finding that /pol/ substantially influences the meme ecosystem with the number of memes it produces, while The_Donald has a higher success rate in pushing them to other communities."
GIANLUCA STRINGHINI,A family of droids -- Android malware detection via behavioral modeling: static vs dynamic analysis,"Following the increasing popularity of mobile ecosystems, cybercriminals have increasingly targeted them, designing and distributing malicious apps that steal information or cause harm to the device's owner. Aiming to counter them, detection techniques based on either static or dynamic analysis that model Android malware, have been proposed. While the pros and cons of these analysis techniques are known, they are usually compared in the context of their limitations e.g., static analysis is not able to capture runtime behaviors, full code coverage is usually not achieved during dynamic analysis, etc. Whereas, in this paper, we analyze the performance of static and dynamic analysis methods in the detection of Android malware and attempt to compare them in terms of their detection performance, using the same modeling approach. To this end, we build on MaMaDroid, a state-of-the-art detection system that relies on static analysis to create a behavioral model from the sequences of abstracted API calls. Then, aiming to apply the same technique in a dynamic analysis setting, we modify CHIMP, a platform recently proposed to crowdsource human inputs for app testing, in order to extract API calls' sequences from the traces produced while executing the app on a CHIMP virtual device. We call this system AuntieDroid and instantiate it by using both automated (Monkey) and user-generated inputs. We find that combining both static and dynamic analysis yields the best performance, with F-measure reaching 0.92. We also show that static analysis is at least as effective as dynamic analysis, depending on how apps are stimulated during execution, and, finally, investigate the reasons for inconsistent misclassifications across methods."
GIANLUCA STRINGHINI,Feels bad man: dissecting automated hateful meme detection through the lens of Facebook’s challenge,
GIANLUCA STRINGHINI,The gospel according to Q: understanding the QAnon conspiracy from the perspective of canonical information,
GIANLUCA STRINGHINI,"A large-scale temporal measurement of Android malicious apps: persistence, migration, and lessons learned",
GIANLUCA STRINGHINI,TrollMagnifier: detecting state-sponsored troll accounts on Reddit,
GIANLUCA STRINGHINI,Finding MNEMON: reviving memories of node embeddings,
GIANLUCA STRINGHINI,"Slapping cats, bopping heads, and Oreo shakes: understanding indicators of virality in TikTok short videos",
GIANLUCA STRINGHINI,A first look at zoombombing,"We conducted the first data-driven study of calls for zoombombing attacks. We analyzed 223 calls for zoombombing posted on Twitter and 4chan. We found that most calls for zoombombing come from insiders who have legitimate access to the meetings, calling into question widely adopted mitigation techniques to secure online meetings."
GIANLUCA STRINGHINI,The evolution of the manosphere across the web,"We present a large-scale characterization of the Manosphere, a conglomerate of Web-based misogynist movements focused on “men’s issues,” which has prospered online. Analyzing 28.8M posts from 6 forums and 51 subreddits, we paint a comprehensive picture of its evolution across the Web, showing the links between its different communities over the years. We find that milder and older communities, such as Pick Up Artists and Men’s Rights Activists, are giving way to more extreme ones like Incels and Men Going Their Own Way, with a substantial migration of active users. Moreover, our analysis suggests that these newer communities are more toxic and misogynistic than the older ones."
GIANLUCA STRINGHINI,Understanding the use of fauxtography on social media,"Despite the influence that image-based communication has on online discourse, the role played by images in disinformation is still not well understood. In this paper, we present the first large-scale study of fauxtography, analyzing the use of manipulated or misleading images in news discussion on online communities. First, we develop a computational pipeline geared to detect fauxtography, and identify over 61k instances of fauxtography discussed on Twitter, 4chan, and Reddit. Then, we study how posting fauxtography affects engagement of posts on social media, finding that posts containing it receive more interactions in the form of re-shares, likes, and comments. Finally, we show that fauxtography images are often turned into memes by Web communities. Our findings show that effective mitigation against disinformation need to take images into account, and highlight a number of challenges in dealing with image-based disinformation."
GIANLUCA STRINGHINI,FirmSolo: Enabling dynamic analysis of binary Linux-based IoT kernel modules,
GIANLUCA STRINGHINI,Why so toxic?: Measuring and triggering toxic behavior in open-domain chatbots,
GIANLUCA STRINGHINI,Cerberus: exploring federated prediction of security events,
GIANLUCA STRINGHINI,Non-polar opposites: analyzing the relationship between echo chambers and hostile intergroup interactions on Reddit,
GIANLUCA STRINGHINI,"""It is just a flu"": assessing the effect of watch history on YouTube's pseudoscientific video recommendations",
GIANLUCA STRINGHINI,"SoK: hate, harassment, and the changing landscape of online abuse","We argue that existing security, privacy, and antiabuse protections fail to address the growing threat of online hate and harassment. In order for our community to understand and address this gap, we propose a taxonomy for reasoning about online hate and harassment. Our taxonomy draws on over 150 interdisciplinary research papers that cover disparate threats ranging from intimate partner violence to coordinated mobs. In the process, we identify seven classes of attacks—such as toxic content and surveillance—that each stem from different attacker capabilities and intents. We also provide longitudinal evidence from a three-year survey that hate and harassment is a pervasive, growing experience for online users, particularly for at-risk communities like young adults and people who identify as LGBTQ+. Responding to each class of hate and harassment requires a unique strategy and we highlight five such potential research directions that ultimately empower individuals, communities, and platforms to do so."
GIANLUCA STRINGHINI,“Is it a qoincidence?”: An exploratory study of QAnon on Voat,"Online fringe communities offer fertile grounds to users seeking and sharing ideas fueling suspicion of mainstream news and conspiracy theories. Among these, the QAnon conspiracy theory emerged in 2017 on 4chan, broadly supporting the idea that powerful politicians, aristocrats, and celebrities are closely engaged in a global pedophile ring. Simultaneously, governments are thought to be controlled by “puppet masters,” as democratically elected officials serve as a fake showroom of democracy. This paper provides an empirical exploratory analysis of the QAnon community on Voat.co, a Reddit-esque news aggregator, which has captured the interest of the press for its toxicity and for providing a platform to QAnon followers. More precisely, we analyze a large dataset from /v/GreatAwakening, the most popular QAnon-related subverse (the Voat equivalent of a subreddit), to characterize activity and user engagement. To further understand the discourse around QAnon, we study the most popular named entities mentioned in the posts, along with the most prominent topics of discussion, which focus on US politics, Donald Trump, and world events. We also use word embeddings to identify narratives around QAnon-specific keywords. Our graph visualization shows that some of the QAnon-related ones are closely related to those from the Pizzagate conspiracy theory and so-called drops by “Q.” Finally, we analyze content toxicity, finding that discussions on /v/GreatAwakening are less toxic than in the broad Voat community."
GIANLUCA STRINGHINI,MaMaDroid: detecting Android malware by building Markov chains of behavioral models (extended version),"As Android has become increasingly popular, so has malware targeting it, thus motivating the research community to propose different detection techniques. However, the constant evolution of the Android ecosystem, and of malware itself, makes it hard to design robust tools that can operate for long periods of time without the need for modifications or costly re-training. Aiming to address this issue, we set to detect malware from a behavioral point of view, modeled as the sequence of abstracted API calls. We introduce MAMADROID, a static-analysis-based system that abstracts app’s API calls to their class, package, or family, and builds a model from their sequences obtained from the call graph of an app as Markov chains. This ensures that the model is more resilient to API changes and the features set is of manageable size. We evaluate MAMADROID using a dataset of 8.5K benign and 35.5K malicious apps collected over a period of 6 years, showing that it effectively detects malware (with up to 0.99 F-measure) and keeps its detection capabilities for long periods of time (up to 0.87 F-measure 2 years after training). We also show that MAMADROID remarkably overperforms DROIDAPIMINER, a state-of-the-art detection system that relies on the frequency of (raw) API calls. Aiming to assess whether MAMADROID’s effectiveness mainly stems from the API abstraction or from the sequencing modeling, we also evaluate a variant of it that uses frequency (instead of sequences), of abstracted API calls. We find that it is not as accurate, failing to capture maliciousness when trained on malware samples that include API calls that are equally or more frequently used by benign apps."
GIANLUCA STRINGHINI,Eight years of rider measurement in the Android malware ecosystem: evolution and lessons learned,"Despite the growing threat posed by Android malware, the research community is still lacking a comprehensive view of common behaviors and trends exposed by malware families active on the platform. Without such view, the researchers incur the risk of developing systems that only detect outdated threats, missing the most recent ones. In this paper, we conduct the largest measurement of Android malware behavior to date, analyzing over 1.2 million malware samples that belong to 1.2K families over a period of eight years (from 2010 to 2017). We aim at understanding how the behavior of Android malware has evolved over time, focusing on repackaging malware. In this type of threats different innocuous apps are piggybacked with a malicious payload (rider), allowing inexpensive malware manufacturing. One of the main challenges posed when studying repackaged malware is slicing the app to split benign components apart from the malicious ones. To address this problem, we use differential analysis to isolate software components that are irrelevant to the campaign and study the behavior of malicious riders alone. Our analysis framework relies on collective repositories and recent advances on the systematization of intelligence extracted from multiple anti-virus vendors. We find that since its infancy in 2010, the Android malware ecosystem has changed significantly, both in the type of malicious activity performed by the malicious samples and in the level of obfuscation used by malware to avoid detection. We then show that our framework can aid analysts who attempt to study unknown malware families. Finally, we discuss what our findings mean for Android malware detection research, highlighting areas that need further attention by the research community."
GIANLUCA STRINGHINI,Disinformation warfare: understanding state-sponsored trolls on Twitter and their influence on the web,"Over the past couple of years, anecdotal evidence has emerged linking coordinated campaigns by state-sponsored actors with efforts to manipulate public opinion on the Web, often around major political events, through dedicated accounts, or “trolls.” Although they are often involved in spreading disinformation on social media, there is little understanding of how these trolls operate, what type of content they disseminate, and most importantly their influence on the information ecosystem. In this paper, we shed light on these questions by analyzing 27K tweets posted by 1K Twitter users identified as having ties with Russia’s Internet Research Agency and thus likely state-sponsored trolls. We compare their behavior to a random set of Twitter users, finding interesting differences in terms of the content they disseminate, the evolution of their account, as well as their general behavior and use of Twitter. Then, using Hawkes Processes, we quantify the influence that trolls had on the dissemination of news on social platforms like Twitter, Reddit, and 4chan. Overall, our findings indicate that Russian trolls managed to stay active for long periods of time and to reach a substantial number of Twitter users with their tweets. When looking at their ability of spreading news content and making it viral, however, we find that their effect on social platforms was minor, with the significant exception of news published by the Russian state-sponsored news outlet RT (Russia Today)."
GIANLUCA STRINGHINI,Large scale crowdsourcing and characterization of Twitter abusive behavior,"In recent years online social networks have suffered an increase in sexism, racism, and other types of aggressive and cyberbullying behavior, often manifesting itself through offensive, abusive, or hateful language. Past scientific work focused on studying these forms of abusive activity in popular online social networks, such as Facebook and Twitter. Building on such work, we present an eight month study of the various forms of abusive behavior on Twitter, in a holistic fashion. Departing from past work, we examine a wide variety of labeling schemes, which cover different forms of abusive behavior. We propose an incremental and iterative methodology that leverages the power of crowdsourcing to annotate a large collection of tweets with a set of abuse-related labels.By applying our methodology and performing statistical analysis for label merging or elimination, we identify a reduced but robust set of labels to characterize abuse-related tweets. Finally, we offer a characterization of our annotated dataset of 80 thousand tweets, which we make publicly available for further scientific exploration."
GIANLUCA STRINGHINI,Email Babel: does language affect criminal activity in compromised webmail accounts?,"We set out to understand the effects of differing language on the ability of cybercriminals to navigate webmail accounts and locate sensitive information in them. To this end, we configured thirty Gmail honeypot accounts with English, Romanian, and Greek language settings. We populated the accounts with email messages in those languages by subscribing them to selected online newsletters. We hid email messages about fake bank accounts in fifteen of the accounts to mimic real-world webmail users that sometimes store sensitive information in their accounts. We then leaked credentials to the honey accounts via paste sites on the Surface Web and the Dark Web, and collected data for fifteen days. Our statistical analyses on the data show that cybercriminals are more likely to discover sensitive information (bank account information) in the Greek accounts than the remaining accounts, contrary to the expectation that Greek ought to constitute a barrier to the understanding of non-Greek visitors to the Greek accounts. We also extracted the important words among the emails that cybercriminals accessed (as an approximation of the keywords that they searched for within the honey accounts), and found that financial terms featured among the top words. In summary, we show that language plays a significant role in the ability of cybercriminals to access sensitive information hidden in compromised webmail accounts."
GIANLUCA STRINGHINI,Who let the trolls out? Towards understanding state-sponsored trolls,"Recent evidence has emerged linking coordinated campaigns by state-sponsored actors to manipulate public opinion on the Web. Campaigns revolving around major political events are enacted via mission-focused ?trolls."" While trolls are involved in spreading disinformation on social media, there is little understanding of how they operate, what type of content they disseminate, how their strategies evolve over time, and how they influence the Web's in- formation ecosystem. In this paper, we begin to address this gap by analyzing 10M posts by 5.5K Twitter and Reddit users identified as Russian and Iranian state-sponsored trolls. We compare the behavior of each group of state-sponsored trolls with a focus on how their strategies change over time, the different campaigns they embark on, and differences between the trolls operated by Russia and Iran. Among other things, we find: 1) that Russian trolls were pro-Trump while Iranian trolls were anti-Trump; 2) evidence that campaigns undertaken by such actors are influenced by real-world events; and 3) that the behavior of such actors is not consistent over time, hence detection is not straightforward. Using Hawkes Processes, we quantify the influence these accounts have on pushing URLs on four platforms: Twitter, Reddit, 4chan's Politically Incorrect board (/pol/), and Gab. In general, Russian trolls were more influential and efficient in pushing URLs to all the other platforms with the exception of /pol/ where Iranians were more influential. Finally, we release our source code to ensure the reproducibility of our results and to encourage other researchers to work on understanding other emerging kinds of state-sponsored troll accounts on Twitter."
GIANLUCA STRINGHINI,Pythia: a framework for the automated analysis of web hosting environments,"A common approach when setting up a website is to utilize third party Web hosting and content delivery networks. Without taking this trend into account, any measurement study inspecting the deployment and operation of websites can be heavily skewed. Unfortunately, the research community lacks generalizable tools that can be used to identify how and where a given website is hosted. Instead, a number of ad hoc techniques have emerged, e.g., using Autonomous System databases, domain prefixes for CNAME records. In this work we propose Pythia, a novel lightweight approach for identifying Web content hosted on third-party infrastructures, including both traditional Web hosts and content delivery networks. Our framework identifies the organization to which a given Web page belongs, and it detects which Web servers are self-hosted and which ones leverage third-party services to provide contents. To test our framework we run it on 40,000 URLs and evaluate its accuracy, both by comparing the results with similar services and with a manually validated groundtruth. Our tool achieves an accuracy of 90% and detects that under 11% of popular domains are self-hosted. We publicly release our tool to allow other researchers to reproduce our findings, and to apply it to their own studies."
GIANLUCA STRINGHINI,Master of puppets: analyzing and attacking a botnet for fun and profit,"A botnet is a network of compromised machines (bots), under the control of an attacker. Many of these machines are infected without their owners’ knowledge, and botnets are the driving force behind several misuses and criminal activities on the Internet (for example spam emails). Depending on its topology, a botnet can have zero or more command and control (C&C) servers, which are centralized machines controlled by the cybercriminal that issue commands and receive reports back from the co-opted bots. In this paper, we present a comprehensive analysis of the command and control infrastructure of one of the world’s largest proprietary spamming botnets between 2007 and 2012: Cutwail/Pushdo. We identify the key functionalities needed by a spamming botnet to operate effectively. We then develop a number of attacks against the command and control logic of Cutwail that target those functionalities, and make the spamming operations of the botnet less effective. This analysis was made possible by having access to the source code of the C&C software, as well as setting up our own Cutwail C&C server, and by implementing a clone of the Cutwail bot. With the help of this tool, we were able to enumerate the number of bots currently registered with the C&C server, impersonate an existing bot to report false information to the C&C server, and manipulate spamming statistics of an arbitrary bot stored in the C&C database. Furthermore, we were able to make the control server inaccessible by conducting a distributed denial of service (DDoS) attack. Our results may be used by law enforcement and practitioners to develop better techniques to mitigate and cripple other botnets, since many of findings are generic and are due to the workflow of C&C communication in general."
GIANLUCA STRINGHINI,LOBO - evaluation of generalization deficiencies in Twitter bot classifiers,"Botnets in online social networks are increasingly often affecting the regular flow of discussion, attacking regular users and their posts, spamming them with irrelevant or offensive content, and even manipulating the popularity of messages and accounts. Researchers and cybercriminals are involved in an arms race, and new and updated botnets designed to defeat current detection systems are constantly developed, rendering such detection systems obsolete. In this paper, we motivate the need for a generalized evaluation in Twitter bot detection and propose a methodology to evaluate bot classifiers by testing them on unseen bot classes. We show that this methodology is empirically robust, using bot classes of varying sizes and characteristics and reaching similar results, and argue that methods trained and tested on single bot classes or datasets might not able to generalize to new bot classes. We train one such classifier on over 200,000 data points and show that it achieves over 97% accuracy. The data used to train and test this classifier includes some of the largest and most varied collections of bots used in literature. We then test this theoretically sound classifier using our methodology, highlighting that it does not generalize well to unseen bot classes. Finally, we discuss the implications of our results, and reasons why some bot classes are easier and faster to detect than others."
GIANLUCA STRINGHINI,The web centipede: understanding how web communities influence each other through the lens of mainstream and alternative news sources,"As the number and the diversity of news outlets on the Web grows, so does the opportunity for ""alternative"" sources of information to emerge. Using large social networks like Twitter and Facebook, misleading, false, or agenda-driven information can quickly and seamlessly spread online, deceiving people or influencing their opinions. Also, the increased engagement of tightly knit communities, such as Reddit and 4chan, further compounds the problem, as their users initiate and propagate alternative information, not only within their own communities, but also to different ones as well as various social media. In fact, these platforms have become an important piece of the modern information ecosystem, which, thus far, has not been studied as a whole. In this paper, we begin to fill this gap by studying mainstream and alternative news shared on Twitter, Reddit, and 4chan. By analyzing millions of posts around several axes, we measure how mainstream and alternative news flows between these platforms. Our results indicate that alt-right communities within 4chan and Reddit can have a surprising level of influence on Twitter, providing evidence that ""fringe"" communities often succeed in spreading alternative news to mainstream social networks and the greater Web."
GIANLUCA STRINGHINI,“You know what to do”: Proactive detection of YouTube videos targeted by coordinated hate attacks,"Video sharing platforms like YouTube are increasingly targeted by aggression and hate attacks. Prior work has shown how these attacks often take place as a result of “raids,” i.e., organized efforts by ad-hoc mobs coordinating from third party communities. Despite the increasing relevance of this phenomenon, however, online services often lack effective countermeasures to mitigate it. Unlike well-studied problems like spam and phishing, coordinated aggressive behavior both targets and is perpetrated by humans, making defense mechanisms that look for automated activity unsuitable. Therefore, the de-facto solution is to reactively rely on user reports and human moderation. In this paper, we propose an automated solution to identify YouTube videos that are likely to be targeted by coordinated harassers from fringe communities like 4chan. First, we characterize and model YouTube videos along several axes (metadata, audio transcripts, thumbnails) based on a ground truth dataset of videos that were targeted by raids. Then, we use an ensemble of classifiers to determine the likelihood that a video will be raided with very good results (AUC up to 94%). Overall, our work provides an important first step towards deploying proactive systems to detect and mitigate coordinated hate attacks on platforms like YouTube."
GIANLUCA STRINGHINI,A qualitative evaluation of two different law enforcement approaches on dark net markets,"This paper presents the results of a qualitative study on discussions about two major law enforcement interventions against Dark Net Market (DNM) users extracted from relevant Reddit forums. We assess the impact of Operation Hyperion and Operation Bayonet (combined with the closure of the site Hansa) by analyzing posts and comments made by users of two Reddit forums created for the discussion of Dark Net Markets. The operations are compared in terms of the size of the discussions, the consequences recorded, and the opinions shared by forum users. We find that Operation Bayonet generated a higher number of discussions on Reddit, and from the qualitative analysis of such discussions it appears that this operation also had a greater impact on the DNM ecosystem. Index Terms—cybercrime, policy, law enforcement, qualitative, drug markets, dark web"
GIANLUCA STRINGHINI,Master of sheets: A tale of compromised cloud documents,"As of 2014, a fifth of EU citizens relied on cloud accounts to store their documents according to a Eurostat report. Although useful, there are downsides to the use of cloud documents. They often accumulate sensitive information over time, including financial information. This makes them attractive targets to cybercriminals. To understand what happens to compromised cloud documents that contain financial information, we set up 100 fake payroll sheets comprising 1000 fake records of fictional individuals. We populated the sheets with traditional bank payment information, cryptocurrency details, and payment URLs. To lure cybercriminals and other visitors into visiting the sheets, we leaked links pointing to the sheets via paste sites. We collected data from the sheets for a month, during which we observed 235 accesses across 98 sheets. Two sheets were not opened. We also recorded 38 modifications in 7 sheets. We present detailed measurements and analysis of accesses, modifications, edits, and devices that visited payment URLs in the sheets. Contrary to our expectations, bank payment URLs received many more clicks than cryptocurrency payment URLs despite the popularity of cryptocurrencies and emerging blockchain technologies. On the other hand, sheets that contained cryptocurrency details recorded more modifications than sheets that contained traditional banking information. In summary, we present a comprehensive picture of what happens to compromised cloud spreadsheets."
GIANLUCA STRINGHINI,Adversarial behaviours knowledge area,"The technological advancements witnessed by our society in recent decades have brought improvements in our quality of life, but they have also created a number of opportunities for attackers to cause harm. Before the Internet revolution, most crime and malicious activity generally required a victim and a perpetrator to come into physical contact, and this limited the reach that malicious parties had. Technology has removed the need for physical contact to perform many types of crime, and now attackers can reach victims anywhere in the world, as long as they are connected to the Internet. This has revolutionised the characteristics of crime and warfare, allowing operations that would not have been possible before. In this document, we provide an overview of the malicious operations that are happening on the Internet today. We first provide a taxonomy of malicious activities based on the attacker’s motivations and capabilities, and then move on to the technological and human elements that adversaries require to run a successful operation. We then discuss a number of frameworks that have been proposed to model malicious operations. Since adversarial behaviours are not a purely technical topic, we draw from research in a number of fields (computer science, criminology, war studies). While doing this, we discuss how these frameworks can be used by researchers and practitioners to develop effective mitigations against malicious online operations."
GIANLUCA STRINGHINI,Attack2vec: Leveraging temporal word embeddings to understand the evolution of cyberattacks,"Despite the fact that cyberattacks are constantly growing in complexity, the research community still lacks effective tools to easily monitor and understand them. In particular, there is a need for techniques that are able to not only track how prominently certain malicious actions, such as the exploitation of specific vulnerabilities, are exploited in the wild, but also (and more importantly) how these malicious actions factor in as attack steps in more complex cyberattacks. In this paper we present ATTACK2VEC, a system that uses temporal word embeddings to model how attack steps are exploited in the wild, and track how they evolve. We test ATTACK2VEC on a dataset of billions of security events collected from the customers of a commercial Intrusion Prevention System over a period of two years, and show that our approach is effective in monitoring the emergence of new attack strategies in the wild and in flagging which attack steps are often used together by attackers (e.g., vulnerabilities that are frequently exploited together). ATTACK2VEC provides a useful tool for researchers and practitioners to better understand cyberattacks and their evolution, and use this knowledge to improve situational awareness and develop proactive defenses."
GIANLUCA STRINGHINI,A human-centered systematic literature review of the computational approaches for online sexual risk detection,"In the era of big data and artificial intelligence, online risk detection has become a popular research topic. From detecting online harassment to the sexual predation of youth, the state-of-the-art in computational risk detection has the potential to protect particularly vulnerable populations from online victimization. Yet, this is a high-risk, high-reward endeavor that requires a systematic and human-centered approach to synthesize disparate bodies of research across different application domains, so that we can identify best practices, potential gaps, and set a strategic research agenda for leveraging these approaches in a way that betters society. Therefore, we conducted a comprehensive literature review to analyze 73 peer-reviewed articles on computational approaches utilizing text or meta-data/multimedia for online sexual risk detection. We identified sexual grooming (75%), sex trafficking (12%), and sexual harassment and/or abuse (12%) as the three types of sexual risk detection present in the extant literature. Furthermore, we found that the majority (93%) of this work has focused on identifying sexual predators after-the-fact, rather than taking more nuanced approaches to identify potential victims and problematic patterns that could be used to prevent victimization before it occurs. Many studies rely on public datasets (82%) and third-party annotators (33%) to establish ground truth and train their algorithms. Finally, the majority of this work (78%) mostly focused on algorithmic performance evaluation of their model and rarely (4%) evaluate these systems with real users. Thus, we urge computational risk detection researchers to integrate more human-centered approaches to both developing and evaluating sexual risk detection algorithms to ensure the broader societal impacts of this important work."
GIANLUCA STRINGHINI,A multi-platform analysis of political news discussion and sharing on web communities,"The news ecosystem encompasses a wide range of sources with varying levels of trustworthiness, and with public commentary giving different spins to the same stories. In this paper, we present a measurement pipeline able to identify news articles that discuss the same story and trace how they are shared on multiple online communities. We compile a list of 1,073 news websites and extract posts from four Web communities (Twitter, Reddit, 4chan, and Gab) that contain URLs from these sources. This yields a dataset of 38M posts containing 15.6M unique news URLs, spanning almost three years. We study the data along several axes, assessing the trustworthiness of shared news stories, analyzing how they are discussed, and measuring the influence various Web communities have in that. Our analysis shows that different communities discuss different types of news, with polarized communities like Gab and /r/The_Donald subreddit disproportionately referencing untrustworthy sources. We also find that fringe communities often have a disproportionate influence on other platforms w .r.t. pushing narratives around certain news, for example, about political elections, immigration, or foreign policy. In fact, fringe communities are seemingly successful in influencing the discussion on false narratives about news events on mainstream social networks."
GIANLUCA STRINGHINI,"""How over is it?"" Understanding the Incel Community on YouTube","YouTube is by far the largest host of user-generated video content worldwide. Alas, the platform has also come under fire for hosting inappropriate, toxic, and hateful content. One community that has often been linked to sharing and publishing hateful and misogynistic content are the Involuntary Celibates (Incels), a loosely defined movement ostensibly focusing on men's issues. In this paper, we set out to analyze the Incel community on YouTube by focusing on this community's evolution over the last decade and understanding whether YouTube's recommendation algorithm steers users towards Incel-related videos. We collect videos shared on Incel communities within Reddit and perform a data-driven characterization of the content posted on YouTube. Among other things, we find that the Incel community on YouTube is getting traction and that, during the last decade, the number of Incel-related videos and comments rose substantially. We also find that users have a 6.3% chance of being suggested an Incel-related video by YouTube's recommendation algorithm within five hops when starting from a non Incel-related video. Overall, our findings paint an alarming picture of online radicalization: not only Incel activity is increasing over time, but platforms may also play an active role in steering users towards such extreme content."
GIANLUCA STRINGHINI,Characterizing the use of images by state-sponsored troll accounts on Twitter,"State-sponsored organizations are increasingly linked to efforts aimed to exploit social media for information warfare and manipulating public opinion. Typically, their activities rely on a number of social network accounts they control, aka trolls, that post and interact with other users disguised as “regular” users. These accounts often use images and memes, along with textual content, in order to increase the engagement and the credibility of their posts. In this paper, we present the first study of images shared by state-sponsored accounts by analyzing a ground truth dataset of 1.8M images posted to Twitter by accounts controlled by the Russian Internet Research Agency. First, we analyze the content of the images as well as their posting activity. Then, using Hawkes Processes, we quantify their influence on popular Web communities like Twitter, Reddit, 4chan’s Politically Incorrect board (/pol/), and Gab, with respect to the dissemination of images. We find that the extensive image posting activity of Russian trolls coincides with real-world events (e.g., the Unite the Right rally in Charlottesville), and shed light on their targets as well as the content disseminated via images. Finally, we show that the trolls were more effective in disseminating politics-related imagery than other images."
GIANLUCA STRINGHINI,BOTection: bot detection by building Markov Chain models of bots network behavior,"Botnets continue to be a threat to organizations, thus various machine learning-based botnet detectors have been proposed. However, the capability of such systems in detecting new or unseen botnets is crucial to ensure its robustness against the rapid evolution of botnets. Moreover, it prolongs the effectiveness of the system in detecting bots, avoiding frequent and time-consuming classifier re-training. We present BOTection, a privacy-preserving bot detection system that models the bot network flow behavior as a Markov Chain. The Markov Chain state transitions capture the bots' network behavior using high-level flow features as states, producing content-agnostic and encryption resilient behavioral features. These features are used to train a classifier to first detect flows produced by bots, and then identify their bot families. We evaluate our system on a dataset of over 7M malicious flows from 12 botnet families, showing its capability of detecting bots' network traffic with 99.78% F-measure and classifying it to a malware family with a 99.09% F-measure. Notably, due to the modeling of general bot network behavior by the Markov Chains, BOTection can detect traffic belonging to unseen bot families with an F-measure of 93.03% making it robust against malware evolution."
GIANLUCA STRINGHINI,Lambretta: learning to rank for Twitter soft moderation,
GIANLUCA STRINGHINI,Raiders of the lost Kek: 3.5 years of augmented 4chan posts from the politically incorrect board,"This paper presents a dataset with over 3.3M threads and 134.5M posts from the Politically Incorrect board (/pol/) of the imageboard forum 4chan, posted over a period of almost 3.5 years (June 2016–November 2019). To the best of our knowledge, this represents the largest publicly available 4chan dataset, providing the community with an archive of posts that have been permanently deleted from 4chan and are otherwise inaccessible. We augment the data with a set of additional labels, including toxicity scores and the named entities mentioned in each post. We also present a statistical analysis of the dataset, providing an overview of what researchers interested in using it can expect, as well as a simple content analysis, shedding light on the most prominent discussion topics, the most popular entities mentioned, and the toxicity level of each post. Overall, we are confident that our work will motivate and assist researchers in studying and understanding 4chan, as well as its role on the greater Web. For instance, we hope this dataset may be used for cross-platform studies of social media, as well as being useful for other types of research like natural language processing. Finally, our dataset can assist qualitative work focusing on in-depth case studies of specific narratives, events, or social theories."
GIANLUCA STRINGHINI,Who watches the watchmen: exploring complaints on the web,"Under increasing scrutiny, many web companies now offer bespoke mechanisms allowing any third party to file complaints (e.g., requesting the de-listing of a URL from a search engine). While this self-regulation might be a valuable web governance tool, it places huge responsibility within the hands of these organisations that demands close examination. We present the first large-scale study of web complaints (over 1 billion URLs). We find a range of complainants, largely focused on copyright enforcement. Whereas the majority of organisations are occasional users of the complaint system, we find a number of bulk senders specialised in targeting specific types of domain. We identify a series of trends and patterns amongst both the domains and complainants. By inspecting the availability of the domains, we also observe that a sizeable portion go offline shortly after complaints are generated. This paper sheds critical light on how complaints are issued, who they pertain to and which domains go offline after complaints are issued."
GIANLUCA STRINGHINI,BORDERPATROL: securing BYOD using fine-grained contextual information,"Companies adopt Bring Your Own Device (BYOD) policies extensively, for both convenience and cost management. The compelling way of putting private and business related applications (apps) on the same device leads to the widespread usage of employee owned devices to access sensitive company data and services. Such practices create a security risk as a legitimate app may send business-sensitive data to third party servers through detrimental app functions or packaged libraries. In this paper, we propose BORDERPATROL, a system for extracting contextual data that businesses can leverage to enforce access control in BYOD-enabled corporate networks through fine-grained policies. BORDERPATROL extracts contextual information, which is the stack trace of the app function that generated the network traffic, on provisioned user devices and transfers this data in IP headers to enforce desired policies at network routers. BORDERPATROL provides a way to selectively prevent undesired functionalities, such as analytics activities or advertisements, and help enforce information dissemination policies of the company while leaving other functions of the app intact. Using 2,000 apps,we demonstrate that BORDERPATROL is effective in preventing packets which originate from previously identified analytics and advertisement libraries from leaving the network premises. In addition, we show BORDERPATROL’s capability in selectively preventing undesirable app functions using case studies."
GIANLUCA STRINGHINI,Detecting cyberbullying and cyberaggression in social media,"Cyberbullying and cyberaggression are increasingly worrisome phenomena affecting people across all demographics.More than half of young social media users worldwide have been exposed to such prolonged and/or coordinated digital harassment. Victims can experience a wide range of emotions, with negative consequences such as embarrassment, depression, isolation from other community members, which embed the risk to lead to even more critical consequences, such as suicide attempts. In this work, we take the first concrete steps to understand the characteristics of abusive behavior in Twitter, one of today’s largest social media platforms. We analyze 1.2 million users and 2.1 million tweets, comparing users participating in discussions around seemingly normal topics like the NBA, to those more likely to be hate-related, such as the Gamergate controversy, or the gender pay inequality at the BBC station. We also explore specific manifestations of abusive behavior, i.e., cyberbullying and cyberaggression, in one of the hate-related communities (Gamergate). We present a robust methodology to distinguish bullies and aggressors from normal Twitter users by considering text, user, and network-based attributes. Using various state-of-the-art machine learning algorithms, we classify these accounts with over 90% accuracy and AUC. Finally, we discuss the current status of Twitter user accounts marked as abusive by our methodology, and study the performance of potential mechanisms that can be used by Twitter to suspend users in the future."
GIANLUCA STRINGHINI,Automatically dismantling online dating fraud,"Online romance scams are a prevalent form of mass-marketing fraud in the West, and yet few studies have addressed the technical or data-driven responses to this problem. In this type of scam, fraudsters craft fake profiles and manually interact with their victims. Because of the characteristics of this type of fraud and of how dating sites operate, traditional detection methods (e.g., those used in spam filtering) are ineffective. In this paper, we present the results of a multi-pronged investigation into the archetype of online dating profiles used in this form of fraud, including their use of demographics, profile descriptions, and images, shedding light on both the strategies deployed by scammers to appeal to victims and the traits of victims themselves. Further, in response to the severe financial and psychological harm caused by dating fraud, we develop a system to detect romance scammers on online dating platforms. Our work presents the first system for automatically detecting this fraud. Our aim is to provide an early detection system to stop romance scammers as they create fraudulent profiles or before they engage with potential victims. Previous research has indicated that the victims of romance scams score highly on scales for idealized romantic beliefs. We combine a range of structured, unstructured, and deep-learned features that capture these beliefs. No prior work has fully analyzed whether these notions of romance introduce traits that could be leveraged to build a detection system. Our ensemble machine-learning approach is robust to the omission of profile details and performs at high accuracy (97%). The system enables development of automated tools for dating site providers and individual users"
GIANLUCA STRINGHINI,Tiresias: predicting security events through deep learning,"With the increased complexity of modern computer attacks, there is a need for defenders not only to detect malicious activity as it happens, but also to predict the specific steps that will be taken by an adversary when performing an attack. However this is still an open research problem, and previous research in predicting malicious events only looked at binary outcomes (eg. whether an attack would happen or not), but not at the specific steps that an attacker would undertake. To fill this gap we present Tiresias xspace, a system that leverages Recurrent Neural Networks (RNNs) to predict future events on a machine, based on previous observations. We test Tiresias xspace on a dataset of 3.4 billion security events collected from a commercial intrusion prevention system, and show that our approach is effective in predicting the next event that will occur on a machine with a precision of up to 0.93. We also show that the models learned by Tiresias xspace are reasonably stable over time, and provide a mechanism that can identify sudden drops in precision and trigger a retraining of the system. Finally, we show that the long-term memory typical of RNNs is key in performing event prediction, rendering simpler methods not up to the task."
GIANLUCA STRINGHINI,Measuring and characterizing hate speech on news websites,"The Web has become the main source for news acquisition. At the same time, news discussion has become more social: users can post comments on news articles or discuss news articles on other platforms like Reddit. These features empower and enable discussions among the users; however, they also act as the medium for the dissemination of toxic discourse and hate speech. The research community lacks a general understanding on what type of content attracts hateful discourse and the possible effects of social networks on the commenting activity on news articles. In this work, we perform a large-scale quantitative analysis of 125M comments posted on 412K news articles over the course of 19 months. We analyze the content of the collected articles and their comments using temporal analysis, user-based analysis, and linguistic analysis, to shed light on what elements attract hateful comments on news articles. We also investigate commenting activity when an article is posted on either 4chan’s Politically Incorrect board (/pol/) or six selected subreddits. We find statistically significant increases in hateful commenting activity around real-world divisive events like the “Unite the Right” rally in Charlottesville and political events like the second and third 2016 US presidential debates. Also, we find that articles that attract a substantial number of hateful comments have different linguistic characteristics when compared to articles that do not attract hateful comments. Furthermore, we observe that the post of a news articles on either /pol/ or the six subreddits is correlated with an increase of (hateful) commenting activity on the news articles."
GIANLUCA STRINGHINI,ANDRuspex: leveraging graph representation learning to predict harmful app installations on mobile devices,"Android's security model severely limits the capabilities of anti-malware software. Unlike commodity anti-malware solutions on desktop systems, their Android counterparts run as sandboxed applications without root privileges and are limited by Android's permission system. As such, PHAs on Android are usually willingly installed by victims, as they come disguised as useful applications with hidden malicious functionality, and are encountered on mobile app stores as suggestions based on the apps that a user previously installed. Users with similar interests and app installation history are likely to be exposed and to decide to install the same PHA. This observation gives us the opportunity to develop predictive approaches that can warn the user about which PHAs they will encounter and potentially be tempted to install in the near future. These approaches could then be used to complement commodity anti-malware solutions, which are focused on post-fact detection, closing the window of opportunity that existing solutions suffer from. In this paper we develop ANDRuspex, a system based on graph representation learning, allowing us to learn latent relationships between user devices and PHAs and leverage them for prediction. We test ANDRuspex on a real world dataset of PHA installations collected by a security company, and show that our approach achieves very high prediction results (up to 0.994 TPR at 0.0001 FPR), while at the same time outperforming alternative baseline methods. We also demonstrate that ANDRuspex is robust and its runtime performance is acceptable for a real world deployment."
GIANLUCA STRINGHINI,"“Go eat a bat, Chang!”: on the emergence of sinophobic behavior on web communities in the face of COVID-19","The outbreak of the COVID-19 pandemic has changed our lives in unprecedented ways. In the face of the projected catastrophic consequences, most countries have enacted social distancing measures in an attempt to limit the spread of the virus. Under these conditions, the Web has become an indispensable medium for information acquisition, communication, and entertainment. At the same time, unfortunately, the Web is being exploited for the dissemination of potentially harmful and disturbing content, such as the spread of conspiracy theories and hateful speech towards specific ethnic groups, in particular towards Chinese people and people of Asian descent since COVID-19 is believed to have originated from China. In this paper, we make a first attempt to study the emergence of Sinophobic behavior on the Web during the outbreak of the COVID-19 pandemic. We collect two large datasets from Twitter and 4chan’s Politically Incorrect board (/pol/) over a time period of approximately five months and analyze them to investigate whether there is a rise or important differences with regard to the dissemination of Sinophobic content. We find that COVID-19 indeed drives the rise of Sinophobia on the Web and that the dissemination of Sinophobic content is a cross-platform phenomenon: it exists on fringe Web communities like /pol/, and to a lesser extent on mainstream ones like Twitter. Using word embeddings over time, we characterize the evolution of Sinophobic slurs on both Twitter and /pol/. Finally, we find interesting differences in the context in which words related to Chinese people are used on the Web before and after the COVID-19 outbreak: on Twitter we observe a shift towards blaming China for the situation, while on /pol/ we find a shift towards using more (and new) Sinophobic slurs."
GIANLUCA STRINGHINI,Do platform migrations compromise content moderation? Evidence from r/The_Donald and r/Incels,"When toxic online communities on mainstream platforms face moderation measures, such as bans, they may migrate to other platforms with laxer policies or set up their own dedicated websites. Previous work suggests that within mainstream platforms, community-level moderation is effective in mitigating the harm caused by the moderated communities. It is, however, unclear whether these results also hold when considering the broader Web ecosystem. Do toxic communities continue to grow in terms of their user base and activity on the new platforms? Do their members become more toxic and ideologically radicalized? In this paper, we report the results of a large-scale observational study of how problematic online communities progress following community-level moderation measures. We analyze data from r/The_Donald and r/Incels, two communities that were banned from Reddit and subsequently migrated to their own standalone websites. Our results suggest that, in both cases, moderation measures significantly decreased posting activity on the new platform, reducing the number of posts, active users, and newcomers. In spite of that, users in one of the studied communities (r/The_Donald) showed increases in signals associated with toxicity and radicalization, which justifies concerns that the reduction in activity may come at the expense of a more toxic and radical community. Overall, our results paint a nuanced portrait of the consequences of community-level moderation and can inform their design and deployment."
GIANLUCA STRINGHINI,AppJitsu: investigating the resiliency of Android applications,"The Android platform gives mobile device users the opportunity to extend the capabilities of their systems by installing developer-authored apps. Companies leverage this capability to reach their customers and conduct business operations such as financial transactions. End-users can obtain custom Android applications (apps) from the Google Play, some of which are security-sensitive due to the nature of the data that they handle, such as apps from the FINANCE category. Although there are recommendations and standardized guidelines for secure app development with various self-defense techniques, the adoption of such methods is not mandatory and is left to the discretion of developers. Unfortunately, malicious actors can tamper with the app runtime environment and then exploit the attack vectors which arise from the tampering, such as executing foreign code with elevated privileges on the mobile platform. In this paper, we present AppJITSU, a dynamic app analysis framework that evaluates the resiliency of security-critical apps. We exercise the most popular 455 financial apps in attack-specific hostile environments to demonstrate the current state of resiliency against known tampering methods. Our results indicate that 25.05% of the tested apps have no resiliency against any common hostile methods or tools, whereas only 10.77% employed all defensive methods."
GIANLUCA STRINGHINI,SocialHEISTing: understanding stolen Facebook accounts,"Online social network (OSN) accounts are often more usercentric than other types of online accounts (e.g., email accounts) because they present a number of demographic attributes such as age, gender, location, and occupation. While these attributes allow for more meaningful online interactions, they can also be used by malicious parties to craft various types of abuse. To understand the effects of demographic attributes on attacker behavior in stolen social accounts, we devised a method to instrument and monitor such accounts. We then created, instrumented, and deployed more than 1000 Facebook accounts, and exposed them to criminals. Our results confirm that victim demographic traits indeed influence the way cybercriminals abuse their accounts. For example, we find that cybercriminals that access teen accounts write messages and posts more than the ones accessing adult accounts, and attackers that compromise male accounts perform disruptive activities such as changing some of their profile information more than the ones that access female accounts. This knowledge could potentially help online services develop new models to characterize benign and malicious activity across various demographic attributes, and thus automatically classify future activity."
GIANLUCA STRINGHINI,"""I'm a professor, which isn't usually a dangerous job"": Internet-facilitated harassment and its impact on researchers","While the Internet has dramatically increased the exposure that research can receive, it has also facilitated harassment against scholars. To understand the impact that these attacks can have on the work of researchers, we perform a series of systematic interviews with researchers including academics, journalists, and activists, who have experienced targeted, Internet-facilitated harassment. We provide a framework for understanding the types of harassers that target researchers, the harassment that ensues, and the personal and professional impact on individuals and academic freedom. We then study preventative and remedial strategies available, and the institutions that prevent some of these strategies from being more effective. Finally, we discuss the ethical structures that could facilitate more equitable access to participating in research without serious personal suffering."
GIANLUCA STRINGHINI,Marked for disruption: tracing the evolution of malware delivery operations targeted for takedown,"The malware and botnet phenomenon is among the most significant threats to cybersecurity today. Consequently, law enforcement agencies, security companies, and researchers are constantly seeking to disrupt these malicious operations through so-called takedown counter-operations. Unfortunately, the success of these takedowns is mixed. Furthermore, very little is understood as to how botnets and malware delivery operations respond to takedown attempts. We present a comprehensive study of three malware delivery operations that were targeted for takedown in 2015–16 using global download metadata provided by Symantec. In summary, we found that: (1) Distributed delivery architectures were commonly used, indicating the need for better security hygiene and coordination by the (ab)used service providers. (2) A minority of malware binaries were responsible for the majority of download activity, suggesting that detecting these “super binaries” would yield the most benefit to the security community. (3) The malware operations exhibited displacing and defiant behaviours following their respective takedown attempts. We argue that these “predictable” behaviours could be factored into future takedown strategies. (4) The malware operations also exhibited previously undocumented behaviours, such as Dridex dropping competing brands of malware, or Dorkbot and Upatre heavily relying on upstream dropper malware. These “unpredictable” behaviours indicate the need for researchers to use better threat-monitoring techniques."
GIANLUCA STRINGHINI,TUBERAIDER: attributing coordinated hate attacks on YouTube videos to their source communities,
GIANLUCA STRINGHINI,"SoK: content moderation in social media, from guidelines to enforcement, and research to practice",
GIANLUCA STRINGHINI,Disturbed YouTube for kids: characterizing and detecting inappropriate videos targeting young children,"A large number of the most-subscribed YouTube channels target children of very young age. Hundreds of toddler-oriented channels on YouTube feature inoffensive, well produced, and educational videos. Unfortunately, inappropriate content that targets this demographic is also common. YouTube’s algorithmic recommendation system regrettably suggests inappropriate content because some of it mimics or is derived from otherwise appropriate content. Considering the risk for early childhood development, and an increasing trend in toddler’s consumption of YouTube media, this is a worrisome problem. In this work, we build a classifier able to discern inappropriate content that targets toddlers on YouTube with 84:3% accuracy, and leverage it to perform a first-of-its-kind, large-scale, quantitative characterization that reveals some of the risks of YouTube media consumption by young children. Our analysis reveals that YouTube is still plagued by such disturbing videos and its currently deployed counter-measures are ineffective in terms of detecting them in a timely manner. Alarmingly, using our classifier we show that young children are not only able, but likely to encounter disturbing videos when they randomly browse the platform starting from benign videos."
GIANLUCA STRINGHINI,Beyond fish and bicycles: exploring the varieties of online women’s ideological spaces,
GREGORY H. WILLIAMS,Labour in a single shot: critical perspectives on Antje Ehmann and Harun Farocki's global video project,"This collection of essays offers a critical assessment of Labour in a Single Shot, a groundbreaking documentary video workshop. From 2011 to 2014, curator Antje Ehmann and film- and videomaker Harun Farocki produced an art project of truly global proportions. They travelled to fifteen cities around the world to conduct workshops inspired by cinema history’s first film, Workers Leaving the Lumière Factory, shot in 1895 by the Lumière brothers in France. While the workshop videos are in colour and the camera was not required to remain static, Ehmann and Farocki’s students were tasked with honouring the original Lumière film’s basic parameters of theme and style. The fascinating result is a collection of more than 550 short videos that have appeared in international exhibitions and on an open-access website, offering the widest possible audience the opportunity to ponder contemporary labour in multiple contexts around the world."
GREGORY H. WILLIAMS,First M87 Event Horizon Telescope results. IV. Imaging the central supermassive black hole,
GREGORY H. WILLIAMS,First Sagittarius A* Event Horizon Telescope results. V. Testing astrophysical models of the galactic center black hole,"In this paper we provide a first physical interpretation for the Event Horizon Telescope's (EHT) 2017 observations of Sgr A*. Our main approach is to compare resolved EHT data at 230 GHz and unresolved non-EHT observations from radio to X-ray wavelengths to predictions from a library of models based on time-dependent general relativistic magnetohydrodynamics simulations, including aligned, tilted, and stellar-wind-fed simulations; radiative transfer is performed assuming both thermal and nonthermal electron distribution functions. We test the models against 11 constraints drawn from EHT 230 GHz data and observations at 86 GHz, 2.2 μm, and in the X-ray. All models fail at least one constraint. Light-curve variability provides a particularly severe constraint, failing nearly all strongly magnetized (magnetically arrested disk (MAD)) models and a large fraction of weakly magnetized models. A number of models fail only the variability constraints. We identify a promising cluster of these models, which are MAD and have inclination i ≤ 30°. They have accretion rate (5.2–9.5) × 10−9 M ⊙ yr−1, bolometric luminosity (6.8–9.2) × 1035 erg s−1, and outflow power (1.3–4.8) × 1038 erg s−1. We also find that all models with i ≥ 70° fail at least two constraints, as do all models with equal ion and electron temperature; exploratory, nonthermal model sets tend to have higher 2.2 μm flux density; and the population of cold electrons is limited by X-ray constraints due to the risk of bremsstrahlung overproduction. Finally, we discuss physical and numerical limitations of the models, highlighting the possible importance of kinetic effects and duration of the simulations."
GREGORY H. WILLIAMS,First M87 Event Horizon Telescope results. VII. Polarization of the ring,"In 2017 April, the Event Horizon Telescope (EHT) observed the near-horizon region around the supermassive black hole at the core of the M87 galaxy. These 1.3 mm wavelength observations revealed a compact asymmetric ring-like source morphology. This structure originates from synchrotron emission produced by relativistic plasma located in the immediate vicinity of the black hole. Here we present the corresponding linear-polarimetric EHT images of the center of M87. We find that only a part of the ring is significantly polarized. The resolved fractional linear polarization has a maximum located in the southwest part of the ring, where it rises to the level of ∼15%. The polarization position angles are arranged in a nearly azimuthal pattern. We perform quantitative measurements of relevant polarimetric properties of the compact emission and find evidence for the temporal evolution of the polarized source structure over one week of EHT observations. The details of the polarimetric data reduction and calibration methodology are provided. We carry out the data analysis using multiple independent imaging and modeling techniques, each of which is validated against a suite of synthetic data sets. The gross polarimetric structure and its apparent evolution with time are insensitive to the method used to reconstruct the image. These polarimetric images carry information about the structure of the magnetic fields responsible for the synchrotron emission. Their physical interpretation is discussed in an accompanying publication."
GREGORY H. WILLIAMS,Resolving the inner parsec of the blazar J1924–2914 with the event horizon telescope,"The blazar J1924–2914 is a primary Event Horizon Telescope (EHT) calibrator for the Galactic center’s black hole Sagittarius A*. Here we present the first total and linearly polarized intensity images of this source obtained with the unprecedented 20 μas resolution of the EHT. J1924–2914 is a very compact flat-spectrum radio source with strong optical variability and polarization. In April 2017 the source was observed quasi-simultaneously with the EHT (April 5–11), the Global Millimeter VLBI Array (April 3), and the Very Long Baseline Array (April 28), giving a novel view of the source at four observing frequencies, 230, 86, 8.7, and 2.3 GHz. These observations probe jet properties from the subparsec to 100 pc scales. We combine the multifrequency images of J1924–2914 to study the source morphology. We find that the jet exhibits a characteristic bending, with a gradual clockwise rotation of the jet projected position angle of about 90° between 2.3 and 230 GHz. Linearly polarized intensity images of J1924–2914 with the extremely fine resolution of the EHT provide evidence for ordered toroidal magnetic fields in the blazar compact core."
GREGORY H. WILLIAMS,A universal power-law prescription for variability from synthetic images of black hole accretion flows,"We present a framework for characterizing the spatiotemporal power spectrum of the variability expected from the horizon-scale emission structure around supermassive black holes, and we apply this framework to a library of general relativistic magnetohydrodynamic (GRMHD) simulations and associated general relativistic ray-traced images relevant for Event Horizon Telescope (EHT) observations of Sgr A*. We find that the variability power spectrum is generically a red-noise process in both the temporal and spatial dimensions, with the peak in power occurring on the longest timescales and largest spatial scales. When both the time-averaged source structure and the spatially integrated light-curve variability are removed, the residual power spectrum exhibits a universal broken power-law behavior. On small spatial frequencies, the residual power spectrum rises as the square of the spatial frequency and is proportional to the variance in the centroid of emission. Beyond some peak in variability power, the residual power spectrum falls as that of the time-averaged source structure, which is similar across simulations; this behavior can be naturally explained if the variability arises from a multiplicative random field that has a steeper high-frequency power-law index than that of the time-averaged source structure. We briefly explore the ability of power spectral variability studies to constrain physical parameters relevant for the GRMHD simulations, which can be scaled to provide predictions for black holes in a range of systems in the optically thin regime. We present specific expectations for the behavior of the M87* and Sgr A* accretion flows as observed by the EHT."
GREGORY H. WILLIAMS,Millimeter light curves of Sagittarius A* observed during the 2017 Event Horizon Telescope campaign,"The Event Horizon Telescope (EHT) observed the compact radio source, Sagittarius A* (Sgr A*), in the Galactic Center on 2017 April 5–11 in the 1.3 mm wavelength band. At the same time, interferometric array data from the Atacama Large Millimeter/submillimeter Array and the Submillimeter Array were collected, providing Sgr A* light curves simultaneous with the EHT observations. These data sets, complementing the EHT very long baseline interferometry, are characterized by a cadence and signal-to-noise ratio previously unattainable for Sgr A* at millimeter wavelengths, and they allow for the investigation of source variability on timescales as short as a minute. While most of the light curves correspond to a low variability state of Sgr A*, the April 11 observations follow an X-ray flare and exhibit strongly enhanced variability. All of the light curves are consistent with a red-noise process, with a power spectral density (PSD) slope measured to be between −2 and −3 on timescales between 1 minute and several hours. Our results indicate a steepening of the PSD slope for timescales shorter than 0.3 hr. The spectral energy distribution is flat at 220 GHz, and there are no time lags between the 213 and 229 GHz frequency bands, suggesting low optical depth for the event horizon scale source. We characterize Sgr A*’s variability, highlighting the different behavior observed just after the X-ray flare, and use Gaussian process modeling to extract a decorrelation timescale and a PSD slope. We also investigate the systematic calibration uncertainties by analyzing data from independent data reduction pipelines."
GREGORY H. WILLIAMS,"Global comedy: humor, irony, biennials",
GREGORY H. WILLIAMS,First Sagittarius A* Event Horizon Telescope results. VI. Testing the black hole metric,"Astrophysical black holes are expected to be described by the Kerr metric. This is the only stationary, vacuum, axisymmetric metric, without electromagnetic charge, that satisfies Einstein’s equations and does not have pathologies outside of the event horizon. We present new constraints on potential deviations from the Kerr prediction based on 2017 EHT observations of Sagittarius A* (Sgr A*). We calibrate the relationship between the geometrically defined black hole shadow and the observed size of the ring-like images using a library that includes both Kerr and non-Kerr simulations. We use the exquisite prior constraints on the mass-to-distance ratio for Sgr A* to show that the observed image size is within ∼10% of the Kerr predictions. We use these bounds to constrain metrics that are parametrically different from Kerr, as well as the charges of several known spacetimes. To consider alternatives to the presence of an event horizon, we explore the possibility that Sgr A* is a compact object with a surface that either absorbs and thermally reemits incident radiation or partially reflects it. Using the observed image size and the broadband spectrum of Sgr A*, we conclude that a thermal surface can be ruled out and a fully reflective one is unlikely. We compare our results to the broader landscape of gravitational tests. Together with the bounds found for stellar-mass black holes and the M87 black hole, our observations provide further support that the external spacetimes of all black holes are described by the Kerr metric, independent of their mass."
GREGORY H. WILLIAMS,Polarimetric properties of Event Horizon Telescope targets from ALMA,"We present the results from a full polarization study carried out with the Atacama Large Millimeter/submillimeter Array (ALMA) during the first Very Long Baseline Interferometry (VLBI) campaign, which was conducted in 2017 April in the λ3 mm and λ1.3 mm bands, in concert with the Global mm-VLBI Array (GMVA) and the Event Horizon Telescope (EHT), respectively. We determine the polarization and Faraday properties of all VLBI targets, including Sgr A*, M87, and a dozen radio-loud active galactic nuclei (AGNs), in the two bands at several epochs in a time window of 10 days. We detect high linear polarization fractions (2%–15%) and large rotation measures (RM &gt; 103.3–105.5 rad m−2), confirming the trends of previous AGN studies at millimeter wavelengths. We find that blazars are more strongly polarized than other AGNs in the sample, while exhibiting (on average) order-of-magnitude lower RM values, consistent with the AGN viewing angle unification scheme. For Sgr A* we report a mean RM of (−4.2 ± 0.3) × 105 rad m−2 at 1.3 mm, consistent with measurements over the past decade and, for the first time, an RM of (–2.1 ± 0.1) × 105 rad m−2 at 3 mm, suggesting that about half of the Faraday rotation at 1.3 mm may occur between the 3 mm photosphere and the 1.3 mm source. We also report the first unambiguous measurement of RM toward the M87 nucleus at millimeter wavelengths, which undergoes significant changes in magnitude and sign reversals on a one year timescale, spanning the range from −1.2 to 0.3 × 105 rad m−2 at 3 mm and −4.1 to 1.5 × 105 rad m−2 at 1.3 mm. Given this time variability, we argue that, unlike the case of Sgr A*, the RM in M87 does not provide an accurate estimate of the mass accretion rate onto the black hole. We put forward a two-component model, comprised of a variable compact region and a static extended region, that can simultaneously explain the polarimetric properties observed by both the EHT (on horizon scales) and ALMA (which observes the combined emission from both components). These measurements provide critical constraints for the calibration, analysis, and interpretation of simultaneously obtained VLBI data with the EHT and GMVA."
GREGORY H. WILLIAMS,"First Sagittarius A* Event Horizon Telescope results. IV. Variability, morphology, and black hole mass","In this paper we quantify the temporal variability and image morphology of the horizon-scale emission from Sgr A*, as observed by the EHT in 2017 April at a wavelength of 1.3 mm. We find that the Sgr A* data exhibit variability that exceeds what can be explained by the uncertainties in the data or by the effects of interstellar scattering. The magnitude of this variability can be a substantial fraction of the correlated flux density, reaching ∼100% on some baselines. Through an exploration of simple geometric source models, we demonstrate that ring-like morphologies provide better fits to the Sgr A* data than do other morphologies with comparable complexity. We develop two strategies for fitting static geometric ring models to the time-variable Sgr A* data; one strategy fits models to short segments of data over which the source is static and averages these independent fits, while the other fits models to the full data set using a parametric model for the structural variability power spectrum around the average source structure. Both geometric modeling and image-domain feature extraction techniques determine the ring diameter to be 51.8 ± 2.3 μas (68% credible intervals), with the ring thickness constrained to have an FWHM between ∼30% and 50% of the ring diameter. To bring the diameter measurements to a common physical scale, we calibrate them using synthetic data generated from GRMHD simulations. This calibration constrains the angular size of the gravitational radius to be 4.8_-0.7^+1.4 μas, which we combine with an independent distance measurement from maser parallaxes to determine the mass of Sgr A* to be 4.0_-0.6^+10^6 M⊙."
GREGORY H. WILLIAMS,"First Sagittarius A* Event Horizon Telescope results. II. EHT and multiwavelength observations, data processing, and calibration","We present Event Horizon Telescope (EHT) 1.3 mm measurements of the radio source located at the position of the supermassive black hole Sagittarius A* (Sgr A*), collected during the 2017 April 5–11 campaign. The observations were carried out with eight facilities at six locations across the globe. Novel calibration methods are employed to account for Sgr A*'s flux variability. The majority of the 1.3 mm emission arises from horizon scales, where intrinsic structural source variability is detected on timescales of minutes to hours. The effects of interstellar scattering on the image and its variability are found to be subdominant to intrinsic source structure. The calibrated visibility amplitudes, particularly the locations of the visibility minima, are broadly consistent with a blurred ring with a diameter of ∼50 μas, as determined in later works in this series. Contemporaneous multiwavelength monitoring of Sgr A* was performed at 22, 43, and 86 GHz and at near-infrared and X-ray wavelengths. Several X-ray flares from Sgr A* are detected by Chandra, one at low significance jointly with Swift on 2017 April 7 and the other at higher significance jointly with NuSTAR on 2017 April 11. The brighter April 11 flare is not observed simultaneously by the EHT but is followed by a significant increase in millimeter flux variability immediately after the X-ray outburst, indicating a likely connection in the emission physics near the event horizon. We compare Sgr A*’s broadband flux during the EHT campaign to its historical spectral energy distribution and find that both the quiescent emission and flare emission are consistent with its long-term behavior."
GREGORY H. WILLIAMS,Broadband multi-wavelength properties of M87 during the 2017 Event Horizon Telescope campaign,"In 2017, the Event Horizon Telescope (EHT) Collaboration succeeded in capturing the first direct image of the center of the M87 galaxy. The asymmetric ring morphology and size are consistent with theoretical expectations for a weakly accreting supermassive black hole of mass ∼6.5 × 109 M ⊙. The EHTC also partnered with several international facilities in space and on the ground, to arrange an extensive, quasi-simultaneous multi-wavelength campaign. This Letter presents the results and analysis of this campaign, as well as the multi-wavelength data as a legacy data repository. We captured M87 in a historically low state, and the core flux dominates over HST-1 at high energies, making it possible to combine core flux constraints with the more spatially precise very long baseline interferometry data. We present the most complete simultaneous multi-wavelength spectrum of the active nucleus to date, and discuss the complexity and caveats of combining data from different spatial scales into one broadband spectrum. We apply two heuristic, isotropic leptonic single-zone models to provide insight into the basic source properties, but conclude that a structured jet is necessary to explain M87’s spectrum. We can exclude that the simultaneous γ-ray emission is produced via inverse Compton emission in the same region producing the EHT mm-band emission, and further conclude that the γ-rays can only be produced in the inner jets (inward of HST-1) if there are strongly particle-dominated regions. Direct synchrotron emission from accelerated protons and secondaries cannot yet be excluded."
GREGORY H. WILLIAMS,Event Horizon Telescope imaging of the archetypal blazar 3C 279 at an extreme 20 microarcsecond resolution,"3C 279 is an archetypal blazar with a prominent radio jet that show broadband flux density variability across the entire electromagnetic spectrum. We use an ultra-high angular resolution technique – global Very Long Baseline Interferometry (VLBI) at 1.3 mm (230 GHz) – to resolve the innermost jet of 3C 279 in order to study its fine-scale morphology close to the jet base where highly variable γ-ray emission is thought to originate, according to various models. The source was observed during four days in April 2017 with the Event Horizon Telescope at 230 GHz, including the phased Atacama Large Millimeter/submillimeter Array (ALMA), at an angular resolution of ∼20 μas (at a redshift of z = 0.536 this corresponds to ∼0.13 pc  ∼ 1700 Schwarzschild radii with a black hole mass M<jats:sub>BH</jats:sub> = 8 × 10^8 M_⊙). Imaging and model-fitting techniques were applied to the data to parameterize the fine-scale source structure and its variation. We find a multicomponent inner jet morphology with the northernmost component elongated perpendicular to the direction of the jet, as imaged at longer wavelengths. The elongated nuclear structure is consistent on all four observing days and across different imaging methods and model-fitting techniques, and therefore appears robust. Owing to its compactness and brightness, we associate the northern nuclear structure as the VLBI “core”. This morphology can be interpreted as either a broad resolved jet base or a spatially bent jet. We also find significant day-to-day variations in the closure phases, which appear most pronounced on the triangles with the longest baselines. Our analysis shows that this variation is related to a systematic change of the source structure. Two inner jet components move non-radially at apparent speeds of ∼15 c and ∼20 c (∼1.3 and ∼1.7 μas day^−1, respectively), which more strongly supports the scenario of traveling shocks or instabilities in a bent, possibly rotating jet. The observed apparent speeds are also coincident with the 3C 279 large-scale jet kinematics observed at longer (cm) wavelengths, suggesting no significant jet acceleration between the 1.3 mm core and the outer jet. The intrinsic brightness temperature of the jet components are ≲10^10 K, a magnitude or more lower than typical values seen at ≥7 mm wavelengths. The low brightness temperature and morphological complexity suggest that the core region of 3C 279 becomes optically thin at short (mm) wavelengths."
GREGORY H. WILLIAMS,First M87 Event Horizon Telescope results. II. Array and instrumentation,"The Event Horizon Telescope (EHT) is a very long baseline interferometry (VLBI) array that comprises millimeter- and submillimeter-wavelength telescopes separated by distances comparable to the diameter of the Earth. At a nominal operating wavelength of ~1.3 mm, EHT angular resolution (λ/D) is ~25 μas, which is sufficient to resolve nearby supermassive black hole candidates on spatial and temporal scales that correspond to their event horizons. With this capability, the EHT scientific goals are to probe general relativistic effects in the strong-field regime and to study accretion and relativistic jet formation near the black hole boundary. In this Letter we describe the system design of the EHT, detail the technology and instrumentation that enable observations, and provide measures of its performance. Meeting the EHT science objectives has required several key developments that have facilitated the robust extension of the VLBI technique to EHT observing wavelengths and the production of instrumentation that can be deployed on a heterogeneous array of existing telescopes and facilities. To meet sensitivity requirements, high-bandwidth digital systems were developed that process data at rates of 64 gigabit s−1, exceeding those of currently operating cm-wavelength VLBI arrays by more than an order of magnitude. Associated improvements include the development of phasing systems at array facilities, new receiver installation at several sites, and the deployment of hydrogen maser frequency standards to ensure coherent data capture across the array. These efforts led to the coordination and execution of the first Global EHT observations in 2017 April, and to event-horizon-scale imaging of the supermassive black hole candidate in M87."
GREGORY H. WILLIAMS,First M87 Event Horizon Telescope results. I. The shadow of the supermassive black hole,"When surrounded by a transparent emission region, black holes are expected to reveal a dark shadow caused by gravitational light bending and photon capture at the event horizon. To image and study this phenomenon, we have assembled the Event Horizon Telescope, a global very long baseline interferometry array observing at a wavelength of 1.3 mm. This allows us to reconstruct event-horizon-scale images of the supermassive black hole candidate in the center of the giant elliptical galaxy M87. We have resolved the central compact radio source as an asymmetric bright emission ring with a diameter of 42 ± 3 μas, which is circular and encompasses a central depression in brightness with a flux ratio gsim10:1. The emission ring is recovered using different calibration and imaging schemes, with its diameter and width remaining stable over four different observations carried out in different days. Overall, the observed image is consistent with expectations for the shadow of a Kerr black hole as predicted by general relativity. The asymmetry in brightness in the ring can be explained in terms of relativistic beaming of the emission from a plasma rotating close to the speed of light around a black hole. We compare our images to an extensive library of ray-traced general-relativistic magnetohydrodynamic simulations of black holes and derive a central mass of M = (6.5 ± 0.7) × 10^9 M ⊙. Our radio-wave observations thus provide powerful evidence for the presence of supermassive black holes in centers of galaxies and as the central engines of active galactic nuclei. They also present a new tool to explore gravity in its most extreme limit and on a mass scale that was so far not accessible."
GREGORY H. WILLIAMS,First Sagittarius A* Event Horizon Telescope results. III. Imaging of the Galactic center supermassive black hole,"We present the first event-horizon-scale images and spatiotemporal analysis of Sgr A* taken with the Event Horizon Telescope in 2017 April at a wavelength of 1.3 mm. Imaging of Sgr A* has been conducted through surveys over a wide range of imaging assumptions using the classical CLEAN algorithm, regularized maximum likelihood methods, and a Bayesian posterior sampling method. Different prescriptions have been used to account for scattering effects by the interstellar medium toward the Galactic center. Mitigation of the rapid intraday variability that characterizes Sgr A* has been carried out through the addition of a “variability noise budget” in the observed visibilities, facilitating the reconstruction of static full-track images. Our static reconstructions of Sgr A* can be clustered into four representative morphologies that correspond to ring images with three different azimuthal brightness distributions and a small cluster that contains diverse nonring morphologies. Based on our extensive analysis of the effects of sparse (u, v)-coverage, source variability, and interstellar scattering, as well as studies of simulated visibility data, we conclude that the Event Horizon Telescope Sgr A* data show compelling evidence for an image that is dominated by a bright ring of emission with a ring diameter of ∼50 μas, consistent with the expected “shadow” of a 4 × 106 M⊙ black hole in the Galactic center located at a distance of 8 kpc."
GREGORY H. WILLIAMS,Characterizing and mitigating intraday variability: reconstructing source structure in accreting black holes with mm-VLBI,"The extraordinary physical resolution afforded by the Event Horizon Telescope has opened a window onto the astrophysical phenomena unfolding on horizon scales in two known black holes, M87* and Sgr A*. However, with this leap in resolution has come a new set of practical complications. Sgr A* exhibits intraday variability that violates the assumptions underlying Earth aperture synthesis, limiting traditional image reconstruction methods to short timescales and data sets with very sparse (u, v) coverage. We present a new set of tools to detect and mitigate this variability. We develop a data-driven, model-agnostic procedure to detect and characterize the spatial structure of intraday variability. This method is calibrated against a large set of mock data sets, producing an empirical estimator of the spatial power spectrum of the brightness fluctuations. We present a novel Bayesian noise modeling algorithm that simultaneously reconstructs an average image and statistical measure of the fluctuations about it using a parameterized form for the excess variance in the complex visibilities not otherwise explained by the statistical errors. These methods are validated using a variety of simulated data, including general relativistic magnetohydrodynamic simulations appropriate for Sgr A* and M87*. We find that the reconstructed source structure and variability are robust to changes in the underlying image model. We apply these methods to the 2017 EHT observations of M87*, finding evidence for variability across the EHT observing campaign. The variability mitigation strategies presented are widely applicable to very long baseline interferometry observations of variable sources generally, for which they provide a data-informed averaging procedure and natural characterization of inter-epoch image consistency."
GREGORY H. WILLIAMS,First Sagittarius A* Event Horizon Telescope results. I. The shadow of the supermassive black hole in the center of the Milky Way,"We present the first Event Horizon Telescope (EHT) observations of Sagittarius A* (Sgr A*), the Galactic center source associated with a supermassive black hole. These observations were conducted in 2017 using a global interferometric array of eight telescopes operating at a wavelength of λ = 1.3 mm. The EHT data resolve a compact emission region with intrahour variability. A variety of imaging and modeling analyses all support an image that is dominated by a bright, thick ring with a diameter of 51.8 ± 2.3 μas (68% credible interval). The ring has modest azimuthal brightness asymmetry and a comparatively dim interior. Using a large suite of numerical simulations, we demonstrate that the EHT images of Sgr A* are consistent with the expected appearance of a Kerr black hole with mass ∼4 × 106 M ⊙, which is inferred to exist at this location based on previous infrared observations of individual stellar orbits, as well as maser proper-motion studies. Our model comparisons disfavor scenarios where the black hole is viewed at high inclination (i &gt; 50°), as well as nonspinning black holes and those with retrograde accretion disks. Our results provide direct evidence for the presence of a supermassive black hole at the center of the Milky Way, and for the first time we connect the predictions from dynamical measurements of stellar orbits on scales of 103–105 gravitational radii to event-horizon-scale images and variability. Furthermore, a comparison with the EHT results for the supermassive black hole M87* shows consistency with the predictions of general relativity spanning over three orders of magnitude in central mass."
GREGORY H. WILLIAMS,The long-baseline neutrino experiment: exploring fundamental symmetries of the universe,"The preponderance of matter over antimatter in the early Universe, the dynamics of the supernova bursts that produced the heavy elements necessary for life and whether protons eventually decay --- these mysteries at the forefront of particle physics and astrophysics are key to understanding the early evolution of our Universe, its current state and its eventual fate. The Long-Baseline Neutrino Experiment (LBNE) represents an extensively developed plan for a world-class experiment dedicated to addressing these questions. LBNE is conceived around three central components: (1) a new, high-intensity neutrino source generated from a megawatt-class proton accelerator at Fermi National Accelerator Laboratory, (2) a near neutrino detector just downstream of the source, and (3) a massive liquid argon time-projection chamber deployed as a far detector deep underground at the Sanford Underground Research Facility. This facility, located at the site of the former Homestake Mine in Lead, South Dakota, is approximately 1,300 km from the neutrino source at Fermilab -- a distance (baseline) that delivers optimal sensitivity to neutrino charge-parity symmetry violation and mass ordering effects. This ambitious yet cost-effective design incorporates scalability and flexibility and can accommodate a variety of upgrades and contributions. With its exceptional combination of experimental configuration, technical capabilities, and potential for transformative discoveries, LBNE promises to be a vital facility for the field of particle physics worldwide, providing physicists from around the globe with opportunities to collaborate in a twenty to thirty year program of exciting science. In this document we provide a comprehensive overview of LBNE's scientific objectives, its place in the landscape of neutrino physics worldwide, the technologies it will incorporate and the capabilities it will possess."
YURI CORRIGAN,"Arkadii bessmertnii (Dostoevskii o dushe, prebyvaiushchei vne tela)","Volume on the ""state of the field"" with regard to Dostoevsky's ""Adolescent."""
YURI CORRIGAN,Dostoevsky in the 21st century,"Roudtable with Stefano Aloe, Carol Apollonio, Kornelija Ičin, Sergei Kibalnik, and Boris Tikhomirov."
YURI CORRIGAN,Dostoevskii on evil as safe haven and anesthetic,"This article enlists Dostoevskii in reconsidering the conceptual barrier often placed between traditional and postmodern forms of evil: between the paradigms of Lucifer (evil as transgressive and malevolent) and Eichmann (evil as thoughtless, obedient, impersonal). Dostoevskii helps us think beyond this binary by presenting both these models of evil (the maliciously transgressive and the thoughtlessly obedient) as diverging symptoms of the same illness. Evil, for Dostoevskii, is caused ultimately by a flight from inwardness. Transgressive forms of violence and submissive forms of obedience share an underlying motivation: as strategies of keeping the self at all costs within the comparatively shallow waters of conscious immediacy. The essay traces Dostoevskii’s neglected psychology of evil over the course of his career, with special attention to new readings of Notes from Underground, Crime and Punishment, and Demons.
 В настоящей статье, новые прочтения прозы Достоевского позволяют нам переосмыслить концептуальный барьер между традиционными и постмодернистскими формами зла: между парадигмами Люцифера (зло как трансгрессивное и злоумышленное начало) и Эйхмана (зло как начало бездумное, послушное и безличное). Достоевский представляет обе эти модели (злонамеренно трансгрессивное зло и зло бездумно послушное) как противоположные симптомы одной и той же духовной болезни. Зло, по Достоевскоему, вызвано бегством от живых форм внутренней жизни. Для Достоевского, трансгрессивные формы насилия, как и покорные формы послушания имеют общую мотивацию: и те и другие представляют собой ответ на боязнь глубинной, внутренней жизни. В статье прослеживается психология зла в прозе Достоевского выработанная писателем в таких произведениях как «Записки из подполья», «Преступление и наказание» и «Бесы».
 "
ROSS BARRETT,In the Vernacular: Photography of the Everyday,
CHUANHUA DUAN,Current monitoring in nanochannels,
CHUANHUA DUAN,Microstructural ordering of nanofibers in flow-directed assembly,"Fabrication of highly ordered and dense nanofibers assemblies is of key importance for high-performance and multi-functional material and device applications. In this work, we design an experimental approach in silico, where shear flow and solvent evaporation are applied to tune the alignment, overlap of nanofibers, and density of the assemblies. Microscopic dynamics of the process is probed by dissipative particle dynamics simulations, where hydrodynamic and thermal fluctuation effects are fully modeled. We find that microstructural ordering of the assembled nanofibers can be established within a specific range of the Peclet numbers and evaporation rates, while the properties of nanofibers and their interaction are crucial for the local stacking order. The underlying mechanisms are elucidated by considering the competition between hydrodynamic coupling and thermal fluctuation. Based on these understandings, a practical design of flow channels for nanofiber assembly with promising mechanical performance is outlined."
CHUANHUA DUAN,Evaporation-assisted patterning beyond random assembly,"Evaporation of solvent and the resulting fluid motion has been recognized as a simple but robust patterning method to yield self-assembled patterns of non-volatile solutes (e.g. microspheres, nanoparticles, bacteria, polymers, proteins, DNA, graphenes, etc.) on plain surfaces [1,2]. Such evaporation-assisted patterning could occur at small scales (O(mm^2)) by depositing and drying individual drops on surfaces, or at larger scales (O(cm^2)) by continuously moving an evaporating meniscus."
CHUANHUA DUAN,Surface charge enhanced kinetically-limited evaporation in nanopores,
ADAM W SWEETING,Consensus guidelines for advancing coral holobiont genome and specimen voucher deposition,"Coral research is being ushered into the genomic era. To fully capitalize on the potential discoveries from this genomic revolution, the rapidly increasing number of high-quality genomes requires effective pairing with rigorous taxonomic characterizations of specimens and the contextualization of their ecological relevance. However, to date there is no formal framework that genomicists, taxonomists, and coral scientists can collectively use to systematically acquire and link these data. Spurred by the recently announced “Coral symbiosis sensitivity to environmental change hub” under the “Aquatic Symbiosis Genomics Project” - a collaboration between the Wellcome Sanger Institute and the Gordon and Betty Moore Foundation to generate gold-standard genome sequences for coral animal hosts and their associated Symbiodiniaceae microalgae (among the sequencing of many other symbiotic aquatic species) - we outline consensus guidelines to reconcile different types of data. The metaorganism nature of the coral holobiont provides a particular challenge in this context and is a key factor to consider for developing a framework to consolidate genomic, taxonomic, and ecological (meta)data. Ideally, genomic data should be accompanied by taxonomic references, i.e., skeletal vouchers as formal morphological references for corals and strain specimens in the case of microalgal and bacterial symbionts (cultured isolates). However, exhaustive taxonomic characterization of all coral holobiont member species is currently not feasible simply because we do not have a comprehensive understanding of all the organisms that constitute the coral holobiont. Nevertheless, guidelines on minimal, recommended, and ideal-case descriptions for the major coral holobiont constituents (coral animal, Symbiodiniaceae microalgae, and prokaryotes) will undoubtedly help in future referencing and will facilitate comparative studies. We hope that the guidelines outlined here, which we will adhere to as part of the Aquatic Symbiosis Genomics Project sub-hub focused on coral symbioses, will be useful to a broader community and their implementation will facilitate cross- and meta-data comparisons and analyses."
MELISSA HOLT,Peer victimization and sexual risk taking among adolescents,
MELISSA HOLT,Multidisciplinary approaches to research on bullying in adolescence,"Bullying is a significant public health problem in the United States that affects youth functioning in multiple domains. Much of the research on bullying to date has focused on children, however, leaving gaps in the literature with respect to understanding bullying among adolescents. In particular, less is known about how adolescents conceptualize bullying, what predicts and is associated with bullying involvement among adolescents, and how prevention programs might address the unique needs of middle and high school students. This special issue proposes that a multidisciplinary perspective might be particularly useful in better understanding bullying among adolescents and determining how to design more effective interventions and prevention programs for this age-group. The current article introduces the special issue by briefly discussing what is known about bullying in adolescence and considering three disciplines (computer science, big data, and virtual communities; media studies; anthropology) that are particularly well situated to move the field forward. Next, this article reviews teen pregnancy prevention efforts, as an example of another adolescent public health concern that has been addressed successfully using a multidisciplinary approach. The article concludes with an overview of the three manuscripts that are part of the special issue."
MELISSA HOLT,The COVID-19 pandemic disrupted both school bullying and cyberbullying,
PETER ROCKERS,Impact of a community-based package of interventions on child development in Zambia: a cluster-randomised controlled trial,"BACKGROUND: Community-based programmes are a critical platform for improving child health and development. We tested the impact of a community based early childhood intervention package in rural Zambia. Methods: We conducted a non-blinded cluster randomised controlled trial in Southern Province, Zambia. 30 clusters of villages were matched based on population density and distance from the nearest health centre, and randomly assigned to intervention (15 clusters and 268 caregiver–child dyads) or control (15 clusters and 258 caregiver–child dyads). Caregivers were eligible if they had a child aged 6–12 months at baseline. In intervention clusters, health workers screened children for infections and malnutrition, and invited caregivers to attend fortnightly group meetings covering a nutrition and child development curriculum. 220 intervention and 215 control dyads were evaluated after 1 year. The primary outcomes were stunting and INTERGROWTH-21st neurodevelopmental assessment (NDA) scores. Weight-for-age and height-for-age z-scores based on WHO growth standards were also analysed. Secondary outcomes were child illness symptoms, dietary intake and caregiver–child interactions based on self-report. Impact was estimated using intention to-treat analysis. RESULTS: The intervention package was associated with a 0.12 SD increase in weight-for-age (95% CI−0.14 to 0.38), a 0.15 SD increase in height-for-age (95% CI −0.18 to 0.48) and a reduction in stunting (OR 0.68; 95% CI 0.36 to 1.28), whereas there was no measurable impact on NDA score. Children receiving the intervention package had fewer symptoms, a more diverse diet and more caregiver interactions. CONCLUSIONS: In settings like Zambia, community based early childhood programmes appear to be feasible and appreciated by caregivers, as evidenced by high rates of uptake. The intervention package improved parenting behaviours and had a small positive, though statistically insignificant, impact on child development. Given the short time frame of the project, larger developmental impact is likely if differential parenting behaviours persist."
PETER ROCKERS,"Dataset for ""A Qualitative Assessment of Community Acceptability and Use of a Locally Developed Children’s Book to Increase Shared Reading and Parent-Child Interactions in Rural Zambia""",
PETER ROCKERS,"Dataset for ""Barriers and facilitators to facility-based delivery in rural Zambia: A qualitative study of women’s perceptions after implementation of an improved Maternity Waiting Homes intervention""","Objectives: Women in sub-Saharan Africa face well-documented barriers to facility-based deliveries. An improved maternity waiting homes (MWH) model was implemented in rural Zambia to bring pregnant women closer to facilities for delivery. We qualitatively assessed whether MWHs changed perceived barriers to facility delivery among remote-living women. Design: We administered in-depth interviews (IDIs) to a randomly-selected subsample of women in intervention (n=78) and control (n=80) groups who participated in the primary quasi-experimental evaluation of an improved MWH model. The IDIs explored perceptions and preferences of delivery location. We conducted content analysis to understand perceived barriers and facilitators to facility delivery. Setting and participants: Participants lived in villages 10+ kilometers from the health facility and had delivered a baby in the previous 12 months. Intervention: The improved MWH model was implemented at 20 rural health facilities. Results: Over 96% of participants in the intervention arm and 90% in the control arm delivered their last baby at a health facility. Key barriers to facility delivery were distance and transportation, and costs associated with delivery. Facilitators included no user fees, penalties for home delivery, desire for safe delivery, and availability of MWHs. Most themes were similar between study arms. Both discussed the role MWHs have in improving access to facility-based delivery. Intervention arm participants expressed that the improved MWH model encourages use and helps overcome the distance barrier. Control arm participants either expressed a desire for an improved MWH model or did not consider it in their decision-making. Conclusions: Even in areas with high facility-based delivery rates in rural Zambia, barriers to access persist. MWHs may be useful to address the distance challenge, but no single intervention is likely to address all barriers experienced by rural, low-resourced populations. MWHs should be considered in a broader systems approach to improving access in remote areas. Trial Registration: ClinicalTrials.gov Identifier: NCT02620436"
PETER ROCKERS,MAHMAZ maternity waiting home: setup cost dataset,"These datasets detail 1) the setup costs expended to set up 10 maternity waiting homes in rural Zambia and 2) the monthly occupancy of the maternity waiting homes. The former includes the date of purchase, cost category, and the purchase amount in Kwacha. The latter describes how many patients visited the maternity waiting home in the last year of our project. We utilized this data to create a manuscript describing the setup costs of these homes, and the cost per admission to the homes, to serve as a guide for future implementors."
PETER ROCKERS,"Dataset for ""If we build it, will they come? Results of a quasi-experimental study assessing the impact of maternity waiting homes on facility-based childbirth and maternity care in Zambia""",
PETER ROCKERS,Study protocol: the impact of growth charts and nutritional supplements on child growth in Zambia (ZamCharts): a cluster randomized controlled trial,
PETER ROCKERS,Study protocol for a cluster-randomized controlled trial of an NCD access to medicines initative: Evaluation of Novartis Access in Kenya,"INTRODUCTION: Novartis recently launched Novartis Access, an initiative to provide a basket of reduced price medicines for non-communicable diseases (NCDs) to be sold through the public and private nonprofit sectors in programme countries. This study will evaluate the impact of Novartis Access on the availability and price of NCD medicines at health facilities and households in Kenya, the first country to receive the programme. METHODS: This study will be a cluster randomised controlled trial. 8 counties in Kenya will be randomly assigned to the intervention or control group using a covariate constrained randomisation method to maximise balance on demographic and health characteristics. In intervention counties, public and private non-profit health facilities will be able to order Novartis Access NCD medicines from the Mission for Essential Drugs and Supplies (MEDS). Data will be collected from a random sample of 384 health facilities and 800 households at baseline, midline after 1-year of intervention, and end-line after 2 years. Quarterly surveillance data will also be collected from health facilities and a subsample of households through phone-based interviews. Households will be eligible if at least one resident has been previously diagnosed and prescribed a medicine for an NCD addressed by Novartis Access, including hypertension and diabetes. The primary outcomes will be availability and price of NCD medicines at health facilities, and availability, price, and expenditures on NCD medicines at households. Impacts will be estimated using intention-to-treat analysis. ETHICS AND DISSEMINATION: This protocol was approved by the Institutional Review Boards at Strathmore University and at Boston University. Informed consent will be obtained from all participants at the start of the trial. The findings of the trial will be disseminated through peer-reviewed journals, international conferences, and meetings and events organised with local stakeholders."
JAY S KIM,Global biotech startup: the K2B story,
JAY S KIM,LabCentral and Boston Bio Innovation Ecosystem,
JAY S KIM,Global biotech startup: the K2B story,
JAY S KIM,LabCentral and Boston Bio Innovation Ecosystem,
JAY S KIM,Boston bio innovation ecosystem: known secrets and hidden secrets,
JAY S KIM,LabCentral and Boston Bio Innovation Ecosystem,
JAY S KIM,Boston bio innovation ecosystem: known secrets and hidden secrets,
JAY S KIM,Global rush to produce Covid-19 vaccine,"Presented the case as a Finalist in DSI Case Competition at the conference - Announced as Winner on Nov 21, 2022"
JAY S KIM,Entrepreneurial opportunities for academic scientists,
JAY S KIM,Global rush to produce Covid-19 vaccine,Case study written primarily for Questrom OMBA 2022
JAY S KIM,Boston bio innovation ecosystem: known secrets and hidden secrets,
JAY S KIM,"First Sagittarius A* Event Horizon Telescope results. II. EHT and multiwavelength observations, data processing, and calibration","We present Event Horizon Telescope (EHT) 1.3 mm measurements of the radio source located at the position of the supermassive black hole Sagittarius A* (Sgr A*), collected during the 2017 April 5–11 campaign. The observations were carried out with eight facilities at six locations across the globe. Novel calibration methods are employed to account for Sgr A*'s flux variability. The majority of the 1.3 mm emission arises from horizon scales, where intrinsic structural source variability is detected on timescales of minutes to hours. The effects of interstellar scattering on the image and its variability are found to be subdominant to intrinsic source structure. The calibrated visibility amplitudes, particularly the locations of the visibility minima, are broadly consistent with a blurred ring with a diameter of ∼50 μas, as determined in later works in this series. Contemporaneous multiwavelength monitoring of Sgr A* was performed at 22, 43, and 86 GHz and at near-infrared and X-ray wavelengths. Several X-ray flares from Sgr A* are detected by Chandra, one at low significance jointly with Swift on 2017 April 7 and the other at higher significance jointly with NuSTAR on 2017 April 11. The brighter April 11 flare is not observed simultaneously by the EHT but is followed by a significant increase in millimeter flux variability immediately after the X-ray outburst, indicating a likely connection in the emission physics near the event horizon. We compare Sgr A*’s broadband flux during the EHT campaign to its historical spectral energy distribution and find that both the quiescent emission and flare emission are consistent with its long-term behavior."
JAY S KIM,The genome of the vervet ( Chlorocebus aethiops sabaeus ),"We describe a genome reference of the African green monkey or vervet (Chlorocebus aethiops). This member of the Old World monkey (OWM) superfamily is uniquely valuable for genetic investigations of simian immunodeficiency virus (SIV), for which it is the most abundant natural host species, and of a wide range of health-related phenotypes assessed in Caribbean vervets (C. a. sabaeus), whose numbers have expanded dramatically since Europeans introduced small numbers of their ancestors from West Africa during the colonial era. We use the reference to characterize the genomic relationship between vervets and other primates, the intra-generic phylogeny of vervet subspecies, and genome-wide structural variations of a pedigreed C. a. sabaeus population. Through comparative analyseswith human and rhesus macaque, we characterize at high resolution the unique chromosomal fission events that differentiate the vervets and their close relatives from most other catarrhine primates, in whom karyotype is highly conserved. We also provide a summary of transposable elements and contrast these with the rhesus macaque and human. Analysis of sequenced genomes representing each of the main vervet subspecies supports previously hypothesized relationships between these populations, which range across most of sub-Saharan Africa, while uncovering high levels of genetic diversity within each. Sequence-based analyses of major histocompatibility complex (MHC) polymorphisms reveal extremely low diversity in Caribbean C. a. sabaeus vervets, compared to vervets from putatively ancestral West African regions. In the C. a. sabaeus research population, we discover the first structural variations that are, in some cases, predicted to have a deleterious effect; future studies will determine the phenotypic impact of these variations."
JAY S KIM,Event Horizon Telescope imaging of the archetypal blazar 3C 279 at an extreme 20 microarcsecond resolution,"3C 279 is an archetypal blazar with a prominent radio jet that show broadband flux density variability across the entire electromagnetic spectrum. We use an ultra-high angular resolution technique – global Very Long Baseline Interferometry (VLBI) at 1.3 mm (230 GHz) – to resolve the innermost jet of 3C 279 in order to study its fine-scale morphology close to the jet base where highly variable γ-ray emission is thought to originate, according to various models. The source was observed during four days in April 2017 with the Event Horizon Telescope at 230 GHz, including the phased Atacama Large Millimeter/submillimeter Array (ALMA), at an angular resolution of ∼20 μas (at a redshift of z = 0.536 this corresponds to ∼0.13 pc  ∼ 1700 Schwarzschild radii with a black hole mass M<jats:sub>BH</jats:sub> = 8 × 10^8 M_⊙). Imaging and model-fitting techniques were applied to the data to parameterize the fine-scale source structure and its variation. We find a multicomponent inner jet morphology with the northernmost component elongated perpendicular to the direction of the jet, as imaged at longer wavelengths. The elongated nuclear structure is consistent on all four observing days and across different imaging methods and model-fitting techniques, and therefore appears robust. Owing to its compactness and brightness, we associate the northern nuclear structure as the VLBI “core”. This morphology can be interpreted as either a broad resolved jet base or a spatially bent jet. We also find significant day-to-day variations in the closure phases, which appear most pronounced on the triangles with the longest baselines. Our analysis shows that this variation is related to a systematic change of the source structure. Two inner jet components move non-radially at apparent speeds of ∼15 c and ∼20 c (∼1.3 and ∼1.7 μas day^−1, respectively), which more strongly supports the scenario of traveling shocks or instabilities in a bent, possibly rotating jet. The observed apparent speeds are also coincident with the 3C 279 large-scale jet kinematics observed at longer (cm) wavelengths, suggesting no significant jet acceleration between the 1.3 mm core and the outer jet. The intrinsic brightness temperature of the jet components are ≲10^10 K, a magnitude or more lower than typical values seen at ≥7 mm wavelengths. The low brightness temperature and morphological complexity suggest that the core region of 3C 279 becomes optically thin at short (mm) wavelengths."
JAY S KIM,First M87 Event Horizon Telescope results. II. Array and instrumentation,"The Event Horizon Telescope (EHT) is a very long baseline interferometry (VLBI) array that comprises millimeter- and submillimeter-wavelength telescopes separated by distances comparable to the diameter of the Earth. At a nominal operating wavelength of ~1.3 mm, EHT angular resolution (λ/D) is ~25 μas, which is sufficient to resolve nearby supermassive black hole candidates on spatial and temporal scales that correspond to their event horizons. With this capability, the EHT scientific goals are to probe general relativistic effects in the strong-field regime and to study accretion and relativistic jet formation near the black hole boundary. In this Letter we describe the system design of the EHT, detail the technology and instrumentation that enable observations, and provide measures of its performance. Meeting the EHT science objectives has required several key developments that have facilitated the robust extension of the VLBI technique to EHT observing wavelengths and the production of instrumentation that can be deployed on a heterogeneous array of existing telescopes and facilities. To meet sensitivity requirements, high-bandwidth digital systems were developed that process data at rates of 64 gigabit s−1, exceeding those of currently operating cm-wavelength VLBI arrays by more than an order of magnitude. Associated improvements include the development of phasing systems at array facilities, new receiver installation at several sites, and the deployment of hydrogen maser frequency standards to ensure coherent data capture across the array. These efforts led to the coordination and execution of the first Global EHT observations in 2017 April, and to event-horizon-scale imaging of the supermassive black hole candidate in M87."
JAY S KIM,First M87 Event Horizon Telescope results. I. The shadow of the supermassive black hole,"When surrounded by a transparent emission region, black holes are expected to reveal a dark shadow caused by gravitational light bending and photon capture at the event horizon. To image and study this phenomenon, we have assembled the Event Horizon Telescope, a global very long baseline interferometry array observing at a wavelength of 1.3 mm. This allows us to reconstruct event-horizon-scale images of the supermassive black hole candidate in the center of the giant elliptical galaxy M87. We have resolved the central compact radio source as an asymmetric bright emission ring with a diameter of 42 ± 3 μas, which is circular and encompasses a central depression in brightness with a flux ratio gsim10:1. The emission ring is recovered using different calibration and imaging schemes, with its diameter and width remaining stable over four different observations carried out in different days. Overall, the observed image is consistent with expectations for the shadow of a Kerr black hole as predicted by general relativity. The asymmetry in brightness in the ring can be explained in terms of relativistic beaming of the emission from a plasma rotating close to the speed of light around a black hole. We compare our images to an extensive library of ray-traced general-relativistic magnetohydrodynamic simulations of black holes and derive a central mass of M = (6.5 ± 0.7) × 10^9 M ⊙. Our radio-wave observations thus provide powerful evidence for the presence of supermassive black holes in centers of galaxies and as the central engines of active galactic nuclei. They also present a new tool to explore gravity in its most extreme limit and on a mass scale that was so far not accessible."
JAY S KIM,First Sagittarius A* Event Horizon Telescope results. I. The shadow of the supermassive black hole in the center of the Milky Way,"We present the first Event Horizon Telescope (EHT) observations of Sagittarius A* (Sgr A*), the Galactic center source associated with a supermassive black hole. These observations were conducted in 2017 using a global interferometric array of eight telescopes operating at a wavelength of λ = 1.3 mm. The EHT data resolve a compact emission region with intrahour variability. A variety of imaging and modeling analyses all support an image that is dominated by a bright, thick ring with a diameter of 51.8 ± 2.3 μas (68% credible interval). The ring has modest azimuthal brightness asymmetry and a comparatively dim interior. Using a large suite of numerical simulations, we demonstrate that the EHT images of Sgr A* are consistent with the expected appearance of a Kerr black hole with mass ∼4 × 106 M ⊙, which is inferred to exist at this location based on previous infrared observations of individual stellar orbits, as well as maser proper-motion studies. Our model comparisons disfavor scenarios where the black hole is viewed at high inclination (i &gt; 50°), as well as nonspinning black holes and those with retrograde accretion disks. Our results provide direct evidence for the presence of a supermassive black hole at the center of the Milky Way, and for the first time we connect the predictions from dynamical measurements of stellar orbits on scales of 103–105 gravitational radii to event-horizon-scale images and variability. Furthermore, a comparison with the EHT results for the supermassive black hole M87* shows consistency with the predictions of general relativity spanning over three orders of magnitude in central mass."
HERBERT T COHEN,"BMQ : Boston medical quarterly: v. 7, no. 1-4",
HERBERT T COHEN,"BMQ : Boston medical quarterly: v. 15, no. 1-4",
HERBERT T COHEN,Previously Unidentified Changes in Renal Cell Carcinoma Gene Expression Identified by Parametric Analysis of Microarray Data,"BACKGROUND. Renal cell carcinoma is a common malignancy that often presents as a metastatic-disease for which there are no effective treatments. To gain insights into the mechanism of renal cell carcinogenesis, a number of genome-wide expression profiling studies have been performed. Surprisingly, there is very poor agreement among these studies as to which genes are differentially regulated. To better understand this lack of agreement we profiled renal cell tumor gene expression using genome-wide microarrays (45,000 probe sets) and compare our analysis to previous microarray studies. METHODS. We hybridized total RNA isolated from renal cell tumors and adjacent normal tissue to Affymetrix U133A and U133B arrays. We removed samples with technical defects and removed probesets that failed to exhibit sequence-specific hybridization in any of the samples. We detected differential gene expression in the resulting dataset with parametric methods and identified keywords that are overrepresented in the differentially expressed genes with the Fisher-exact test. RESULTS. We identify 1,234 genes that are more than three-fold changed in renal tumors by t-test, 800 of which have not been previously reported to be altered in renal cell tumors. Of the only 37 genes that have been identified as being differentially expressed in three or more of five previous microarray studies of renal tumor gene expression, our analysis finds 33 of these genes (89%). A key to the sensitivity and power of our analysis is filtering out defective samples and genes that are not reliably detected. CONCLUSIONS. The widespread use of sample-wise voting schemes for detecting differential expression that do not control for false positives likely account for the poor overlap among previous studies. Among the many genes we identified using parametric methods that were not previously reported as being differentially expressed in renal cell tumors are several oncogenes and tumor suppressor genes that likely play important roles in renal cell carcinogenesis. This highlights the need for rigorous statistical approaches in microarray studies."
BARBARA E SLACK,Inhibition of Dynamin-Dependent Endocytosis Increases Shedding of the Amyloid Precursor Protein Ectodomain and Reduces Generation Of Amyloid β Protein,"BACKGROUND. The amyloid precursor protein (APP) is transported via the secretory pathway to the cell surface, where it may be cleaved within its ectodomain by α-secretase, or internalized within clathrin-coated vesicles. An alternative proteolytic pathway occurs within the endocytic compartment, where the sequential action of β- and γ-secretases generates the amyloid β protein (Aβ). In this study, we investigated the effects of modulators of endocytosis on APP processing. RESULTS. Human embryonic kidney cells were transfected with a dominant negative mutant of dynamin I, an important mediator of clathrin-dependent endocytosis, and APP proteolysis was analyzed. Overexpression of the mutant dynamin (dyn I K44A) resulted in increased shedding of the APP ectodomain (sAPPα), accumulation of the C-terminal α-secretase product C83, and a reduction in the release of Aβ. Levels of mature APP on the cell surface were increased in cells expressing dyn I K44A, and internalization of surface-immunolabeled APP, assessed by fluorescence microscopy, was inhibited. Dynamin is a substrate for protein kinase C (PKC), and it was hypothesized that activators of PKC, which are known to stimulate α-secretase-mediated cleavage of APP, might exert their effects by inhibiting dynamin-dependent endocytosis. However, the internalization of surface-biotinylated APP was unaffected by treatment of cells with phorbol 12-myristate 13-acetate in the presence of the α-secretase inhibitor TAPI-1. CONCLUSION. The results indicate that APP is internalized by a dynamin-dependent process, and suggest that alterations in the activity of proteins that mediate endocytosis might lead to significant changes in Aβ production."
DOUGLAS P HOLMES,Delayed buckling of spherical shells due to viscoelastic knockdown of the critical load,"We performed dynamic pressure buckling experiments on defect-seeded spherical shells made of a common silicone elastomer. Unlike in quasi-static experiments, shells buckled at ostensibly subcritical pressures, i.e. below the experimentally determined critical load at which buckling occurs elastically, often following a significant delay period from the time of load application. While emphasizing the close connections to elastic shell buckling, we rely on viscoelasticity to explain our observations. In particular, we demonstrate that the lower critical load may be determined from the material properties, which is rationalized by a simple analogy to elastic spherical shell buckling. We then introduce a model centred on empirical quantities to show that viscoelastic creep deformation lowers the critical load in the same predictable, quantifiable way that a growing defect would in an elastic shell. This allows us to capture how both the deflection at instability and the time delay depend on the applied pressure, material properties and defect geometry. These quantities are straightforward to measure in experiments. Thus, our work not only provides intuition for viscoelastic behaviour from an elastic shell buckling perspective but also offers an accessible pathway to introduce tunable, time-controlled actuation to existing mechanical actuators, e.g. pneumatic grippers."
DOUGLAS P HOLMES,Elastic instabilities govern the morphogenesis of the optic cup,"Because the normal operation of the eye depends on sensitive morphogenetic processes for its eventual shape, developmental flaws can lead to wide-ranging ocular defects. However, the physical processes and mechanisms governing ocular morphogenesis are not well understood. Here, using analytical theory and nonlinear shell finite-element simulations, we show, for optic vesicles experiencing matrix-constrained growth, that elastic instabilities govern the optic cup morphogenesis. By capturing the stress amplification owing to mass increase during growth, we show that the morphogenesis is driven by two elastic instabilities analogous to the snap through in spherical shells, where the second instability is sensitive to the optic cup geometry. In particular, if the optic vesicle is too slender, it will buckle and break axisymmetry, thus, preventing normal development. Our results shed light on the morphogenetic mechanisms governing the formation of a functional biological system and the role of elastic instabilities in the shape selection of soft biological structures."
DOUGLAS P HOLMES,Efficient snap-through of spherical caps by applying a localized curvature stimulus,"In bistable actuators and other engineered devices, a homogeneous stimulus (e.g., mechanical, chemical, thermal, or magnetic) is often applied to an entire shell to initiate a snap-through instability. In this work, we demonstrate that restricting the active area to the shell boundary allows for a large reduction in its size, thereby decreasing the energy input required to actuate the shell. To do so, we combine theory with 1D finite element simulations of spherical caps with a non-homogeneous distribution of stimulus-responsive material. We rely on the effective curvature stimulus, i.e., the natural curvature induced by the non-mechanical stimulus, which ensures that our results are entirely stimulus-agnostic. To validate our numerics and demonstrate this generality, we also perform two sets of experiments, wherein we use residual swelling of bilayer silicone elastomers-a process that mimics differential growth-as well as a magneto-elastomer to induce curvatures that cause snap-through. Our results elucidate the underlying mechanics, offering an intuitive route to optimal design for efficient snap-through."
DOUGLAS P HOLMES,Emergence of structure in columns of grains and elastic loops,"It is possible to build free-standing, load-bearing structures using only rocks and loops of elastic material. We investigate how these structures emerge, and find that the necessary maximum loop spacing (the critical spacing) is a function of the frictional properties of the grains and the elasticity of the confining material. We derive a model to understand both of these relationships, which depends on a simplification of the behavior of the grains at the edge of a structure. We find that higher friction leads to larger stable grain-grain and grain-loop contact angles resulting in a simple function for the frictional critical spacing, which depends linearly on friction to first order. On the other hand, a higher bending rigidity enables the loops to better contain the hydrostatic pressure of the grains, which we understand using a hydroelastic scale. These findings will illuminate the stabilization of dirt by plant roots, and potentially enable the construction of simple adhesion-less structures using only granular material and fiber."
DOUGLAS P HOLMES,Kirigami actuators,"Thin elastic sheets bend easily and, if they are patterned with cuts, can deform in sophisticated ways. Here we show that carefully tuning the location and arrangement of cuts within thin sheets enables the design of mechanical actuators that scale down to atomically-thin 2D materials. We first show that by understanding the mechanics of a single non-propagating crack in a sheet, we can generate four fundamental forms of linear actuation: roll, pitch, yaw, and lift. Our analytical model shows that these deformations are only weakly dependent on thickness, which we confirm with experiments on centimeter-scale objects and molecular dynamics simulations of graphene and MoS₂ nanoscale sheets. We show how the interactions between non-propagating cracks can enable either lift or rotation, and we use a combination of experiments, theory, continuum computational analysis, and molecular dynamics simulations to provide mechanistic insights into the geometric and topological design of kirigami actuators."
DOUGLAS P HOLMES,Stimuli-responsive shell theory,"Soft matter mechanics generally involve finite deformations and instabilities of structures in response to a wide range of mechanical and non-mechanical stimuli. Modeling plates and shells is generally a challenge due to their geometrically nonlinear response to loads; however, non-mechanical loads further complicate matters as it is often not clear how they modify the shell’s energy functional. In this work, we demonstrate how to form a mechanical interpretation of these non-mechanical stimuli, in which the standard shell strain energy can be augmented with potentials corresponding to how a non-mechanical stimulus acts to change the shell’s area and curvature via the natural stretch and curvature. As a result, the effect of non-mechanical stimuli to deform shells is transformed into effective external loadings, and this framework allows for the application of analytical and computational tools that are standard within the mechanics community. Furthermore, we generalize the effect of mass change during biological growth to account for its effect on the stress constitution. The theory is formulated based on a standard, stress-free reference configuration which is known a priori, meaning it can be physically observed, and only requires the solution of a single-field equation, the standard mechanical momentum or equilibrium equation, despite capturing the effects of non-mechanical stimuli. We validate the performance of this model by several benchmark problems, and finally, we apply it to complex examples, including the snapping of the Venus flytrap, leaf growth, and the buckling of electrically active polymer plates. Overall, we expect that mechanicians and non-mechanicians alike can use the approach presented here to quickly modify existing computational tools with effective external loadings calculated in this novel theory to study how various types of non-mechanical stimuli impact the mechanics and physics of thin shell structures."
ROSINA M GEORGIADIS,Secondary structure effects on DNA hybridization kinetics: a solution versus surface comparison,"The hybridization kinetics for a series of designed 25mer probe�target pairs having varying degrees of secondary structure have been measured by UV absorbance and surface plasmon resonance (SPR) spectroscopy in solution and on the surface, respectively. Kinetic rate constants derived from the resultant data decrease with increasing probe and target secondary structure similarly in both solution and surface environments. Specifically, addition of three intramolecular base pairs in the probe and target structure slow hybridization by a factor of two. For individual strands containing four or more intramolecular base pairs, hybridization cannot be described by a traditional two-state model in solution-phase nor on the surface. Surface hybridization rates are also 20- to 40-fold slower than solution-phase rates for identical sequences and conditions. These quantitative findings may have implications for the design of better biosensors, particularly those using probes with deliberate secondary structure."
ROSINA M GEORGIADIS,Secondary structure effects on DNA hybridization kinetics: a solution versus surface comparison,"The hybridization kinetics for a series of designed 25mer probe-target pairs having varying degrees of secondary structure have been measured by UV absorbance and surface plasmon resonance (SPR) spectroscopy in solution and on the surface, respectively. Kinetic rate constants derived from the resultant data decrease with increasing probe and target secondary structure similarly in both solution and surface environments. Specifically, addition of three intramolecular base pairs in the probe and target structure slow hybridization by a factor of two. For individual strands containing four or more intramolecular base pairs, hybridization cannot be described by a traditional two-state model in solution-phase nor on the surface. Surface hybridization rates are also 20- to 40-fold slower than solution-phase rates for identical sequences and conditions. These quantitative findings may have implications for the design of better biosensors, particularly those using probes with deliberate secondary structure."
ROSINA M GEORGIADIS,Secondary Structure Effects on DNA Hybridization Kinetics: A Solution Versus Surface Comparison,"The hybridization kinetics for a series of designed 25mer probe–target pairs having varying degrees of secondary structure have been measured by UV absorbance and surface plasmon resonance (SPR) spectroscopy in solution and on the surface, respectively. Kinetic rate constants derived from the resultant data decrease with increasing probe and target secondary structure similarly in both solution and surface environments. Specifically, addition of three intramolecular base pairs in the probe and target structure slow hybridization by a factor of two. For individual strands containing four or more intramolecular base pairs, hybridization cannot be described by a traditional two-state model in solution-phase nor on the surface. Surface hybridization rates are also 20- to 40-fold slower than solution-phase rates for identical sequences and conditions. These quantitative findings may have implications for the design of better biosensors, particularly those using probes with deliberate secondary structure."
JAMES KEITH VINCENT,Proceedings of the Sixth International Workshop on Web Caching and Content Distribution,"OVERVIEW: The International Web Content Caching and Distribution Workshop (WCW) is a premiere technical meeting for researchers and practitioners interested in all aspects of content caching, distribution and delivery on the Internet. The 2001 WCW meeting was held on the Boston University Campus. Building on the successes of the five previous WCW meetings, WCW01 featured a strong technical program and record participation from leading researchers and practitioners in the field. This report includes all the technical papers presented at WCW'01. NOTE: Proceedings of WCW'01 are published by Elsevier. Hard copies of these proceedings can be purchased through the workshop organizers. As a service to the community, electronic copies of all WCW'01 papers are accessible through Technical Report BUCS‐TR‐2001‐017, available from the Boston University Computer Science Technical Report Archives at http://www.cs.bu.edu/techreps. [Ed.note: URL outdated. Use http://www.bu.edu/cs/research/technical-reports or http://hdl.handle.net/2144/1455 in this repository to access the reports.]"
JAMES KEITH VINCENT,A genome-wide association study reveals variants in ARL15 that influence adiponectin levels,"The adipocyte-derived protein adiponectin is highly heritable and inversely associated with risk of type 2 diabetes mellitus (T2D) and coronary heart disease (CHD). We meta-analyzed 3 genome-wide association studies for circulating adiponectin levels (n = 8,531) and sought validation of the lead single nucleotide polymorphisms (SNPs) in 5 additional cohorts (n = 6,202). Five SNPs were genome-wide significant in their relationship with adiponectin (P≤5×10−8). We then tested whether these 5 SNPs were associated with risk of T2D and CHD using a Bonferroni-corrected threshold of P≤0.011 to declare statistical significance for these disease associations. SNPs at the adiponectin-encoding ADIPOQ locus demonstrated the strongest associations with adiponectin levels (P-combined = 9.2×10−19 for lead SNP, rs266717, n = 14,733). A novel variant in the ARL15 (ADP-ribosylation factor-like 15) gene was associated with lower circulating levels of adiponectin (rs4311394-G, P-combined = 2.9×10−8, n = 14,733). This same risk allele at ARL15 was also associated with a higher risk of CHD (odds ratio [OR] = 1.12, P = 8.5×10−6, n = 22,421) more nominally, an increased risk of T2D (OR = 1.11, P = 3.2×10−3, n = 10,128), and several metabolic traits. Expression studies in humans indicated that ARL15 is well-expressed in skeletal muscle. These findings identify a novel protein, ARL15, which influences circulating adiponectin levels and may impact upon CHD risk. Author Summary Through a meta-analysis of genome-wide association studies of 14,733 individuals, we identified common base-pair variants in the genome which influence circulating adiponectin levels. Since adiponectin is an adipocyte-derived circulating protein which has been inversely associated with risk of obesity-related diseases such as type 2 diabetes (T2D) and coronary heart disease (CHD), we next sought to understand if the identified variants influencing adiponectin levels also influence risk of T2D, CHD, and several metabolic traits. In addition to confirming that variation at the ADIPOQ locus influences adiponectin levels, our analyses point to a variant in the ARL15 (ADP-ribosylation factor-like 15) locus which decreases adiponectin levels and increases risk of CHD and T2D. Further, this same variant was associated with increased fasting insulin levels and glycated hemoglobin. While the function of ARL15 is not known, we provide insight into the tissue specificity of ARL15 expression. These results thus provide novel insights into the physiology of the adiponectin pathway and obesity-related diseases."
JAWWAD NOOR,Temptation and guilt,
JAWWAD NOOR,An axiomatic approach to the law of small numbers,
JAWWAD NOOR,Constrained optimal discounting,
DEBORAH BURTON,The Puccini Code,"Written in the style of novelist Dan Brown and using actual quotations from Puccini’s letters and other documents, the author creates the characters Prof. Segugio and her assistant Christie Hunter who explore Puccini’s compositional practices in the unfinished opera Turandot. They work toward solving the riddles of Puccini’s technique – parallel constructions, abrupt changes in texture and style, a sense of tonal coherence in polytonal or atonal settings – by reading contemporary and modern critics and by closely examining the scores. Prof. Segugio ultimately sorts Puccini’s unusual techniques into two compositional types: direct and indirect conflation, two forms of layering that combine to create a score with a diatonic basis be- neath modernistic elements. Documentary evidence supporting these conclusions is found in an unpublished note by the composer, at Yale’s Beinecke Rare Book Library, and in a rare sketch for Turandot’s finale with written indications by the composer."
DEBORAH BURTON,"Orfeo, Osmin and Otello: towards a theory of opera analysis",Three diverse operatic selections are discussed in light of a new approach to opera analysis
DEBORAH BURTON,Guida e conseguente: Padre Martini and Galeazzi on fugue,
DEBORAH BURTON,In his shoes: The Marriage of Figaro and the Movies,
DEBORAH BURTON,"A new finale for Puccini's Turandot, realized by Deborah Burton",
PATRICIA CORTES,Should mothers work? How perceptions of the social norm affect individual attitudes toward work in the U.S,
PATRICIA CORTES,The eighteenth data release of the Sloan Digital Sky Surveys: targeting and first spectra from SDSS-V,"The eighteenth data release (DR18) of the Sloan Digital Sky Survey (SDSS) is the first one for SDSS-V, the fifth generation of the survey. SDSS-V comprises three primary scientific programs or “Mappers”: the Milky Way Mapper (MWM), the Black Hole Mapper (BHM), and the Local Volume Mapper. This data release contains extensive targeting information for the two multiobject spectroscopy programs (MWM and BHM), including input catalogs and selection functions for their numerous scientific objectives. We describe the production of the targeting databases and their calibration and scientifically focused components. DR18 also includes ∼25,000 new SDSS spectra and supplemental information for X-ray sources identified by eROSITA in its eFEDS field. We present updates to some of the SDSS software pipelines and preview changes anticipated for DR19. We also describe three value-added catalogs (VACs) based on SDSS-IV data that have been published since DR17, and one VAC based on the SDSS-V data in the eFEDS field."
PATRICIA CORTES,"Discovery of a hot, transiting, Earth-sized planet and a second temperate, non-transiting planet around the M4 dwarf GJ 3473 (TOI-488)","We present the confirmation and characterisation of GJ 3473 b (G 50–16, TOI-488.01), a hot Earth-sized planet orbiting an M4 dwarf star, whose transiting signal (P = 1.1980035 ± 0.0000018 d) was first detected by the Transiting Exoplanet Survey Satellite (TESS). Through a joint modelling of follow-up radial velocity observations with CARMENES, IRD, and HARPS together with extensive ground-based photometric follow-up observations with LCOGT, MuSCAT, and MuSCAT2, we determined a precise planetary mass, M_b = 1.86 ± 0.30 M_⨁, and radius, R_b = 1.264 ± 0.050 R_⊕. Additionally, we report the discovery of a second, temperate, non-transiting planet in the system, GJ 3473 c, which has a minimum mass, M_c sin i = 7.41 ± 0.91 M_⊕, and orbital period, P_c = 15.509 ± 0.033 d. The inner planet of the system, GJ 3473 b, is one of the hottest transiting Earth-sized planets known thus far, accompanied by a dynamical mass measurement, which makes it a particularly attractive target for thermal emission spectroscopy."
BENJAMIN SIEGEL,'The claims of Asia and the Far East’: India and the FAO in the age of ambivalent internationalism,"If any nation were poised to actualize the developmental promises that the Food and Agriculture Organization (FAO) extended to the international community, it was India. India's independence came in the wake of devastating famine in Bengal and the fears of its recurrence, and the nationalists who had midwifed India's freedom staked their legitimacy to the promise of food for all. Yet from independence, the FAO played only a marginal role in India's agricultural development, its projects reflecting a winnowing scale of ambition. From early investigations into the improved cultivation of basic food grains, the FAO's projects grew increasingly modest by the time of the Green Revolution, revolving around modest improvements to capitalist agriculture, from wool shearing to timber and fishery development. Instead, India drew more substantively upon resources made available by the Ford and Rockefeller Foundations, the United States Technical Cooperation Mission and occasional Soviet largesse. Meanwhile, the Indian most associated with the FAO, B.R. Sen (Director-General, 1956–1967), struggled to align the Organization's capacities with India's scarcity crises, even as his own understanding of famine drew upon his experience as India's Director of Food during the Bengal Famine."
BENJAMIN SIEGEL,"'Self-help which ennobles a nation': development, citizenship, and the obligations of eating in India's austerity years","In the years immediately following independence, India's political leadership, assisted by a network of civic organizations, sought to transform what, how, and how much Indians ate. These campaigns, this article argues, embodied a broader post-colonial project to reimagine the terms of citizenship and development in a new nation facing enduring scarcity. Drawing upon wartime antecedent, global ideologies of population and land management, and an ethos of austerity imbued with the power to actualize economic self-reliance, the new state urged its citizens to give up rice and wheat, whose imports sapped the nation of the foreign currency needed for industrial development. In place of these staples, India's new citizens were asked to adopt ‘substitute’ and ‘subsidiary’ foods—including bananas, groundnuts, tapioca, yams, beets, and carrots—and give up a meal or more each week to conserve India's scant grain reserves. And as Indian planners awaited the possibility of fundamental agricultural advance and agrarian reform, they looked to food technology and the promise of ‘artificial rice’ as a means of making up for India's perennial food deficit. India's women, as anchors of the household—and therefore, the nation—were tasked with facilitating these dietary transformations, and were saddled with the blame when these modernist projects failed. Unable to marshal the resources needed to undertake fundamental agricultural reform, India's planners placed greater faith in their ability to exercise authority over certain aspects of Indian citizenship itself, tying the remaking of practices and sentiments to the reconstruction of a self-reliant national economy."
BENJAMIN SIEGEL,“Kans is king and the cultivator is his subject”: environmental history and agrarian development in modern India,"Throughout the nineteenth and twentieth centuries, cultivators and administrators in India contended with the ravages of kans grass (Saccharum spontaneum), a deeply-rooted wild sugarcane that rendered productive land wholly barren. Difficult to eliminate and endemic throughout India, kans proved particularly destructive in north and central India, particularly in the regions of Jhansi, Bundelkhand, and the Himalayan Terai. Yet the fight against this ecological antagonist was bound up in broader political transformations. As India’s colonial agriculture grew increasingly tied to global markets in the late nineteenth century, and these dry regions offered new possible spaces for settled agriculture, imperial administrators grew increasingly certain that mechanical tractors held the solution to its eradication. And as postcolonial Indian nationalists cast the production of abundant food as central to their political legitimacy, they held out the eradication of kans as a national aim, enlisting the World Bank as a partner. Yet by the 1960s, kans grass “disappeared” as an environmental foe, as faith in the promises of large-scale postcolonial planning were eclipsed by alternate visions of agricultural productivity. Pushing beyond the forests and waterways that have overwhelmingly characterized environmental history in South Asia, this article demonstrates how the ostensibly natural world could confound plans for agricultural development and the notions of state power which underwrote them. By taking up the region’s agroecosystems, this essay underscores the inexorability of ecological concerns to settled agriculture, and offers a reminder that weeds open windows into the intertwined histories of political and environmental change."
BENJAMIN SIEGEL,"The kibbutz and the Ashram: Sarvodaya agriculture, Israeli aid, and the global imaginaries of Indian development","In the first two decades of Indian independence, members of the Sarvodaya movement—India’s popular, non-state program for Gandhian social uplift—sought to partner with representatives of Israel’s developmental apparatus to build a communal agricultural settlement at Gandhi’s former ashram. Working against the lure of large-scale, Nehruvian development, Cold War politics, and cool formal diplomatic relations between the two countries, Indian votaries of small-scale rural uplift saw in Israeli collective agriculture the chance to give Gandhian “constructive work” a practical program rooted in voluntary, village-based socialism—a goal that eluded Gandhi himself. Israeli planners saw their work with Indian civil society as a means of securing the formal diplomatic sanction largely stymied by India’s relationship with the broader Muslim world. Gandhi’s vision of the Indian “village Republic” and the Israeli model of agrarian collectivism both owed their origins to nineteenth-century utopian thought, and both projects felt anachronistic by the time of their decade-long joint effort, whose initial promise succumbed to realpolitik and the hegemony of the developmental state. Yet their work foregrounds the enduring international stake that Indian civil society maintained in development and nation-building, long presumed to have withered with the arrival of the nation-state."
BENJAMIN SIEGEL,Modernizing peasants and 'master farmers': all-India crop competitions and the politics of progressive agriculture in early independent India,"In the years following independence, looking toward agricultural self-sufficiency, India's national leadership sought to identify cultivators endowed with the daring, grit, and experimental character needed to actualize the promise of plenty. Drawing on Western modernization theory and the idioms of colonial and nationalist economics, India's bureaucrats and politicians contrasted the nation's “progressive farmers” with the passivity and superstition alleged to be characteristic of the majority of peasants, establishing crop competitions and the title of Krishi Pandit—“master farmer”—to reward and trumpet these qualities. Yet the progressive farmers winning these titles were not the agrarian poor, but rather an ascendant, self-cultivating peasantry armed with the capital and connections needed to raise their yields. In a subsequent era of egalitarian reform, exemplified in the Community Development Program, these same progressive farmers continued to bag awards but bucked planners' expectations that they would serve as natural leaders in villages. As these producers mobilized politically, and India's bureaucrats and politicians moved toward the Green Revolution consensus that agricultural productivity would require an inequitable concentration of inputs, progressive farmers emerged as “bullock capitalists,” a demand group that would transform national politics but do little for the aims of equity and rural development."
GEORGIOS ZERVAS,Extending snBench to Support Hierarchical and Configurable Scheduling,"It is useful in systems that must support multiple applications with various temporal requirements to allow application-specific policies to manage resources accordingly. However, there is a tension between this goal and the desire to control and police possibly malicious programs. The Java-based Sensor Execution Environment (SXE) in snBench presents a situation where such considerations add value to the system. Multiple applications can be run by multiple users with varied temporal requirements, some Real-Time and others best effort. This paper outlines and documents an implementation of a hierarchical and configurable scheduling system with which different applications can be executed using application-specific scheduling policies. Concurrently the system administrator can define fairness policies between applications that are imposed upon the system. Additionally, to ensure forward progress of system execution in the face of malicious or malformed user programs, an infrastructure for execution using multiple threads is described."
GEORGIOS ZERVAS,The Cache Inference Problem and its Application to Content and Request Routing,"In many networked applications, independent caching agents cooperate by servicing each other's miss streams, without revealing the operational details of the caching mechanisms they employ. Inference of such details could be instrumental for many other processes. For example, it could be used for optimized forwarding (or routing) of one's own miss stream (or content) to available proxy caches, or for making cache-aware resource management decisions. In this paper, we introduce the Cache Inference Problem (CIP) as that of inferring the characteristics of a caching agent, given the miss stream of that agent. While CIP is insolvable in its most general form, there are special cases of practical importance in which it is, including when the request stream follows an Independent Reference Model (IRM) with generalized power-law (GPL) demand distribution. To that end, we design two basic ""litmus"" tests that are able to detect LFU and LRU replacement policies, the effective size of the cache and of the object universe, and the skewness of the GPL demand for objects. Using extensive experiments under synthetic as well as real traces, we show that our methods infer such characteristics accurately and quite efficiently, and that they remain robust even when the IRM/GPL assumptions do not hold, and even when the underlying replacement policies are not ""pure"" LFU or LRU. We exemplify the value of our inference framework by considering example applications."
GEORGIOS ZERVAS,Adaptive Weighing Designs for Keyword Value Computation,"Attributing a dollar value to a keyword is an essential part of running any profitable search engine advertising campaign. When an advertiser has complete control over the interaction with and monetization of each user arriving on a given keyword, the value of that term can be accurately tracked. However, in many instances, the advertiser may monetize arrivals indirectly through one or more third parties. In such cases, it is typical for the third party to provide only coarse-grained reporting: rather than report each monetization event, users are aggregated into larger channels and the third party reports aggregate information such as total daily revenue for each channel. Examples of third parties that use channels include Amazon and Google AdSense. In such scenarios, the number of channels is generally much smaller than the number of keywords whose value per click (VPC) we wish to learn. However, the advertiser has flexibility as to how to assign keywords to channels over time. We introduce the channelization problem: how do we adaptively assign keywords to channels over the course of multiple days to quickly obtain accurate VPC estimates of all keywords? We relate this problem to classical results in weighing design, devise new adaptive algorithms for this problem, and quantify the performance of these algorithms experimentally. Our results demonstrate that adaptive weighing designs that exploit statistics of term frequency, variability in VPCs across keywords, and flexible channel assignments over time provide the best estimators of keyword VPCs."
GEORGIOS ZERVAS,"Fake It till you make it: reputation, competition, and Yelp review fraud","Consumer reviews are now part of everyday decision making. Yet the credibility of these reviews is fundamentally undermined when businesses commit review fraud, creating fake reviews for themselves or their competitors. We investigate the economic incentives to commit review fraud on the popular review platform Yelp, using two complementary approaches and data sets. We begin by analyzing restaurant reviews that are identified by Yelp’s filtering algorithm as suspicious, or fake—and treat these as a proxy for review fraud (an assumption we provide evidence for). We present four main findings. First, roughly 16% of restaurant reviews on Yelp are filtered. These reviews tend to be more extreme (favorable or unfavorable) than other reviews, and the prevalence of suspicious reviews has grown significantly over time. Second, a restaurant is more likely to commit review fraud when its reputation is weak, i.e., when it has few reviews or it has recently received bad reviews. Third, chain restaurants—which benefit less from Yelp—are also less likely to commit review fraud. Fourth, when restaurants face increased competition, they become more likely to receive unfavorable fake reviews. Using a separate data set, we analyze businesses that were caught soliciting fake reviews through a sting conducted by Yelp. These data support our main results and shed further light on the economic incentives behind a business’s decision to leave fake reviews."
GEORGIOS ZERVAS,You get what you give: theory and evidence of reciprocity in the sharing economy,"We develop an analytical framework of peer interaction in the sharing economy that incorporates reciprocity, the tendency to increase (decrease) effort in response to others’ increased (decreased) effort. In our model, buyers (sellers) can induce sellers (buyers) to exert more effort by behaving well themselves. We demonstrate that this joint increased effort can improve the utility of both parties and influence the market equilibrium. We also show that bilateral reputation systems, which allow both buyers and sellers to review each other, are more responsive to reciprocity than unilateral reputation systems. By rewarding reciprocal behavior, bilateral reputation systems generate trust among strangers and informally regulate their behavior. We test the predictions of our model using data from Airbnb, a popular peer-to-peer accommodation platform. We show that Airbnb hosts that are more reciprocal receive higher ratings, and that higher rated hosts can increase their prices. Therefore, reciprocity affects equilibrium prices on Airbnb through its impact on ratings, as predicted by our analytical framework."
GEORGIOS ZERVAS,Online reputation management: estimating the impact of management responses on consumer reviews,"We investigate the relationship between a firm’s use of management responses and its online reputation. We focus on the hotel industry and present several findings. First, hotels are likely to start responding following a negative shock to their ratings. Second, hotels respond to positive, negative, and neutral reviews at roughly the same rate. Third, by exploiting variation in the rate with which hotels respond on different review platforms and variation in the likelihood with which consumers are exposed to management responses, we find a 0.12-star increase in ratings and a 12% increase in review volume for responding hotels. Interestingly, when hotels start responding, they receive fewer but longer negative reviews. To explain this finding, we argue that unsatisfied consumers become less likely to leave short indefensible reviews when hotels are likely to scrutinize them. Our results highlight an interesting trade-off for managers considering responding: fewer negative ratings at the cost of longer and more detailed negative feedback."
GEORGIOS ZERVAS,The supply and demand effects of review platforms,"Review platforms such as Yelp and TripAdvisor aggregate crowd-sourced information about users' experiences with products and services. We analyze their impact on the hotel industry using a panel of hotel prices, sales and reviews from five US states over a 10-year period from 2005--2014. Both hotel demand and prices are positively correlated with their average ratings on TripAdvisor, Expedia and Hotels.com, and such correlations have grown over our sample period from a statistical zero in the base year to a substantial level today: a hotel rated one star higher on all the platforms on average has 25% higher demand, and charges 9% more. We argue that the price increases are due to a combination of revenue management and re-pricing: increased demand from higher ratings shifts hotels along an upward sloping supply curve, and also causes small but significant changes in the supply curve itself. A natural experiment in our data that caused abrupt changes in the ratings of some hotels but not others, suggests that these associations are causal. Building on this causal interpretation, we estimate heterogenous treatment effects, showing that the impact of review platforms on hotels varies by organization form and hotel class. Specifically, we show that independent hotels that had little outside reputation prior to the entry of review platforms stand to gain more than chains."
GEORGIOS ZERVAS,The rise of the sharing economy: estimating the impact of Airbnb on the hotel industry,"Peer-to-peer markets, collectively known as the sharing economy, have emerged as alternative suppliers of goods and services traditionally provided by long-established industries. We explore the economic impact of the sharing economy on incumbent firms by studying the case of Airbnb, a prominent platform for short-term accommodations. We analyze Airbnb's entry into the state of Texas, and quantify its impact on the Texas hotel industry over the subsequent decade. We estimate that in Austin, where Airbnb supply is highest, the causal impact on hotel revenue is in the 8-10% range; moreover, the impact is non-uniform, with lower-priced hotels and those hotels not catering to business travelers being the most affected. The impact manifests itself primarily through less aggressive hotel room pricing, an impact that benefits all consumers, not just participants in the sharing economy. The price response is especially pronounced during periods of peak demand, such as SXSW, and is due to a differentiating feature of peer-to-peer platforms -- enabling instantaneous supply to scale to meet demand."
ELIZABETH RANDALL,Rurality or distance to care and the risk of homelessness among Afghanistan and Iraq veterans,"INTRODUCTION: To date, no studies have examined the relationship of rurality and distance to nearest VA facility to risk of homelessness. METHODS: We examined differences in the rate of homelessness within a year of a Veteran's first encounter with the VA following last military separation based on rurality and distance to the nearest VA facility using multivariable log-binomial regressions. RESULTS: In our cohort of 708,120 Veterans, 73% were determined to have a forwarding address in urban areas, 59.2% and 86.7% lived within 40 miles of the nearest VA medical center (VAMC), respectively. Veterans living in a rural area and those living between 20+ miles away from the nearest VAMC were at a lower risk for homelessness. CONCLUSIONS: Our unique dataset allowed us to explore the relationship between geography and homelessness. These results are important to policy makers in understanding the risk factors for homelessness among Veterans and planning interventions."
ELIZABETH RANDALL,Buildout and integration of an automated high-throughput CLIA laboratory for SARS-CoV-2 testing on a large urban campus,"In 2019, the first cases of SARS-CoV-2 were detected in Wuhan, China, and by early 2020 the first cases were identified in the United States. SARS-CoV-2 infections increased in the US causing many states to implement stay-at-home orders and additional safety precautions to mitigate potential outbreaks. As policies changed throughout the pandemic and restrictions lifted, there was an increase in demand for COVID-19 testing which was costly, difficult to obtain, or had long turn-around times. Some academic institutions, including Boston University (BU), created an on-campus COVID-19 screening protocol as part of a plan for the safe return of students, faculty, and staff to campus with the option for in-person classes. At BU, we put together an automated high-throughput clinical testing laboratory with the capacity to run 45,000 individual tests weekly by Fall of 2020, with a purpose-built clinical testing laboratory, a multiplexed reverse transcription PCR (RT-qPCR) test, robotic instrumentation, and trained staff. There were many challenges including supply chain issues for personal protective equipment and testing materials in addition to equipment that were in high demand. The BU Clinical Testing Laboratory (CTL) was operational at the start of Fall 2020 and performed over 1 million SARS-CoV-2 PCR tests during the 2020-2021 academic year."
MAKARAND MODY,The accommodation experiencescape: a comparative assessment of hotels and Airbnb,"PURPOSE: Accommodations providers in the sharing economy are increasingly competing with the hotel industry vis-à-vis the guest experience. Additionally, experience-related research remains underrepresented in the hospitality and tourism literature. This paper aims to develop and test a model of experiential consumption to provide a better understanding of an emerging phenomenon in the hospitality industry. In so doing, the authors also expand Pine and Gilmore’s original experience economy construct. DESIGN/METHODOLOGY/APPROACH: Using data from a survey of 630 customers who stayed at a hotel or an Airbnb in the previous three months, the authors performed a multi-step analysis procedure centered on structural equation modeling to validate the model. Findings The authors demonstrate that the dimensions of serendipity, localness, communitas and personalization represent valuable additions to Pine and Gilmore’s original experience economy construct. Airbnb appears to outperform the hotel industry in the provision of all experience dimensions. The authors further define the pathways that underlie the creation of extraordinary, memorable experiences, which subsequently elicit favorable behavioral intentions. PRACTICAL IMPLICATIONS: The findings suggest the need for the hotel industry to adopt a content marketing paradigm that leverages various dimensions of the experience economy to provide customers with valuable and relevant experiences. The industry must also pay greater attention to its use of branding, signage and promotional messaging to encourage customers to interpret their experiences through the lens of these dimensions. ORIGINALITY/VALUE: The study expands a seminal construct from the field of services marketing in the context of the accommodations industry. The Accommodations Experiencescape is offered as a tool for strategic experience design. The study also offers a model of experiential consumption that explains customers’ experiences with accommodations providers."
MAKARAND MODY,The different shades of responsibility: examining domestic and international travelers' motivations for responsible tourism in India,"To address the scarcity of research concerning the demand side of responsible tourism, the present study examines the motivations of domestic and international travelers in India. Data were collected using an Internet survey distributed via e-mail and Facebook to the clients of five responsible tourism operators in India. Using Dann's push–pull typology, factor analysis uncovered nine underlying motivations for responsible tourism, with significant differences between domestic and international travelers for these factors. Cluster analysis revealed three distinct segments of travelers – Responsibles, Novelty Seekers, and Socializers – that differ in their core underlying motivations for responsible tourism and in their socio-demographic characteristics. The study contributes one responsibility-specific push and one pull factor to the literature about travel motivation. Also the findings suggest that operators and destination marketers must develop their products and marketing communications to address the heterogeneity of motivations underlying responsible tourism."
MAKARAND MODY,Restorative servicescapes in health care: examining the influence of hotel-like attributes on patient well-being,"This study examines how 527 patients across different health states assessed the influence of hotel-like attributes on their well-being. Using theoretical mechanisms of attention restoration underlying restorative servicescapes, we postulated that hotel-like products and services will enhance patients’ perceived well-being, which, in turn, will favorably affect their behavioral intentions. We also tested an alternative model that included additional direct relationships between hotel-like products and services and behavioral intentions, based on the tenets of cue utilization theory. After conducting a series of nested model comparison procedures, we confirmed that the alternative model provided a theoretically and empirically stronger explanation for the dynamics of hotel-like restorative servicescapes. Although the differences between less healthy and more healthy patients were not statistically significant, the less healthy group demonstrated the same pattern of relationships as in the overall model, indicating that such patients may be more likely to derive greater restorative benefits from hotel-like hospital rooms, which may also make them more likely to pay higher out-of-pocket expenses for such rooms. The study furthers the empirical research agenda on evidence-based design (EBD) and the role of hospitality in health care."
MAKARAND MODY,Adding evidence to the debate: quantifying Airbnb's disruptive impact on ten key hotel markets,"Airbnb's entry into the lodging landscape has dramatically increased the available supply of rooms for accommodating prospective visitors at a destination. In a competitive market, an increase in supply while keeping demand relatively constant would decrease prices and revenues. While Airbnb is expected to negatively impact the hotel industry, the effects of Airbnb on the performance of the hotel industry have not been extensively quantified. Also, existing studies on Airbnb's economic impacts are limited in their inferential, temporal, and/or geographical scope. In view of this gap in the literature, the present study examines the effects of Airbnb supply on key hotel performance metrics: room revenues (RevPAR), average daily rates (ADR), and occupancy rates (OCC) in ten major U.S. hotel markets for the period between July 2008 and June 2017. The results demonstrate that an increasing Airbnb supply negatively impacts all three performance metrics within the hotel industry. Moreover, while previous research has demonstrated a negative impact on lower-end hotels, our findings provide evidence of Airbnb's growing impact on the mainstream market across hotel class segments, signaling a high level of consistency with the tenets of the theory of disruptive innovation. The magnitude of these effects is not only statistically but also economically significant. Theoretical and practical implications are discussed."
MAKARAND MODY,Hospitality healthscapes: a conjoint analysis approach to understanding patient responses to hotel-like hospital rooms,"In an increasingly competitive market, healthcare providers are incorporating best practices from the hospitality industry to improve the patient experience. The present study offers a model of hospitality healthscapes to provide a patient-based perspective of the infusion of hospitality into healthcare. A study of 406 respondents examined the hotel-like attributes that patients prefer in hospital rooms and the effect of their provision on patients’ well-being and willingness to pay higher out-of-pocket expenses. Using conjoint analysis and 3D visual representations of hospital rooms, the study found that high-end material finishes and hospitality-certified healthcare staff were the two greatest influences on patient choice. The study also found some differences between the preferences of “less healthy” and “more healthy” patients, with the less healthy patients willing to pay, on average, 13% higher out-of-pocket expenses for hotel-like hospital rooms than the more healthy patients. This study represents the first attempt in the evidence-based design literature to holistically and empirically examine the infusion of hospitality into healthcare by emphasizing the “patient as customer.” The findings have important marketing implications for healthcare providers who wish to enhance the patient experience."
MAKARAND MODY,Boston Hospitality Review: Spring 2017,
MAKARAND MODY,Integrating country and brand images: Using the product-Country image framework to understand travelers' loyalty towards responsible tourism operators,"While much research into loyalty has been conducted at the destination level, tourists' loyalty towards their intermediary has not been considered. To address this gap, the present study develops a model of tourists' loyalty towards responsible tourism operators by integrating two streams of literature. The first stream pertains to branding, consumer behavior, and international business, specifically Product-Country Image (PCI), while the second stream pertains to the extensive work concerning the concepts of destination image and destination loyalty in tourism. Data were collected using an Internet survey of domestic and international travelers to five responsible tourism operators in India. Results indicate that tourists' motivations to participate in responsible tourism and their perceptions of the destination and the operator's brand constitute the determinants of their attitudinal and behavioral loyalty towards their operator. The study advances the PCI framework in the context of tourism, thus contributing to the literature on image measurement and also extending place image theory. The findings have important product development and positioning implications for operators and destination marketers in India."
MAKARAND MODY,Examining the motivations for social entrepreneurship using Max Weber's typology of rationality,"PURPOSE: This paper aims to utilize a framework from classic sociology – Max Weber’s Typology of Rationality – to understand the motivations for social entrepreneurship in responsible tourism in India. The critical role of the social entrepreneur in effecting the phenomenon of social entrepreneurship has been largely under-recognized. The authors seek to explore, develop and enhance Weber’s theoretical arguments in the context of the tourism industry. Design/methodology/approach The authors used a constructivism paradigm and Seidman’s (2006) Three Interview Series technique to obtain the narratives of two social entrepreneurs in India. Data were analyzed using a hybrid thematic coding procedure. FINDINGS: Findings indicate that there exists a dynamic interplay between the formal and substantive rationalities that underlie the behavior of social entrepreneurs. The authors also discuss how entrepreneurs draw upon their formal and substantive repertoires to create their identities through the simultaneous processes of apposition (“Me”) and opposition (“Not Me”). PRACTICAL IMPLICATIONS: The findings provide an important recognition of the impact of formal and substantive rationalities on the conceptualization, implementation and manifestation of social enterprise for a variety of stakeholders. ORIGINALITY/VALUE: This paper makes a significant contribution to understanding the why and the how of social entrepreneurship in responsible tourism. It provides a framework that can be widely applied to develop and enhance Weberian theory and further the understanding of the fundamental nature of human behavioral phenomena in tourism and beyond."
MAKARAND MODY,Consumption authenticity in the age of the sharing economy: The key to creating loyal customers who love your brand,"Airbnb continues to gain popularity as an accommodation alternative to hotels, with the authenticity of the consumption experience being a critical differentiating factor. However, the hospitality literature has not fully explored whether and how brands in the sharing economy as well as traditional hotel brands are facilitating authentictravel experiences and the impact of these experiences on brand love and brand loyalty. The purpose of this study is twofold. First, we develop a model of consumption authenticity in the accommodations industry and identify, operationalize, and measure its components. Second, we examine the impact of consumption authenticity on brand love and brand loyalty in both hotels and Airbnb accommodations. By surveying 1,256 American participants recruited from Amazon Mechanical Turk, we found that Airbnb leverages brand, existential, and intra-personal consumption authenticity in creating brand-loving and brand-loyal customers, while hotels utilize only brand authenticity. Implications for theory and practice are discussed, and areas of future research are identified."
MAKARAND MODY,Gaming can be sustainable too! Using Social Representation Theory to examine the moderating effects of tourism diversification on residents' tax paying behavior,"Tourism authorities in the Las Vegas region have suggested the diversification of the tourism industry as a strategy to improve the vitality of rural communities outside of the metropolitan area. The present study uses Social Representation Theory as the conceptual basis to test the moderating effects of the various types of proposed tourism development on residents' willingness to pay higher taxes to support such development. A survey of 301 residents in Las Vegas rural communities examined how the factors of economic dependence on tourism, community attachment, and ecocentric attitude towards tourism influence residents' perceptions of tourism's impacts. A higher economic dependence on tourism and higher levels of community attachment led to more favorable perceptions of tourism's economic and social impacts. The economic impacts, in turn, resulted in a willingness to pay higher taxes, irrespective of the type of tourism development proposed by the Las Vegas authorities. The results suggest that rural communities reinforce a hegemonic social representation of tourism in order to characterize the ethos of capitalist urbanism that pervades the economic development discourse. The residents' social construction of tourism has important implications for tourism planners in the region and suggests the adoption of an inclusive tourism diversification strategy that leverages both gaming and alternative tourism."
MAKARAND MODY,Study abroad and the development of college students' travel venturesomeness,
MAKARAND MODY,The influence of hospitable design and service on patient responses,"A study of 216 respondents examined a medical center environment’s influence on patient responses. A stimulus–organism–response (S-O-R) model was adapted to the theory that more hospitable healthcare servicescape elements will affect patients’ overall satisfaction with healthcare experience, loyalty intentions, and willingness to pay out-of-pocket expenses for healthcare services. Servicescape elements included atmospherics of the healthcare environment, service delivery by healthcare staff, physical design of the healthcare environment, and wayfinding. Results of structural equation modeling confirmed that the four servicescape elements – had a significant impact on patients’ overall satisfaction with the healthcare experience. Furthermore, overall satisfaction with the healthcare experience predicted patients’ loyalty intentions and willingness to pay out-of-pocket expenses for healthcare services. The study makes a significant contribution to the empirical modeling of patients’ behavioral responses to hospitable healthcare environments."
MAKARAND MODY,The augmented convention offering: the impact of destination and product images on attendees' perceived benefits,"In order to benefit from the significant dual spending of meetings, incentives, conventions/conferences, exhibitions/events (MICE) attendees, destination marketers have attempted to identify key success criteria that enable increased convention and exhibition participation. Given the significant growth of the MICE industry in Asia, this study examines the role of destination and product images on Chinese attendees' perceptions of the benefits acquired through convention and exhibition participation in the regions of Macau and Hong Kong. Data were collected using an intercept survey and a systematic random sampling procedure. Structural Equation Modeling was used to test a model that integrates two strands of literature from the fields of marketing and international business: Product–Country Image (PCI) and the Augmented Service Offering (ASO). Results show that a favorable overall destination image positively impacts the image of the MICE product of the destination, which, in turn, leads to a greater perception of personal and professional benefit acquisition. Based on these findings, the authors propose the Augmented MICE Offering as a theoretical framework that can serve as a foundation for more comprehensive inquiry into the decision-making process of the MICE attendee and postattendance behavioral impacts. The study also provides important positioning and communication implications for MICE destinations."
MAKARAND MODY,Creating Memorable Experiences in the Accommodations Industry: A Core-Periphery Framework of Experiential Consumption,
MAKARAND MODY,Hotel-like hospital rooms' impact on patient well-being and willingness to pay: An examination using the theory of supportive design,"While there is increasing evidence to suggest the importance of the provision of hospitality in healthcare settings, research on these developments remains under-represented, particularly in the hospitality literature. In response, the present study builds on Ulrich’s (1991) Theory of Supportive Design to examine patient responses to hotel-like features in a hospital room. Specifically, the study examines how features that foster a sense of control, create positive distractions, and provide access to social support influence patients’ well-being, and subsequently, their likelihood to choose hotel-like hospital rooms and their willingness to pay higher out-of-pocket expenses for such rooms. [TRUNCATED]"
MAKARAND MODY,Examining the Personal and Institutional Determinants of Research Productivity in Hospitality and Tourism Management,"The transition toward a post-capitalist knowledge-oriented economy has resulted in an increasingly competitive academic environment, where the success of faculty is dependent on their research productivity. This study examines the personal and institutional determinants of the quantity and quality of the research productivity of hospitality and tourism management faculty in US institutions. A survey of 98 faculty found that a different set of determinants impact the quantity and quality aspects of research productivity. Also, institutional determinants were found to play a larger role, indicating the need for administrators to strive for a culture that is supportive of and an infrastructure that is conducive to their faculty’s research success. The authors use the field of hospitality and tourism management as a case study to develop a holistic and cohesive framework for knowledge worker productivity that can guide the evaluation, hiring, and development of researchers."
MAKARAND MODY,The Influence of a Hospitable Healthcare Environment on Patient Emotions and Behavioral Responses,"A structural model is proposed and empirically examined that investigates the influence of a medical center’s environment on patient responses. A stimulus-organism-response (S-O-R) model, often used to frame hospitality service research, is adapted as the basis of the theory that elements included in a healthcare Servicescape will affect emotional responses of patients, which in turn influence their overall satisfaction with experience and likelihood to return, recommend to others, and willingness to pay higher out of pocket expenses behavioral intentions. Analyzed elements of the Servicescape include physical design, layout, atmospherics, and service delivery."
MAKARAND MODY,Boston Hospitality Review: Fall 2017,
MAKARAND MODY,Platforms in the peer-to-peer sharing economy,"Purpose – This article examines peer-to-peer sharing platform business models, their sources of competitive advantage, and the roles, motivations, and behaviors of key actors in their ecosystems. Design/methodology/approach – This paper uses a conceptual approach that is rooted in the service, tourism and hospitality, and strategy literature. Findings – First, this paper defines key types of platform business models in the sharing economy and describes their characteristics. In particular, we propose the differentiation between sharing platforms of capacity-constrained versus capacity-unconstrained assets and advance five core properties of the former. Second, we contrast platform business models with their pipeline business model counterparts to understand the fundamental differences between them. One important conclusion is that platforms cater to vastly more heterogeneous assets and consumer needs, and therefore, require liquidity and analytics for high quality matching. Third, we examine the competitive position of platforms and conclude that their widely taken “winner takes it all” assumption is not valid. Primary network effects are less important once a critical level of liquidity has been reached and may even turn negative if increased listings raise friction in the form of search costs. Once a critical level of liquidity has been reached, a platform’s competitive position depends on stakeholder trust and service provider and user loyalty. Fourth, we integrate and synthesize the literature on key platform stakeholders of platform businesses (i.e. users, service providers, and regulators) and their roles and motivations. Finally, directions for further research are advanced. Practical implications – This article helps platform owners, service providers, and users understand better the implications of sharing platform business models and how to position themselves in such ecosystems. Originality/value – This article integrates the extant literature on sharing platforms, takes a novel approach in delineating their key properties and dimensions, and provides insights into the evolving and dynamic forms of sharing platforms including converging business models."
MAKARAND MODY,Making better places to visit: Using the product—country image framework to understand travelers’ loyalty towards responsible tourism operators,The present study examines the antecedents of travelers’ loyalty towards responsible tourism operators in India. A model of brand loyalty was developed by integrating two strands of literature: product—country Image (PCI) and extensive work concerning the concepts of destination image and destination loyalty. Results indicate tourists’ motivations to participate in responsible tourism and their perceptions of the destination and the operator’s brand constitute the determinants of their attitudinal and behavioral loyalty towards their operator.The study adds to our understanding of the demand side of responsible tourism while extending place image theory.
MAKARAND MODY,Consumption authenticity in the age of the sharing economy: the keys to creating loyal customers who love your brand,"Airbnb has gained popularity as an alternative to hotels, with the authenticity of the consumption experience being a critical differentiating factor. However, the hospitality and tourism literature has not fully explored how Airbnb and traditional hotel brands are facilitating authentic travel experiences and the impact of these experiences on brand love and brand loyalty. In this study, we explore three elements of consumption authenticity and examine their how they interact in the context of an accommodation brand. Second, we compare the components of consumption authenticity across hotels and Airbnb, and examine their relative impact on brand love for these two segments of the accommodations industry. We found that hotels and Airbnb draw upon different sources of authenticity to create brand-loving customers. Our results indicated that Airbnb leverages brand, existential, and intrapersonal authenticity in creating brand-loving and brand-loyal customers, while hotels utilize only brand authenticity. Thus, the keys to creating customers who love and are loyal to the brand differ between hotels and Airbnb. Implications for theory and practice are discussed, and areas of future research are identified."
MAKARAND MODY,Boston Hospitality Review: Winter 2018,
MAKARAND MODY,Boston Hospitality Review: Fall 2018,
MAKARAND MODY,Boston Hospitality Review: Winter 2019,
MAKARAND MODY,Boston Hospitality Review: Spring 2016,
MAKARAND MODY,Airbnb 2.0: is it a sharing economy platform or a lodging corporation?,"Research on Airbnb has provided significant evidence that it has an adverse impact on hotel performance. However, the impact of a more recent Airbnb-related phenomenon that remains under-explored is the increasing professionalization of Airbnb and the prevalence of multi-unit hosts who offer more than one listing on the platform and are typically more dynamic in terms of issues like managing inventory and providing more standardized experiences. This professionalization begs the question of whether Airbnb should be considered a sharing economy platform or a lodging corporation (Airbnb 2.0). To answer this question, the present study identifies which types of Airbnb properties (entire homes, private rooms, or shared rooms) and host structures (single- or multi-unit hosts) are the biggest threats to traditional lodging companies in the U.S., and which states are most affected by the presence of Airbnb. The findings have significant implications for researchers and many practitioners associated with the phenomenon."
MAKARAND MODY,Using segmentation to compete in the age of the sharing economy: testing a core-periphery framework,"Airbnb has emerged as a credible competitive threat to the hotel industry. Consequently, hotel brands are having to rethink the experiences they provide to customer in an increasingly competitive environment. Despite these trends in the industry, experience-related research that examines and informs these developments remains under-represented in the hospitality and tourism literature. The present study offers a systematic approach to examine the potential differences in experiential consumption in the accommodations industry. Using a multiple-group analysis approach, it examines the moderating effects of individual characteristics and situational factors on the nature and dynamics of experiential consumption in the accommodations industry. The findings of the study culminate in the core-periphery framework of the hospitality consumption experience that can provide a relevant theoretical lens for future research into the different sectors and types of experiences within the hospitality and tourism industry. The study also outlines important implications for the hotel industry’s strategic experience design initiatives, from the standpoint of product development, the segmentation, targeting and positioning (STP) process, and marketing communications."
MAKARAND MODY,Not in my backyard? Is the anti-Airbnb discourse truly warranted?,
MAKARAND MODY,Going back to its roots: can hospitableness provide hotels competitive advantage over the sharing economy?,"While the customer experience is at the heart of the hospitality industry, experience-related research remains underrepresented. This gap is critical, particularly given the emerging threat of the sharing economy to the hotel industry along experiential factors. Using data from a survey of 630 customers who stayed at a hotel or an Airbnb, the authors use structural equation modeling to compare two models with alternative conceptualizations of the dynamics of experiential consumption in the accommodations industry. Building on the concept of the experiencescape from the branding and hospitality and tourism literatures, the model enhances Pine and Gilmore’s (1998) original experience economy construct by demonstrating the critical role of the dimension of hospitableness in facilitating favorable experiential and brand-related outcomes, particularly in the context of the hotel experience. The findings have important implications for the hotel industry’s strategic experience design initiatives and emphasize the need to use hospitableness in order to create a competitive advantage in a rapidly changing environment."
DAVID GLICK,2020 Menino Survey of Mayors: policing and protests,"The 2020 Menino Survey of Mayors represents the seventh nationally representative survey of American mayors and is based on interviews with 130 sitting mayors from 38 states. The 2020 Survey explores mayoral views on COVID-19 recovery, policing and protests, parks and greenspace, and the 2020 Census. The third set of findings, released in January 2021, explores mayors’ recognition of racial inequality, their roles during protests in their communities, and how they hope to reform their police departments. The 2020 Survey continues with the support of Citi and The Rockefeller Foundation."
DAVID GLICK,2020 Menino Survey of Mayors: Urban parks and the public realm: equity & access in post-COVID cities,
DAVID GLICK,Cities in American federalism: evidence on state-local government conflict from a survey of mayors,"Previous scholarship on American federalism has largely focused on the national government's increasingly conflictual relationship with the states. While some studies have explored the rise of mandates at the state level, there has been comparatively less attention on state–local relationships. Using a new survey of mayors, we explore variations in local government attitudes towards their state governments. We find some evidence that, regardless of partisanship, mayors in more conservative states are unhappy about state funding and—especially—regulations. More strikingly, we also uncover a partisan mismatch in which Democratic mayors provide especially negative ratings of their state’s funding and—even more strongly—regulations. These findings have important implications for state–local relations as cities continue to become more Democratic and Republicans increasingly dominate state-level contests."
DAVID GLICK,"As the Trump administration retreats on climate change, US cities are moving forward",
DAVID GLICK,Partisanship and preemption: mayors on local autonomy,Contribution to spotlight in PS: Political Science & Politics: Home Rule Be Damned: Exploring Policy Conflicts between the Statehouse and City Hall
DAVID GLICK,2018 Menino Survey of Mayors,"The 2018 Menino Survey of Mayors represents the fifth scientifically rigorous and nationally representative survey of American mayors released by the Boston University Initiatives on Cities and supported by Citi Community Development and The Rockefeller Foundation. The Survey, based on interviews with 110 sitting mayors conducted in 2018, reveals mayoral views on economic development—including corporate recruitment, financial incentives, the sharing economy, and social mobility—as well as public health, housing, and intergovernmental relations."
DAVID GLICK,Do mayors run for higher office? New evidence on progressive ambition,"The mayor’s office potentially offers a launchpad for statewide and national political ambitions. We know relatively little, however, about how frequently mayors actually run for higher office, and which mayors choose to do so. This article combines longitudinal data on the career paths of the mayors of 200 big cities with new survey and interview data to investigate these questions. While we find that individual and city traits—especially gender—have some predictive power, the overwhelming story is that relatively few mayors—just under one-fifth—ever seek higher office. We suggest that ideological, institutional, and electoral factors all help to explain why so few mayors exhibit progressive ambition."
DAVID GLICK,Gaps and opportunities: supporting Boston’s BIPOC small businesses,"This report captures small business service providers’ views on the most salient challenges confronting Boston’s Black, Indigenous, and people of color (BIPOC) small business owners and entrepreneurs, and their priorities for the future. The report draws on 30 in-depth survey interviews, conducted between November 2021 and February 2022, with leaders from the ecosystem of organizations that are focused on supporting the growth of BIPOC small businesses. The report also juxtaposes the viewpoints and priorities of Boston’s ecosystem against America’s mayors using findings from the national Menino Survey of Mayors."
DAVID GLICK,Mayoral views on economic incentives: valuable tools or a bad use of resources?,"Mayoral Views on Economic Incentives: Valuable Tools or a Bad Use of Resources? explores which types of cities and mayors embrace – or reject – tax concessions and subsidies to attract or retain business. The authors find considerable variation in how individual mayors think about these issues; personal traits of the mayor (e.g., party and time in office) and city level characteristics (e.g., economic performance) do not predict their views on economic incentives. The absence of clear patterns suggests to the authors that the supposedly omnipresent pressure to provide inducements to business investment is not the recurring, vivid presence in the lives of mayors that we might expect."
DAVID GLICK,"2022 Menino Survey of Mayors: economic opportunity, poverty & well-being","The 2022 Menino Survey of Mayors represents the ninth nationally representative survey of American mayors and is based on interviews with 118 sitting mayors from 38 states. The 2022 Survey explores mayoral views on climate and energy, poverty and rising costs of living, and health and safety. The second and final set of findings, released in April 2023, analyzes mayors’ views on key economic challenges – including poverty and the rising cost of living – and tools they can use at the local level. It also investigates what mayors perceive to be the main public health and public safety challenges in their communities. The 2022 Survey continues with the support of The Rockefeller Foundation."
DAVID GLICK,Mayoral views on racism and discrimination,"This report, which draws on data from the 2017 Menino Survey of Mayors, explores how mayors of medium-sized and large cities understand race, discrimination and equity in their communities and on a national level. The report cites three key findings: 1) Mayors believe that the four groups most discriminated against in their cities and across the country are immigrants, transgender individuals, black people and Muslims. In relation to these group and others, mayors perceive far more discrimination in the country as a whole than in their own communities. 2) Mayors believe that access to public services is significantly better for white people than for people of color, except for subsidized housing. More than half of all mayors report that white people have better access to jobs, educational opportunities, housing and healthcare, and are treated better by police and the courts. 3) While mayors see disparities in access to services, they overwhelmingly believe that the quality of services is largely equal across different groups of people, except for educational services, which they think is worse for people of color. The report also highlights several successful initiatives that cities, including Anaheim, Boston, Louisville and New Orleans, have undertaken in combating discrimination."
DAVID GLICK,"Recruiting large online samples in the United States and India: Facebook, Mechanical Turk and Qualtrics","This article examines online recruitment via Facebook, Mechanical Turk (MTurk), and Qualtrics panels in India and the United States. It compares over 7300 respondents—1000 or more from each source and country—to nationally representative benchmarks in terms of demographics, political attitudes and knowledge, cooperation, and experimental replication. In the United States, MTurk offers the cheapest and fastest recruitment, Qualtrics is most demographically and politically representative, and Facebook facilitates targeted sampling. The India samples look much less like the population, though Facebook offers broad geographical coverage. We find online convenience samples often provide valid inferences into how partisanship moderates treatment effects. Yet they are typically unrepresentative on such political variables, which has implications for the external validity of sample average treatment effects."
DAVID GLICK,City learning: evidence of policy information diffusion from a survey of U.S. mayors,"Most studies of policy diffusion attempt to infer the processes through which policies spread by observing outputs (policy adoptions). We approach these issues from the other direction by directly analyzing a key policymaking input—information about others’ policies. Moreover, we do so by investigating policy diffusion in cities rather than states. Using a survey of U.S. mayors, more specifically, mayors’ own lists of cities they look to for ideas, we find evidence that distance, similarity, and capacity all influence the likelihood of a policy maker looking to a particular jurisdiction for policy information. We also consider whether these traits are complements or substitutes and provide some evidence for the latter. Specifically, we find that, at times, mayors eschew similarity and distance to look to highly respected “high capacity” cities but that there is no tradeoff between distance and similarity."
DAVID GLICK,Who participates in local government? Evidence from meeting minutes,"Scholars and policymakers have highlighted institutions that enable community participation as a potential buffer against existing political inequalities. Yet these venues may bias policy discussions in favor of an unrepresentative group of individuals. To explore who participates, we compile a novel data set by coding thousands of instances of citizens speaking at planning and zoning board meetings concerning housing development. We match individuals to a voter file to investigate local political participation in housing and development policy. We find that individuals who are older, male, longtime residents, voters in local elections, and homeowners are significantly more likely to participate in these meetings. These individuals overwhelmingly (and to a much greater degree than the general public) oppose new housing construction. These participatory inequalities have important policy implications and may be contributing to rising housing costs."
DAVID GLICK,Does race affect access to government services? An experiment exploring street-level bureaucrats and access to public housing,"While experimental studies of local election officials have found evidence of racial discrimination, we know little about whether these biases manifest in bureaucracies that provide access to valuable government programs and are less tied to politics. We address these issues in the context of affordable housing programs using a randomized field experiment. We explore responsiveness to putative white, black, and Hispanic requests for aid in the housing application process. In contrast to prior findings, public housing officials respond at equal rates to black and white email requests. We do, however, find limited evidence of responsiveness discrimination toward Hispanics. Moreover, we observe substantial differences in email tone. Hispanic housing applicants were 20 percentage points less likely to be greeted by name than were their black and white counterparts. This disparity in tone is somewhat more muted in more diverse locations, but it does not depend on whether a housing official is Hispanic."
DAVID GLICK,Mayoral Policy Making: Results from the 21st Century Mayors Leadership Survey,"Mayoral Policy-Making: Results from the 21st Century Mayors Leadership survey represents the first nationally representative survey of American mayoral priorities. The report, released by the Boston University Initiative on Cities, is based on interviews with over seventy American mayors from cities of all sizes and affluence. Sitting mayors offered their perspectives on challenges facing their cities, personal policy priorities and planned political capital expenditures, and responded to a series of trade off questions related to gentrification, income inequality and climate change. It highlights the importance mayors place on the physical, fiscal and social infrastructure of their cities, and – contrary to prior research - suggests that party affiliation has a significant influence on mayoral priority-setting."
DAVID GLICK,2022 Menino Survey of Mayors: mayors and the climate crisis,"The 2022 Menino Survey of Mayors represents the ninth nationally representative survey of American mayors and is based on interviews with 118 sitting mayors from 38 states. The 2022 Survey explores mayoral views on climate and energy, poverty and rising costs of living, and health and safety. The first set of findings, released in January 2023, delves into mayors’ current views on local climate action, focusing on their beliefs about the underlying issues and threats, their sense of the tools they have at their disposal, and their enthusiasm for using them. The 2022 Survey continues with the support of The Rockefeller Foundation."
DAVID GLICK,2019 Menino Survey of Mayors,"The 2019 Menino Survey of Mayors represents the sixth nationally representative survey of American mayors and is based on interviews with 119 sitting mayors from 38 states. The 2019 Survey explores mayoral views on issues ranging from infrastructure and transportation priorities — including mobility and public safety — to the changing nature of work. The 2019 Survey also provides the first in-depth examination of mayors’ reactions to and expectations for the Opportunity Zones program, a significant new federal initiative to stimulate urban development. The 2019 Survey continues with the support of Citi Community Development and The Rockefeller Foundation."
DAVID GLICK,2021 Menino Survey of Mayors: Building back better,"The 2021 Menino Survey of Mayors represents the eighth nationally representative survey of American mayors and is based on interviews with 126 sitting mayors from 39 states. The 2021 Survey explores mayoral views on COVID-19 recovery, equity and small business, closing the racial wealth gap, and housing and homelessness. The first set of findings, released in November 2021, delves into the challenges mayors are facing in light of the ongoing pandemic—and the extent to which massive support from the federal government has helped to fill the gap."
DAVID GLICK,2017 Menino Survey of Mayors,"The 2017 Menino Survey of Mayors represents the fourth scientifically rigorous and nationally representative survey of American mayors released by the Boston University Initiatives on Cities. The Menino Survey, based on interviews with 115 sitting mayors conducted in 2017, provides insight into mayoral priorities, policy views and relationships with their key partners, including other levels of government. Researchers spoke with mayors about a range of topics including affordable housing, climate change, city-to-city networks, and data-driven decision-making."
DAVID GLICK,Counting the city: mayoral views on the 2020 Census,"As the 2020 Census concludes at the end of September, a large majority of the mayors of America’s major cities are extremely concerned that their cities’ populations will be undercounted. According to Boston University’s 2020 Menino Survey of Mayors – the only national representative survey of American mayors – 82% of local leaders are “very” or “somewhat concerned” about undercounting their cities’ populations; only 6% of mayors were “not concerned at all.” While there is a small partisan difference in level of concern (19% of Republican mayors are “not concerned at all” compared to 4% of Democratic mayors), nearly two-thirds of Republican mayors are somewhat or very concerned that their populations will be undercounted."
DAVID GLICK,2021 Menino Survey of Mayors: Closing the racial wealth gap,"The 2021 Menino Survey of Mayors represents the eighth nationally representative survey of American mayors and is based on interviews with 126 sitting mayors from 39 states. The 2021 Survey explores mayoral views on COVID-19 recovery, equity and small business, closing the racial wealth gap, and housing and homelessness. The third and final set of findings, released in March 2022, explores how mayors are approaching the racial wealth gap in their cities."
DAVID GLICK,2020 Menino Survey of Mayors: COVID-19 recovery and the future of cities,"The 2020 Menino Survey of Mayors details insights and perspectives shared by a representative sample of 130 mayors leading U.S. cities with populations of more than 75,000 residents. This year’s Survey explores mayoral views on COVID-19 recovery and implications, policing and protests, parks and greenspace, and the 2020 Census. This report focuses on the COVD-19 related findings and outlines mayors’ responses to the global pandemic, perceptions of its impact, and expectations for the future of their cities. The 2020 Survey continues with the support of Citi and The Rockefeller Foundation."
DAVID GLICK,2015 Menino Survey of Mayors,"The 2015 Menino Survey of Mayors represents the second nationally representative survey of American mayors released by the Boston University Initiatives on Cities. The Survey, based on interviews with 89 sitting mayors conducted in 2015, provides insight into mayoral priorities, policy views and relationships with their key partners, including other levels of government. Sitting mayors shared insight on their specific infrastructure needs and spending priorities, from roads and transit to water treatment and bike lanes, and reacted to police reforms proposed by the White House. They also shed light on the difficult choices they must often make, to promote affordable housing or improve the fiscal health of their city. A significant portion of the Survey is devoted to mayoral leadership, including areas of mayoral control and constituent approval, as well as constraints they confront under increasingly politicized and polarized state legislatures."
DAVID GLICK,"Mayors, partisanship, and redistribution: evidence directly from U.S. mayors","Policymakers and scholars are increasingly looking to cities to address challenges including income inequality. No existing research, however, directly and systematically measures local political elites’ preferences for redistribution. We interview and survey 72 American mayors—including many from the nation’s largest cities—and collect public statements and policy programs to measure when and why mayors prioritize redistribution. While many of the mayors’ responses are consistent with being constrained by economic imperatives, a sizable minority prioritize redistributive programs. Moving beyond the question of whether mayors support redistribution, we find that partisanship explains much of the variation in a mayor’s propensity for redistribution. Moreover, the impact of partisanship very rarely varies with institutional and economic contexts. These findings suggest that national political debates may be shaping local priorities in ways contrary to conventional views, and that they may matter even more than other recent findings conclude."
DAVID GLICK,2016 Menino Survey of Mayors,"The 2016 Menino Survey of Mayors represents the third scientifically rigorous and nationally representative survey of American mayors released by the Boston University Initiatives on Cities. The Menino Survey, based on interviews with 102 sitting mayors conducted in 2016, provides insight into mayoral priorities, policy views and relationships with their key partners, including other levels of government. This year's research was largely focused on Mayors' ""people priorities"" on subjects like poverty, immigration, inclusion, and city image. Mayors also discussed the impact of the 2016 presidential election on their cities and their hopes for the Trump administration."
DAVID GLICK,2023 Menino Survey of Mayors: building for a Green Future: Cities and the IRA,"The 2023 Menino Survey of Mayors represents the tenth nationally representative survey of American mayors and is based on interviews with 118 sitting mayors from 39 states. The 2023 Survey explores mayoral views on Inflation Reduction Act (IRA) implementation and issues ranging from clean energy and permitting, to public messaging, to capacity challenges, to government accountability and control. The first set of findings, Building for a Green Future: Cities & the IRA, released in March 2024, details mayors’ initial experiences with the Inflation Reduction Act (IRA) and identifies key challenges at the local level to realizing the law’s potential."
DAVID GLICK,2023 Menino Survey: Mayoral Accountability and Control,"The 2023 Menino Survey of Mayors represents the tenth nationally representative survey of American mayors and is based on interviews with 118 sitting mayors from 39 states. The 2023 Survey explores mayoral views on Inflation Reduction Act (IRA) implementation and issues ranging from clean energy and permitting, to public messaging, to capacity challenges, to government accountability and control. The second set of findings, Mayoral Accountability and Control, released in April 2024, examines how mayors view their control and accountability over a variety of elements of local government, and how these perceptions have changed in recent years."
DAVID GLICK,Is the Supreme Court’s legitimacy vulnerable to intense appointment politics? Democrats’ changed views around Justice Ginsburg’s death,"Justice Ruth Bader Ginsburg’s death near the end of the Trump presidency set off a fight in which Republicans moved to rapidly replace her over Democrats’ objections. I use a survey that was in the field at the time to assess whether this period affected the Court’s legitimacy. I find that Democrats who responded in the days just after Justice Ginsburg’s death saw the Court as less legitimate than those who responded shortly before it. These findings connect to broader questions about the sources of Court legitimacy, the mechanisms through which it changes, and the impact of contestation over appointments."
WILLIAM WATERS,Theories of lyric [Introductory essay],
WILLIAM WATERS,"Bostonia: v. 17, no. 1-9",
WILLIAM WATERS,Are motion pictures of value as aids to the effective teaching of a unit in seventh grade social studies?,
WILLIAM WATERS,On the need for International Solar Terrestrial Program Next (ISTPNext),
WILLIAM WATERS,Scintillation light detection in the 6-m drift-length ProtoDUNE Dual Phase liquid argon TPC,"DUNE is a dual-site experiment for long-baseline neutrino oscillation studies, neutrino astrophysics and nucleon decay searches. ProtoDUNE Dual Phase (DP) is a 6  ×  6  ×  6 m 3 liquid argon time-projection-chamber (LArTPC) that recorded cosmic-muon data at the CERN Neutrino Platform in 2019-2020 as a prototype of the DUNE Far Detector. Charged particles propagating through the LArTPC produce ionization and scintillation light. The scintillation light signal in these detectors can provide the trigger for non-beam events. In addition, it adds precise timing capabilities and improves the calorimetry measurements. In ProtoDUNE-DP, scintillation and electroluminescence light produced by cosmic muons in the LArTPC is collected by photomultiplier tubes placed up to 7 m away from the ionizing track. In this paper, the ProtoDUNE-DP photon detection system performance is evaluated with a particular focus on the different wavelength shifters, such as PEN and TPB, and the use of Xe-doped LAr, considering its future use in giant LArTPCs. The scintillation light production and propagation processes are analyzed and a comparison of simulation to data is performed, improving understanding of the liquid argon properties."
WILLIAM WATERS,Prospects for beyond the standard model physics searches at the deep underground neutrino experiment: DUNE collaboration,"The Deep Underground Neutrino Experiment (DUNE) will be a powerful tool for a variety of physics topics. The high-intensity proton beams provide a large neutrino flux, sampled by a near detector system consisting of a combination of capable precision detectors, and by the massive far detector system located deep underground. This configuration sets up DUNE as a machine for discovery, as it enables opportunities not only to perform precision neutrino measurements that may uncover deviations from the present three-flavor mixing paradigm, but also to discover new particles and unveil new interactions and symmetries beyond those predicted in the Standard Model (SM). Of the many potential beyond the Standard Model (BSM) topics DUNE will probe, this paper presents a selection of studies quantifying DUNE's sensitivities to sterile neutrino mixing, heavy neutral leptons, non-standard interactions, CPT symmetry violation, Lorentz invariance violation, neutrino trident production, dark matter from both beam induced and cosmogenic sources, baryon number violation, and other new physics topics that complement those at high-energy colliders and significantly extend the present reach."
WILLIAM WATERS,Identification and reconstruction of low-energy electrons in the ProtoDUNE-SP detector,
WILLIAM WATERS,The long-baseline neutrino experiment: exploring fundamental symmetries of the universe,"The preponderance of matter over antimatter in the early Universe, the dynamics of the supernova bursts that produced the heavy elements necessary for life and whether protons eventually decay --- these mysteries at the forefront of particle physics and astrophysics are key to understanding the early evolution of our Universe, its current state and its eventual fate. The Long-Baseline Neutrino Experiment (LBNE) represents an extensively developed plan for a world-class experiment dedicated to addressing these questions. LBNE is conceived around three central components: (1) a new, high-intensity neutrino source generated from a megawatt-class proton accelerator at Fermi National Accelerator Laboratory, (2) a near neutrino detector just downstream of the source, and (3) a massive liquid argon time-projection chamber deployed as a far detector deep underground at the Sanford Underground Research Facility. This facility, located at the site of the former Homestake Mine in Lead, South Dakota, is approximately 1,300 km from the neutrino source at Fermilab -- a distance (baseline) that delivers optimal sensitivity to neutrino charge-parity symmetry violation and mass ordering effects. This ambitious yet cost-effective design incorporates scalability and flexibility and can accommodate a variety of upgrades and contributions. With its exceptional combination of experimental configuration, technical capabilities, and potential for transformative discoveries, LBNE promises to be a vital facility for the field of particle physics worldwide, providing physicists from around the globe with opportunities to collaborate in a twenty to thirty year program of exciting science. In this document we provide a comprehensive overview of LBNE's scientific objectives, its place in the landscape of neutrino physics worldwide, the technologies it will incorporate and the capabilities it will possess."
CHARLOTTE HOWELL,Symbolic capital and the production discourse of The American Music Show: a microhistory of Atlanta cable access,"The American Music Show, an Atlanta cable public access television show that ran from 1981 to 2005, is not only a forgotten piece of production history but also a fertile case study. This article—situated in both local Atlanta and national cable access contexts in which the show began—uses the tools of production studies to construct a microhistory of local cable access, analyzing the hopes, ideals, ethos, and actual production practices that surrounded the show. The producers of The American Music Show refl ect on their work in the initial years of the show as creatively avant-garde but ultimately limited within the commercial structures of television. It is that tension that has enabled them to claim part of the show’s symbolic capital."
CHARLOTTE HOWELL,This show was religious?!: Online reactions to religion in Lost and Battlestar Galactica finales,"As the American populace is increasingly identifying as non-religious, religious representation is surprisingly also increasing on television, leading many to discuss the limits and boundaries of acceptable representations of religion through the cultural forum of television. The series finales of Lost and Battlestar Galactica serve as a particular pair of case studies I place in discussion with each other about religious-representational and generic concerns. Online reactions in discussion forums or comment sections to the religious elements in these finales generally occur in one of two ways: negative reactions that set the religious endings in opposition to the genre expectations viewers had for the shows or generally positive reactions that focus on the religious themes as successful affective tools that provided adequate or at least justified narrative closure. In both discursive strains, the tone was overwhelmingly respectful and occasionally aware that those entering into the discussions were engaging in larger cultural debates, providing one site of exploring the changing role of religion in popular television through a study of expectations of science fiction narratives and their conclusions."
RONALD E. WHEELER,Genome-wide significance for a modifier of age at neurological onset in Huntington's disease at 6q23-24: the HD MAPS study,"BACKGROUND: Age at onset of Huntington's disease (HD) is correlated with the size of the abnormal CAG repeat expansion in the HD gene; however, several studies have indicated that other genetic factors also contribute to the variability in HD age at onset. To identify modifier genes, we recently reported a whole-genome scan in a sample of 629 affected sibling pairs from 295 pedigrees, in which six genomic regions provided suggestive evidence for quantitative trait loci (QTL), modifying age at onset in HD. METHODS: In order to test the replication of this finding, eighteen microsatellite markers, three from each of the six genomic regions, were genotyped in 102 newly recruited sibling pairs from 69 pedigrees, and data were analyzed, using a multipoint linkage variance component method, in the follow-up sample and the combined sample of 352 pedigrees with 753 sibling pairs. RESULTS: Suggestive evidence for linkage at 6q23-24 in the follow-up sample (LOD = 1.87, p = 0.002) increased to genome-wide significance for linkage in the combined sample (LOD = 4.05, p = 0.00001), while suggestive evidence for linkage was observed at 18q22, in both the follow-up sample (LOD = 0.79, p = 0.03) and the combined sample (LOD = 1.78, p = 0.002). Epistatic analysis indicated that there is no interaction between 6q23-24 and other loci. CONCLUSION: In this replication study, linkage for modifier of age at onset in HD was confirmed at 6q23-24. Evidence for linkage was also found at 18q22. The demonstration of statistically significant linkage to a potential modifier locus opens the path to location cloning of a gene capable of altering HD pathogenesis, which could provide a validated target for therapeutic development in the human patient."
HELEN JENKINS,"(The) historic, economic, and social aspects of the laundry industry in America ..",
GREGG JAEGER,Topological qubits as carriers of quantum information in optics,"Winding number is a topologically significant quantity that has found valuable applications in various areas of mathematical physics. Here, topological qubits are shown capable of formation from winding number superpositions and so of being used in the communication of quantum information in linear optical systems, the most common realm for quantum communication. In particular, it is shown that winding number qubits appear in several aspects of such systems, including quantum electromagnetic states of spin, momentum, orbital angular momentum, polarization of beams of particles propagating in free-space, optical fiber, beam splitters, and optical multiports."
GREGG JAEGER,Entangled-coherent-state quantum key distribution with entanglement witnessing,"An entanglement witness approach to quantum coherent state key distribution and a system for its practical implementation are described. In this approach, eavesdropping can be detected by a change in sign of either of two witness functions, an entanglement witness S or an eavesdropping witness W. The effects of loss and eavesdropping on system operation are evaluated as a function of distance. Although the eavesdropping witness W does not directly witness entanglement for the system, its behavior remains related to that of the true entanglement witness S. Furthermore, W is easier to implement experimentally than S. W crosses the axis at a finite distance, in a manner reminiscent of entanglement sudden death. The distance at which this occurs changes measurably when an eavesdropper is present. The distance dependance of the two witnesses due to amplitude reduction and due to increased variance resulting from both ordinary propagation losses and possible eavesdropping activity is provided. Finally, the information content and secure key rate of a continuous variable protocol using this witness approach are given."
GREGG JAEGER,Book review: Bohmian mechanics and quantum theory: an appraisal,"A review of ""Bohmian Mechanics and Quantum Theory: An Appraisal"" (James Cushing, Arthur Fine and Sheldon Goldstein, Eds.), an extensive collection of articles on Bohmian mechanics. In addition to broad, critical overviews of Bohmian mechanics, the reviewed collection contains extensions and hybrid versions of the theory and several detailed applications to practical situations. Comment: 4 pages as plain text, no figures. (Reason for new version: typos in abstract corrected.) To appear in Studies in History and Philosophy of Modern Physics"
GREGG JAEGER,"Entanglement, mixedness, and spin-flip symmetry in multiple-qubit systems","A relationship between a recently introduced multipartite entanglement measure, state mixedness, and spin-flip symmetry is established for any finite number of qubits. It is also shown that, for those classes of states invariant under the spin-flip transformation, there is a complementarity relation between multipartite entanglement and mixedness. A number of example classes of multiple-qubit systems are studied in light of this relationship."
GREGG JAEGER,Complementarity and path distinguishability: Some recent results concerning photon pairs,"Two results concerning photon pairs, one previously reported and one new, are summarized. It was previously shown that if the two photons are prepared in a quantum state formed from bar-A and bar-A' for photon 1 and bar-B and bar-B' for photon 2, then both one- and two-particle interferometry can be studied. If upsilon(sub i) is the visibility of one-photon interference fringes (i = 1,2) and upsilon(sub 12) is the visibility of two-photon fringes (a concept which we explicitly define), then upsilon(sub i) squared + upsilon(sub 12) squared is less than or equal to 1. The second result concerns the distinguishability of the paths of photon 2, using the known 2-photon state. A proposed measure E for path distinguishability is based upon finding an optimum strategy for betting on the outcome of a path measurement. Mandel has also proposed a measure of distinguishability P(sub D), defined in terms of the density operator rho of photon 2. We show that E is greater than or equal to P(sub D) and that upsilon(sub 2) = (1 - E(exp 2))exp 1/2."
GREGG JAEGER,“Wave-Packet Reduction” and the quantum character of the actualization of potentia,"Werner Heisenberg introduced the notion of quantum potentia in order to accommodate the indeterminism associated with quantum measurement. Potentia captures the capacity of the system to be found to possess a property upon a corresponding sharp measurement in which it is actualized. The specific potentiae of the individual system are represented formally by the complex amplitudes in the measurement bases of the eigenstate in which it is prepared. All predictions for future values of system properties can be made by an experimenter using the probabilities which are the squared moduli of these amplitudes that are the diagonal elements of the density matrix description of the pure ensemble to which the system, so prepared, belongs. Heisenberg considered the change of the ensemble attribution following quantum measurement to be analogous to the classical change in Gibbs’ thermodynamics when measurement of the canonical ensemble enables a microcanonical ensemble description. This analogy, presented by Heisenberg as operating at the epistemic level, is analyzed here. It has led some to claim not only that the change of the state in measurement is classical mechanical, bringing its quantum character into question, but also that Heisenberg held this to be the case. Here, these claims are shown to be incorrect, because the analogy concerns the change of ensemble attribution by the experimenter upon learning the result of the measurement, not the actualization of the potentia responsible for the change of the individual system state which—in Heisenberg’s interpretation of quantum mechanics—is objective in nature and independent of the experimenter’s knowledge."
GREGG JAEGER,The elementary particles of quantum fields,"The elementary particles of relativistic quantum field theory are not simple field quanta, as has long been assumed. Rather, they supplement quantum fields, on which they depend on but to which they are not reducible, as shown here with particles defined instead as a unified collection of properties that appear in both physical symmetry group representations and field propagators. This notion of particle provides consistency between the practice of particle physics and its basis in quantum field theory."
GREGG JAEGER,Uncertainty relations and possible experience,"The uncertainty principle can be understood as a condition of joint indeterminacy of classes of properties in quantum theory. The mathematical expressions most closely associated with this principle have been the uncertainty relations, various inequalities exemplified by the well known expression regarding position and momentum introduced by Heisenberg. Here, recent work involving a new sort of “logical” indeterminacy principle and associated relations introduced by Pitowsky, expressable directly in terms of probabilities of outcomes of measurements of sharp quantum observables, is reviewed and its quantum nature is discussed. These novel relations are derivable from Boolean “conditions of possible experience” of the quantum realm and have been considered both as fundamentally logical and as fundamentally geometrical. This work focuses on the relationship of indeterminacy to the propositions regarding the values of discrete, sharp observables of quantum systems. Here, reasons for favoring each of these two positions are considered. Finally, with an eye toward future research related to indeterminacy relations, further novel approaches grounded in category theory and intended to capture and reconceptualize the complementarity characteristics of quantum propositions are discussed in relation to the former."
GREGG JAEGER,Localizability and elementary particles,"The well-definedness of particles of any kind depends on the limits, approximations, or other conditions that may or may not be involved, for example, whether there are interactions and whether ostensibly related energy is localizable. In particular, their theoretical status differs between its non-relativistic and relativistic versions: One can properly define interacting elementary particles in single-system non-relativistic quantum mechanics, at least in the case of non-zero mass systems; by contrast, one is severely challenged to define even these properly in the relativistic quantum field theories that now underlie the study of particle physics. Here, the impact of localizability on this status is reviewed in relation to the work of Paul Busch on positive operator valued measures that significantly probes the relevance of quantum unsharpness to it."
GREGG JAEGER,Quantum contextuality and indeterminacy,"The circumstances of measurement have more direct significance in quantum than in classical physics, where they can be neglected for well-performed measurements. In quantum mechanics, the dispositions of the measuring apparatus-plus-environment of the system measured for a property are a non-trivial part of its formalization as the quantum observable. A straightforward formalization of context, via equivalence classes of measurements corresponding to sets of sharp target observables, was recently given for sharp quantum observables. Here, we show that quantum contextuality, the dependence of measurement outcomes on circumstances external to the measured quantum system, can be manifested not only as the strict exclusivity of different measurements of sharp observables or valuations but via quantitative differences in the property statistics across simultaneous measurements of generalized quantum observables, by formalizing quantum context via coexistent generalized observables rather than only its subset of compatible sharp observables. Here, the question of whether such quantum contextuality follows from basic quantum principles is then addressed, and it is shown that the Principle of Indeterminacy is sufficient for at least one form of non-trivial contextuality. Contextuality is thus seen to be a natural feature of quantum mechanics rather than something arising only from the consideration of impossible measurements, abstract philosophical issues, hidden-variables theories, or other alternative, classical models of quantum behavior."
GREGG JAEGER,Developments in quantum probability and the Copenhagen approach,"In the Copenhagen approach to quantum mechanics as characterized by Heisenberg, probabilities relate to the statistics of measurement outcomes on ensembles of systems and to individual measurement events via the actualization of quantum potentiality. Here, brief summaries are given of a series of key results of different sorts that have been obtained since the final elements of the Copenhagen interpretation were offered and it was explicitly named so by Heisenberg—in particular, results from the investigation of the behavior of quantum probability since that time, the mid-1950s. This review shows that these developments have increased the value to physics of notions characterizing the approach which were previously either less precise or mainly symbolic in character, including complementarity, indeterminism, and unsharpness."
GREGG JAEGER,"""Wave-packet reduction"" and the quantum character of the actualization of potentia","Werner Heisenberg introduced the notion of quantum potentia in order to accommodate the indeterminism associated with quantum measurement. Potentia captures the capacity of the system to be found to possess a property upon a corresponding sharp measurement in which it is actualized. The specific potentiae of the individual system are represented formally by the complex amplitudes in the measurement bases of the eigenstate in which it is prepared. All predictions for future values of system properties can be made by an experimenter using the probabilities which are the squared moduli of these amplitudes that are the diagonal elements of the density matrix description of the pure ensemble to which the system, so prepared, belongs. Heisenberg considered the change of the ensemble attribution following quantum measurement to be analogous to the classical change in Gibbs’ thermodynamics when measurement of the canonical ensemble enables a microcanonical ensemble description. This analogy, presented by Heisenberg as operating at the epistemic level, is analyzed here. It has led some to claim not only that the change of the state in measurement is classical mechanical, bringing its quantum character into question, but also that Heisenberg held this to be the case. Here, these claims are shown to be incorrect, because the analogy concerns the change of ensemble attribution by the experimenter upon learning the result of the measurement, not the actualization of the potentia responsible for the change of the individual system state which—in Heisenberg’s interpretation of quantum mechanics—is objective in nature and independent of the experimenter’s knowledge"
GREGG JAEGER,A realist view of the quantum world,"A realist view of the quantum world is given along the lines of Werner Heisenberg’s Copenhagen interpretation of quantum mechanics and set in contrast to that associated with John von Neumann by Henry Stapp. This view is distinguished by, among other elements: (i) the notion of quantum potentia and its actualization which results in classical recorded values of measured quantities, (ii) the grounding of the existence and chancy character of individual measurement events in the plenitude principle as applied to the set of eigenvalues of observables on the space of quantum states, and (iii) the identification of the individuals of the theory by a straightforward individuation principle."
GREGG JAEGER,Quantum contextuality in the Copenhagen approach,"The origin and basis of the notion of quantum contextuality is identified in the Copenhagen approach to quantum mechanics, where context is automatically invoked by its requirement that the experimental arrangement involved in any measurements or set of measurements be taken into account while, in general, the outcome of a measurement may depend on other measurements immediately preceding or jointly performed on the same system. For Bohr, the specification of the experimental situation of any measurement is essential to its significance in light of complementarity and the omnipresence of the quantum of action in physics; for Heisenberg, the incompatibility of pairs of sharp measurements belonging to different situations coheres with both the completeness of the quantum state as an objective physical description and the principle of indeterminacy. Here, context in the Copenhagen approach is taken to be the equivalence class of experimental arrangements corresponding to a set of compatible measurements of quantum observables in standard quantum mechanics; the associated form of contextuality in quantum mechanics arises via the non-commutativity in general of sharp observables, proven by von Neumann, that can appear, providing different contexts. This notion is related to theoretical situations explored later by Bell, by Kochen and Specker, and by others in relation to the classification of hidden-variables theories and elsewhere in physics. This article is part of the theme issue 'Contextuality and probability in quantum mechanics and beyond'."
GREGG JAEGER,"Quantum unsharpness, potentiality, and reality","Paul Busch argued that the positive operator (valued) measure, a generalization of the standard quantum observable, enables a consistent notion of unsharp reality based on a quantifiable degree of reality whereby systems can possess generalized properties jointly, whereas related sharp properties cannot be so possessed (Busch and Jaeger in Found Phys 40:1341, 2010). Here, the work leading up to the formalization of this notion to which he made great contributions is reviewed and explicated in relation to Heisenberg’s notions of potentiality and actuality. The notion of unsharp reality is then extended further by the introduction of a distinction between actual and actualizable elements of reality based on these mathematical innovations."
GREGG JAEGER,Information and the reconstruction of quantum physics,"The reconstruction of quantum physics has been connected with the interpretation of the quantum formalism, and has continued to be so with the recent deeper consideration of the relation of information to quantum states and processes. This recent form of reconstruction has mainly involved conceiving quantum theory on the basis of informational principles, providing new perspectives on physical correlations and entanglement that can be used to encode information. By contrast to the traditional, interpretational approach to the foundations of quantum mechanics, which attempts directly to establish the meaning of the elements of the theory and often touches on metaphysical issues, the newer, more purely reconstructive approach sometimes defers this task, focusing instead on the mathematical derivation of the theoretical apparatus from simple principles or axioms. In its most pure form, this sort of theory reconstruction is fundamentally the mathematical derivation of the elements of theory from explicitly presented, often operational principles involving a minimum of extra‐mathematical content. Here, a representative series of specifically information‐based treatments—from partial reconstructions that make connections with information to rigorous axiomatizations, including those involving the theories of generalized probability and abstract systems—is reviewed."
GREGG JAEGER,The conceptual and mathematical basis of quantum potentiality and chance,
GREGG JAEGER,Are virtual particles less real?,"The question of whether virtual quantum particles exist is considered here in light of previous critical analysis and under the assumption that there are particles in the world as described by quantum field theory. The relationship of the classification of particles to quantum-field-theoretic calculations and the diagrammatic aids that are often used in them is clarified. It is pointed out that the distinction between virtual particles and others and, therefore, judgments regarding their reality have been made on basis of these methods rather than on their physical characteristics. As such, it has obscured the question of their existence. It is here argued that the most influential arguments against the existence of virtual particles but not other particles fail because they either are arguments against the existence of particles in general rather than virtual particles per se, or are dependent on the imposition of classical intuitions on quantum systems, or are simply beside the point. Several reasons are then provided for considering virtual particles real, such as their descriptive, explanatory, and predictive value, and a clearer characterization of virtuality—one in terms of intermediate states—that also applies beyond perturbation theory is provided. It is also pointed out that in the role of force mediators, they serve to preclude action-at-a-distance between interacting particles. For these reasons, it is concluded that virtual particles are as real as other quantum particles."
GREGG JAEGER,The ontology of Haag's local quantum physics,"The ontology of Local Quantum Physics, Rudolf Haag's framework for relativistic quantum theory, is reviewed and discussed. It is one of spatiotemporally localized events and unlocalized causal intermediaries, including the elementary particles, which come progressively into existence in accordance with a fundamental arrow of time. Haag's conception of quantum theory is distinguished from others in which events are also central, especially those of Niels Bohr and John Wheeler, with which it has been compared."
GREGG JAEGER,The particle of Haag's local quantum physics: a critical assessment,"Rudolf Haag's Local Quantum Physics (LQP) is an alternative framework to conventional relativistic quantum field theory for combining special relativity and quantum theory based on first principles, making it of great interest for the purposes of conceptual analysis despite currently being relatively limited as a tool for making experimental predictions. In LQP, the elementary particles are defined as species of causal link between interaction events, together with which they comprise its most fundamental entities. This notion of particle has yet to be independently assessed as such. Here, it is captured via a set of propositions specifying particle characteristics and then compared to previous particle notions. Haag's particle differs decisively with respect to mechanical intuitions about particles by lacking, among other things, even an approximate independent space-time location. This notion is thus found to differ greatly even from those of relativistic quantum mechanics and quantum field theory, which have been applied to the known elementary particles."
LOUIS AWAD,Exosuit-induced improvements in walking after stroke: comprehensive analysis on gait energetics and biomechanics,Outstanding Poster Presentation Finalist
LOUIS AWAD,Identifying candidates for targeted gait rehabilitation: better prediction through biomechanics-informed characterization,"BACKGROUND: Walking speed has been used to predict the efficacy of gait training; however, poststroke motor impairments are heterogeneous and different biomechanical strategies may underlie the same walking speed. Identifying which individuals will respond best to a particular gait rehabilitation program using walking speed alone may thus be limited. The objective of this study was to determine if, beyond walking speed, participants' baseline ability to generate propulsive force from their paretic limbs (paretic propulsion) influences the improvements in walking speed resulting from a paretic propulsion-targeting gait intervention. METHODS: Twenty seven participants >6 months poststroke underwent a 12-week locomotor training program designed to target deficits in paretic propulsion through the combination of fast walking with functional electrical stimulation to the paretic ankle musculature (FastFES). The relationship between participants' baseline usual walking speed (UWSbaseline), maximum walking speed (MWSbaseline), and paretic propulsion (propbaseline) versus improvements in usual walking speed (∆UWS) and maximum walking speed (∆MWS) were evaluated in moderated regression models. RESULTS: UWSbaseline and MWSbaseline were, respectively, poor predictors of ΔUWS (R 2  = 0.24) and ΔMWS (R 2  = 0.01). Paretic propulsion × walking speed interactions (UWSbaseline × propbaseline and MWSbaseline × propbaseline) were observed in each regression model (R 2 s = 0.61 and 0.49 for ∆UWS and ∆MWS, respectively), revealing that slower individuals with higher utilization of the paretic limb for forward propulsion responded best to FastFES training and were the most likely to achieve clinically important differences. CONCLUSIONS: Characterizing participants based on both their walking speed and ability to generate paretic propulsion is a markedly better approach to predicting walking recovery following targeted gait rehabilitation than using walking speed alone."
LOUIS AWAD,Assisting paretic ankle motion with a soft exosuit can reduce whole-body compensatory gait patterns and improve walking efficiency for patients after stroke,
LOUIS AWAD,Soft exosuits increase walking speed and distance after stroke,Finalist for best poster abstract and presentation
LOUIS AWAD,A uni-lateral soft exosuit for the paretic ankle can reduce gait compensations in patients post-stroke,
LOUIS AWAD,Biomechanical mechanisms underlying exosuit-induced improvements in walking economy after stroke,"Stroke-induced hemiparetic gait is characteristically asymmetric and metabolically expensive. Weakness and impaired control of the paretic ankle contribute to reduced forward propulsion and ground clearance—walking subtasks critical for safe and efficient locomotion. Targeted gait interventions that improve paretic ankle function after stroke are therefore warranted. We have developed textile-based, soft wearable robots that transmit mechanical power generated by off-board or body-worn actuators to the paretic ankle using Bowden cables (soft exosuits) and have demonstrated the exosuits can overcome deficits in paretic limb forward propulsion and ground clearance, ultimately reducing the metabolic cost of hemiparetic walking. This study elucidates the biomechanical mechanisms underlying exosuit-induced reductions in metabolic power. We evaluated the relationships between exosuit-induced changes in the body center of mass (COM) power generated by each limb, individual joint powers, and metabolic power. Compared to walking with an exosuit unpowered, exosuit assistance produced more symmetrical COM power generation during the critical period of the step-to-step transition (22.4±6.4% more symmetric). Changes in individual limb COM power were related to changes in paretic (R2= 0.83, P= 0.004) and nonparetic (R2= 0.73, P= 0.014) ankle power. Interestingly, despite the exosuit providing direct assistance to only the paretic limb, changes in metabolic power were related to changes in nonparetic limb COM power (R2= 0.80, P= 0.007), not paretic limb COM power (P> 0.05). These findings provide a fundamental understanding of how individuals poststroke interact with an exosuit to reduce the metabolic cost of hemiparetic walking."
LOUIS AWAD,Identifying candidates for targeted gait rehabilitation after stroke: better prediction through biomechanics-informed characterization,"BACKGROUND: Walking speed has been used to predict the efficacy of gait training; however, poststroke motor impairments are heterogeneous and different biomechanical strategies may underlie the same walking speed. Identifying which individuals will respond best to a particular gait rehabilitation program using walking speed alone may thus be limited. The objective of this study was to determine if, beyond walking speed, participants' baseline ability to generate propulsive force from their paretic limbs (paretic propulsion) influences the improvements in walking speed resulting from a paretic propulsion-targeting gait intervention. METHODS: Twenty seven participants >6 months poststroke underwent a 12-week locomotor training program designed to target deficits in paretic propulsion through the combination of fast walking with functional electrical stimulation to the paretic ankle musculature (FastFES). The relationship between participants' baseline usual walking speed (UWSbaseline), maximum walking speed (MWSbaseline), and paretic propulsion (propbaseline) versus improvements in usual walking speed (∆UWS) and maximum walking speed (∆MWS) were evaluated in moderated regression models. RESULTS: UWSbaseline and MWSbaseline were, respectively, poor predictors of ΔUWS (R (2)  = 0.24) and ΔMWS (R (2)  = 0.01). Paretic propulsion × walking speed interactions (UWSbaseline × propbaseline and MWSbaseline × propbaseline) were observed in each regression model (R (2) s = 0.61 and 0.49 for ∆UWS and ∆MWS, respectively), revealing that slower individuals with higher utilization of the paretic limb for forward propulsion responded best to FastFES training and were the most likely to achieve clinically important differences. CONCLUSIONS: Characterizing participants based on both their walking speed and ability to generate paretic propulsion is a markedly better approach to predicting walking recovery following targeted gait rehabilitation than using walking speed alone."
LOUIS AWAD,These legs were made for propulsion: advancing the diagnosis and treatment of post-stroke propulsion deficits,"Advances in medical diagnosis and treatment have facilitated the emergence of precision medicine. In contrast, locomotor rehabilitation for individuals with acquired neuromotor injuries remains limited by the dearth of (i) diagnostic approaches that can identify the specific neuromuscular, biomechanical, and clinical deficits underlying impaired locomotion and (ii) evidence-based, targeted treatments. In particular, impaired propulsion by the paretic limb is a major contributor to walking-related disability after stroke; however, few interventions have been able to target deficits in propulsion effectively and in a manner that reduces walking disability. Indeed, the weakness and impaired control that is characteristic of post-stroke hemiparesis leads to heterogeneous deficits that impair paretic propulsion and contribute to a slow, metabolically-expensive, and unstable gait. Current rehabilitation paradigms emphasize the rapid attainment of walking independence, not the restoration of normal propulsion function. Although walking independence is an important goal for stroke survivors, independence achieved via compensatory strategies may prevent the recovery of propulsion needed for the fast, economical, and stable gait that is characteristic of healthy bipedal locomotion. We posit that post-stroke rehabilitation should aim to promote independent walking, in part, through the acquisition of enhanced propulsion. In this expert review, we present the biomechanical and functional consequences of post-stroke propulsion deficits, review advances in our understanding of the nature of post-stroke propulsion impairment, and discuss emerging diagnostic and treatment approaches that have the potential to facilitate new rehabilitation paradigms targeting propulsion restoration."
LOUIS AWAD,"The ReWalk ReStore™ soft robotic exosuit: a multi-site clinical trial of the safety, reliability, and feasibility of exosuit-augmented post-stroke gait rehabilitation","BACKGROUND: Atypical walking in the months and years after stroke constrain community reintegration and reduce mobility, health, and quality of life. The ReWalk ReStore™ is a soft robotic exosuit designed to assist the propulsion and ground clearance subtasks of post-stroke walking by actively assisting paretic ankle plantarflexion and dorsiflexion. Previous proof-of-concept evaluations of the technology demonstrated improved gait mechanics and energetics and faster and farther walking in users with post-stroke hemiparesis. We sought to determine the safety, reliability, and feasibility of using the ReStore™ during post-stroke rehabilitation. METHODS: A multi-site clinical trial (NCT03499210) was conducted in preparation for an application to the United States Food and Drug Administration (FDA). The study included 44 users with post-stroke hemiparesis who completed up to 5 days of training with the ReStore™ on the treadmill and over ground. In addition to primary and secondary endpoints of safety and device reliability across all training activities, an exploratory evaluation of the effect of multiple exposures to using the device on users' maximum walking speeds with and without the device was conducted prior to and following the five training visits. RESULTS: All 44 study participants completed safety and reliability evaluations. Thirty-six study participants completed all five training days. No device-related falls or serious adverse events were reported. A low rate of device malfunctions was reported by clinician-operators. Regardless of their reliance on ancillary assistive devices, after only 5 days of walking practice with the device, study participants increased both their device-assisted (Δ: 0.10 ± 0.03 m/s) and unassisted (Δ: 0.07 ± 0.03 m/s) maximum walking speeds (P's < 0.05). CONCLUSIONS: When used under the direction of a licensed physical therapist, the ReStore™ soft exosuit is safe and reliable for use during post-stroke gait rehabilitation to provide targeted assistance of both paretic ankle plantarflexion and dorsiflexion during treadmill and overground walking. TRIAL REGISTRATION: NCT03499210. Prospectively registered on March 28, 2018."
LOUIS AWAD,Towards neuroscience of the everyday world (NEW) using functional near infrared spectroscopy,"Functional near-infrared spectroscopy (fNIRS) assesses human brain activity by noninvasively measuring changes of cerebral hemoglobin concentrations caused by modulation of neuronal activity. Recent progress in signal processing and advances in system design, such as miniaturization, wearability, and system sensitivity, have strengthened fNIRS as a viable and cost-effective complement to functional magnetic resonance imaging, expanding the repertoire of experimental studies that can be performed by the neuroscience community. The availability of fNIRS and electroencephalography for routine, increasingly unconstrained, and mobile brain imaging is leading toward a new domain that we term “Neuroscience of the Everyday World” (NEW). In this light, we review recent advances in hardware, study design, and signal processing, and discuss challenges and future directions."
LOUIS AWAD,Soft wearable robots can increase walking speed and distance after stroke: Proof-of-concept,
LOUIS AWAD,Unilateral ankle assisting soft robotic exosuit can improve post-stroke gait during overground walking,
LOUIS AWAD,Indirect measurement of anterior-posterior ground reaction forces using a minimal set of wearable inertial sensors: from healthy to hemiparetic walking,"BACKGROUND: The anterior-posterior ground reaction force (AP-GRF) and propulsion and braking point metrics derived from the AP-GRF time series are indicators of locomotor function across healthy and neurological diagnostic groups. In this paper, we describe the use of a minimal set of wearable inertial measurement units (IMUs) to indirectly measure the AP-GRFs generated during healthy and hemiparetic walking. METHODS: Ten healthy individuals and five individuals with chronic post-stroke hemiparesis completed a 6-minute walk test over a walking track instrumented with six forceplates while wearing three IMUs securely attached to the pelvis, thigh, and shank. Subject-specific models driven by IMU-measured thigh and shank angles and an estimate of body acceleration provided by the pelvis IMU were used to generate indirect estimates of the AP-GRF time series. Propulsion and braking point metrics (i.e., peaks, peak timings, and impulses) were extracted from the IMU-generated time series. Peaks and impulses were expressed as % bodyweight (%bw) and peak timing was expressed as % stance phase (%sp). A 75%-25% split of 6-minute walk test data was used to train and validate the models. Indirect estimates of the AP-GRF time series and point metrics were compared to direct measurements made by the forceplates. RESULTS: Indirect measurements of the AP-GRF time series approximated the direct measurements made by forceplates, with low error and high consistency in both the healthy (RMSE= 4.5%bw; R2= 0.93) and post-stroke (RMSE= 2.64%bw; R2= 0.90) cohorts. In the healthy cohort, the average errors between indirect and direct measurements of the peak propulsion magnitude, peak propulsion timing, and propulsion impulse point estimates were 2.37%bw, 0.67%sp, and 0.43%bw. In the post-stroke cohort, the average errors for these point estimates were 1.07%bw, 1.27%sp, and 0.31%bw. Average errors for the braking estimates were higher, but comparable. CONCLUSIONS: Accurate estimates of AP-GRF metrics can be generated using three strategically mounted IMUs and subject-specific calibrations. This study advances the development of point-of-care diagnostic systems that can catalyze the routine assessment and management of propulsion and braking locomotor deficits during rehabilitation."
LOUIS AWAD,Soft wearable robots can reduce the energy cost of poststroke walking: a proof-of-concept study,
JONATHAN J. WISCO,Gastrointestinal embryology related clinical conditions,
JONATHAN J. WISCO,Bugs & drugs,
JONATHAN J. WISCO,Pulmonary embryology related clinical conditions,
JONATHAN J. WISCO,Cancer classification and metastasis,
JONATHAN J. WISCO,Musculoskeletal joints & testing,
JONATHAN J. WISCO,Cranial nerves and testing,
JONATHAN J. WISCO,Pulmonary function tests,
JONATHAN J. WISCO,Medical imaging,
JONATHAN J. WISCO,Cardiac embryology related clinical conditions,
JONATHAN J. WISCO,Nephritic syndrome (Glomerulonephritis),
JONATHAN J. WISCO,Nephrotic syndrome,
JONATHAN J. WISCO,HPA axis disorders,
JONATHAN J. WISCO,Mechanism of diuretics,
JONATHAN J. WISCO,A closer look at Cushing's syndrome,
JONATHAN J. WISCO,"Patellofemoral joint dissection, donor IBXFT","This three-part illustration provides anterior views of the patellofemoral joint dissection. The first image shows the knee in an extended position, providing a clear view of the patella, femur, and tibia with the patella in its natural resting position within the femoral groove. The second image elevates the patella to reveal the underlying structures, including the articular surface of the femur and the patellar tendon attachment, showing the contact area between the patella and femur. The third image depicts the knee in a flexed position, showing changes in patellar alignment and its relationship with the femur and tibia during knee movement."
JONATHAN J. WISCO,"Heart dissection, donor IBXFT","This illustration depicts the anterior heart dissection. On the left, the image shows the exterior of the heart with dashed lines indicating the planned incision sites for the dissection. These lines outline the areas to be cut to provide access to internal structures. On the right, the image reveals the heart after the incisions have been made and the outer layers have been cut. The internal structures, including the muscular walls of the ventricles and the myocardial fibers, are visible."
JONATHAN J. WISCO,"Second rib cut, donor IBXFT",This illustration provides a view of the second rib cut procedure using bone shears. The image demonstrates the technique for cutting through the second rib while ensuring the preservation of the surrounding anatomical structures. This step follows the cutting of lower ribs and precedes the first rib cut.
JONATHAN J. WISCO,"First rib cut, donor IBXFT",
JAMES G MCDANIEL,Smoothed particle hydrodynamics modeling of electrodeposition and dendritic growth under migration- and diffusion-controlled mass transport,"In many electrochemical processes, the transport of charged species is governed by the Nernst–Planck equation, which includes terms for both diffusion and electrochemical migration. In this work, a multi-physics, multi-species model based on the smoothed particle hydrodynamics (SPH) method is presented to model the Nernst–Planck equation in systems with electrodeposition. Electrodeposition occurs when ions are deposited onto an electrode. These deposits create complex boundary geometries, which can be challenging for numerical methods to resolve. SPH is a particularly effective numerical method for systems with moving and deforming boundaries due to its particle nature. This paper discusses the SPH implementation of the Nernst–Planck equations with electrodeposition and verifies the model with an analytical solution and a numerical integrator. A convergence study of migration and precipitation is presented to illustrate the model’s accuracy, along with comparisons of the deposition growth front to experimental results."
DONALD LUCAS,Second elergy a transcription for orchestra,
DONALD LUCAS,San Antonio Statement on Brominated and Chlorinated Flame Retardants,
DONALD LUCAS,The Event Horizon general relativistic magnetohydrodynamic code comparison project,"Recent developments in compact object astrophysics, especially the discovery of merging neutron stars by LIGO, the imaging of the black hole in M87 by the Event Horizon Telescope, and high- precision astrometry of the Galactic Center at close to the event horizon scale by the GRAVITY experiment motivate the development of numerical source models that solve the equations of general relativistic magnetohydrodynamics (GRMHD). Here we compare GRMHD solutions for the evolution of a magnetized accretion flow where turbulence is promoted by the magnetorotational instability from a set of nine GRMHD codes: Athena++, BHAC, Cosmos++, ECHO, H-AMR, iharm3D, HARM-Noble, IllinoisGRMHD, and KORAL. Agreement among the codes improves as resolution increases, as measured by a consistently applied, specially developed set of code performance metrics. We conclude that the community of GRMHD codes is mature, capable, and consistent on these test problems."
DONALD LUCAS,The Mucosae-Associated Epithelial Chemokine (MEC/CCL28) Modulates Immunity in HIV Infection,BACKGROUND. CCL28 (MEC) binds to CCR3 and CCR10 and recruits IgA-secreting plasma cells (IgA-ASC) in the mucosal lamina propria (MLP). Mucosal HIV-specific IgA are detected in HIV-infection and exposure. The CCL28 circuit was analyzed in HIV-infected and-exposed individuals and in HIV-unexposed controls; the effect of CCL28 administration on gastrointestinal MLP IgA-ASC was verified in a mouse model. METHODOLOGY/FINDINGS. CCL28 was augmented in breast milk (BM) plasma and saliva of HIV-infected and –exposed individuals; CCR3+ and CCR10+ B lymphocytes were increased in these same individuals. Additionally: 1) CCL28 concentration in BM was associated with longer survival in HIV vertically-infected children; and 2) gastro-intestinal mucosal IgA-ASC were significantly increased in VSV-immunized mice receiving CCL28. CONCLUSIONS. CCL28 mediates mucosal immunity in HIV exposure and infection. CCL28-including constructs should be considered in mucosal vaccines to prevent HIV infection of the gastro-intestinal MLP via modulation of IgA-ASC.
DONALD LUCAS,The SNO+ experiment,
DONALD LUCAS,Current status and future prospects of the SNO+ experiment,"SNO+ is a large liquid scintillator-based experiment located 2 km underground at SNOLAB, Sudbury, Canada. It reuses the Sudbury Neutrino Observatory detector, consisting of a 12 m diameter acrylic vessel which will be filled with about 780 tonnes of ultra-pure liquid scintillator. Designed as a multipurpose neutrino experiment, the primary goal of SNO+ is a search for the neutrinoless double-beta decay (0νββ) of ^130Te. In Phase I, the detector will be loaded with 0.3% natural tellurium, corresponding to nearly 800 kg of ^130Te, with an expected effective Majorana neutrino mass sensitivity in the region of 55–133 meV, just above the inverted mass hierarchy. Recently, the possibility of deploying up to ten times more natural tellurium has been investigated, which would enable SNO+ to achieve sensitivity deep into the parameter space for the inverted neutrino mass hierarchy in the future. Additionally, SNO+ aims to measure reactor antineutrino oscillations, low energy solar neutrinos, and geoneutrinos, to be sensitive to supernova neutrinos, and to search for exotic physics. A first phase with the detector filled with water will begin soon, with the scintillator phase expected to start after a few months of water data taking. The 0νββ Phase I is foreseen for 2017."
MANUEL EGELE,FirmSolo: Enabling dynamic analysis of binary Linux-based IoT kernel modules,
MANUEL EGELE,BORDERPATROL: securing BYOD using fine-grained contextual information,"Companies adopt Bring Your Own Device (BYOD) policies extensively, for both convenience and cost management. The compelling way of putting private and business related applications (apps) on the same device leads to the widespread usage of employee owned devices to access sensitive company data and services. Such practices create a security risk as a legitimate app may send business-sensitive data to third party servers through detrimental app functions or packaged libraries. In this paper, we propose BORDERPATROL, a system for extracting contextual data that businesses can leverage to enforce access control in BYOD-enabled corporate networks through fine-grained policies. BORDERPATROL extracts contextual information, which is the stack trace of the app function that generated the network traffic, on provisioned user devices and transfers this data in IP headers to enforce desired policies at network routers. BORDERPATROL provides a way to selectively prevent undesired functionalities, such as analytics activities or advertisements, and help enforce information dissemination policies of the company while leaving other functions of the app intact. Using 2,000 apps,we demonstrate that BORDERPATROL is effective in preventing packets which originate from previously identified analytics and advertisement libraries from leaving the network premises. In addition, we show BORDERPATROL’s capability in selectively preventing undesirable app functions using case studies."
MANUEL EGELE,AppJitsu: investigating the resiliency of Android applications,"The Android platform gives mobile device users the opportunity to extend the capabilities of their systems by installing developer-authored apps. Companies leverage this capability to reach their customers and conduct business operations such as financial transactions. End-users can obtain custom Android applications (apps) from the Google Play, some of which are security-sensitive due to the nature of the data that they handle, such as apps from the FINANCE category. Although there are recommendations and standardized guidelines for secure app development with various self-defense techniques, the adoption of such methods is not mandatory and is left to the discretion of developers. Unfortunately, malicious actors can tamper with the app runtime environment and then exploit the attack vectors which arise from the tampering, such as executing foreign code with elevated privileges on the mobile platform. In this paper, we present AppJITSU, a dynamic app analysis framework that evaluates the resiliency of security-critical apps. We exercise the most popular 455 financial apps in attack-specific hostile environments to demonstrate the current state of resiliency against known tampering methods. Our results indicate that 25.05% of the tested apps have no resiliency against any common hostile methods or tools, whereas only 10.77% employed all defensive methods."
WILLIAM MOORE,Focus: Summer 2015,
WILLIAM MOORE,Focus: Summer 2018,
WILLIAM MOORE,METTL13 methylation of eEF1A increases translational output to promote tumorigenesis,"Increased protein synthesis plays an etiologic role in diverse cancers. Here, we demonstrate that METTL13 (methyltransferase-like 13) dimethylation of eEF1A (eukaryotic elongation factor 1A) lysine 55 (eEF1AK55me2) is utilized by Ras-driven cancers to increase translational output and promote tumorigenesis in vivo. METTL13-catalyzed eEF1A methylation increases eEF1A's intrinsic GTPase activity in vitro and protein production in cells. METTL13 and eEF1AK55me2 levels are upregulated in cancer and negatively correlate with pancreatic and lung cancer patient survival. METTL13 deletion and eEF1AK55me2 loss dramatically reduce Ras-driven neoplastic growth in mouse models and in patient-derived xenografts (PDXs) from primary pancreatic and lung tumors. Finally, METTL13 depletion renders PDX tumors hypersensitive to drugs that target growth-signaling pathways. Together, our work uncovers a mechanism by which lethal cancers become dependent on the METTL13-eEF1AK55me2 axis to meet their elevated protein synthesis requirement and suggests that METTL13 inhibition may constitute a targetable vulnerability of tumors driven by aberrant Ras signaling."
WILLIAM MOORE,"Bostonia, first series: v. 8, no. 1-4",
WILLIAM MOORE,Christian education in the light of three theological views of man,
WILLIAM MOORE,Transistor applications,"The Transistor is a new device employing a semi-conductor base material in conjunction with multiple point contacts to perform many of the functions of vacuum tubes. Although the unit is still in an embryonic stage, its many advantages offer incentive for research. A convenient subject cross-file for analysis of reference data is described. The history of amplifying crystals is outlined for the period beginning 1923 to June, 1948. An analogy is draw between the commercial history of previous inventions end the present status of the Transistor. The history and publicity accorded the Transistor are presented, and analyzed in terms of its potential acceptance as a commercial electronic component. Recently reported developments and public demonstrations are discussed. Sketches and micro-photographs show the details of contacts and germanium wafers as currently produced. Size is compared with standard components. Possibilities for mass production are considered. A brief survey of the theory of conduction in semi-conductors is given as a basis for the theory of Transistor action. An analogy to space charge control is offered. Transistor action is described and typical results presented. Analysis of the action by the use of total derivatives shows that the reflex trans-conductance term describes an effect which cause the voltage across the input terminals to reverse and throw the unit into a regenerative state of operation. The methods of dimensional analysis are employed to investigate the possible combinations of parameters which can occur. It is found that free charge cannot be one of these parameters. The trans-conductance is seen to be a function of the collector impedance. Experiments on the construction of Transistors from 1N34 germanium diode parts are described. Microphotographs show the stages of assembly. Test equipment and procedures are described. Typical circuits and results are give in diagrams and graphs. It is found that units suitable for low performance applications can be assembled satisfactorily on an experimental basis. Characteristics. of twenty-three commercial units are tabulated and are found to disperse widely on a scatter diagram. Performance of units in various circuits is analyzed. A simple R-C oscillator circuit, based on the presence of like phase at input and output, is investigated and found to have interesting and useful properties. The reversal of emitter voltage is experimentally verified. The potential applications of Transistors are evaluated in terms of known and anticipated characteristics. Twenty advantages and fifteen disadvantages are briefly summarized in decreasing order of importance. Circuit functions are divided into five generic groups. Within each group the specific type of circuit is discussed in terms of Transistor characteristics. Any predominantly advantageous specific applications are mentioned. A bibliography of fifty-nine references on Transistors is appended."
WILLIAM MOORE,Impact of muscle trauma on stem cell recruitment during post-natal ectopic bone formation,"INTRODUCTION: Trauma to the musculoskeletal system can result in heterotopic ossification, a condition where aberrant bone tissue is synthesized and mineralized in the soft tissues of the body. Satellite cells expressing Pax7 are the predominant stem cell population found within adult skeletal muscle tissues. Once activated by trauma, satellite cells are primarily implicated in skeletal muscle regeneration by differentiating towards myocytes. Previous research in the lab has shown that no Pax7 derived cells were seen in either the fracture callus or periosteal ectopic bone induced by demineralized bone matrix (DBM). Questions however persist whether trauma can activate Pax7 cells to contribute to ectopic bone formation and whether muscle trauma will enhance the ability of DBM to induce ectopic bone in muscle. OBJECTIVES: Identify how muscle trauma effects DBM-induced ectopic bone formation and characterize the contribution of the Pax7 satellite cell population in DBM-induced ectopic bone formation after muscle trauma. METHODS: The tamoxifen inducible Pax7^tm1(cre/ER2)Gaka/J transgenic mice were crossed with B6.Cg-Gt(ROSA)26sor<tm14(CAG-tdTomato)Hze>/J to create Pax7/Ai14 reporter. These animals were subsequently crossed with B6,129S7-Rag1^tm1Mom/J mice. This created a transgenic reporter mouse that allows for the implantation of human DBM. Two tamoxifen doses (within 48 hours) were given to the animals approximately 31 days prior to surgery. Ectopic bone was induced by surgical implantation of DBM (50 mg) with 0.1 µg of bone morphogenic protein 2 (BMP-2) on the femoral periosteum or in the skeletal muscle tissue of the upper hind limb. Following implantation, mice received varying amounts of blunt force trauma to induce skeletal muscle trauma. Ectopic bone was then evaluated radiologically using plain film and micro-computed tomography, and histologically through fluorescence and brightfield microscopy. Micro-computed tomography allowed for the calculation of the ectopic bone volume, as well as the creation of 3D renderings of the ectopic bone. Fluorescence microscopy allowed for the visualization of recruited Pax7 positive satellite cells to the DBM-induced ectopic bone. Trichrome staining techniques allowed for the visualization and categorization of tissue types including skeletal muscle, un-mineralized and mineralized bone, and cartilage. RESULTS: Muscle trauma did not significantly change the volume of ectopic bone that was induced by BMP-2 supplemented DBM that was implanted on either the periosteum or in skeletal muscle. However, the amount of BMP2 that was needed within DBM to induce ectopic bone within muscle was greatly decreased with muscle trauma. Intriguingly, muscle trauma resulted in the activation and recruitment of Pax7 positive cells to the DBM-induced ectopic bone in both periosteal and skeletal muscle implants. CONCLUSIONS: Skeletal muscle trauma does not appear to impact the resulting bone volume of BMP2 supplemented DBM induced ectopic bone formation. However, the decreased dose of BMP-2 that was needed to induce ectopic bone formation within muscle suggests that trauma sensitized the stem cell populations that contribute to ectopic bone to BMP induction. The appearance of Pax7 within the newly formed ectopic bone with muscle trauma suggests that the muscle trauma effects the plasticity of Pax7 satellite enabling them to contribute to ectopic bone formation. Further research is needed to elucidate the molecular mechanism(s), which muscle trauma activates that favor ectopic bone formation and promotes the plasticity of Pax7 muscle satellite cells. These studies provide basis for the identification of novel therapeutic targets to treat heterotopic ossification."
WILLIAM MOORE,A study of the ability of prospective elementary teachers to understand and use maps,
WILLIAM MOORE,Broadband multi-wavelength properties of M87 during the 2017 Event Horizon Telescope campaign,"In 2017, the Event Horizon Telescope (EHT) Collaboration succeeded in capturing the first direct image of the center of the M87 galaxy. The asymmetric ring morphology and size are consistent with theoretical expectations for a weakly accreting supermassive black hole of mass ∼6.5 × 109 M ⊙. The EHTC also partnered with several international facilities in space and on the ground, to arrange an extensive, quasi-simultaneous multi-wavelength campaign. This Letter presents the results and analysis of this campaign, as well as the multi-wavelength data as a legacy data repository. We captured M87 in a historically low state, and the core flux dominates over HST-1 at high energies, making it possible to combine core flux constraints with the more spatially precise very long baseline interferometry data. We present the most complete simultaneous multi-wavelength spectrum of the active nucleus to date, and discuss the complexity and caveats of combining data from different spatial scales into one broadband spectrum. We apply two heuristic, isotropic leptonic single-zone models to provide insight into the basic source properties, but conclude that a structured jet is necessary to explain M87’s spectrum. We can exclude that the simultaneous γ-ray emission is produced via inverse Compton emission in the same region producing the EHT mm-band emission, and further conclude that the γ-rays can only be produced in the inner jets (inward of HST-1) if there are strongly particle-dominated regions. Direct synchrotron emission from accelerated protons and secondaries cannot yet be excluded."
WILLIAM MOORE,Taking the pulse of Earth's tropical forests using networks of highly distributed plots,"Tropical forests are the most diverse and productive ecosystems on Earth. While better understanding of these forests is critical for our collective future, until quite recently efforts to measure and monitor them have been largely disconnected. Networking is essential to discover the answers to questions that transcend borders and the horizons of funding agencies. Here we show how a global community is responding to the challenges of tropical ecosystem research with diverse teams measuring forests tree-by-tree in thousands of long-term plots. We review the major scientific discoveries of this work and show how this process is changing tropical forest science. Our core approach involves linking long-term grassroots initiatives with standardized protocols and data management to generate robust scaled-up results. By connecting tropical researchers and elevating their status, our Social Research Network model recognises the key role of the data originator in scientific discovery. Conceived in 1999 with RAINFOR (South America), our permanent plot networks have been adapted to Africa (AfriTRON) and Southeast Asia (T-FORCES) and widely emulated worldwide. Now these multiple initiatives are integrated via ForestPlots.net cyber-infrastructure, linking colleagues from 54 countries across 24 plot networks. Collectively these are transforming understanding of tropical forests and their biospheric role. Together we have discovered how, where and why forest carbon and biodiversity are responding to climate change, and how they feedback on it. This long-term pan-tropical collaboration has revealed a large long-term carbon sink and its trends, as well as making clear which drivers are most important, which forest processes are affected, where they are changing, what the lags are, and the likely future responses of tropical forests as the climate continues to change. By leveraging a remarkably old technology, plot networks are sparking a very modern revolution in tropical forest science. In the future, humanity can benefit greatly by nurturing the grassroots communities now collectively capable of generating unique, long-term understanding of Earth's most precious forests."
WILLIAM MOORE,Scintillation light detection in the 6-m drift-length ProtoDUNE Dual Phase liquid argon TPC,"DUNE is a dual-site experiment for long-baseline neutrino oscillation studies, neutrino astrophysics and nucleon decay searches. ProtoDUNE Dual Phase (DP) is a 6  ×  6  ×  6 m 3 liquid argon time-projection-chamber (LArTPC) that recorded cosmic-muon data at the CERN Neutrino Platform in 2019-2020 as a prototype of the DUNE Far Detector. Charged particles propagating through the LArTPC produce ionization and scintillation light. The scintillation light signal in these detectors can provide the trigger for non-beam events. In addition, it adds precise timing capabilities and improves the calorimetry measurements. In ProtoDUNE-DP, scintillation and electroluminescence light produced by cosmic muons in the LArTPC is collected by photomultiplier tubes placed up to 7 m away from the ionizing track. In this paper, the ProtoDUNE-DP photon detection system performance is evaluated with a particular focus on the different wavelength shifters, such as PEN and TPB, and the use of Xe-doped LAr, considering its future use in giant LArTPCs. The scintillation light production and propagation processes are analyzed and a comparison of simulation to data is performed, improving understanding of the liquid argon properties."
WILLIAM MOORE,Prospects for beyond the standard model physics searches at the deep underground neutrino experiment: DUNE collaboration,"The Deep Underground Neutrino Experiment (DUNE) will be a powerful tool for a variety of physics topics. The high-intensity proton beams provide a large neutrino flux, sampled by a near detector system consisting of a combination of capable precision detectors, and by the massive far detector system located deep underground. This configuration sets up DUNE as a machine for discovery, as it enables opportunities not only to perform precision neutrino measurements that may uncover deviations from the present three-flavor mixing paradigm, but also to discover new particles and unveil new interactions and symmetries beyond those predicted in the Standard Model (SM). Of the many potential beyond the Standard Model (BSM) topics DUNE will probe, this paper presents a selection of studies quantifying DUNE's sensitivities to sterile neutrino mixing, heavy neutral leptons, non-standard interactions, CPT symmetry violation, Lorentz invariance violation, neutrino trident production, dark matter from both beam induced and cosmogenic sources, baryon number violation, and other new physics topics that complement those at high-energy colliders and significantly extend the present reach."
WILLIAM MOORE,Identification and reconstruction of low-energy electrons in the ProtoDUNE-SP detector,
WILLIAM MOORE,The long-baseline neutrino experiment: exploring fundamental symmetries of the universe,"The preponderance of matter over antimatter in the early Universe, the dynamics of the supernova bursts that produced the heavy elements necessary for life and whether protons eventually decay --- these mysteries at the forefront of particle physics and astrophysics are key to understanding the early evolution of our Universe, its current state and its eventual fate. The Long-Baseline Neutrino Experiment (LBNE) represents an extensively developed plan for a world-class experiment dedicated to addressing these questions. LBNE is conceived around three central components: (1) a new, high-intensity neutrino source generated from a megawatt-class proton accelerator at Fermi National Accelerator Laboratory, (2) a near neutrino detector just downstream of the source, and (3) a massive liquid argon time-projection chamber deployed as a far detector deep underground at the Sanford Underground Research Facility. This facility, located at the site of the former Homestake Mine in Lead, South Dakota, is approximately 1,300 km from the neutrino source at Fermilab -- a distance (baseline) that delivers optimal sensitivity to neutrino charge-parity symmetry violation and mass ordering effects. This ambitious yet cost-effective design incorporates scalability and flexibility and can accommodate a variety of upgrades and contributions. With its exceptional combination of experimental configuration, technical capabilities, and potential for transformative discoveries, LBNE promises to be a vital facility for the field of particle physics worldwide, providing physicists from around the globe with opportunities to collaborate in a twenty to thirty year program of exciting science. In this document we provide a comprehensive overview of LBNE's scientific objectives, its place in the landscape of neutrino physics worldwide, the technologies it will incorporate and the capabilities it will possess."
JESSE MEZ,Clinicopathological evaluation of chronic traumatic encephalopathy in players of American football,"IMPORTANCE: Players of American football may be at increased risk of long-term neurological conditions, particularly chronic traumatic encephalopathy (CTE). OBJECTIVE: To determine the neuropathological and clinical features of deceased football players with CTE. DESIGN, SETTING, AND PARTICIPANTS: Case series of 202 football players whose brains were donated for research. Neuropathological evaluations and retrospective telephone clinical assessments (including head trauma history) with informants were performed blinded. Online questionnaires ascertained athletic and military history. EXPOSURES: Participation in American football at any level of play. MAIN OUTCOMES AND MEASURES: Neuropathological diagnoses of neurodegenerative diseases, including CTE, based on defined diagnostic criteria; CTE neuropathological severity (stages I to IV or dichotomized into mild [stages I and II] and severe [stages III and IV]); informant-reported athletic history and, for players who died in 2014 or later, clinical presentation, including behavior, mood, and cognitive symptoms and dementia. RESULTS: Among 202 deceased former football players (median age at death, 66 years [interquartile range, 47-76 years]), CTE was neuropathologically diagnosed in 177 players (87%; median age at death, 67 years [interquartile range, 52-77 years]; mean years of football participation, 15.1 [SD, 5.2]), including 0 of 2 pre–high school, 3 of 14 high school (21%), 48 of 53 college (91%), 9 of 14 semiprofessional (64%), 7 of 8 Canadian Football League (88%), and 110 of 111 National Football League (99%) players. Neuropathological severity of CTE was distributed across the highest level of play, with all 3 former high school players having mild pathology and the majority of former college (27 [56%]), semiprofessional (5 [56%]), and professional (101 [86%]) players having severe pathology. Among 27 participants with mild CTE pathology, 26 (96%) had behavioral or mood symptoms or both, 23 (85%) had cognitive symptoms, and 9 (33%) had signs of dementia. Among 84 participants with severe CTE pathology, 75 (89%) had behavioral or mood symptoms or both, 80 (95%) had cognitive symptoms, and 71 (85%) had signs of dementia. CONCLUSIONS AND RELEVANCE: In a convenience sample of deceased football players who donated their brains for research, a high proportion had neuropathological evidence of CTE, suggesting that CTE may be related to prior participation in football."
IVANA DELALLE,Capzb2 Interacts with β-Tubulin to Regulate Growth Cone Morphology and Neurite Outgrowth,"An actin regulatory protein unexpectedly also controls microtubule polymerization during the formation and maintenance of cellular outgrowths in neurons. Capping protein (CP) is a heterodimer that regulates actin assembly by binding to the barbed end of F-actin. In cultured nonneuronal cells, each CP subunit plays a critical role in the organization and dynamics of lamellipodia and filopodia. Mutations in either α or β CP subunit result in retinal degeneration in Drosophila. However, the function of CP subunits in mammalian neurons remains unclear. Here, we investigate the role of the β CP subunit expressed in the brain, Capzb2, in growth cone morphology and neurite outgrowth. We found that silencing Capzb2 in hippocampal neurons resulted in short neurites and misshapen growth cones in which microtubules overgrew into the periphery and completely overlapped with F-actin. In searching for the mechanisms underlying these cytoskeletal abnormalities, we identified β-tubulin as a novel binding partner of Capzb2 and demonstrated that Capzb2 decreases the rate and the extent of tubulin polymerization in vitro. We mapped the region of Capzb2 that was required for the subunit to interact with β-tubulin and inhibit microtubule polymerization. A mutant Capzb2 lacking this region was able to bind F-actin and form a CP heterodimer with α2-subunit. However, this mutant was unable to rescue the growth cone and neurite outgrowth phenotypes caused by Capzb2 knockdown. Together, these data suggest that Capzb2 plays an important role in growth cone formation and neurite outgrowth and that the underlying mechanism may involve direct interaction between Capzb2 and microtubules. Author SummaryNeuronal growth, migration, and survival depend on the regulated formation of cellular outgrowths called neurites. Extension of normal neurites requires coordinated interactions between cytoskeletal networks made up of microfilaments (composed of F-actin) and microtubules (formed by tubulin) in structures called growth cones that form at the tips of growing neurites. Capping protein (CP) is a heterodimer that regulates F-actin assembly in a variety of cell types. Surprisingly, the neuronal CP β subunit, Capzb2, not only regulates F-actin assembly, but also inhibits microtubule polymerization by direct interaction with tubulin. We further show that this function of Capzb2 is required for establishment of the normal shape of growth cones and the appropriate length of neurites. Our data thus reveal an unexpected, dual role for CP in the regulation of both microfilaments and microtubules in neurons."
IVANA DELALLE,Modulators of Cytoskeletal Reorganization in CA1 Hippocampal Neurons Show Increased Expression in Patients at Mid-Stage Alzheimer's Disease,"During the progression of Alzheimer's disease (AD), hippocampal neurons undergo cytoskeletal reorganization, resulting in degenerative as well as regenerative changes. As neurofibrillary tangles form and dystrophic neurites appear, sprouting neuronal processes with growth cones emerge. Actin and tubulin are indispensable for normal neurite development and regenerative responses to injury and neurodegenerative stimuli. We have previously shown that actin capping protein beta2 subunit, Capzb2, binds tubulin and, in the presence of tau, affects microtubule polymerization necessary for neurite outgrowth and normal growth cone morphology. Accordingly, Capzb2 silencing in hippocampal neurons resulted in short, dystrophic neurites, seen in neurodegenerative diseases including AD. Here we demonstrate the statistically significant increase in the Capzb2 expression in the postmortem hippocampi in persons at mid-stage, Braak and Braak stage (BB) III-IV, non-familial AD in comparison to controls. The dynamics of Capzb2 expression in progressive AD stages cannot be attributed to reactive astrocytosis. Moreover, the increased expression of Capzb2 mRNA in CA1 pyramidal neurons in AD BB III-IV is accompanied by an increased mRNA expression of brain derived neurotrophic factor (BDNF) receptor tyrosine kinase B (TrkB), mediator of synaptic plasticity in hippocampal neurons. Thus, the up-regulation of Capzb2 and TrkB may reflect cytoskeletal reorganization and/or regenerative response occurring in hippocampal CA1 neurons at a specific stage of AD progression."
MARCUS BELLAMY,Supply chain network structure and environmental information disclosure,"Recognizing that supply network structure has implications for a focal firm’s ability to access environmental information embedded in its supply network, this paper draws on structural, environmental, and financial data from Bloomberg to test the relationship between a focal firm’s supply network structure and its extent of environmental information disclosure."
MARCUS BELLAMY,Surge pricing on a service platform under spatial spillovers: evidence from Uber,"Ride-sharing platforms employ surge pricing to match anticipated capacity spillover with demand. We develop an optimization model to characterize the relationship between surge price and spillover. We test predicted relationships using a spatial panel model on a dataset from Ubers operation. Results reveal that Ubers pricing accounts for both capacity and price spillover. There is a debate in the management community on the ecacy of labor welfare mechanisms associated with shared capacity. We conduct counterfactual analysis to provide guidance in regards to the debate, for managing congestion, while accounting for consumer and labor welfare through this online platform."
MARCUS BELLAMY,Supply network drivers of risk and performance,"This chapter reviews historical and contemporary research in economics, operations management, and finance that adopts a network perspective for modeling interactions between agents. It argues that incorporating extended network characteristics in the analysis can yield unique insights compared to the analysis done at the level of dyads or local neighborhoods. The chapter explains how new network-based models contribute to the academic debate and advance our understanding of supply network drivers of performance and risk. This includes a discussion on the structural configuration of a firm’s interconnected portfolio of upstream supplier and downstream customer relationships and its role in influencing financial and operational performance as well as its innovation."
MARCUS BELLAMY,Visual analytics for supply network management: system design and evaluation,"We propose a visual analytic system to augment and enhance decision-making processes of supply chain managers. Several design requirements drive the development of our integrated architecture and lead to three primary capabilities of our system prototype. First, a visual analytic system must integrate various relevant views and perspectives that highlight different structural aspects of a supply network. Second, the system must deliver required information on-demand and update the visual representation via user-initiated interactions. Third, the system must provide both descriptive and predictive analytic functions for managers to gain contingency intelligence. Based on these capabilities we implement an interactive web-based visual analytic system. Our system enables managers to interactively apply visual encodings based on different node and edge attributes to facilitate mental map matching between abstract attributes and visual elements. Grounded in cognitive fit theory, we demonstrate that an interactive visual system that dynamically adjusts visual representations to the decision environment can significantly enhance decision-making processes in a supply network setting. We conduct multi-stage evaluation sessions with prototypical users that collectively confirm the value of our system. Our results indicate a positive reaction to our system. We conclude with implications and future research opportunities."
JENNIFER DAVIDS,A large peptidome dataset improves HLA class I epitope prediction across most of the human population,"Prediction of HLA epitopes is important for the development of cancer immunotherapies and vaccines. However, current prediction algorithms have limited predictive power, in part because they were not trained on high-quality epitope datasets covering a broad range of HLA alleles. To enable prediction of endogenous HLA class I-associated peptides across a large fraction of the human population, we used mass spectrometry to profile >185,000 peptides eluted from 95 HLA-A, -B, -C and -G mono-allelic cell lines. We identified canonical peptide motifs per HLA allele, unique and shared binding submotifs across alleles and distinct motifs associated with different peptide lengths. By integrating these data with transcript abundance and peptide processing, we developed HLAthena, providing allele-and-length-specific and pan-allele-pan-length prediction models for endogenous peptide presentation. These models predicted endogenous HLA class I-associated ligands with 1.5-fold improvement in positive predictive value compared with existing tools and correctly identified >75% of HLA-bound peptides that were observed experimentally in 11 patient-derived tumor cell lines."
JENNIFER DAVIDS,Cumulative Community-Level Lead Exposure and Pulse Pressure: The Normative Aging Study,"BACKGROUND. Pulse pressure increases with age in industrialized societies as a manifestation of arterial stiffening. Lead accumulates in the vasculature and is associated with vascular oxidative stress, which can promote functional and structural vascular disease. OBJECTIVES. We tested the hypothesis that cumulative community-level lead exposure, measured with K-X-ray fluorescence, is associated with pulse pressure in a cohort of adult men. METHODS AND RESULTS. In a cross-sectional analysis of 593 men not treated with antihypertensive medication, tibia lead was positively associated with pulse pressure (p < 0.001). Adjusting for age, race, diabetes, family history of hypertension, education, waist circumference, alcohol intake, smoking history, height, heart rate, fasting glucose, and total cholesterol-to-HDL ratio, increasing quintiles of tibia lead remained associated with increased pulse pressure (ptrend = 0.02). Men with tibia lead above the median (19.0 μg/g) had, on average, a 4.2-mmHg (95% confidence interval, 1.9-6.5) higher pulse pressure than men with tibia lead level below the median. In contrast, blood lead level was not associated with pulse pressure. CONCLUSIONS. These data indicate that lead exposure may contribute to the observed increase in pulse pressure that occurs with aging in industrialized societies. Lead accumulation may contribute to arterial aging, perhaps providing mechanistic insight into the observed association of low-level lead exposure with cardiovascular mortality."
JENNIFER DAVIDS,Cumulative Lead Exposure and Tooth Loss in Men: The Normative Aging Study,"BACKGROUND. Individuals previously exposed to lead remain at risk because of endogenous release of lead stored in their skeletal compartments. However, it is not known if long-term cumulative lead exposure is a risk factor for tooth loss. OBJECTIVES. We examined the association of bone lead concentrations with loss of natural teeth. METHODS. We examined 333 men enrolled in the Veterans Affairs Normative Aging Study. We used a validated K-shell X-ray fluorescence (KXRF) method to measure lead concentrations in the tibial midshaft and patella. A dentist recorded the number of teeth remaining, and tooth loss was categorized as 0, 1-8 or ≥ 9 missing teeth. We used proportional odds models to estimate the association of bone lead biomarkers with tooth loss, adjusting for age, smoking, diabetes, and other putative confounders. RESULTS. Participants with ≥ 9 missing teeth had significantly higher bone lead concentrations than those who had not experienced tooth loss. In multivariable-adjusted analyses, men in the highest tertile of tibia lead (> 23 μg/g) and patella lead (> 36 μg/g) had approximately three times the odds of having experienced an elevated degree of tooth loss (≥ 9 vs. 0-8 missing teeth or ≥ 1 vs. 0 missing teeth) as those in the lowest tertile [prevalence odds ratio (OR) = 3.03; 95% confidence interval (CI), 1.60-5.76 and OR = 2.41; 95% CI, 1.30-4.49, respectively]. Associations between bone lead biomarkers and tooth loss were similar in magnitude to the increased odds observed in participants who were current smokers. CONCLUSION. Long-term cumulative lead exposure is associated with increased odds of tooth loss."
JENNIFER DAVIDS,Direct Assessment of Cumulative Aryl Hydrocarbon Receptor Agonist Activity in Sera from Experimentally Exposed Mice and Environmentally Exposed Humans,"BACKGROUND. Aryl hydrocarbon receptor (AhR) ligands adversely affect many biological processes. However, assessment of the significance of human exposures is hampered by an incomplete understanding of how complex mixtures affect AhR activation/inactivation. OBJECTIVES. These studies used biological readouts to provide a broader context for estimating human risk than that obtained with serum extraction and gas chromatography/mass spectroscopy (GC/MS)-based assays alone. METHODS. AhR agonist activity was quantified in sera from dioxin-treated mice, commercial human sources, and polychlorinated biphenyl (PCB)-exposed Faroe Islanders using an AhR-driven reporter cell line. To validate relationships between serum AhR agonist levels and biological outcomes, AhR agonist activity in mouse sera correlated with toxic end points. AhR agonist activity in unmanipulated (""neat"") human sera was compared with these biologically relevant doses and with GC/MS-assayed PCB levels. RESULTS. Mouse serum AhR agonist activity correlated with injected dioxin dose, thymic atrophy, and heptomegaly, validating the use of neat serum to assess AhR agonist activity. AhR agonist activity in sera from Faroe Islanders varied widely, was associated with the frequency of recent pilot whale dinners, but did not correlate with levels of PCBs quantified by GC/MS. Surprisingly, significant ""baseline"" AhR activity was found in commercial human sera. CONCLUSIONS. An AhR reporter assay revealed cumulative levels of AhR activation potential in neat serum, whereas extraction may preclude detection of important non-dioxin-like biological activity. Significant levels of AhR agonist activity in commercial sera and in Faroe Islander sera, compared with that from experimentally exposed mice, suggest human exposures that are biologically relevant in both populations."
JENNIFER DAVIDS,Asbestos Burden Predicts Survival in Pleural Mesothelioma,"BACKGROUND. Malignant pleural mesothelioma (MPM) is a rapidly fatal asbestos-associated malignancy with a median survival time of < 1 year following diagnosis. Treatment strategy is determined in part using known prognostic factors. OBJECTIVE. The aim of this study was to examine the relationship between asbestos exposure and survival outcome in MPM in an effort to advance the understanding of the contribution of asbestos exposure to MPM prognosis. METHODS. We studied incident cases of MPM patients enrolled through the International Mesothelioma Program at Brigham and Women's Hospital in Boston, Massachusetts, using survival follow-up, self-reported asbestos exposure (n = 128), and a subset of cases (n = 80) with quantitative asbestos fiber burden measures. RESULTS. Consistent with the established literature, we found independent, significant associations between male sex and reduced survival (p < 0.04), as well as between nonepithelioid tumor histology and reduced survival (p < 0.02). Although self-reported exposure to asbestos was not predictive of survival among our cases, stratifying quantitative asbestos fiber burden [number of asbestos bodies per gram of lung (wet weight)] into groups of low (0-99 asbestos bodies), moderate (100-1,099), and high fiber burden (> 1,099), suggested a survival duration association among these groups (p = 0.06). After adjusting for covariates in a Cox model, we found that patients with a low asbestos burden had a 3-fold elevated risk of death compared to patients with a moderate fiber burden [95% confidence interval (CI), 0.95-9.5; p = 0.06], and patients with a high asbestos burden had a 4.8-fold elevated risk of death (95% CI, 1.5-15.0; p < 0.01) versus those with moderate exposure. CONCLUSION. Our data suggest that patient survival is associated with asbestos fiber burden in MPM and is perhaps modified by susceptibility."
JENNIFER DAVIDS,Association of Cumulative Lead Exposure with Parkinson's Disease,"BACKGROUND. Research using reconstructed exposure histories has suggested an association between heavy metal exposures, including lead, and Parkinson's disease (PD), but the only study that used bone lead, a biomarker of cumulative lead exposure, found a nonsignificant increase in risk of PD with increasing bone lead. OBJECTIVES. We sought to assess the association between bone lead and PD. METHODS. Bone lead concentrations were measured using 109Cd excited K-shell X-ray fluorescence from 330 PD patients (216 men, 114 women) and 308 controls (172 men, 136 women) recruited from four clinics for movement disorders and general-community cohorts. Adjusted odds ratios (ORs) for PD were calculated using logistic regression. RESULTS. The average age of cases and controls at bone lead measurement was 67 (SD = 10) and 69 (SD = 9) years of age, respectively. In primary analyses of cases and controls recruited from the same groups, compared with the lowest quartile of tibia lead, the OR for PD in the highest quartile was 3.21 [95% confidence interval (CI), 1.17-8.83]. Results were similar but slightly weaker in analyses restricted to cases and controls recruited from the movement disorders clinics only (fourth-quartile OR = 2.57; 95% CI, 1.11-5.93) or when we included controls recruited from sites that did not also contribute cases (fourth-quartile OR = 1.91; 95% CI, 1.01-3.60). We found no association with patella bone lead. CONCLUSIONS. These findings, using an objective biological marker of cumulative lead exposure among typical PD patients seen in our movement disorders clinics, strengthen the evidence that cumulative exposure to lead increases the risk of PD."
JENNIFER DAVIDS,Modifying Effects of the HFE Polymorphisms on the Association between Lead Burden and Cognitive Decline,"BACKGROUND. As iron and lead promote oxidative damage, and hemochromatosis (HFE) gene polymorphisms increase body iron burden, HFE variant alleles may modify the lead burden and cognitive decline relationship. OBJECTIVE. Our goal was to assess the modifying effects of HFE variants on the lead burden and cognitive decline relation in older adults. METHODS. We measured tibia and patella lead using K-X-ray fluorescence (1991-1999) among participants of the Normative Aging Study, a longitudinal study of community-dwelling men from greater Boston. We assessed cognitive function with the Mini-Mental State Examination (MMSE) twice (1993-1998 and 1995-2000) and genotyped participants for HFE polymorphisms. We estimated the adjusted mean differences in lead-associated annual cognitive decline across HFE genotype groups (n = 358). RESULTS. Higher tibia lead was associated with steeper cognitive decline among participants with at least one HFE variant allele compared with men with only wild-type alleles (p interaction = 0.03), such that a 15 μg/g increase in tibia lead was associated with a 0.2 point annual decrement in MMSE score among HFE variant allele carriers. This difference in scores among men with at least one variant allele was comparable to the difference in baseline MMSE scores that we observed among men who were 4 years apart in age. Moreover, the deleterious association between tibia lead and cognitive decline appeared progressively worse in participants with increasingly more copies of HFE variant alleles (p-trend = 0.008). Results for patella lead were similar. CONCLUSION. Our findings suggest that HFE polymorphisms greatly enhance susceptibility to lead-related cognitive impairment in a pattern consistent with allelelic dose."
JENNIFER DAVIDS,LHS 1610A: a nearby mid-M dwarf with a companion that is likely a brown dwarf,"We present the spectroscopic orbit of LHS 1610A, a newly discovered single-lined spectroscopic binary with a trigonometric distance placing it at 9.9 ± 0.2 pc. We obtained spectra with the TRES instrument on the 1.5 m Tillinghast Reflector at the Fred Lawrence Whipple Observatory located on Mt. Hopkins in AZ. We demonstrate the use of the TiO molecular bands at 7065–7165 Å to measure radial velocities and achieve an average estimated velocity uncertainty of 28 m s−1. We measure the orbital period to be 10.6 days and calculate a minimum mass of 44.8 ± 3.2 M Jup for the secondary, indicating that it is likely a brown dwarf. We place an upper limit to 3σ of 2500 K on the effective temperature of the companion from infrared spectroscopic observations using IGRINS on the 4.3 m Discovery Channel Telescope. In addition, we present a new photometric rotation period of 84.3 days for the primary star using data from the MEarth-South Observatory, with which we show that the system does not eclipse."
JENNIFER DAVIDS,Family-focused treatment for childhood depression: model and case illustrations,"Although the evidence base for treatment of depressive disorders in adolescents has strengthened in recent years, less is known about the treatment of depression in middle to late childhood. A family-based treatment may be optimal in addressing the interpersonal problems and symptoms frequently evident among depressed children during this developmental phase, particularly given data indicating that attributes of the family environment predict recovery versus continuing depression among depressed children. Family-Focused Treatment for Childhood Depression (FFT-CD) is designed as a 15-session family treatment with both the youth and parents targeting two putative mechanisms involved in recovery: (a) enhancing family support, specifically decreasing criticism and increasing supportive interactions; and (b) strengthening specific cognitive-behavioral skills within a family context that have been central to CBT for depression, specifically behavioral activation, communication, and problem solving. This article describes in detail the FFT-CD protocol and illustrates its implementation with three depressed children and their families. Common themes/challenges in treatment included family stressors, comorbidity, parental mental health challenges, and inclusion/integration of siblings into sessions. These three children experienced positive changes from pre- to posttreatment on assessor-rated depressive symptoms, parent- and child-rated depressive symptoms, and parent-rated internalizing and externalizing symptoms. These changes were maintained at follow-up evaluations 4 and 9 months following treatment completion."
JENNIFER DAVIDS,High time for conservation: adding the environment to the debate on marijuana liberalization,"The liberalization of marijuana policies, including the legalization of medical and recreational marijuana, is sweeping the United States and other countries. Marijuana cultivation can have significant negative collateral effects on the environment that are often unknown or overlooked. Focusing on the state of California, where by some estimates 60%–70% of the marijuana consumed in the United States is grown, we argue that (a) the environmental harm caused by marijuana cultivation merits a direct policy response, (b) current approaches to governing the environmental effects are inadequate, and (c) neglecting discussion of the environmental impacts of cultivation when shaping future marijuana use and possession policies represents a missed opportunity to reduce, regulate, and mitigate environmental harm."
JENNIFER DAVIDS,"The scale, scope and impact of alternative care for OVC in developing countries","Over 145 million children worldwide have lost one or both parents due to various causes, 15 million of these are due to AIDS (1,2); and many more have been made vulnerable due to other causes. The global community has responded by putting in place various care arrangements for these children. However, the scale, scope and impact of these alternative care approaches have not been well summarized. The aim of this literature review is to synthesize and analyze available data on alternative care approaches and the impact of these placements on the lives of orphans and other vulnerable children. Both the short-term and long term wellbeing of a child depends a lot on where they live and the care they receive in those settings."
JENNIFER DAVIDS,"Rx: the official, unabridged, ""how to"" guide to 1st year: 1988-1989",
JENNIFER DAVIDS,"Children of female sex workers and drug users: a review of vulnerability, resilience and family-centred models of care","BACKGROUND Injection drug users and female sex workers are two of the populations most at risk for becoming infected with HIV in countries with concentrated epidemics. Many of the adults who fall into these categories are also parents, but little is known about the vulnerabilities faced by their children, their children's sources of resilience, or programmes providing services to these often fragile families. This review synthesizes evidence from disparate sources describing the vulnerabilities and resilience of the children of female sex workers and drug users, and documents some models of care that have been put in place to assist them. REVIEW A large literature assessing the vulnerability and resilience of children of drug users and alcoholics in developed countries was found. Research on the situation of the children of sex workers is extremely limited. Children of drug users and sex workers can face unique risks, stigma and discrimination, but both child vulnerability and resilience are associated in the drug use literature with the physical and mental health of parents and family context. Family-centred interventions have been implemented in low- and middle-income contexts, but they tend to be small, piecemeal and struggling to meet demand; they are poorly documented, and most have not been formally evaluated. We present preliminary descriptive data from an organization working with pregnant and new mothers who are drug users in Ukraine and from an organization providing services to sex workers and their families in Zambia. CONCLUSIONS Because parents' drug use or sex work is often illegal and hidden, identifying their children can be difficult and may increase children's vulnerability and marginalization. Researchers and service providers, therefore, need to proceed with caution when attempting to reach these populations, but documentation and evaluation of current programmes should be prioritized."
JENNIFER DAVIDS,"Caribbean Corals in Crisis: Record Thermal Stress, Bleaching, and Mortality in 2005","BACKGROUND. The rising temperature of the world's oceans has become a major threat to coral reefs globally as the severity and frequency of mass coral bleaching and mortality events increase. In 2005, high ocean temperatures in the tropical Atlantic and Caribbean resulted in the most severe bleaching event ever recorded in the basin. METHODOLOGY/PRINCIPAL FINDINGS. Satellite-based tools provided warnings for coral reef managers and scientists, guiding both the timing and location of researchers' field observations as anomalously warm conditions developed and spread across the greater Caribbean region from June to October 2005. Field surveys of bleaching and mortality exceeded prior efforts in detail and extent, and provided a new standard for documenting the effects of bleaching and for testing nowcast and forecast products. Collaborators from 22 countries undertook the most comprehensive documentation of basin-scale bleaching to date and found that over 80% of corals bleached and over 40% died at many sites. The most severe bleaching coincided with waters nearest a western Atlantic warm pool that was centered off the northern end of the Lesser Antilles. CONCLUSIONS/SIGNIFICANCE. Thermal stress during the 2005 event exceeded any observed from the Caribbean in the prior 20 years, and regionally-averaged temperatures were the warmest in over 150 years. Comparison of satellite data against field surveys demonstrated a significant predictive relationship between accumulated heat stress (measured using NOAA Coral Reef Watch's Degree Heating Weeks) and bleaching intensity. This severe, widespread bleaching and mortality will undoubtedly have long-term consequences for reef ecosystems and suggests a troubled future for tropical marine ecosystems under a warming climate."
JENNIFER DAVIDS,"Children of female sex workers and injection drug users: a review of vulnerability, resilience, and family-centered models of care in low and middle-income countries","Background: Injection drug users and female sex workers are often categorized as two of the populations most at risk for becoming infected with HIV in countries with concentrated epidemics. Many of the adults who fall into these categories in low and middle income contexts are also parents, but little is known about the vulnerabilities faced by their children, their sources of resilience, or programs providing services to these often fragile families. Methods: We reviewed the peer-reviewed and gray literature to synthesize current knowledge on the situation of these children and families, and interventions currently in place in low and middle income countries. Organizational websites and references of all relevant sources were manually searched, and key informants from service organizations were contacted by phone and email. Results: A large amount of literature assessing the vulnerability and resilience of children of drug users and alcoholics in developed countries was found. Their children can face unique risks, stigma, and discrimination, but child vulnerability and resilience are associated in the substance abuse literature with the physical and mental health of parents and family context. Research on the situation of the children of sex workers is extremely limited. Interventions have been implemented in low and middle-income contexts but they tend to be small, piecemeal, struggling to meet demand; and undocumented, and most have not been evaluated. We present preliminary descriptive data from an organization working with pregnant and new mothers who are drug users in Ukraine and an organization providing services to sex workers and their families in Zambia. Discussion: Because parents’ drug use, sex work, or same sex relationships are often illegal and hidden, identifying their children can be difficult and may increase their vulnerability and marginalization. Therefore, researchers and service providers must proceed with caution when attempting to reach this population. Promising components of family-centered care include: strengthening family caring capacity through home visitation and peer support, providing early childhood development programs and crèches or drop-in centers for children; economic strengthening and job skills training for parents. Integration of legal assistance with health and other social services is also gaining increased international attention."
JENNIFER DAVIDS,Melting the ICE: lessons from China and the West in the transition from the internal combustion engine to electric vehicles,"A decade after the launch of the contemporary global electric vehicle (EV) market, most cities face a major challenge preparing for rising EV demand. Some cities, and the leaders who shape them, are meeting and even leading demand for EV infrastructure. This book aggregates deep, groundbreaking research in the areas of urban EV deployment for city managers, private developers, urban planners, and utilities who want to understand and lead change."
JENNIFER DAVIDS,Quantum biology revisited,"Photosynthesis is a highly optimized process from which valuable lessons can be learned about the operating principles in nature. Its primary steps involve energy transport operating near theoretical quantum limits in efficiency. Recently, extensive research was motivated by the hypothesis that nature used quantum coherences to direct energy transfer. This body of work, a cornerstone for the field of quantum biology, rests on the interpretation of small-amplitude oscillations in two-dimensional electronic spectra of photosynthetic complexes. This Review discusses recent work reexamining these claims and demonstrates that interexciton coherences are too short lived to have any functional significance in photosynthetic energy transfer. Instead, the observed long-lived coherences originate from impulsively excited vibrations, generally observed in femtosecond spectroscopy. These efforts, collectively, lead to a more detailed understanding of the quantum aspects of dissipation. Nature, rather than trying to avoid dissipation, exploits it via engineering of exciton-bath interaction to create efficient energy flow."
JENNIFER DAVIDS,A super-earth and sub-neptune transiting the late-type M Dwarf LP 791-18,"Planets occur most frequently around cool dwarfs, but only a handful of specific examples are known to orbit the latest-type M stars. Using TESS photometry, we report the discovery of two planets transiting the low-mass star called LP 791-18 (identified by TESS as TOI 736). This star has spectral type M6V, effective temperature 2960 K, and radius 0.17 R ⊙, making it the third-coolest star known to host planets. The two planets straddle the radius gap seen for smaller exoplanets; they include a 1.1R ⊕ planet on a 0.95 day orbit and a 2.3R ⊕ planet on a 5 day orbit. Because the host star is small the decrease in light during these planets' transits is fairly large (0.4% and 1.7%). This has allowed us to detect both planets' transits from ground-based photometry, refining their radii and orbital ephemerides. In the future, radial velocity observations and transmission spectroscopy can both probe these planets' bulk interior and atmospheric compositions, and additional photometric monitoring would be sensitive to even smaller transiting planets."
JENNIFER DAVIDS,Clonal kinetics and single-cell transcriptional profiling of CAR-T cells in patients undergoing CD19 CAR-T immunotherapy,"Chimeric antigen receptor (CAR) T-cell therapy has produced remarkable anti-tumor responses in patients with B-cell malignancies. However, clonal kinetics and transcriptional programs that regulate the fate of CAR-T cells after infusion remain poorly understood. Here we perform TCRB sequencing, integration site analysis, and single-cell RNA sequencing (scRNA-seq) to profile CD8+ CAR-T cells from infusion products (IPs) and blood of patients undergoing CD19 CAR-T immunotherapy. TCRB sequencing shows that clonal diversity of CAR-T cells is highest in the IPs and declines following infusion. We observe clones that display distinct patterns of clonal kinetics, making variable contributions to the CAR-T cell pool after infusion. Although integration site does not appear to be a key driver of clonal kinetics, scRNA-seq demonstrates that clones that expand after infusion mainly originate from infused clusters with higher expression of cytotoxicity and proliferation genes. Thus, we uncover transcriptional programs associated with CAR-T cell behavior after infusion."
JENNIFER DAVIDS,Asbestos exposure predicts cell cycle control Gene promoter methylation in pleural mesothelioma,"Malignant pleural mesothelioma (MPM) is a rapidly fatal tumor with increasing incidence worldwide responsible for many thousands of deaths annually. Although there is a clear link between exposure to asbestos and mesothelioma, and asbestos is known to be both clastogenic and cytotoxic to mesothelial cells, the mechanisms of causation of MPM remain largely unknown. However, there is a rapidly emerging literature that describes inactivation of a diverse array of tumor suppressor genes (TSGs) via promoter DNA CpG methylation in MPM, although the etiology of these alterations remains unclear. We studied the relationships among promoter methylation silencing, asbestos exposure, patient demographics and tumor histology using a directed approach; examining six cell cycle control pathway TSGs in an incident case series of 70 MPMs. Promoter hypermethylation of APC, CCND2, CDKN2A, CDKN2B, HPPBP1 and RASSF1 were assessed. We observed significantly higher lung asbestos body burden if any of these cell cycle genes were methylated (P<0.02), and there was a significant trend of increasing asbestos body counts as the number of methylated cell cycle pathway genes increased from 0 to 1 to >1 (P<0.005). This trend of increasing asbestos body count and increasing number of methylated cell cycle pathway genes remained significant (P<0.05) after controlling for age, gender and tumor histology. These data suggest a novel tumorigenic mechanism of action of asbestos and may contribute to the understanding of precisely how asbestos exposure influences the etiology and clinical course of malignant mesothelioma."
JENNIFER DAVIDS,The genome of the vervet ( Chlorocebus aethiops sabaeus ),"We describe a genome reference of the African green monkey or vervet (Chlorocebus aethiops). This member of the Old World monkey (OWM) superfamily is uniquely valuable for genetic investigations of simian immunodeficiency virus (SIV), for which it is the most abundant natural host species, and of a wide range of health-related phenotypes assessed in Caribbean vervets (C. a. sabaeus), whose numbers have expanded dramatically since Europeans introduced small numbers of their ancestors from West Africa during the colonial era. We use the reference to characterize the genomic relationship between vervets and other primates, the intra-generic phylogeny of vervet subspecies, and genome-wide structural variations of a pedigreed C. a. sabaeus population. Through comparative analyseswith human and rhesus macaque, we characterize at high resolution the unique chromosomal fission events that differentiate the vervets and their close relatives from most other catarrhine primates, in whom karyotype is highly conserved. We also provide a summary of transposable elements and contrast these with the rhesus macaque and human. Analysis of sequenced genomes representing each of the main vervet subspecies supports previously hypothesized relationships between these populations, which range across most of sub-Saharan Africa, while uncovering high levels of genetic diversity within each. Sequence-based analyses of major histocompatibility complex (MHC) polymorphisms reveal extremely low diversity in Caribbean C. a. sabaeus vervets, compared to vervets from putatively ancestral West African regions. In the C. a. sabaeus research population, we discover the first structural variations that are, in some cases, predicted to have a deleterious effect; future studies will determine the phenotypic impact of these variations."
JENNIFER DAVIDS,GJ 1252 b: A 1.2 R ⊕ planet transiting an M3 dwarf at 20.4 pc,"We report the discovery of GJ 1252 b, a planet with a radius of 1.193 ± 0.074 R⊕ and an orbital period of 0.52 days around an M3-type star (0.381 ± 0.019 M⊙, 0.391 ± 0.020 R⊙) located 20.385 ± 0.019 pc away. We use TESS data, ground-based photometry and spectroscopy, Gaia astrometry, and high angular resolution imaging to show that the transit signal seen in the TESS data must originate from a transiting planet. We do so by ruling out all false positive scenarios that attempt to explain the transit signal as originating from an eclipsing stellar binary. Precise Doppler monitoring also leads to a tentative mass measurement of 2.09 ± 0.56 M⊕. The host star proximity, brightness (V = 12.19 mag, K = 7.92 mag), low stellar activity, and the system’s short orbital period make this planet an attractive target for detailed characterization, including precise mass measurement, looking for other objects in the system, and planet atmosphere characterization."
JENNIFER DAVIDS,Aryl hydrocarbon receptor (AhR) agonists suppress Interleukin-6 expression by bone marrow stromal cells: an immunotoxicology study,"BACKGROUND: Bone marrow stromal cells produce cytokines required for the normal growth and development of all eight hematopoietic cell lineages. Aberrant cytokine production by stromal cells contributes to blood cell dyscrasias. Consequently, factors that alter stromal cell cytokine production may significantly compromise the development of normal blood cells. We have shown that environmental chemicals, such as aromatic hydrocarbon receptor (AhR) agonists, suppress B lymphopoiesis by modulating bone marrow stromal cell function. Here, we extend these studies to evaluate the potential for two prototypic AhR agonists, 7,12-dimethylbenz [a]anthracene (DMBA) and 2,3,7,8-tetrachlorodibenzo-p-dioxin (TCDD), to alter stromal cell cytokine responses. METHODS: Bone marrow stromal cells were treated with AhR agonists and bacterial lipopolysaccharide (LPS) to mimic innate inflammatory cytokine responses and to study the effects of AhR ligands on those responses. Steady state cytokine RNA levels were screened by RNAse protection assays (RPA) and quantified by real-time PCR. Cytokine (IL-6) protein production was measured by ELISA. NF-κB EMSAs were used to study IL-6 transcriptional regulation. RESULTS: RPAs indicated that AhR+ bone marrow stromal cells consistently up-regulated genes encoding IL-6 and LIF in response to LPS, presumably through activation of Toll-like receptor 4. Pre-treatment with low doses of DMBA or TCDD selectively abrogated IL-6 gene induction but had no effect on LIF mRNA. Real-time-PCR indicated a significant inhibition of IL-6 mRNA by AhR ligands within 1 hour of LPS challenge which was reflected in a profound down-regulation of IL-6 protein induction, with DMBA and TCDD suppressing IL-6 levels as much as 65% and 88%, respectively. This potent inhibitory effect persisted for at least 72 hours. EMSAs measuring NF-κB binding to IL-6 promoter sequences, an event known to induce IL-6 transcription, indicated a significant decrease in the LPS-mediated induction of DNA-binding RelA/p50 and c-Rel/p50 heterodimers in the presence of DMBA. CONCLUSIONS: Common environmental AhR agonists can suppress the response to bacterial lipopolysaccharide, a model for innate inflammatory responses, through down-regulation of IL-6, a cytokine critical to the growth of several hematopoietic cell subsets, including early B cells. This suppression occurs at least at the level of IL-6 gene transcription and may be regulated by NF-κB."
JENNIFER DAVIDS,"Three red suns in the sky: A transiting, terrestrial planet in a triple M-dwarf system at 6.9 pc","We present the discovery from Transiting Exoplanet Survey Satellite (TESS) data of LTT 1445Ab. At a distance of 6.9 pc, it is the second nearest transiting exoplanet system found to date, and the closest one known for which the primary is an M dwarf. The host stellar system consists of three mid-to-late M dwarfs in a hierarchical configuration, which are blended in one TESS pixel. We use MEarth data and results from the Science Processing Operations Center data validation report to determine that the planet transits the primary star in the system. The planet has a radius of ${1.38}_{-0.12}^{+0.13}$ ${R}_{\oplus }$, an orbital period of ${5.35882}_{-0.00031}^{+0.00030}$ days, and an equilibrium temperature of ${433}_{-27}^{+28}$ K. With radial velocities from the High Accuracy Radial Velocity Planet Searcher, we place a 3σ upper mass limit of 8.4 ${M}_{\oplus }$ on the planet. LTT 1445Ab provides one of the best opportunities to date for the spectroscopic study of the atmosphere of a terrestrial world. We also present a detailed characterization of the host stellar system. We use high-resolution spectroscopy and imaging to rule out the presence of any other close stellar or brown dwarf companions. Nineteen years of photometric monitoring of A and BC indicate a moderate amount of variability, in agreement with that observed in the TESS light-curve data. We derive a preliminary astrometric orbit for the BC pair that reveals an edge-on and eccentric configuration. The presence of a transiting planet in this system hints that the entire system may be co-planar, implying that the system may have formed from the early fragmentation of an individual protostellar core."
JENNIFER DAVIDS,The eighteenth data release of the Sloan Digital Sky Surveys: targeting and first spectra from SDSS-V,"The eighteenth data release (DR18) of the Sloan Digital Sky Survey (SDSS) is the first one for SDSS-V, the fifth generation of the survey. SDSS-V comprises three primary scientific programs or “Mappers”: the Milky Way Mapper (MWM), the Black Hole Mapper (BHM), and the Local Volume Mapper. This data release contains extensive targeting information for the two multiobject spectroscopy programs (MWM and BHM), including input catalogs and selection functions for their numerous scientific objectives. We describe the production of the targeting databases and their calibration and scientifically focused components. DR18 also includes ∼25,000 new SDSS spectra and supplemental information for X-ray sources identified by eROSITA in its eFEDS field. We present updates to some of the SDSS software pipelines and preview changes anticipated for DR19. We also describe three value-added catalogs (VACs) based on SDSS-IV data that have been published since DR17, and one VAC based on the SDSS-V data in the eFEDS field."
JENNIFER DAVIDS,Reproductive inequality in humans and other mammals,"To address claims of human exceptionalism, we determine where humans fit within the greater mammalian distribution of reproductive inequality. We show that humans exhibit lower reproductive skew (i.e., inequality in the number of surviving offspring) among males and smaller sex differences in reproductive skew than most other mammals, while nevertheless falling within the mammalian range. Additionally, female reproductive skew is higher in polygynous human populations than in polygynous nonhumans mammals on average. This patterning of skew can be attributed in part to the prevalence of monogamy in humans compared to the predominance of polygyny in nonhuman mammals, to the limited degree of polygyny in the human societies that practice it, and to the importance of unequally held rival resources to women's fitness. The muted reproductive inequality observed in humans appears to be linked to several unusual characteristics of our species-including high levels of cooperation among males, high dependence on unequally held rival resources, complementarities between maternal and paternal investment, as well as social and legal institutions that enforce monogamous norms."
JENNIFER DAVIDS,"The L 98-59 system: three transiting, terrestrial-size planets orbiting a nearby M dwarf","We report the Transiting Exoplanet Survey Satellite (TESS) discovery of three terrestrial-size planets transiting L 98-59 (TOI-175, TIC 307210830)—a bright M dwarf at a distance of 10.6 pc. Using the Gaia-measured distance and broadband photometry, we find that the host star is an M3 dwarf. Combined with the TESS transits from three sectors, the corresponding stellar parameters yield planet radii ranging from 0.8 R ⊕ to 1.6 R ⊕. All three planets have short orbital periods, ranging from 2.25 to 7.45 days with the outer pair just wide of a 2:1 period resonance. Diagnostic tests produced by the TESS Data Validation Report and the vetting package DAVE rule out common false-positive sources. These analyses, along with dedicated follow-up and the multiplicity of the system, lend confidence that the observed signals are caused by planets transiting L 98-59 and are not associated with other sources in the field. The L 98-59 system is interesting for a number of reasons: the host star is bright (V = 11.7 mag, K = 7.1 mag) and the planets are prime targets for further follow-up observations including precision radial-velocity mass measurements and future transit spectroscopy with the James Webb Space Telescope; the near-resonant configuration makes the system a laboratory to study planetary system dynamical evolution; and three planets of relatively similar size in the same system present an opportunity to study terrestrial planets where other variables (age, metallicity, etc.) can be held constant. L 98-59 will be observed in four more TESS sectors, which will provide a wealth of information on the three currently known planets and have the potential to reveal additional planets in the system."
JENNIFER DAVIDS,"Bostonia: 2000-2001, no. 1-4",
JENNIFER DAVIDS,Exploiting diverse chemical collections to uncover novel antifungals,"The rise in drug resistance amongst pathogenic fungi, paired with the limited arsenal of antifungals available is an imminent threat to our medical system. To address this, we screened two distinct compound libraries to identify novel strategies to expand the antifungal armamentarium. The first collection wasthe RIKEN Natural Product Depository (NPDepo), which was screened for antifungal activity against four major human fungal pathogens: Candida albicans, Candida glabrata, Candida auris, and Cryptococcus neoformans. Through a prioritization pipeline, one compound, NPD6433, emerged as having broad-spectrum antifungal activity and minimal mammalian cytotoxicity. Chemical-genetic and biochemical assays demonstrated that NPD6433 inhibits the essential fungal enzyme fatty acid synthase 1 (Fas1). Treatment with NPD6433 inhibited various virulence traits in C. neoformans and C. auris, and rescued mammalian cell growth in a co-culture model with C. auris. The second compound library screened was adiversity-oriented collectionfrom Boston University. This chemical screen was focused on identifying novel molecules that enhance the activity of the widely deployed antifungal, fluconazole, against C. auris. Through this endeavour, we discovered a potent compound that enhanced fluconazole efficacy against C. auris through increasing azole intracellular accumulation. This activity was dependent on expression of the multidrug transporter geneCDR1, suggesting that this compound targets efflux mechanisms. Furthermore, this molecule significantly reduced fungal burden alone and in combination with fluconazole in a murine model of C. auris disseminated infection. Overall, this work identifies novel compounds with bioactivity against fungal pathogens, revealing important biology, and paving the way for the critical development of therapeutic strategies."
JENNIFER DAVIDS,"O/IR polarimetry for the 2010 decade (CGT): Science at the edge, sharp tools for all",Science opportunities and recommendations concerning optical/infrared polarimetry for the upcoming decade in the field of extragalactic astrophysics. Community-based White Paper to Astro2010 in response to the call for such papers.
JENNIFER DAVIDS,"O/IR polarimetry for the 2010 decade (GAN): Science at the edge, sharp tools for all",Science opportunities and recommendations concerning optical/infrared polarimetry for the upcoming decade in the field of Galactic science. Community-based White Paper to Astro2010 in response to the call for such papers.
JENNIFER DAVIDS,"O/IR polarimetry for the 2010 decade (PSF): Science at the edge, sharp tools for all",Science opportunities and recommendations concerning optical/infrared polarimetry for the upcoming decade in the fields of planetary systems and star formation. Community-based White Paper to Astro2010 in response to the call for such papers.
JENNIFER DAVIDS,"O/IR polarimetry for the 2010 decade (SSE): Science at the edge, sharp tools for all",Science opportunities and recommendations concerning optical/infrared polarimetry for the upcoming decade in the field of extragalactic astrophysics. Community-based White Paper to Astro2010 in response to the call for such papers.
JENNIFER DAVIDS,Understanding polarized foreground from dust: Towards reliable measurements of CMB polarization,Science opportunities and recommendations concerning optical/infrared polarimetry for the upcoming decade in the field of cosmology. Community-based White Paper to Astro2010 in response to the call for such papers.
JENNIFER DAVIDS,The long-baseline neutrino experiment: exploring fundamental symmetries of the universe,"The preponderance of matter over antimatter in the early Universe, the dynamics of the supernova bursts that produced the heavy elements necessary for life and whether protons eventually decay --- these mysteries at the forefront of particle physics and astrophysics are key to understanding the early evolution of our Universe, its current state and its eventual fate. The Long-Baseline Neutrino Experiment (LBNE) represents an extensively developed plan for a world-class experiment dedicated to addressing these questions. LBNE is conceived around three central components: (1) a new, high-intensity neutrino source generated from a megawatt-class proton accelerator at Fermi National Accelerator Laboratory, (2) a near neutrino detector just downstream of the source, and (3) a massive liquid argon time-projection chamber deployed as a far detector deep underground at the Sanford Underground Research Facility. This facility, located at the site of the former Homestake Mine in Lead, South Dakota, is approximately 1,300 km from the neutrino source at Fermilab -- a distance (baseline) that delivers optimal sensitivity to neutrino charge-parity symmetry violation and mass ordering effects. This ambitious yet cost-effective design incorporates scalability and flexibility and can accommodate a variety of upgrades and contributions. With its exceptional combination of experimental configuration, technical capabilities, and potential for transformative discoveries, LBNE promises to be a vital facility for the field of particle physics worldwide, providing physicists from around the globe with opportunities to collaborate in a twenty to thirty year program of exciting science. In this document we provide a comprehensive overview of LBNE's scientific objectives, its place in the landscape of neutrino physics worldwide, the technologies it will incorporate and the capabilities it will possess."
LEAH KRONENBERG,Seeing the Light Part II: the reception of Aratus’s LEPTĒ acrostic in Greek and Latin literature,"Part I of this study argued that Aratus’s decision to base his LEPTĒ acrostic, which occurs during a discussion of moonlight (Phaen. 783-87), on Homer’s LEUKĒ acrostic (Il. 24.1-5) was motivated by the connection in Homer between the adjective λευκός and various types of light from the sky, including the light of dawn, which appears shortly after the acrostic (Il. 24.12), and the light of the moon (Il. 23.455). In Part II, I argue that a study of the reception of Aratus’s acrostic in Greek and Latin poetry reveals that many ancient poets solved the “riddle” of how Aratus’s acrostic relates to Homer’s."
ANDREW LYASOFF,General incomplete-market equilibria in continuous time,"The paper develops the continuous-time (infinite state space) counterpart of the discretetime general incomplete-market equilibrium model due to Dumas and Lyasoff [11]. It is shown that the main conclusions from [11] carry over to the infinite dimensional case: the requirements that all market participants can solve their investment-consumption problems at the optimum, that their individual pricing measures produce identical spot prices for all actively traded streams of stochastic payoffs, and the markets clear, generate the same number of restrictions as there are degrees of freedom in fixing the equilibrium (choice of asset prices, consumption plans, and investment strategies) – regardless of the degree of market incompleteness. Since both “restrictions” and “degrees of freedom” are uncountably infinite in number, the identification of the equilibrium involves a framework that is very different in nature from the one employed in the case of finite economies."
MARGARET LITVIN,Full of noises: when “World Shakespeare” met the “Arab Spring”,"In summer 2012, to coincide with the Olympic Games, the United Kingdom celebrated a summer of Shakespeare. Troupes from around the world were invited to produce their own versions of plays from the playwright's corpus. 2012 was also a very eventful year, politically, in the Arab world, as people reacted to what had been dubbed the “Arab Spring”. This article looks at three plays produced by Arabic companies for the World Shakespeare Festival: the Palestinian Ashtar Theatre's Richard II, the Iraqi Theatre Company's Romeo and Juliet in Baghdad, and the Tunisian Artistes Producteurs Associés’ Macbeth: Leila and Ben – A Bloody History. Using these performances, this article examines how different Arabic theatre troupes negotiate expectations of different audiences as well as their own artistic aims using the “playable surface” of Shakespeare's plays."
MARGARET LITVIN,Syrian theatre in Berlin,
MARGARET LITVIN,"Hamlet Globe to Globe: two years, 190,000 miles, 197 countries, one play",
MARGARET LITVIN,Arab Shakespeares at the World Shakespeare Congress,"Why and how do contemporary theatre practitioners from across ‘the Arab world’—a misleadingly simple shorthand for a vast, diverse, and rapidly changing region of the globe—adapt and perform Shakespeare? On Friday the 5th of August in the Great Hall of King’s College London, the 2016 World Shakespeare Congress’s ‘Arab Shakespeares’ panel convened to analyse the significance, the challenges, and the creative innovations of translations, appropriations, and productions of Shakespeare’s works in the Middle East, North Africa, and the Arabian Peninsula. The panel provided a lively set of perspectives on the myriad ways in which Shakespeare is currently being re-cast, re-set, and re-created in the Arab World."
TIMOTHY CALLAGHAN,The multiple hit hypothesis for Gulf War illness: self-reported chemical/biological weapons exposure and mild traumatic brain injury,"The Gulf War Illness Consortium (GWIC) was designed to identify objective biomarkers of Gulf War Illness (GWI) in 1991 Gulf War veterans. The symptoms of GWI include fatigue, pain, cognitive problems, gastrointestinal, respiratory, and skin problems. Neurotoxicant exposures during deployment, such as pesticides, sarin, and pyridostigmine bromide pills have been identified as contributors to GWI. We have also found an association between mild traumatic brain injury (mTBI) and increased rates of GWI. However, the combined impact of these physical and chemical exposures has not yet been explored in GWI. The objective of this study was to examine both self-reported mTBI and exposure to chemical/biological weapons (CBW) as a multiple or two hit model for increased risk of GWI and other chronic health conditions. The study population included 125 Gulf War (GW) veterans from the Boston GWIC. Exposure to CBW was reported in 47.2% of the study population, and 35.2% reported sustaining a mTBI during the war. Results confirmed that those with both exposures (mTBI and CBW) had higher rates of comorbid chronic health conditions while rates of GWI were equivalent for mTBI and CBW or mTBI alone. The timing of exposure to mTBI was found to be strikingly different between those with GWI and those without it. Correspondingly, 42.3% of GWI cases reported experiencing a mTBI during military service while none of the controls did (p = 0.0002). Rates of mTBI before and after the war did not differ between the cases and controls. In addition, 54% of cases compared to 14.3% of controls (p = <0.001) reported being exposed to CBW during military service. The current study examined the relation of the separate and combined effects of exposure to mTBI and CBW in 1991 GW veterans. The findings from this study suggest that both exposure to mTBI and CBW are associated with the development of GWI and multiple chronic health conditions and that combined exposure appears to lead to higher risk of chronic health effects."
MILOS POPOVIC,Laser module for optical data communication system,"A laser module includes a laser source and an optical marshalling module. The laser source is configured to generate and output a plurality of laser beams. The plurality of laser beams have different wavelengths relative to each other. The different wavelengths are distinguishable to an optical data communication system. The optical marshalling module is configured to receive the plurality of laser beams from the laser source and distribute a portion of each of the plurality of laser beams to each of a plurality of optical output ports of the optical marshalling module, such that all of the different wavelengths of the plurality of laser beams are provided to each of the plurality of optical output ports of the optical marshalling module. An optical amplifying module can be included to amplify laser light output from the optical marshalling module and provide the amplified laser light as output from the laser module."
MILOS POPOVIC,In-situ photonic circuit field characterization in electronics-photonics CMOS platform via backside flip-chip near-field scanning optical microscopy,We demonstrate device field characterization using NSOM collection and interaction measurement modes via the backside buried-oxide of large scale photonic circuits fabricated in monolithic electronics-photonics CMOS platforms (here a microdisk resonator) post-processed using flip-chip substrate-removal.
MILOS POPOVIC,"Sub-decibel efficiency, bi-layer, O-band fiber-to-chip grating coupler demonstrated in a 45 nm CMOS foundry platform","We demonstrate a grating coupler with 0.85 dB fiber-to-chip coupling loss in the O-band (1,300 nm), implemented in a 45 nm CMOS foundry platform."
MILOS POPOVIC,Toward quantum electronic-photonic systems-on-chip: a monolithic source of quantum-correlated photons with integrated frequency locking electronics and pump rejection,"We demonstrate a CMOS electronic-photonic photon-pair source with integrated feedback-controlled frequency locking, >80 dB on-chip pump rejection, and signal/idler demultiplexing, achieving a CAR of ≃5 at ≃40 ccps pair rate."
MILOS POPOVIC,Fast-tuning adiabatic microrings for CROW filters and athermal WDM receivers in a 45 nm SOI CMOS process,"Adiabatic microrings with opposing p/n contacts achieve full carrier sweepout in reverse bias and energy-efficient carrier injection in forward bias, exhibiting 200GHz/V peak shift in C-band for athermal tuning over a 220 GHz range."
MILOS POPOVIC,Electronic-photonic quantum systems-on-chip,"We present progress towards realizing electronic-photonic quantum systems on-chip; particularly, entangled photon-pair sources, placing them in the context of previous work, and outlining our vision for mass-producible quantum networking blocks."
MILOS POPOVIC,Monolithically integrated high-order vernier filters and tuning circuits for electronic-photonic quantum system-on-chip,"We demonstrate a monolithically integrated 6th-order filter, with heater driver circuits implemented alongside photonics in a zero-change 45 nm CMOS platform, achieving <1 dB drop loss and >80 dB on-chip pump power suppression."
MILOS POPOVIC,Photon-Pair Generation in a 45 nm CMOS Microring Cavity: Impact of Spontaneous Raman Scattering,We characterize the impact of spontaneous Raman scattering (SRS) on photon-pair generation via spontaneous four-wave mixing (SFWM) in a CMOS microring cavity by analyzing the single counts in each channel to separate out the contribution of SRS from SFWM. We find the contribution of SRS to the photon counts to be low compared to that from SFWM.
MILOS POPOVIC,Reflectionless standing-wave operation in microring resonators,We demonstrate a scheme for microring resonators to operate as standing-wave resonators while eliminating reflections and maintaining traveling-wave-resonator-like p-n junction microring modulators to achieve higher performance than other junction geometries.
MILOS POPOVIC,Silicon waveguides and resonators with sub-0.1 dB/cm propagation loss and over 7 million Q in a foundry process,Propagation loss is characterized vs. waveguide width in a 220 nm silicon photonics foundry platform to form a compact model. Test paperclips and racetrack resonators with quality factors up to 7.6 million reveal losses as low as 0.064 dB/cm.
MILOS POPOVIC,"Can one critically couple to a multimode, coupled-cavity finite equispaced comb resonator?","A finite-equispaced-comb resonator based on N “Kac-matrix” coupled cavities could be an important photonic building block. To maximally excite all comblines: there’s a best cavity to couple to the bus waveguide; and, we “critically couple” the geometric mean of the supermode escape rates."
MILOS POPOVIC,Tunable source of quantum-correlated photons with integrated pump rejection in a silicon CMOS platform,"A wavelength-tunable, silicon photon-pair source based on spontaneous four-wave mixing, integrated with a pump rejection filter in a single, flip-chip packaged CMOS chip, is demonstrated with a coincidence-to-accidentals ratio of 9.1 with no off-chip pump filtering."
MILOS POPOVIC,Polarization-Insensitive one-dimensional grating coupler demonstrated in a CMOS-photonics foundry platform,"We demonstrate a one-dimensional dual polarization fiber-to-chip grating coupler implemented in a CMOS-photonics foundry platform, with a measured 1 dB polarization-dependent loss bandwidth of 70 nm in the O-band."
MILOS POPOVIC,Broadband repeatable <0.025 dB average loss rapid adiabatic based 3-dB coupler in a 45 nm SOI CMOS process,We demonstrate a 75 µm-long rapid adiabatic coupler (RAC) with an average insertion loss <0.025 dB/coupler and an average power splitting ratio of 50±1.09% over 40 nm bandwidth and 68 reticles across a 300 mm 45 nm SOI CMOS wafer.
MILOS POPOVIC,"Photonic molecule electro-optic modulators for efficient, widely tunable RF sideband generation and wavelength conversion",We propose photonic molecule electro-optic modulators with tunable supermode splitting for efficient widely tunable RF sideband generation. Using an auxiliary tunable off-resonant cavity as a variable coupler maintains a high Q/V.
MILOS POPOVIC,Dispersion-compensated microring photon pair source design with configurable purity–pair rate–heralding efficiency tradeoff,"We present a Si microring-based photon pair source design with tailored pump/signal/idler escape rates allowing configurable purity-rate-heralding tradeoffs, while maintaining efficiency through tunable dispersion compensation. We validate the subcomponents using stimulated FWM experiments."
MILOS POPOVIC,"Rapid adiabatic 3 dB coupler with 50±1% splitting over 200 nm including S, C and L bands in 45 nm CMOS platform",We demonstrate a 70 µm-long silicon rapid adiabatic coupler (RAC) with <0.07 dB insertion loss over 50 nm and power splitting ratio 50 ± 1% over 200 nm bandwidth fabricated in the commercial 45RF ‘zero change’ CMOS electronics-photonics platform.
MILOS POPOVIC,Frequency translating add/drop filters based on electro-optically modulated photonic molecules,"We demonstrate a new category of optical add-drop filters, with a frequency- translated drop-port response. Comprising modulated coupled resonators, they support Butter- worth, Chebyshev and other passband shapes typical to linear high-order filters."
MILOS POPOVIC,Finite line-number equi-spaced resonances based on coupled cavity resonators,We investigate a linear configuration of coupled cavity resonators based on tri-diagonal Kac matrix which enables such cavities to support finite equi-spaced comb of resonances. Such resonator may allow designing cavities which decouple cavity size from comb spacings.
MILOS POPOVIC,Photonic resonators with microring-like behavior based on standing wave cavity pairs with opposite-symmetry modes,
MILOS POPOVIC,Polarization insensitive grating coupler based on a zero-birefringence corelet waveguide,
MILOS POPOVIC,Toward hybrid integration of exotic materials in an electronic-photonic CMOS platform via substrate removal,"We demonstrate direct access to the silicon device layer of a monolithic CMOS electronics-photonics platform with a full-digital back-end-metal stack, in post-fabrication at die level, allowing the integration of functional materials (e.g. into slot waveguides)."
MILOS POPOVIC,Electronic-photonic millimeter-wave sensing element based on monolithically integrated LNA and triple-cavity ring modulator,"We demonstrate CMOS-integrated mm-wave-to-optical sensing elements comprising LNAs and triple-ring modulators that break the conversion-bandwidth tradeoff, showing a projected noise figure of 24 dB at 57 GHz (30 mW/element, -45dBm RF-input, 6dBm laser LO). The elements are tileable at small pitches, enabling photonic disaggregation of large-scale phased arrays."
MILOS POPOVIC,A monolithically integrated electronic-photonic front-end utilizing micro-ring modulators for large-scale mm-wave sensing,
MILOS POPOVIC,Passband shapes that minimize the insertion loss and bandwidth of coupled-resonator bandpass filters,We use a general theory to show a new class of bandpass filter shapes for coupled-resonator filters that provides the lowest insertion loss and the narrowest bandwidth achievable for a given intrinsic Q and bandwidth.
MILOS POPOVIC,Thermal crosstalk rejection for scaling quantum-photonic systems-on-chip with monolithically integrated electronics,We demonstrate integrated feedback control of a C-band microring quantum-correlated photon-pair source fabricated in a monolithic electronics-photonics platform that maintains lock in the presence of nearby on-die thermal disturbances.
JOANNA DAVIDSON,Multidisciplinary approaches to research on bullying in adolescence,"Bullying is a significant public health problem in the United States that affects youth functioning in multiple domains. Much of the research on bullying to date has focused on children, however, leaving gaps in the literature with respect to understanding bullying among adolescents. In particular, less is known about how adolescents conceptualize bullying, what predicts and is associated with bullying involvement among adolescents, and how prevention programs might address the unique needs of middle and high school students. This special issue proposes that a multidisciplinary perspective might be particularly useful in better understanding bullying among adolescents and determining how to design more effective interventions and prevention programs for this age-group. The current article introduces the special issue by briefly discussing what is known about bullying in adolescence and considering three disciplines (computer science, big data, and virtual communities; media studies; anthropology) that are particularly well situated to move the field forward. Next, this article reviews teen pregnancy prevention efforts, as an example of another adolescent public health concern that has been addressed successfully using a multidisciplinary approach. The article concludes with an overview of the three manuscripts that are part of the special issue."
JOANNA DAVIDSON,"Cultivating Knowledge: Development, Dissemblance, and Discursive Contradictions among the Diola of Guinea-Bissau","Development practitioners are eager to “learn from farmers” in their efforts to address Africa’s deteriorating agricultural output. But many agrarian groups, such as Diola wet rice cultivators of Guinea-Bissau, have well-established norms that regulate the circulation of knowledge—whether about agriculture, household economy, or day-to-day activities. By exploring how Diola manage information about the natural and supranatural world and exercise evasion and restraint in quotidian interaction, this article problematizes the assumptions that knowledge is an extractable resource; that more knowledge is better; and that democratized knowledge leads to progress. It considers how the Diola tendency to circumscribe information both challenges external development objectives and contours the ways Diola themselves confront their declining economic conditions."
JOANNA DAVIDSON,Basket Cases and Breadbaskets: Sacred Rice and Agricultural Development in Postcolonial Africa,"Based on ethnographic research among rural Diola in Guinea-Bissau, I provide a broad view of the history and interpenetration of rice in social, political, religious, and ecological domains, while chronicling the current difficulties of residents in this region who are no longer able to grown enough of it. These farmers’ experiences are unfolding at a time of revitalized attention to agricultural development in Africa, particularly under the auspices of the New Green Revolution for Africa. I examine the premises that constitute the resuscitated effort to address the plight of African farmers. I argue that the totalizing quality of rice in Diola and other rice-cultivating societies requires a development approach that takes into account dimensions of agrarian life not encapsulated by the high- modernist and anti-political orientation of the New Green Revolution for Africa."
JOANNA DAVIDSON,"Native Birth: Identity and Territory in Postcolonial Guinea-Bissau, West Africa",
